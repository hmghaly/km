{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hmghaly/km/blob/main/robin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi8TGgVz5Sj6",
        "outputId": "54d5ba5c-75ac-438e-a6c7-6da1af4ad461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "cwd='/content/drive/MyDrive/stocks' #directory where we keep the data\n",
        "os.chdir(cwd)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdwI-JNg-0Fu"
      },
      "source": [
        "#Installing and using robinhood library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXQ8p5AIjtRc",
        "outputId": "83f0e843-ae89-4967-edbc-971188482f27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting robin_stocks\n",
            "  Downloading robin_stocks-2.1.0-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting cryptography\n",
            "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 49.0 MB/s \n",
            "\u001b[?25hCollecting python-dotenv\n",
            "  Downloading python_dotenv-0.19.2-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from robin_stocks) (2.27.1)\n",
            "Collecting pyotp\n",
            "  Downloading pyotp-2.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->robin_stocks) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->robin_stocks) (2.21)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->robin_stocks) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->robin_stocks) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->robin_stocks) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->robin_stocks) (1.24.3)\n",
            "Installing collected packages: python-dotenv, pyotp, cryptography, robin-stocks\n",
            "Successfully installed cryptography-36.0.1 pyotp-2.6.0 python-dotenv-0.19.2 robin-stocks-2.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install robin_stocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UU581VejwWp",
        "outputId": "e1627139-099d-444f-e70b-37da76bbeb68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'robin_stocks'...\n",
            "remote: Enumerating objects: 2518, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 2518 (delta 18), reused 15 (delta 6), pack-reused 2484\u001b[K\n",
            "Receiving objects: 100% (2518/2518), 8.20 MiB | 10.64 MiB/s, done.\n",
            "Resolving deltas: 100% (1650/1650), done.\n"
          ]
        }
      ],
      "source": [
        "import os, shutil\n",
        "robin_dir=os.path.join(cwd,\"robin_stocks\")\n",
        "if os.path.exists(robin_dir): shutil.rmtree(robin_dir)\n",
        "!git clone https://github.com/jmfernandes/robin_stocks.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnIc4RVmj8Sy",
        "outputId": "4b59d93a-b9ce-4e38-a20b-34df156cc4cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/stocks/robin_stocks\n"
          ]
        }
      ],
      "source": [
        "cd robin_stocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm9Hg-lFkCdr",
        "outputId": "77cdf56b-c923-435a-8932-dc1c169ceba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing /content/drive/MyDrive/stocks/robin_stocks\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from robin-stocks==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: pyotp in /usr/local/lib/python3.7/dist-packages (from robin-stocks==2.1.0) (2.6.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.7/dist-packages (from robin-stocks==2.1.0) (0.19.2)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.7/dist-packages (from robin-stocks==2.1.0) (36.0.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->robin-stocks==2.1.0) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->robin-stocks==2.1.0) (2.21)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->robin-stocks==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->robin-stocks==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->robin-stocks==2.1.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->robin-stocks==2.1.0) (2.10)\n",
            "Building wheels for collected packages: robin-stocks\n",
            "  Building wheel for robin-stocks (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for robin-stocks: filename=robin_stocks-2.1.0-py3-none-any.whl size=70671 sha256=0cd428680d4e3ad01cea7df3a0d16070d9f3987e398cb313eb9d6088554093fc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8g_84yr3/wheels/3d/a6/8c/a1e816ea9fa3c6160f36296f05b6995fe8b2d0f1d201390ecc\n",
            "Successfully built robin-stocks\n",
            "Installing collected packages: robin-stocks\n",
            "  Attempting uninstall: robin-stocks\n",
            "    Found existing installation: robin-stocks 2.1.0\n",
            "    Uninstalling robin-stocks-2.1.0:\n",
            "      Successfully uninstalled robin-stocks-2.1.0\n",
            "Successfully installed robin-stocks-2.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vIz0zEv5vOX"
      },
      "outputs": [],
      "source": [
        "#we should set the environ variables first\n",
        "!export robinhood_username=\"\"\n",
        "!export robinhood_password=\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27x6Uj4DkHsC",
        "outputId": "cd85952e-af5f-4b3c-eac5-e75ffb536893"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Robinhood username: hmghaly@gmail.com\n",
            "Robinhood password: ··········\n",
            "Enter Robinhood code for validation: 932127\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'access_token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJleHAiOjE2NDc1NDIzNjksInRva2VuIjoiNnM2S2s3RXBDb1lDTFdpelc3QlRsaTdXdE1keXFmIiwidXNlcl9pZCI6IjY1NDcxZTU3LWE3NmYtNGU3Yy1hMWM3LWY5Nzc2NzMyNjkwNCIsImRldmljZV9oYXNoIjoiNzgxNzE5OGNhZGUwNjMzMjgxNWJiOTBhMDUwNmRlNWQiLCJzY29wZSI6ImludGVybmFsIiwiZGN0IjoxNjQ2NzY3Mzg5LCJzZXJ2aWNlX3JlY29yZHMiOlt7ImhhbHRlZCI6ZmFsc2UsInNlcnZpY2UiOiJudW1tdXNfdXMiLCJzaGFyZF9pZCI6MSwic3RhdGUiOiJhdmFpbGFibGUifSx7ImhhbHRlZCI6ZmFsc2UsInNlcnZpY2UiOiJicm9rZWJhY2tfdXMiLCJzaGFyZF9pZCI6OSwic3RhdGUiOiJhdmFpbGFibGUifV0sInVzZXJfb3JpZ2luIjoiVVMiLCJvcHRpb25zIjpmYWxzZSwibGV2ZWwyX2FjY2VzcyI6ZmFsc2V9.jfZjc7R8NnH_KRAugYiyF4F1yfJiiwsfU1wMpfVcLdVIEKe5fGKnavJhi314byqV_e2wjMpUf0m_NqsgEZHMeJ3iHJ9g-MHfu1Qe5KPEHQw7JhgBfg6dpiSgz4G0VZm46FXqXEh62RnQ5SoUMPnT4LFmJtzmUDoOdZK64J2umBXgr2v-HOk_716WcKEbr272yicTNFqm4i2y735H2jd0XUOirgUdMl14Bc7QsTsHggGWkwXPq2sMJ_tWlrjZgRM5otnV1Zipky5Sgse3m_Eg8d6gAyoA84RH4hSZA-bBfdxXNAdDwo4N2jNDbChN9Ly00j3SwfdaHmLWe89tVgp2TQ',\n",
              " 'backup_code': None,\n",
              " 'detail': 'logged in with brand new authentication code.',\n",
              " 'expires_in': 778566,\n",
              " 'mfa_code': None,\n",
              " 'refresh_token': 's0Z6u39QS1GcNZKhDMzdDapHwTSbmQ',\n",
              " 'scope': 'internal',\n",
              " 'token_type': 'Bearer'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import robin_stocks as rs\n",
        "import os \n",
        "\n",
        "robin_user = os.environ.get(\"robinhood_username\")\n",
        "robin_pass = os.environ.get(\"robinhood_password\") #ss!\n",
        "#rs.robinhood.l\n",
        "rs.robinhood.login(username=robin_user,\n",
        "         password=robin_pass,\n",
        "         expiresIn=86400,\n",
        "         by_sms=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jNL3cgaMhes",
        "outputId": "8f8debd0-e920-4e8a-a410-1547e84dde06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "364\n"
          ]
        }
      ],
      "source": [
        "#dropbox_data = rs.stocks.get_stock_historicals([\"GOOG\"], interval=\"hour\", span=\"week\")\n",
        "dropbox_data = rs.robinhood.stocks.get_stock_historicals([\"GOOG\"], interval=\"hour\", span=\"3month\")\n",
        "#dropbox_data = rs.stocks.get_stock_historicals()\n",
        "dropbox_data[:10]\n",
        "print(len(dropbox_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pek5SfrNl-E",
        "outputId": "dba38d09-a922-469c-abc3-7db2671d7bae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "symbol STWD quantity 14.26504800\n",
            "average_buy_price: 14.0203 current price: 19.09\n",
            "created_at: 2020-10-29T14:12:53.010228Z\n",
            "----\n",
            "symbol IPDN quantity 60.00000000\n",
            "average_buy_price: 1.5898 current price: 1.6\n",
            "created_at: 2020-11-23T19:48:35.597659Z\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "#check the account and the current stock positions\n",
        "import requests\n",
        "\n",
        "\n",
        "#dir(rs.orders.stocks.urls)\n",
        "#rs.profiles.load_basic_profile()\n",
        "#rs.profiles.load_portfolio_profile()\n",
        "#rs.profiles.load_investment_profile()\n",
        "#rs.profiles.load_user_profile()\n",
        "#rs.account.get_all_positions()\n",
        "positions=[rs.account.get_open_stock_positions()]\n",
        "for p0 in positions[0]:\n",
        "  stock_url=p0[\"instrument\"]\n",
        "  average_buy_price=p0[\"average_buy_price\"]\n",
        "  quantity=p0[\"quantity\"]\n",
        "  created_at=p0[\"created_at\"]\n",
        "  res=requests.get(stock_url)\n",
        "  stock_dict=res.json()\n",
        "  symbol=stock_dict[\"symbol\"]\n",
        "  price=float(rs.stocks.get_latest_price(symbol)[0])\n",
        "  print(\"symbol\",symbol,\"quantity\",quantity)\n",
        "  print(\"average_buy_price:\", average_buy_price,\"current price:\",price)\n",
        "  print(\"created_at:\",created_at)\n",
        "  #print(p0)\n",
        "  print(\"----\")\n",
        "#print(len(positions[0]))\n",
        "#requests.get\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVdw3CcYLkAO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(cwd)\n",
        "from time import sleep\n",
        "import json\n",
        "data_dir=os.path.join(cwd,\"data\")\n",
        "if not os.path.exists(data_dir): os.makedirs(data_dir)\n",
        "fopen=open(\"stock_symbols.txt\")\n",
        "symbols=fopen.read().split(\"\\n\")\n",
        "fopen.close()\n",
        "#print(len(symbols),symbols[:10])\n",
        "for i,sym in enumerate(symbols):\n",
        "  #cur_symbols=symbols[i*50:(i+1)*50]\n",
        "  \n",
        "  company_fname=\"%s.json\"%sym\n",
        "  company_fpath=os.path.join(data_dir,company_fname)\n",
        "  if os.path.exists(company_fpath): \n",
        "    company_fopen=open(company_fpath)\n",
        "    content=company_fopen.read()\n",
        "    company_fopen.close()\n",
        "    if content==\"\": content_list=[]\n",
        "    else: content_list=json.loads(content)\n",
        "    \n",
        "    \n",
        "    historical_data= rs.stocks.get_stock_historicals([sym], interval=\"hour\", span=\"3month\")\n",
        "    for item in historical_data:\n",
        "      if not item in content_list: content_list.append(item)\n",
        "      #if item in content_list:print(\">>>> found\",item)\n",
        "      #else:print(\"???? NOT found\",item)\n",
        "\n",
        "    #print(len(historical_data))\n",
        "    \n",
        "  #if os.path.exists(company_fpath): continue #we should use this to update the data\n",
        "\n",
        "  print(sym,len(content_list))\n",
        "\n",
        "  #historical_data= rs.stocks.get_stock_historicals([sym], interval=\"hour\", span=\"3month\")\n",
        "  company_fopen=open(company_fpath,\"w\")\n",
        "  #company_fopen.write(json.dumps(historical_data))\n",
        "  company_fopen.write(json.dumps(content_list))\n",
        "  \n",
        "  company_fopen.close()\n",
        "  # print(len(historical_data))\n",
        "  # print(historical_data[0])\n",
        "  # print(\"--------\")\n",
        "  sleep(0.2)\n",
        "  if i%10==0: print(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYap4UccgufB"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "data_dir=os.path.join(cwd,\"data\")\n",
        "files=os.listdir(data_dir)\n",
        "print(len(files))\n",
        "tmp_list=[]\n",
        "for fname in files[:400]:\n",
        "  fpath=os.path.join(data_dir,fname)\n",
        "  fopen=open(fpath)\n",
        "  content_list=json.loads(fopen.read())\n",
        "  fopen.close()\n",
        "  low_high_close_prices=[(float(v[\"high_price\"]),float(v[\"low_price\"]),float(v[\"close_price\"])) for v in content_list]\n",
        "  high_prices=[float(v[\"high_price\"]) for v in content_list]\n",
        "  tmp_list.append(high_prices)\n",
        "  print(len(content_list))\n",
        "  print(content_list[0])\n",
        "  print(high_prices)\n",
        "  print(\"---\")\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeY1A7TxkaBL",
        "outputId": "25ef960d-2190-4b4b-dc31-3f5f92a7def8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input tensor shape torch.Size([1, 100])\n",
            "output tensor shape torch.Size([1, 10])\n",
            "epoch number: 0\n",
            "training loss: tensor(1.0923, grad_fn=<AddBackward0>) dev_loss tensor(0.8226, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 1\n",
            "training loss: tensor(0.9994, grad_fn=<AddBackward0>) dev_loss tensor(0.7777, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 2\n",
            "training loss: tensor(0.9134, grad_fn=<AddBackward0>) dev_loss tensor(0.7364, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 3\n",
            "training loss: tensor(0.8337, grad_fn=<AddBackward0>) dev_loss tensor(0.6983, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 4\n",
            "training loss: tensor(0.7596, grad_fn=<AddBackward0>) dev_loss tensor(0.6629, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 5\n",
            "training loss: tensor(0.6906, grad_fn=<AddBackward0>) dev_loss tensor(0.6301, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 6\n",
            "training loss: tensor(0.6265, grad_fn=<AddBackward0>) dev_loss tensor(0.5998, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 7\n",
            "training loss: tensor(0.5670, grad_fn=<AddBackward0>) dev_loss tensor(0.5719, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 8\n",
            "training loss: tensor(0.5119, grad_fn=<AddBackward0>) dev_loss tensor(0.5464, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 9\n",
            "training loss: tensor(0.4611, grad_fn=<AddBackward0>) dev_loss tensor(0.5231, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 10\n",
            "training loss: tensor(0.4145, grad_fn=<AddBackward0>) dev_loss tensor(0.5022, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 11\n",
            "training loss: tensor(0.3719, grad_fn=<AddBackward0>) dev_loss tensor(0.4835, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 12\n",
            "training loss: tensor(0.3334, grad_fn=<AddBackward0>) dev_loss tensor(0.4670, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 13\n",
            "training loss: tensor(0.2987, grad_fn=<AddBackward0>) dev_loss tensor(0.4528, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 14\n",
            "training loss: tensor(0.2678, grad_fn=<AddBackward0>) dev_loss tensor(0.4407, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 15\n",
            "training loss: tensor(0.2405, grad_fn=<AddBackward0>) dev_loss tensor(0.4307, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 16\n",
            "training loss: tensor(0.2168, grad_fn=<AddBackward0>) dev_loss tensor(0.4226, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 17\n",
            "training loss: tensor(0.1964, grad_fn=<AddBackward0>) dev_loss tensor(0.4163, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 18\n",
            "training loss: tensor(0.1791, grad_fn=<AddBackward0>) dev_loss tensor(0.4117, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 19\n",
            "training loss: tensor(0.1646, grad_fn=<AddBackward0>) dev_loss tensor(0.4085, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 20\n",
            "training loss: tensor(0.1527, grad_fn=<AddBackward0>) dev_loss tensor(0.4064, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 21\n",
            "training loss: tensor(0.1430, grad_fn=<AddBackward0>) dev_loss tensor(0.4053, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 22\n",
            "training loss: tensor(0.1353, grad_fn=<AddBackward0>) dev_loss tensor(0.4049, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 23\n",
            "training loss: tensor(0.1292, grad_fn=<AddBackward0>) dev_loss tensor(0.4049, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 24\n",
            "training loss: tensor(0.1245, grad_fn=<AddBackward0>) dev_loss tensor(0.4053, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 25\n",
            "training loss: tensor(0.1209, grad_fn=<AddBackward0>) dev_loss tensor(0.4058, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 26\n",
            "training loss: tensor(0.1182, grad_fn=<AddBackward0>) dev_loss tensor(0.4064, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 27\n",
            "training loss: tensor(0.1161, grad_fn=<AddBackward0>) dev_loss tensor(0.4069, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 28\n",
            "training loss: tensor(0.1145, grad_fn=<AddBackward0>) dev_loss tensor(0.4074, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 29\n",
            "training loss: tensor(0.1134, grad_fn=<AddBackward0>) dev_loss tensor(0.4078, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 30\n",
            "training loss: tensor(0.1125, grad_fn=<AddBackward0>) dev_loss tensor(0.4080, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 31\n",
            "training loss: tensor(0.1118, grad_fn=<AddBackward0>) dev_loss tensor(0.4083, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 32\n",
            "training loss: tensor(0.1113, grad_fn=<AddBackward0>) dev_loss tensor(0.4084, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 33\n",
            "training loss: tensor(0.1109, grad_fn=<AddBackward0>) dev_loss tensor(0.4085, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 34\n",
            "training loss: tensor(0.1106, grad_fn=<AddBackward0>) dev_loss tensor(0.4086, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 35\n",
            "training loss: tensor(0.1104, grad_fn=<AddBackward0>) dev_loss tensor(0.4087, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 36\n",
            "training loss: tensor(0.1102, grad_fn=<AddBackward0>) dev_loss tensor(0.4087, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 37\n",
            "training loss: tensor(0.1101, grad_fn=<AddBackward0>) dev_loss tensor(0.4087, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 38\n",
            "training loss: tensor(0.1100, grad_fn=<AddBackward0>) dev_loss tensor(0.4087, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 39\n",
            "training loss: tensor(0.1099, grad_fn=<AddBackward0>) dev_loss tensor(0.4088, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 40\n",
            "training loss: tensor(0.1098, grad_fn=<AddBackward0>) dev_loss tensor(0.4088, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 41\n",
            "training loss: tensor(0.1097, grad_fn=<AddBackward0>) dev_loss tensor(0.4088, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 42\n",
            "training loss: tensor(0.1097, grad_fn=<AddBackward0>) dev_loss tensor(0.4088, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 43\n",
            "training loss: tensor(0.1096, grad_fn=<AddBackward0>) dev_loss tensor(0.4089, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 44\n",
            "training loss: tensor(0.1096, grad_fn=<AddBackward0>) dev_loss tensor(0.4089, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 45\n",
            "training loss: tensor(0.1096, grad_fn=<AddBackward0>) dev_loss tensor(0.4089, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 46\n",
            "training loss: tensor(0.1095, grad_fn=<AddBackward0>) dev_loss tensor(0.4089, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 47\n",
            "training loss: tensor(0.1095, grad_fn=<AddBackward0>) dev_loss tensor(0.4090, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 48\n",
            "training loss: tensor(0.1095, grad_fn=<AddBackward0>) dev_loss tensor(0.4090, grad_fn=<AddBackward0>)\n",
            "========\n",
            "epoch number: 49\n",
            "training loss: tensor(0.1094, grad_fn=<AddBackward0>) dev_loss tensor(0.4090, grad_fn=<AddBackward0>)\n",
            "========\n"
          ]
        }
      ],
      "source": [
        "#Let's build the network - here is a small cheat sheet for possible RNN classes based on input and output size\n",
        "#https://github.com/hmghaly/rnn/blob/master/classes.py\n",
        "\n",
        "#here the size of the output is the same as the size of the input\n",
        "#the depth of the output depends on the number of possible outcome categories (e.g. different phonemes)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import random\n",
        "\n",
        "torch.manual_seed(1)\n",
        "random.seed(1)\n",
        "class RNN(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_depth,number_layers,batch_size=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.batch_size=batch_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size,number_layers) #from input to hidden\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2out = nn.Linear(hidden_size, output_depth) #from hidden to output\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def forward(self, feature_list): #list of features for each data point\n",
        "        lstm_out, _ = self.lstm( feature_list.view(len( feature_list), 1, -1))\n",
        "        tag_space = self.hidden2out(lstm_out.view(len( feature_list), -1))\n",
        "        #print(tag_space.view([1,1,1]))\n",
        "        tag_scores = torch.sigmoid(tag_space)\n",
        "        #tag_scores = torch.softmax(tag_space)\n",
        "\n",
        "        #return tag_scores\n",
        "        return tag_space\n",
        "       \n",
        "    def init_hidden(self):\n",
        "        return (torch.zeros(1, self.batch_size, self.hidden_size),\n",
        "                torch.zeros(1, self.batch_size, self.hidden_size))  \n",
        "\n",
        "n_input=100\n",
        "n_hidden =64\n",
        "n_layers=2\n",
        "depth=10\n",
        "\n",
        "models_dir=os.path.join(cwd,\"models\")\n",
        "if not os.path.exists(models_dir): os.makedirs(models_dir)\n",
        "model_prefix=\"model\"\n",
        "\n",
        "sample_size=n_input+depth #how many points for the input and prediction\n",
        "\n",
        "rnn = RNN(n_input, n_hidden, depth,n_layers)\n",
        "\n",
        "#n_data_points=len(tmp_list)\n",
        "n_data_points=1\n",
        "input_tensor=torch.rand((n_data_points, n_input))\n",
        "output = rnn(input_tensor)\n",
        "print(\"input tensor shape\", input_tensor.shape)\n",
        "#print(output)\n",
        "print(\"output tensor shape\", output.shape)\n",
        "\n",
        "loss_func = nn.MSELoss()\n",
        "#loss_func = nn.MSELoss()\n",
        "#loss_func = F.nll_loss()\n",
        "\n",
        "LR=0.000005\n",
        "#LR=0.05\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
        "\n",
        "train_size=int(len(tmp_list[0])*0.75)\n",
        "full_size=len(tmp_list[0])\n",
        "\n",
        "for e0 in range(50):\n",
        "  print(\"epoch number:\",e0)\n",
        "  training_loss=0\n",
        "  for i in range(0,train_size-sample_size):\n",
        "    #print(i)\n",
        "    rnn.hidden = rnn.init_hidden()\n",
        "    rnn.zero_grad()  \n",
        "\n",
        "    for tm in tmp_list:\n",
        "      input_list=[]\n",
        "      output_list=[]\n",
        "      raw_input_slice=tm[i:i+n_input]\n",
        "      val0=raw_input_slice[-1]\n",
        "      input_slice=[(v-val0)/val0 for v in raw_input_slice]\n",
        "      input_list.append(input_slice)\n",
        "      raw_output_slice=tm[i+n_input:i+sample_size]\n",
        "      \n",
        "      \n",
        "      output_slice=[(v-val0)/val0 for v in raw_output_slice]\n",
        "      # print(\"input:\", input_slice)\n",
        "      # print(\"raw:\", raw_output_slice)\n",
        "      # print(\"val0\",val0)\n",
        "      # print(\"output:\", output_slice)\n",
        "      # print(\"-------\")\n",
        "\n",
        "      output_list.append(output_slice)\n",
        "      \n",
        "      input_tensor=torch.tensor(input_list)\n",
        "      output_tensor=torch.tensor(output_list)\n",
        "      predicted_tensor = rnn(input_tensor)\n",
        "      #print(\"output_tensor\",output_tensor)\n",
        "      #print(\"predicted_tensor\",predicted_tensor)\n",
        "      # if e0>=19:\n",
        "      #   for j_ in range(len(output_tensor)):\n",
        "      #     print(\"actual:\", output_tensor[j_])\n",
        "      #     print(\"predicted:\", predicted_tensor[j_])\n",
        "      #     print(\"----\")\n",
        "      #   print(\"=========\")\n",
        "    loss = loss_func(output_tensor, predicted_tensor) #calculate the loss, difference between the output and the desired outcome tensors\n",
        "    #loss= F.nll_loss(output_tensor, predicted_tensor)\n",
        "    training_loss+=loss\n",
        "    loss.backward()\n",
        "    optimizer.step()  \n",
        "  # print(\"training loss:\", training_loss)\n",
        "  # print(\"========\")\n",
        "\n",
        "  dev_loss=0\n",
        "  for i in range(train_size-sample_size,full_size-sample_size):\n",
        "    #print(i)\n",
        "    rnn.hidden = rnn.init_hidden()\n",
        "    rnn.zero_grad()  \n",
        "\n",
        "    for tm in tmp_list:\n",
        "      input_list=[]\n",
        "      output_list=[]\n",
        "      raw_input_slice=tm[i:i+n_input]\n",
        "      val0=raw_input_slice[-1]\n",
        "      input_slice=[(v-val0)/val0 for v in raw_input_slice]\n",
        "      input_list.append(input_slice)\n",
        "      raw_output_slice=tm[i+n_input:i+sample_size]\n",
        "      \n",
        "      \n",
        "      output_slice=[(v-val0)/val0 for v in raw_output_slice]\n",
        "      output_list.append(output_slice)\n",
        "      \n",
        "      input_tensor=torch.tensor(input_list)\n",
        "      output_tensor=torch.tensor(output_list)\n",
        "      predicted_tensor = rnn(input_tensor)\n",
        "    loss = loss_func(output_tensor, predicted_tensor) #calculate the loss, difference between the output and the desired outcome tensors\n",
        "    #loss= F.nll_loss(output_tensor, predicted_tensor)\n",
        "    dev_loss+=loss\n",
        "    # loss.backward()\n",
        "    # optimizer.step()  \n",
        "  print(\"training loss:\", training_loss,\"dev_loss\",dev_loss)\n",
        "  print(\"========\")\n",
        "\n",
        "  model_fname=\"%s_%s.model\"%( model_prefix,e0)\n",
        "  model_fpath=os.path.join(models_dir,model_fname)\n",
        "\n",
        "  torch.save({\n",
        "              'epoch': e0,\n",
        "              'model_state_dict': rnn.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              'training_loss': training_loss,\n",
        "              'dev_loss': dev_loss,\n",
        "              'n_input':n_input,\n",
        "              'n_hidden':n_hidden,\n",
        "              'n_layers':n_layers,\n",
        "              'depth':depth,\n",
        "              'LR':LR\n",
        "\n",
        "              }, model_fpath)\n",
        "\n",
        "  # print(input_tensor.shape)\n",
        "  # print(output_tensor.shape)\n",
        "\n",
        "\n",
        "    # print(\"input:\", tmp_list[0][i:i+n_input])\n",
        "    # print(\"output:\", tmp_list[0][i+n_input:i+sample_size])\n",
        "    # print(\"-----\")\n",
        "\n",
        "  # print(\"input:\", tmp_list[0][i:i+n_input])\n",
        "  # print(\"output:\", tmp_list[0][i+n_input:i+sample_size])\n",
        "  # print(\"-----\")\n",
        "\n",
        "# for fname in files:\n",
        "#   json_file_path=\"\"\n",
        "#   wav_file_path=\"\"\n",
        "#   features=extract_features(wav_file_path)\n",
        "#   labels=extract_labels(json_file_path)\n",
        "#   labels_tensor=convert2tensor(labels)\n",
        "#   n_data_points=len(labels)\n",
        "\n",
        "#   rnn.hidden = rnn.init_hidden()\n",
        "#   rnn.zero_grad()\n",
        "\n",
        "\n",
        "#   input_tensor=torch.rand((n_data_points, n_input)) #n_input = 129\n",
        "#   output = rnn(input_tensor)\n",
        "\n",
        "#   loss = loss_func(output, labels_tensor) #calculate the loss, difference between the output and the desired outcome tensors\n",
        "\n",
        " \n",
        "#   loss.backward()\n",
        "#   optimizer.step()  \n",
        "\n",
        "\n",
        "  # # a=random.randint(0,9) #start from a random number\n",
        "  # # rand_tensor = 0.2*torch.rand((3, 4)) + a #generating input tensor from the random number, that consists of random numbers +/- 0.1 of the random number\n",
        "  # # outcome=[0.]*n_output #initializing outcome tensor\n",
        "  # # outcome[a]=1. #filling the index corresponding to the generated random number, which is the outcome\n",
        "  # # outcome_tensor=torch.tensor(outcome).view([1,1,n_output]) #convert it to tensor with shape (1,1,size of outcome/output)\n",
        "  # for i in range(len(rand_tensor)): #feed the network sequentially with the input tensors\n",
        "  #   cur_tensor=rand_tensor[i].view([1,1,n_input])\n",
        "  #   output = rnn(cur_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ0YvjUx3Dib",
        "outputId": "7bd8452e-d42b-40f3-d7f1-b9b38096b8aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[23.7398,\n",
              " 23.7398,\n",
              " 23.7398,\n",
              " 23.7398,\n",
              " 23.7398,\n",
              " 23.875,\n",
              " 23.875,\n",
              " 23.875,\n",
              " 23.875,\n",
              " 23.96]"
            ]
          },
          "execution_count": 37,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_output_slice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-DBVlfKkk8o"
      },
      "outputs": [],
      "source": [
        "price = rs.stocks.get_latest_price('MA', includeExtendedHours=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jMlzwtomv4Y",
        "outputId": "51036262-75d8-4499-c8dc-70c752783cc4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['336.340000']"
            ]
          },
          "execution_count": 10,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlC3Ybhkm4E0",
        "outputId": "e0c94dcc-9646-4289-abcb-f301e5d17bee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['1.669900']"
            ]
          },
          "execution_count": 25,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rs.stocks.get_latest_price(\"IBIO\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMzrEpyfqRRX"
      },
      "outputs": [],
      "source": [
        "rs.stocks.get_latest_price()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFfYmsb2nF5G",
        "outputId": "78dea1f4-14d4-4304-efad-fb4e00c1a8af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'begins_at': '2020-10-27T14:00:00Z',\n",
              "  'close_price': '1.880000',\n",
              "  'high_price': '1.890000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.860000',\n",
              "  'open_price': '1.880000',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 429216},\n",
              " {'begins_at': '2020-10-27T15:00:00Z',\n",
              "  'close_price': '1.910000',\n",
              "  'high_price': '1.910000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.870000',\n",
              "  'open_price': '1.870100',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 188943},\n",
              " {'begins_at': '2020-10-27T16:00:00Z',\n",
              "  'close_price': '1.925000',\n",
              "  'high_price': '1.970000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.900000',\n",
              "  'open_price': '1.910000',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 712290},\n",
              " {'begins_at': '2020-10-27T17:00:00Z',\n",
              "  'close_price': '1.920000',\n",
              "  'high_price': '1.930000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.880000',\n",
              "  'open_price': '1.930000',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 180821},\n",
              " {'begins_at': '2020-10-27T18:00:00Z',\n",
              "  'close_price': '1.910000',\n",
              "  'high_price': '1.920000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.900000',\n",
              "  'open_price': '1.910200',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 114239},\n",
              " {'begins_at': '2020-10-27T19:00:00Z',\n",
              "  'close_price': '1.903800',\n",
              "  'high_price': '1.920000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.900000',\n",
              "  'open_price': '1.900000',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 216028},\n",
              " {'begins_at': '2020-10-28T14:00:00Z',\n",
              "  'close_price': '1.825000',\n",
              "  'high_price': '1.840000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.800000',\n",
              "  'open_price': '1.835000',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 301382},\n",
              " {'begins_at': '2020-10-28T15:00:00Z',\n",
              "  'close_price': '1.820100',\n",
              "  'high_price': '1.840000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.820000',\n",
              "  'open_price': '1.825000',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 117669},\n",
              " {'begins_at': '2020-10-28T16:00:00Z',\n",
              "  'close_price': '1.828900',\n",
              "  'high_price': '1.840000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.820000',\n",
              "  'open_price': '1.830000',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 102822},\n",
              " {'begins_at': '2020-10-28T17:00:00Z',\n",
              "  'close_price': '1.839700',\n",
              "  'high_price': '1.840000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.820000',\n",
              "  'open_price': '1.820000',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 182761},\n",
              " {'begins_at': '2020-10-28T18:00:00Z',\n",
              "  'close_price': '1.840000',\n",
              "  'high_price': '1.840000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.830000',\n",
              "  'open_price': '1.830100',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 105721},\n",
              " {'begins_at': '2020-10-28T19:00:00Z',\n",
              "  'close_price': '1.830000',\n",
              "  'high_price': '1.860000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.830000',\n",
              "  'open_price': '1.835000',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 282506},\n",
              " {'begins_at': '2020-10-29T14:00:00Z',\n",
              "  'close_price': '1.765000',\n",
              "  'high_price': '1.795000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.760000',\n",
              "  'open_price': '1.781500',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 511437},\n",
              " {'begins_at': '2020-10-29T15:00:00Z',\n",
              "  'close_price': '1.795000',\n",
              "  'high_price': '1.800000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.760000',\n",
              "  'open_price': '1.764800',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 338312},\n",
              " {'begins_at': '2020-10-29T16:00:00Z',\n",
              "  'close_price': '1.796900',\n",
              "  'high_price': '1.810000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.790000',\n",
              "  'open_price': '1.790000',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 254352},\n",
              " {'begins_at': '2020-10-29T17:00:00Z',\n",
              "  'close_price': '1.795000',\n",
              "  'high_price': '1.800000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.790000',\n",
              "  'open_price': '1.795000',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 76821},\n",
              " {'begins_at': '2020-10-29T18:00:00Z',\n",
              "  'close_price': '1.770000',\n",
              "  'high_price': '1.800000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.770000',\n",
              "  'open_price': '1.795300',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 260940},\n",
              " {'begins_at': '2020-10-29T19:00:00Z',\n",
              "  'close_price': '1.775000',\n",
              "  'high_price': '1.790000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.770000',\n",
              "  'open_price': '1.775000',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 275422},\n",
              " {'begins_at': '2020-10-30T14:00:00Z',\n",
              "  'close_price': '1.605900',\n",
              "  'high_price': '1.690000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.580000',\n",
              "  'open_price': '1.675900',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 1143717},\n",
              " {'begins_at': '2020-10-30T15:00:00Z',\n",
              "  'close_price': '1.636900',\n",
              "  'high_price': '1.640000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.600000',\n",
              "  'open_price': '1.609500',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 434380},\n",
              " {'begins_at': '2020-10-30T16:00:00Z',\n",
              "  'close_price': '1.640000',\n",
              "  'high_price': '1.650000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.620000',\n",
              "  'open_price': '1.635000',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 493230},\n",
              " {'begins_at': '2020-10-30T17:00:00Z',\n",
              "  'close_price': '1.700000',\n",
              "  'high_price': '1.700000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.630000',\n",
              "  'open_price': '1.640000',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 300110},\n",
              " {'begins_at': '2020-10-30T18:00:00Z',\n",
              "  'close_price': '1.729900',\n",
              "  'high_price': '1.735000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.695000',\n",
              "  'open_price': '1.699100',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 409636},\n",
              " {'begins_at': '2020-10-30T19:00:00Z',\n",
              "  'close_price': '1.750000',\n",
              "  'high_price': '1.750000',\n",
              "  'interpolated': False,\n",
              "  'low_price': '1.720000',\n",
              "  'open_price': '1.726600',\n",
              "  'session': 'reg',\n",
              "  'symbol': 'IBIO',\n",
              "  'volume': 395227}]"
            ]
          },
          "execution_count": 29,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rs.stocks.get_stock_historicals(\"IBIO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzfG2plP-rcO"
      },
      "source": [
        "#Installing and using yahoo finance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYu8rEGDoMAA",
        "outputId": "38f130fa-4e98-405d-e30d-47d6ab25d96c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.70-py2.py3-none-any.whl (26 kB)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting lxml>=4.5.1\n",
            "  Downloading lxml-4.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 11.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.5)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Installing collected packages: requests, lxml, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.8.0 requests-2.27.1 yfinance-0.1.70\n"
          ]
        }
      ],
      "source": [
        "#https://towardsdatascience.com/3-basic-steps-of-stock-market-analysis-in-python-917787012143\n",
        "!pip install yfinance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "rgxY24-7DjL3",
        "outputId": "d33a876b-7861-46ca-8d2f-c3d96b5be816"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-34d4d30ce33d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0myfinance\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0myf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TSLA\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2020-11-01\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2020-12-01\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "df = yf.download(\"TSLA\", start=\"2020-11-01\", end=\"2020-12-01\", interval=\"1d\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3qloNU9_VlG"
      },
      "source": [
        "#Building and Testing Prediction model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSkR7EHQyG_u"
      },
      "source": [
        "##main functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBJw1B7D_aUW",
        "outputId": "2f93c723-8ea5-4191-9f23-b98f7b6c1a5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['-100', '-90', '-80', '-70', '-60', '-50', '-40', '-30', '-20', '-19', '-18', '-17', '-16', '-15', '-14', '-13', '-12', '-11', '-10', '-9', '-8', '-7', '-6', '-5', '-4', '-3', '-2', '-1', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '30', '40', '50', '60', '70', '80', '90', '100', '']\n",
            "11\n",
            "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
            "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
            "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
            "[[1.0, 0.0, 0.0, 0.7, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]]\n",
            "[('-10', 1.0), ('-4', 0.7), ('0', 0.5), ('-8', 0.0), ('-6', 0.0), ('-2', 0.0), ('2', 0.0), ('4', 0.0), ('6', 0.0), ('8', 0.0), ('10', 0.0)]\n",
            "[('6', 1.0), ('-4', 0.2), ('-10', 0.0), ('-8', 0.0), ('-6', 0.0), ('-2', 0.0), ('0', 0.0), ('2', 0.0), ('4', 0.0), ('8', 0.0), ('10', 0.0)]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#define functions to extract features and process labels\n",
        "def get_diff_percent(val0,ref_val0): #ref_val is the present val\n",
        "  try:\n",
        "    diff0=val0-ref_val0\n",
        "    precent0=100*(diff0/ref_val0)\n",
        "    return int(precent0)\n",
        "  except:\n",
        "    return -100 #we'll need to check if this is a good default value\n",
        "\n",
        "def get_str_percent(int_percent0):\n",
        "  if abs(int_percent0)<20: return str(int_percent0)\n",
        "  elif abs(int_percent0)>20 and abs(int_percent0)<100: return str(round(10*int_percent0/10))\n",
        "  elif int_percent0>=100: return \"100\"\n",
        "  elif int_percent0<-100: return \"-100\"\n",
        "  else: return \"\"\n",
        "mv_labels=[\"-100\"] #movement labels\n",
        "mv_labels+=[str(v) for v in range(-90,-20,10)]\n",
        "mv_labels+=[str(v) for v in range(-20,20)]\n",
        "mv_labels+=[str(v) for v in range(20,100,10)]\n",
        "mv_labels+=[\"100\",\"\"]\n",
        "print(mv_labels)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # if abs(int_percent0)<20: return str(int_percent0)\n",
        "  # elif abs(int_percent0)>20 and abs(int_percent0)<100: return str(round(10*int_percent0/10))\n",
        "  # elif int_percent0>=100: return \"100\"\n",
        "  # elif int_percent0<-100: return \"-100\"\n",
        "  # else: return \"\"\n",
        "\n",
        "def get_one_hot(diff_int,labels_list):\n",
        "  out_array=[0.]*len(labels_list)\n",
        "  percent_str=get_str_percent(diff_int)\n",
        "  if not percent_str in labels_list: \n",
        "    out_array[-1]=1. \n",
        "  else:\n",
        "    label_i=labels_list.index(percent_str)\n",
        "    out_array[label_i]=1. \n",
        "  return out_array\n",
        "\n",
        "def list2one_hot(int_list,labels_list):\n",
        "  output=[]\n",
        "  for int0 in int_list: output.append(get_one_hot(int0,labels_list)) \n",
        "  return output\n",
        "\n",
        "\n",
        "# 5, 6, 7, 8, 9\n",
        "def get_str_percent2(int_percent0):\n",
        "  if abs(int_percent0)<=1: return \"0\"\n",
        "  elif int_percent0>1 and int_percent0<=5: return \"3\"\n",
        "  elif int_percent0>5 and int_percent0<=9: return \"7\"\n",
        "  elif int_percent0>9: return \"10\"\n",
        "  elif int_percent0<-1 and int_percent0>=-5: return \"-3\"\n",
        "  elif int_percent0<-5 and int_percent0>=-9: return \"-7\"\n",
        "  elif int_percent0<-9: return \"-10\"\n",
        "  else: return \"\"\n",
        "\n",
        "mv_labels2=[\"-10\",\"-7\",\"-3\",\"0\",\"3\",\"7\",\"10\"]\n",
        "def get_one_hot2(diff_int,labels_list):\n",
        "  out_array=[0.]*len(labels_list)\n",
        "  percent_str=get_str_percent2(diff_int)\n",
        "  if not percent_str in labels_list: \n",
        "    out_array[-1]=1. \n",
        "  else:\n",
        "    label_i=labels_list.index(percent_str)\n",
        "    out_array[label_i]=1. \n",
        "  return out_array\n",
        "\n",
        "def list2one_hot2(int_list,labels_list):\n",
        "  output=[]\n",
        "  for int0 in int_list: output.append(get_one_hot2(int0,labels_list)) \n",
        "  return output\n",
        "\n",
        "#Output processing\n",
        "def out2labels(rnn_flat_out,label_list): #a flat rnn output to split into slices, and get the label weights for each slice\n",
        "  final_list=[]\n",
        "  n_slices=int(len(rnn_flat_out)/len(label_list))\n",
        "  for i0 in range(n_slices):\n",
        "    i1=i0+1\n",
        "    cur_slice=rnn_flat_out[i0*len(label_list):i1*len(label_list)]\n",
        "    tmp_list=[]\n",
        "    for lb0,cs0 in zip(label_list,cur_slice): tmp_list.append((lb0,cs0))\n",
        "    tmp_list.sort(key=lambda x:-x[-1])\n",
        "    final_list.append(tmp_list)\n",
        "  return final_list\n",
        "\n",
        "# #Getting the input\n",
        "# def get_norm_close2(fpath,prev_n0=20,next_n0=10,train_ratio=0.75):\n",
        "#   pd_df=pd.read_csv(fpath)\n",
        "#   close_col=pd_df[\"Close\"]\n",
        "#   data_len=len(close_col)\n",
        "#   all_data=[]\n",
        "#   for test_i in range(prev_n0,len(close_col)-next_n0):\n",
        "#     cur_close_val=close_col[test_i]\n",
        "#     prev_items=close_col[test_i-prev_n0:test_i].to_list() #[0,1,2,3,4,5,6,7,8,9] predict the closing today and the following next_n-1 days\n",
        "#     next_items=close_col[test_i+1:test_i+next_n0+1].to_list()\n",
        "#     normalized_prev=[get_diff_percent(v0,cur_close_val) for v0 in prev_items]\n",
        "#     normalized_next=[get_diff_percent(v0,cur_close_val) for v0 in next_items]\n",
        "#     all_data.append((normalized_prev,normalized_next))\n",
        "#   train_size=int(train_ratio*data_len)\n",
        "#   train_data=all_data[:train_size]\n",
        "#   test_data=all_data[train_size:]\n",
        "#   return train_data,test_data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def check_selling(predictions,output_list,params0={},nofilter=False,pos_threshold=0.3,neg_threshold=0.3,diff_threshold=0,pos_ratio_threshold=0.5,n_top_preds=20,sort_by_diff_wt=True,sort_by_pos_wt=False,debug_vals=False):\n",
        "  pos_threshold=params0.get(\"pos_threshold\",pos_threshold)\n",
        "  neg_threshold=params0.get(\"neg_threshold\",neg_threshold)\n",
        "  diff_threshold=params0.get(\"diff_threshold\",diff_threshold)\n",
        "  n_top_preds=params0.get(\"n_top_preds\",n_top_preds)\n",
        "  sort_by_diff_wt=params0.get(\"sort_by_diff_wt\",sort_by_diff_wt)\n",
        "  sort_by_pos_wt=params0.get(\"sort_by_pos_wt\",sort_by_pos_wt)\n",
        "\n",
        "  selling_pts=[]\n",
        "  for pred_i,ot_pd in enumerate(zip(output_list,predictions)):\n",
        "    ot,pd=ot_pd\n",
        "    pd.sort(key=lambda x:-x[-1])\n",
        "    tmp_pd=[(v[0],round(v[1],4)) for v in pd]\n",
        "    #if debug_vals: print(tmp_pd[:n_top_preds])\n",
        "    if ot==\"\": continue\n",
        "    pred_positive,pred_negative,pred_total=0,0,0\n",
        "    \n",
        "    for p_ in pd[:n_top_preds]:\n",
        "      mv_str,mv_pred_val=p_\n",
        "      if mv_str==\"\" or mv_str==\"0\": continue\n",
        "      mv_int=int(mv_str)\n",
        "      if mv_int>0: pred_positive+=mv_pred_val\n",
        "      if mv_int<0: pred_negative+=mv_pred_val\n",
        "      pred_total+=mv_pred_val\n",
        "    pred_positive=round(pred_positive,2)\n",
        "    pred_negative=round(pred_negative,2)\n",
        "    diff_pos_neg=pred_positive-pred_negative\n",
        "    diff_pos_neg=round(diff_pos_neg,2)\n",
        "\n",
        "    norm_pred_positive=round(pred_positive/pred_total,2)\n",
        "    norm_pred_negative=round(pred_negative/pred_total,2)\n",
        "    norm_diff_pos_neg=norm_pred_positive-norm_pred_negative\n",
        "    norm_diff_pos_neg=round(norm_diff_pos_neg,2)\n",
        "\n",
        "    #tmp_pred=[(v[0],round(v[1],2)) for v in pd]\n",
        "    cur_item=(int(ot),pred_i, norm_pred_positive, pred_positive,pred_negative,diff_pos_neg)\n",
        "    excluded=True\n",
        "    above_pos_th,below_neg_th,above_diff_th=False,False,False\n",
        "    if pred_positive>pos_threshold: above_pos_th=True\n",
        "    if pred_negative<neg_threshold: below_neg_th=True\n",
        "    if diff_pos_neg>diff_threshold: above_diff_th=True\n",
        "    #pos_ratio_threshold\n",
        "    #if pred_positive>pos_threshold and pred_negative<neg_threshold and diff_pos_neg>diff_threshold and pred_positive>pos_ratio_threshold: excluded=False \n",
        "\n",
        "    if nofilter: selling_pts.append(cur_item)\n",
        "    elif pred_positive>pos_threshold and pred_negative<neg_threshold and diff_pos_neg>diff_threshold:  # and norm_pred_positive<pos_ratio_threshold\n",
        "      selling_pts.append(cur_item)\n",
        "    #elif pred_positive>pos_threshold and pred_negative<neg_threshold and diff_pos_neg>diff_threshold: \n",
        "      #excluded=False\n",
        "    if debug_vals: print(\"Actual\",ot, \"pred_positive:\",pred_positive,\"- pred_negative:\",pred_negative, \" - diff_pos_neg:\",diff_pos_neg,\"- excluded:\",excluded)\n",
        "    if debug_vals: print(\"Actual\",ot, \"norm_pred_positive:\",norm_pred_positive,\"- norm_pred_negative:\",norm_pred_negative, \" - norm_diff_pos_neg:\",norm_diff_pos_neg,\"- excluded:\",excluded)\n",
        "    if debug_vals: print(\"above_pos_th\",above_pos_th, pos_threshold)\n",
        "    if debug_vals: print(\"below_neg_th\",below_neg_th, neg_threshold)\n",
        "    if debug_vals: print(\"above_diff_th\",above_diff_th, diff_threshold)\n",
        "    #if debug_vals: print(\"above_pos_th,below_neg_th,above_diff_th\",above_pos_th,below_neg_th,above_diff_th)\n",
        "  if sort_by_diff_wt: selling_pts.sort(key=lambda x:-x[-1])\n",
        "  if sort_by_pos_wt: selling_pts.sort(key=lambda x:-x[2])\n",
        "  if sort_by_diff_wt and sort_by_pos_wt: selling_pts.sort(key=lambda x:(-x[-1],-x[2]))\n",
        "  selling_pts=[v for v in selling_pts if v[2]>pos_ratio_threshold]\n",
        "  return selling_pts\n",
        "\n",
        "class selling_pred:\n",
        "  def __init__(self,predictions,n_top_preds=20):\n",
        "    self.selling_pts=[]\n",
        "    for pred_i,pd in enumerate(predictions):\n",
        "      local_pred_dict={} #predictions for the day\n",
        "      pd.sort(key=lambda x:-x[-1])\n",
        "      pd=pd[:n_top_preds]\n",
        "      #pd=[(int(v[0]),round(v[1],4)) for v in pd if v[0]!=\"\" and v[1]>=0]\n",
        "      pd=[(int(v[0]),round(v[1],4)) for v in pd if v[0]!=\"\"]\n",
        "      local_pred_dict[\"top\"]=pd[0]#(pd[0][0],round(pd[0][1],2))\n",
        "      pred_total=sum([v[1] for v in pd])\n",
        "      pred_pos_items=[v for v in pd if v[0]>0]\n",
        "      pred_neg_items=[v for v in pd if v[0]<0]\n",
        "      pred_pos=sum([v[1] for v in pred_pos_items])\n",
        "      pred_neg=sum([v[1] for v in pred_neg_items])\n",
        "      above_dict={} #showing the prediction weights for a certain movment or above\n",
        "      below_dict={} #same for the other side\n",
        "      for pos_i in range(1,10):\n",
        "        pos_items_above=[v for v in pred_pos_items if v[0]>=pos_i]\n",
        "        tmp_sum=sum([v[1] for v in pos_items_above])\n",
        "        above_dict[pos_i]=round(tmp_sum/pred_total,4)\n",
        "      for neg_i in range(-10,0):\n",
        "        neg_items_below=[v for v in pred_neg_items if v[0]<=neg_i]\n",
        "        tmp_sum=sum([v[1] for v in neg_items_below])\n",
        "        below_dict[neg_i]=round(tmp_sum/pred_total,4)\n",
        "\n",
        "      local_pred_dict[\"above_dict\"]=above_dict\n",
        "      local_pred_dict[\"below_dict\"]=below_dict\n",
        "      # pred_positive,pred_negative,pred_total=0,0,0\n",
        "      # tmp_mv_val_dict={} #prediction values for each movement label (as int)\n",
        "      # pd_pos_items,pd_neg_items=[],[]\n",
        "      # for p_ in pd:\n",
        "      #   mv_label_int,mv_val=p_\n",
        "      #   tmp_mv_val_dict[mv_int]=mv_pred_val\n",
        "      #   if mv_int>0: \n",
        "      #     pred_positive+=mv_pred_val\n",
        "      #     pd_pos_items.append(p_)\n",
        "      #   if mv_int<0: \n",
        "      #     pred_negative+=mv_pred_val\n",
        "      #     pd_neg_items.append(p_)\n",
        "      #   pred_total+=mv_pred_val\n",
        "      pred_pos=round(pred_pos,2)\n",
        "      #pred_negative=round(pred_negative,2)\n",
        "      pred_pos_ratio=round(pred_pos/pred_total,2)\n",
        "      local_pred_dict[\"pred_positive\"]=pred_pos\n",
        "      local_pred_dict[\"pred_pos_ratio\"]=pred_pos_ratio\n",
        "      # local_pred_dict[\"pos_items\"]=pd_pos_items\n",
        "      # local_pred_dict[\"neg_items\"]=pd_neg_items\n",
        "\n",
        "      self.selling_pts.append(local_pred_dict)\n",
        "      continue\n",
        "\n",
        "\n",
        "    #   diff_pos_neg=pred_positive-pred_negative\n",
        "    #   diff_pos_neg=round(diff_pos_neg,2)\n",
        "\n",
        "    #   norm_pred_positive=round(pred_positive/pred_total,2)\n",
        "    #   norm_pred_negative=round(pred_negative/pred_total,2)\n",
        "    #   norm_diff_pos_neg=norm_pred_positive-norm_pred_negative\n",
        "    #   norm_diff_pos_neg=round(norm_diff_pos_neg,2)\n",
        "\n",
        "    #   #tmp_pred=[(v[0],round(v[1],2)) for v in pd]\n",
        "    #   cur_item=(int(ot),pred_i, pred_positive,pred_negative,diff_pos_neg)\n",
        "    #   excluded=True\n",
        "    #   above_pos_th,below_neg_th,above_diff_th=False,False,False\n",
        "    #   if pred_positive>pos_threshold: above_pos_th=True\n",
        "    #   if pred_negative<neg_threshold: below_neg_th=True\n",
        "    #   if diff_pos_neg>diff_threshold: above_diff_th=True\n",
        "\n",
        "    #   if nofilter: selling_pts.append(cur_item)\n",
        "    #   elif pred_positive>pos_threshold and pred_negative<neg_threshold and diff_pos_neg>diff_threshold: \n",
        "    #     selling_pts.append(cur_item)\n",
        "    #     excluded=False\n",
        "    #   if debug_vals: print(\"Actual\",ot, \"pred_positive:\",pred_positive,\"- pred_negative:\",pred_negative, \" - diff_pos_neg:\",diff_pos_neg,\"- excluded:\",excluded)\n",
        "    #   if debug_vals: print(\"Actual\",ot, \"norm_pred_positive:\",norm_pred_positive,\"- norm_pred_negative:\",norm_pred_negative, \" - norm_diff_pos_neg:\",norm_diff_pos_neg,\"- excluded:\",excluded)\n",
        "    #   if debug_vals: print(\"above_pos_th\",above_pos_th, pos_threshold)\n",
        "    #   if debug_vals: print(\"below_neg_th\",below_neg_th, neg_threshold)\n",
        "    #   if debug_vals: print(\"above_diff_th\",above_diff_th, diff_threshold)\n",
        "    #   #if debug_vals: print(\"above_pos_th,below_neg_th,above_diff_th\",above_pos_th,below_neg_th,above_diff_th)\n",
        "    # if sort_by_diff_wt: selling_pts.sort(key=lambda x:-x[-1])\n",
        "    # if sort_by_pos_wt: selling_pts.sort(key=lambda x:-x[2])\n",
        "    # if sort_by_diff_wt and sort_by_pos_wt: selling_pts.sort(key=lambda x:(-x[-1],-x[2]))\n",
        "\n",
        "# import pandas as pd\n",
        "# pd_df=pd.read_csv(\"AAPL.csv\")\n",
        "# print(pd_df.keys())\n",
        "# print(len(close_col))\n",
        "# close_date_col=pd_df[['Date',\"Close\"]]\n",
        "# close_col=pd_df[\"Close\"]\n",
        "\n",
        "# test_i=15\n",
        "# prev_n,next_n=10,10\n",
        "# cur_close_val=close_col[test_i]\n",
        "# prev_items=close_col[test_i-prev_n:test_i].to_list() #[0,1,2,3,4,5,6,7,8,9] predict the closing today and the following next_n-1 days\n",
        "# next_items=close_col[test_i+1:test_i+next_n+1].to_list()\n",
        "# print(\"cur_close_val\",cur_close_val)\n",
        "\n",
        "# normalized_prev=[get_diff_percent(v0,cur_close_val) for v0 in prev_items]\n",
        "# print(\"prev_items\",prev_items)\n",
        "# print(\"normalized_prev\",normalized_prev)\n",
        "# prev_oh=list2one_hot(normalized_prev,mv_labels)\n",
        "# print(np.array(prev_oh).shape)\n",
        "\n",
        "\n",
        "# normalized_next=[get_diff_percent(v0,cur_close_val) for v0 in next_items]\n",
        "# print(\"next_items\",next_items)\n",
        "# print(\"normalized_next\",normalized_next)\n",
        "# next_oh=list2one_hot(normalized_next,mv_labels)\n",
        "# print(np.array(next_oh).shape)\n",
        "\n",
        "#   #print(np.array(prev_oh).shape)\n",
        "# print(len(all_data))\n",
        "\n",
        "class io_cls: #input to output: category >< onehot\n",
        "  def __init__(self,spacing=2,max_val=10): #for a general purpose, this can be where we define the labels\n",
        "    self.spacing=spacing\n",
        "    self.max_val=max_val\n",
        "    self.all_labels=[]\n",
        "    for mv_val0 in range(-max_val,max_val+1,spacing):self.all_labels.append(str(mv_val0))\n",
        "    self.n_labels=len(self.all_labels)\n",
        "    #print(self.all_labels)\n",
        "  def one_hot(self,val_list,ref_val): #and this is when we convert from categorical to one hot\n",
        "    self.diff_list=[]\n",
        "    self.one_hot_list=[]\n",
        "    for val0 in val_list:\n",
        "      diff0=val0-ref_val\n",
        "      precent0=100*(diff0/ref_val)\n",
        "      precent0_norm=int(round(precent0/self.spacing)*self.spacing) #int(round(spacing*precent0)/spacing)\n",
        "      if precent0_norm<=-self.max_val: diff_str=str(-self.max_val)\n",
        "      elif precent0_norm>=self.max_val: diff_str=str(self.max_val)\n",
        "      else: diff_str=str(precent0_norm)\n",
        "      self.diff_list.append(diff_str)\n",
        "      # print(precent0,precent0_norm,diff_str)\n",
        "      tmp_one_hot_vals=[0.]*len(self.all_labels)\n",
        "      if diff_str in self.all_labels: \n",
        "        tmp_i=self.all_labels.index(diff_str)\n",
        "        tmp_one_hot_vals[tmp_i]=1.\n",
        "      self.one_hot_list.append(tmp_one_hot_vals)\n",
        "      # print(tmp_one_hot_vals)\n",
        "      # print(\"-------\")\n",
        "    return self.one_hot_list\n",
        "  def out2labels(self,rnn_flat_out): #a flat rnn output to split into slices, and get the label weights for each slice - and then from one hot to categorical\n",
        "    final_list=[]\n",
        "    n_slices=int(len(rnn_flat_out)/len(self.all_labels))\n",
        "    for i0 in range(n_slices):\n",
        "      i1=i0+1\n",
        "      cur_slice=rnn_flat_out[i0*len(self.all_labels):i1*len(self.all_labels)]\n",
        "      tmp_list=[]\n",
        "      for lb0,cs0 in zip(self.all_labels,cur_slice): tmp_list.append((lb0,cs0))\n",
        "      tmp_list.sort(key=lambda x:-x[-1])\n",
        "      final_list.append(tmp_list)\n",
        "    return final_list\n",
        "\n",
        "#Getting the input\n",
        "def get_norm_close(fpath,prev_n0=20,next_n0=10,train_ratio=0.75):\n",
        "  pd_df=pd.read_csv(fpath)\n",
        "  close_col=pd_df[\"Close\"]\n",
        "  data_len=len(close_col)\n",
        "  all_data=[]\n",
        "  for test_i in range(prev_n0,len(close_col)-next_n0):\n",
        "    \n",
        "    prev_items=close_col[test_i-prev_n0:test_i].to_list() #[0,1,2,3,4,5,6,7,8,9] predict the closing today and the following next_n-1 days\n",
        "    #cur_close_val=prev_items[-1] #close_col[test_i]\n",
        "    #next_items=close_col[test_i+1:test_i+next_n0+1].to_list()\n",
        "    next_items=close_col[test_i:test_i+next_n0].to_list()\n",
        "    # normalized_prev=[get_diff_percent(v0,cur_close_val) for v0 in prev_items]\n",
        "    # normalized_next=[get_diff_percent(v0,cur_close_val) for v0 in next_items]\n",
        "    # all_data.append((normalized_prev,normalized_next))\n",
        "    all_data.append((prev_items,next_items))    \n",
        "  train_size=int(train_ratio*data_len)\n",
        "  train_data=all_data[:train_size]\n",
        "  test_data=all_data[train_size:]\n",
        "  return train_data,test_data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cur_io_obj=io_cls()\n",
        "print(cur_io_obj.n_labels)\n",
        "cur_one_hot=cur_io_obj.one_hot([9,17,14,19,15.5,15.8,16.2,17.1],16)\n",
        "for oh in cur_one_hot:\n",
        "  print(oh)\n",
        "test_oh0=[[1.0, 0.0, 0.0, 0.7, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]]\n",
        "print(test_oh0)\n",
        "ab=np.array(test_oh0).ravel()\n",
        "test_categorical_out=cur_io_obj.out2labels(ab)\n",
        "for a in test_categorical_out:\n",
        "  print(a)\n",
        "#cur_obj=diff_one_hot([15,17,14,19,15.5,15.8,16.2,17.1],16)\n",
        "#cur_obj.all_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=17.5\n",
        "print(round(a/2)*2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuyWn11i2_6z",
        "outputId": "8bce4ebc-0411-4eca-d5ac-3febe684ff33"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPfqK3t5-i4Z"
      },
      "source": [
        "##RNN network definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bwjXHJxgmfm",
        "outputId": "fa7f4f9d-87b8-444e-dafd-1f25f61f06cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded network\n",
            "RNN(\n",
            "  (lstm): LSTM(7, 64, num_layers=2)\n",
            "  (hidden2out): Linear(in_features=64, out_features=70, bias=True)\n",
            ")\n",
            "torch.Size([1, 1, 70])\n",
            "tensor([[[0.4797, 0.4727, 0.4756, 0.4925, 0.4697, 0.5230, 0.5289, 0.5283,\n",
            "          0.5250, 0.4737, 0.5000, 0.5056, 0.5037, 0.4692, 0.4892, 0.5217,\n",
            "          0.5255, 0.5060, 0.4888, 0.4770, 0.4855, 0.5287, 0.5030, 0.5060,\n",
            "          0.5024, 0.5143, 0.5009, 0.5214, 0.4737, 0.5131, 0.5378, 0.5121,\n",
            "          0.4725, 0.5252, 0.4992, 0.4808, 0.5292, 0.5054, 0.5317, 0.4859,\n",
            "          0.4861, 0.5076, 0.5107, 0.4929, 0.5184, 0.5146, 0.4873, 0.5072,\n",
            "          0.5268, 0.5236, 0.4827, 0.4860, 0.5135, 0.4676, 0.4811, 0.5077,\n",
            "          0.5020, 0.4875, 0.5009, 0.4691, 0.5066, 0.4826, 0.4785, 0.5165,\n",
            "          0.4897, 0.4834, 0.5004, 0.4798, 0.5084, 0.5181]]], device='cuda:0',\n",
            "       grad_fn=<SigmoidBackward0>)\n",
            "torch.Size([1, 1, 70])\n",
            "tensor([[[0.4801, 0.4719, 0.4767, 0.4941, 0.4687, 0.5235, 0.5293, 0.5280,\n",
            "          0.5249, 0.4732, 0.4981, 0.5050, 0.5037, 0.4677, 0.4879, 0.5210,\n",
            "          0.5257, 0.5063, 0.4893, 0.4765, 0.4847, 0.5288, 0.5023, 0.5052,\n",
            "          0.5030, 0.5137, 0.5002, 0.5217, 0.4726, 0.5139, 0.5373, 0.5109,\n",
            "          0.4719, 0.5246, 0.4981, 0.4803, 0.5287, 0.5053, 0.5328, 0.4854,\n",
            "          0.4858, 0.5075, 0.5114, 0.4944, 0.5183, 0.5154, 0.4873, 0.5086,\n",
            "          0.5269, 0.5239, 0.4822, 0.4865, 0.5131, 0.4677, 0.4809, 0.5073,\n",
            "          0.5016, 0.4870, 0.5011, 0.4699, 0.5067, 0.4816, 0.4780, 0.5165,\n",
            "          0.4884, 0.4843, 0.5007, 0.4813, 0.5086, 0.5172]]], device='cuda:0',\n",
            "       grad_fn=<SigmoidBackward0>)\n",
            "torch.Size([1, 1, 70])\n",
            "tensor([[[0.4798, 0.4720, 0.4764, 0.4939, 0.4687, 0.5233, 0.5291, 0.5279,\n",
            "          0.5252, 0.4729, 0.4985, 0.5051, 0.5032, 0.4676, 0.4882, 0.5209,\n",
            "          0.5253, 0.5070, 0.4887, 0.4768, 0.4836, 0.5292, 0.5025, 0.5058,\n",
            "          0.5032, 0.5138, 0.5005, 0.5221, 0.4728, 0.5138, 0.5371, 0.5105,\n",
            "          0.4722, 0.5247, 0.4986, 0.4807, 0.5283, 0.5046, 0.5325, 0.4849,\n",
            "          0.4861, 0.5071, 0.5108, 0.4940, 0.5183, 0.5152, 0.4877, 0.5077,\n",
            "          0.5271, 0.5231, 0.4821, 0.4871, 0.5130, 0.4681, 0.4812, 0.5070,\n",
            "          0.5014, 0.4873, 0.5011, 0.4705, 0.5066, 0.4819, 0.4785, 0.5164,\n",
            "          0.4884, 0.4848, 0.5008, 0.4811, 0.5084, 0.5171]]], device='cuda:0',\n",
            "       grad_fn=<SigmoidBackward0>)\n",
            "torch.Size([1, 1, 70])\n",
            "tensor([[[0.4805, 0.4721, 0.4762, 0.4940, 0.4688, 0.5241, 0.5283, 0.5278,\n",
            "          0.5251, 0.4739, 0.4981, 0.5053, 0.5043, 0.4688, 0.4889, 0.5222,\n",
            "          0.5248, 0.5050, 0.4892, 0.4759, 0.4852, 0.5277, 0.5020, 0.5056,\n",
            "          0.5035, 0.5138, 0.5000, 0.5210, 0.4735, 0.5131, 0.5376, 0.5124,\n",
            "          0.4719, 0.5246, 0.4981, 0.4803, 0.5287, 0.5056, 0.5328, 0.4855,\n",
            "          0.4855, 0.5073, 0.5117, 0.4940, 0.5190, 0.5156, 0.4877, 0.5090,\n",
            "          0.5270, 0.5237, 0.4824, 0.4858, 0.5128, 0.4676, 0.4803, 0.5071,\n",
            "          0.5016, 0.4869, 0.5011, 0.4700, 0.5064, 0.4816, 0.4782, 0.5172,\n",
            "          0.4884, 0.4845, 0.5002, 0.4813, 0.5085, 0.5170]]], device='cuda:0',\n",
            "       grad_fn=<SigmoidBackward0>)\n",
            "torch.Size([1, 1, 70])\n",
            "tensor([[[0.4795, 0.4727, 0.4761, 0.4934, 0.4695, 0.5223, 0.5297, 0.5287,\n",
            "          0.5237, 0.4741, 0.4995, 0.5047, 0.5035, 0.4681, 0.4886, 0.5216,\n",
            "          0.5263, 0.5060, 0.4889, 0.4767, 0.4866, 0.5288, 0.5031, 0.5056,\n",
            "          0.5019, 0.5135, 0.5005, 0.5220, 0.4727, 0.5142, 0.5381, 0.5117,\n",
            "          0.4721, 0.5255, 0.4989, 0.4808, 0.5291, 0.5063, 0.5325, 0.4862,\n",
            "          0.4858, 0.5079, 0.5110, 0.4942, 0.5180, 0.5142, 0.4861, 0.5078,\n",
            "          0.5265, 0.5251, 0.4824, 0.4860, 0.5138, 0.4681, 0.4818, 0.5085,\n",
            "          0.5017, 0.4864, 0.5011, 0.4686, 0.5072, 0.4819, 0.4774, 0.5156,\n",
            "          0.4894, 0.4827, 0.5006, 0.4807, 0.5091, 0.5181]]], device='cuda:0',\n",
            "       grad_fn=<SigmoidBackward0>)\n",
            "torch.Size([1, 1, 70])\n",
            "tensor([[[0.4805, 0.4716, 0.4767, 0.4946, 0.4688, 0.5237, 0.5285, 0.5280,\n",
            "          0.5242, 0.4743, 0.4975, 0.5048, 0.5042, 0.4681, 0.4878, 0.5214,\n",
            "          0.5252, 0.5052, 0.4894, 0.4760, 0.4857, 0.5282, 0.5018, 0.5045,\n",
            "          0.5026, 0.5132, 0.4997, 0.5213, 0.4729, 0.5138, 0.5383, 0.5116,\n",
            "          0.4717, 0.5247, 0.4981, 0.4806, 0.5284, 0.5064, 0.5338, 0.4853,\n",
            "          0.4857, 0.5075, 0.5119, 0.4952, 0.5184, 0.5150, 0.4864, 0.5090,\n",
            "          0.5269, 0.5246, 0.4822, 0.4851, 0.5130, 0.4681, 0.4809, 0.5074,\n",
            "          0.5016, 0.4865, 0.5011, 0.4697, 0.5070, 0.4809, 0.4776, 0.5167,\n",
            "          0.4871, 0.4837, 0.5006, 0.4821, 0.5091, 0.5164]]], device='cuda:0',\n",
            "       grad_fn=<SigmoidBackward0>)\n",
            "torch.Size([1, 1, 70])\n",
            "tensor([[[0.4801, 0.4716, 0.4763, 0.4945, 0.4687, 0.5234, 0.5284, 0.5277,\n",
            "          0.5247, 0.4734, 0.4978, 0.5051, 0.5037, 0.4681, 0.4878, 0.5212,\n",
            "          0.5255, 0.5060, 0.4889, 0.4765, 0.4846, 0.5287, 0.5022, 0.5051,\n",
            "          0.5029, 0.5139, 0.5000, 0.5218, 0.4730, 0.5136, 0.5381, 0.5113,\n",
            "          0.4724, 0.5244, 0.4982, 0.4810, 0.5278, 0.5051, 0.5328, 0.4851,\n",
            "          0.4864, 0.5071, 0.5111, 0.4941, 0.5182, 0.5144, 0.4869, 0.5083,\n",
            "          0.5274, 0.5233, 0.4828, 0.4860, 0.5123, 0.4684, 0.4807, 0.5068,\n",
            "          0.5015, 0.4867, 0.5012, 0.4703, 0.5071, 0.4809, 0.4787, 0.5167,\n",
            "          0.4872, 0.4844, 0.5004, 0.4816, 0.5086, 0.5162]]], device='cuda:0',\n",
            "       grad_fn=<SigmoidBackward0>)\n",
            "torch.Size([1, 1, 70])\n",
            "tensor([[[0.4804, 0.4732, 0.4767, 0.4927, 0.4687, 0.5241, 0.5288, 0.5274,\n",
            "          0.5254, 0.4742, 0.4991, 0.5054, 0.5037, 0.4683, 0.4882, 0.5213,\n",
            "          0.5254, 0.5051, 0.4896, 0.4760, 0.4854, 0.5279, 0.5020, 0.5057,\n",
            "          0.5028, 0.5127, 0.5004, 0.5207, 0.4738, 0.5134, 0.5364, 0.5127,\n",
            "          0.4718, 0.5246, 0.4980, 0.4803, 0.5289, 0.5058, 0.5324, 0.4855,\n",
            "          0.4855, 0.5074, 0.5113, 0.4931, 0.5188, 0.5158, 0.4877, 0.5089,\n",
            "          0.5266, 0.5239, 0.4818, 0.4858, 0.5129, 0.4676, 0.4804, 0.5077,\n",
            "          0.5023, 0.4870, 0.5009, 0.4697, 0.5064, 0.4819, 0.4787, 0.5165,\n",
            "          0.4889, 0.4837, 0.5009, 0.4811, 0.5079, 0.5171]]], device='cuda:0',\n",
            "       grad_fn=<SigmoidBackward0>)\n",
            "torch.Size([1, 1, 70])\n",
            "tensor([[[0.4802, 0.4721, 0.4763, 0.4940, 0.4688, 0.5239, 0.5291, 0.5280,\n",
            "          0.5250, 0.4739, 0.4984, 0.5052, 0.5041, 0.4682, 0.4884, 0.5216,\n",
            "          0.5253, 0.5053, 0.4893, 0.4760, 0.4853, 0.5283, 0.5024, 0.5056,\n",
            "          0.5028, 0.5135, 0.5004, 0.5210, 0.4730, 0.5134, 0.5376, 0.5118,\n",
            "          0.4720, 0.5247, 0.4981, 0.4803, 0.5289, 0.5060, 0.5331, 0.4856,\n",
            "          0.4853, 0.5074, 0.5115, 0.4941, 0.5187, 0.5155, 0.4872, 0.5087,\n",
            "          0.5268, 0.5242, 0.4821, 0.4858, 0.5132, 0.4675, 0.4808, 0.5075,\n",
            "          0.5018, 0.4871, 0.5009, 0.4696, 0.5065, 0.4817, 0.4778, 0.5166,\n",
            "          0.4885, 0.4837, 0.5006, 0.4812, 0.5087, 0.5173]]], device='cuda:0',\n",
            "       grad_fn=<SigmoidBackward0>)\n",
            "torch.Size([1, 1, 70])\n",
            "tensor([[[0.4803, 0.4723, 0.4764, 0.4927, 0.4693, 0.5238, 0.5283, 0.5281,\n",
            "          0.5248, 0.4741, 0.4992, 0.5057, 0.5045, 0.4694, 0.4894, 0.5224,\n",
            "          0.5246, 0.5052, 0.4888, 0.4765, 0.4855, 0.5280, 0.5023, 0.5054,\n",
            "          0.5030, 0.5139, 0.5003, 0.5206, 0.4743, 0.5130, 0.5384, 0.5123,\n",
            "          0.4721, 0.5249, 0.4989, 0.4804, 0.5291, 0.5060, 0.5325, 0.4857,\n",
            "          0.4857, 0.5076, 0.5114, 0.4937, 0.5189, 0.5149, 0.4872, 0.5079,\n",
            "          0.5264, 0.5238, 0.4828, 0.4852, 0.5131, 0.4677, 0.4808, 0.5077,\n",
            "          0.5019, 0.4874, 0.5012, 0.4692, 0.5067, 0.4822, 0.4783, 0.5171,\n",
            "          0.4886, 0.4837, 0.5000, 0.4805, 0.5086, 0.5173]]], device='cuda:0',\n",
            "       grad_fn=<SigmoidBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        }
      ],
      "source": [
        "#Let's build the network - here is a small cheat sheet for possible RNN classes based on input and output size\n",
        "#RNN Definition\n",
        "#https://github.com/hmghaly/rnn/blob/master/classes.py\n",
        "\n",
        "#here the size of the output is the same as the size of the input\n",
        "#the depth of the output depends on the number of possible outcome categories (e.g. different phonemes)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "torch.manual_seed(1)\n",
        "random.seed(1)\n",
        "#device = torch.device('cpu')\n",
        "device = torch.device('cuda')\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size,num_layers, matching_in_out=False, batch_size=1):\n",
        "    super(RNN, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = num_layers\n",
        "    self.batch_size = batch_size\n",
        "    self.matching_in_out = matching_in_out #length of input vector matches the length of output vector \n",
        "    self.lstm = nn.LSTM(input_size, hidden_size,num_layers)\n",
        "    self.hidden2out = nn.Linear(hidden_size, output_size)\n",
        "    #self.softmax = nn.LogSoftmax(dim=1)\n",
        "    #self.sigmoid = torch.sigmoid(dim=1)\n",
        "    self.hidden = self.init_hidden()\n",
        "  def forward(self, feature_list):\n",
        "    feature_list=torch.tensor(feature_list)\n",
        "    \n",
        "    feature_list=feature_list.to(device) #### <<<<<<<<<<<<<<<<< \n",
        "    if self.matching_in_out:\n",
        "      lstm_out, _ = self.lstm( feature_list.view(len( feature_list), 1, -1))\n",
        "      output_space = self.hidden2out(lstm_out.view(len( feature_list), -1))\n",
        "      output_scores = torch.sigmoid(output_space) #we'll need to check if we need this sigmoid\n",
        "      return output_scores #output_scores\n",
        "    else:\n",
        "      for i in range(len(feature_list)):\n",
        "        cur_ft_tensor=feature_list[i]#.view([1,1,self.input_size])\n",
        "        cur_ft_tensor=cur_ft_tensor.view([1,1,self.input_size])\n",
        "        lstm_out, self.hidden = self.lstm(cur_ft_tensor, self.hidden)\n",
        "        outs=self.hidden2out(lstm_out)\n",
        "        outs=torch.sigmoid(outs) #check this\n",
        "        #outs = self.softmax(outs).to(device)\n",
        "        #outs = self.sigmoid(outs).to(device)\n",
        "        #self.softmax = nn.LogSoftmax(dim=1)\n",
        "      return outs\n",
        "  def init_hidden(self):\n",
        "    #return torch.rand(self.num_layers, self.batch_size, self.hidden_size)\n",
        "    return (torch.rand(self.num_layers, self.batch_size, self.hidden_size).to(device),\n",
        "            torch.rand(self.num_layers, self.batch_size, self.hidden_size).to(device))\n",
        "\n",
        "\n",
        "prev_n=20\n",
        "next_n=10\n",
        "print(\"loaded network\") #uncomment the following text to test it\n",
        "n_input=len(mv_labels2)\n",
        "n_output=next_n*len(mv_labels2)\n",
        "n_hidden =64#64\n",
        "n_layers=2\n",
        "\n",
        "rnn = RNN(n_input, n_hidden, n_output,n_layers, matching_in_out=False).to(device)\n",
        "\n",
        "print(rnn)\n",
        "for a in range(10):\n",
        "  input_tensor=torch.rand((prev_n, n_input)).to(device)\n",
        "  output = rnn(input_tensor)\n",
        "  print(output.shape)\n",
        "  print(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Nmcg1v7JVps"
      },
      "source": [
        "##Load training/testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qeoiAnq6PNs",
        "outputId": "6659249b-c9c2-403a-d01c-19067442ed9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AAPL\n",
            "10352 7786 2566\n",
            "GOOG\n",
            "4374 3303 1071\n",
            "FB\n",
            "2422 1839 583\n",
            "AMZN\n",
            "6200 4672 1528\n",
            "EA\n",
            "8135 6123 2012\n",
            "IBM\n",
            "13118 9861 3257\n",
            "MSFT\n",
            "9026 6792 2234\n",
            "GM\n",
            "2799 2121 678\n",
            "UPS\n",
            "5572 4201 1371\n",
            "PG\n",
            "13118 9861 3257\n",
            "all_training 56559 all_testing 18557\n",
            "([-5, -10, -17, -15, -12, -7, -2, 1, 6, 16, 18, 15, 11, 13, 10, 5, 1, 0, 4, 3], [0, 2, 1, 7, 4, 6, 7, 7, 5, 4])\n"
          ]
        }
      ],
      "source": [
        "#Step 1 - loading data\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "prev_n,next_n=20,10\n",
        "\n",
        "root_dir='stock_market_data/sp500/csv'\n",
        "test_files=[\"AAPL\",\"GOOG\",\"FB\",\"AMZN\",\"EA\",\"IBM\",\"MSFT\",\"GM\",\"UPS\",\"PG\"]\n",
        "\n",
        "\n",
        "all_training=[]\n",
        "all_testing=[]\n",
        "#pd_df=pd.read_csv(\"AAPL.csv\")\n",
        "for fname in test_files:\n",
        "  cur_fname= fname+\".csv\"\n",
        "  cur_fpath=os.path.join(root_dir,cur_fname)\n",
        "  pd_df=pd.read_csv(cur_fpath)\n",
        "  close_col=pd_df[\"Close\"]\n",
        "  data_len=len(close_col)\n",
        "\n",
        "  all_data=[]\n",
        "  for test_i in range(prev_n,len(close_col)-next_n):\n",
        "    cur_close_val=close_col[test_i]\n",
        "    prev_items=close_col[test_i-prev_n:test_i].to_list() #[0,1,2,3,4,5,6,7,8,9] predict the closing today and the following next_n-1 days\n",
        "    next_items=close_col[test_i+1:test_i+next_n+1].to_list()\n",
        "    normalized_prev=[get_diff_percent(v0,cur_close_val) for v0 in prev_items]\n",
        "    normalized_next=[get_diff_percent(v0,cur_close_val) for v0 in next_items]\n",
        "    #prev_oh=list2one_hot(normalized_prev,normalized_next)\n",
        "    #next_oh=list2one_hot(normalized_next,mv_labels)\n",
        "    all_data.append((normalized_prev,normalized_next))\n",
        "    #all_data.append((prev_oh,next_oh))\n",
        "\n",
        "  train_size=int(0.75*data_len)\n",
        "  train_data=all_data[:train_size]\n",
        "  test_data=all_data[train_size:]\n",
        "  all_training.extend(train_data)\n",
        "  all_testing.extend(test_data)\n",
        "  print(fname)\n",
        "  print(len(all_data),len(train_data),len(test_data))\n",
        "print(\"all_training\",len(all_training),\"all_testing\",len(all_testing) )\n",
        "print(all_training[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Lm-tK1ntDbQ"
      },
      "source": [
        "##Start Training - OLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "lcMTQmw3vNYM",
        "outputId": "d81a35b5-a7a2-4015-f8ff-4f1aa90f04c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN(\n",
            "  (lstm): LSTM(7, 64, num_layers=4)\n",
            "  (hidden2out): Linear(in_features=64, out_features=70, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n",
            "epoch # 0\n",
            "all_training 7786 all_testing 2566\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-4fa8f46842ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mrnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#calculate the loss, difference between the output and the desired outcome tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-9ba4fb30bf77>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, feature_list)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mcur_ft_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#.view([1,1,self.input_size])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcur_ft_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_ft_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_ft_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mouts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m#outs=torch.sigmoid(outs) #check this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 692\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input and parameter tensors are not at the same device, found input tensor at cuda:0 and parameter tensor at cpu"
          ]
        }
      ],
      "source": [
        "#Then let's start iterating\n",
        "n_epochs=100\n",
        "# model_name=\"exp2-3stocks-32\"\n",
        "# model_name=\"exp2-3stocks-128\"\n",
        "model_name=\"exp2-10stocks-128\"\n",
        "model_name=\"exp2-10stocks-64-3layer\"\n",
        "model_name=\"exp2-10stocks-64-3layer-test1\"\n",
        "# model_name=\"exp2-10stocks-64-4layer-TEST\"\n",
        "model_dir=os.path.join(cwd,\"models\", model_name) \n",
        "if not os.path.exists(model_dir): os.makedirs(model_dir)\n",
        "log_fpath=os.path.join(model_dir,\"log.txt\")\n",
        "\n",
        "cur_mv_labels=mv_labels2\n",
        "n_input=len(cur_mv_labels)\n",
        "n_output=next_n*len(cur_mv_labels)\n",
        "\n",
        "n_hidden =64 #64\n",
        "n_layers=4\n",
        "\n",
        "rnn = RNN(n_input, n_hidden, n_output,n_layers, matching_in_out=False)\n",
        "max_train_size=500\n",
        "max_test_size=500\n",
        "# max_train_size=None\n",
        "# max_test_size=None\n",
        "\n",
        "\n",
        "print(rnn)\n",
        "# input_tensor=torch.rand((prev_n, n_input))\n",
        "# output = rnn(input_tensor)\n",
        "# print(output.shape)\n",
        "\n",
        "LR=0.0000001\n",
        "#LR=0.0005\n",
        "loss_func = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
        "\n",
        "tmp_params={}\n",
        "tmp_params[\"LR\"]=LR\n",
        "tmp_params[\"prev_n\"]=prev_n\n",
        "tmp_params[\"next_n\"]=next_n\n",
        "tmp_params[\"n_training\"]=len(all_training)\n",
        "tmp_params[\"n_testing\"]=len(all_testing)\n",
        "\n",
        "\n",
        "log_fopen=open(log_fpath,\"a\")\n",
        "log_fopen.write(str(rnn)+\"\\n\")\n",
        "log_fopen.write(str(tmp_params)+\"\\n\")\n",
        "log_fopen.close()\n",
        "\n",
        "\n",
        "for e0 in range(n_epochs):\n",
        "  print(\"epoch #\",e0)\n",
        "  print(\"all_training\",len(all_training),\"all_testing\",len(all_testing))\n",
        "\n",
        "  PATH=os.path.join(model_dir, \"model-%s.model\"%e0)\n",
        "  if os.path.exists(PATH):\n",
        "    checkpoint = torch.load(PATH)\n",
        "    rnn.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    print(\"loaded model for this epoch\",PATH)\n",
        "    for a,b in  checkpoint.items():\n",
        "      if \"loss\" in a.lower(): print(a,round(b,6))\n",
        "    continue \n",
        "  #continue\n",
        "  total_train_loss=0\n",
        "  total_test_loss=0\n",
        "  train_counter,test_counter=0,0\n",
        "  balance=0\n",
        "  n_sells=0\n",
        "  cur_training_items=all_training\n",
        "  if max_train_size!=None: cur_training_items=all_training[:500]\n",
        "  cur_testing_items=all_testing\n",
        "  if max_test_size!=None: cur_testing_items=all_testing[:500]\n",
        "\n",
        "#max_test_size=500\n",
        "\n",
        "\n",
        "  for i0,tr0 in enumerate(cur_training_items):\n",
        "    if i0%5000==0: print(i0)\n",
        "    input_list,output_list=tr0\n",
        "    input_oh=list2one_hot2(input_list,cur_mv_labels)\n",
        "    output_oh=list2one_hot2(output_list,cur_mv_labels)\n",
        "    input_tensor,output_tensor=torch.tensor(input_oh).to(device) , torch.tensor(output_oh).ravel().to(device)\n",
        "    rnn.hidden = rnn.init_hidden()\n",
        "    rnn.zero_grad()\n",
        "    rnn_output = rnn(input_tensor).to(device)\n",
        "    loss = loss_func(output_tensor, rnn_output) #calculate the loss, difference between the output and the desired outcome tensors\n",
        "    loss.backward()\n",
        "    optimizer.step()  \n",
        "    total_train_loss+=loss.item()\n",
        "    train_counter+=1\n",
        "  print(\"TESTING\")\n",
        "  for i0,tr0 in enumerate(cur_testing_items):\n",
        "    if i0%1000==0: print(i0)\n",
        "    input_list,output_list=tr0\n",
        "    input_oh=list2one_hot2(input_list,cur_mv_labels)\n",
        "    output_oh=list2one_hot2(output_list,cur_mv_labels)\n",
        "    input_tensor,output_tensor=torch.tensor(input_oh) , torch.tensor(output_oh).ravel()\n",
        "\n",
        "    rnn.hidden = rnn.init_hidden()\n",
        "    rnn.zero_grad()\n",
        "    rnn_output = rnn(input_tensor)\n",
        "    loss = loss_func(output_tensor, rnn_output) #calculate the loss, difference between the output and the desired outcome tensors\n",
        "    total_test_loss+=loss.item()\n",
        "    test_counter+=1\n",
        "    #let's see the actual performance\n",
        "    #rnn_output\n",
        "    rnn_output2 = rnn_output.ravel().tolist()\n",
        "    predictions0=out2labels(rnn_output2,cur_mv_labels)\n",
        "    #print(\"mv_labels\",mv_labels)\n",
        "    test_params={}\n",
        "    test_params[\"pos_threshold\"]=0.3\n",
        "    test_params[\"neg_threshold\"]=0.3\n",
        "    # test_params[\"diff_threshold\"]=-1\n",
        "    test_params[\"nofilter\"]=False\n",
        "    test_params[\"pos_ratio_threshold\"]=0.5\n",
        "    \n",
        "\n",
        "    \n",
        "    # for pd_item in predictions0:\n",
        "    #   pd_item.sort(key=lambda x:-x[-1])\n",
        "    #   pred_positive,pred_negative=0,0\n",
        "    #   for p_ in pd_item[:20]:\n",
        "    #     mv_str,mv_pred_val=p_\n",
        "    #     if mv_str==\"\" or mv_str==\"0\": continue\n",
        "    #     mv_int=int(mv_str)\n",
        "    #     if mv_int>0: pred_positive+=mv_pred_val\n",
        "    #     if mv_int<0: pred_negative+=mv_pred_val\n",
        "    #   pred_positive=round(pred_positive,2)\n",
        "    #   pred_negative=round(pred_negative,2)\n",
        "    #   diff_pos_neg=pred_positive-pred_negative\n",
        "    #   diff_pos_neg=round(diff_pos_neg,2)\n",
        "      # print(pd_item[:5])\n",
        "      #print(\"+ve\",pred_positive,\", -ve\",pred_negative,\"diff_pos_neg\",diff_pos_neg)\n",
        "\n",
        "\n",
        "    #print(\"--------\")\n",
        "    cur_selling_pts=[]\n",
        "    #cur_selling_pts=check_selling(predictions0,output_list,test_params,nofilter=False, debug_vals=False)\n",
        "    if cur_selling_pts:\n",
        "      increment=cur_selling_pts[0][0]\n",
        "      actual0,i_,pos_ratio ,pos0,neg0,diff0=cur_selling_pts[0]\n",
        "      balance+=increment\n",
        "      n_sells+=1\n",
        "\n",
        "\n",
        "    # potential_selling_pts=check_selling(predictions0,output_list, test_params)\n",
        "    # if potential_selling_pts:\n",
        "    #   old_balance=int(balance)\n",
        "    #   increment=potential_selling_pts[0][0]\n",
        "    #   balance+=increment\n",
        "    #   n_sells+=1\n",
        "    #   #print(i0, \"increment\",increment, \"balance\", balance, \"old_balance\",old_balance)\n",
        "    # #print(i0, potential_selling_pts)\n",
        "\n",
        "  avg_train_loss=round(total_train_loss/train_counter,6)\n",
        "  avg_test_loss=round(total_test_loss/test_counter, 6) \n",
        "  #avg_test_pred_offset=round(sum(all_pred_offsets)/len(all_pred_offsets) ,4)\n",
        "  #print(\"train loss: %s - test loss: %s\"%(avg_train_loss,avg_test_loss)) #n_sells\n",
        "  #print(\"train loss: %s - test loss: %s - balance: %s\"%(avg_train_loss,avg_test_loss,balance)\n",
        "  \n",
        "  line=\"epoch # %s - train loss: %s - test loss: %s  - n_sells: %s - balance: %s\"%(e0, avg_train_loss,avg_test_loss, n_sells,balance)\n",
        "  print(line)\n",
        "  log_fopen=open(log_fpath,\"a\")\n",
        "  log_fopen.write(line+\"\\n\")\n",
        "  log_fopen.close()  \n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "#   avg_train_loss=round(total_train_loss/len(train_set),4)\n",
        "#   avg_test_loss=round(total_test_loss/len(test_set), 4) \n",
        "#   avg_test_pred_offset=round(sum(all_pred_offsets)/len(all_pred_offsets) ,4)\n",
        "#   print(\"train loss: %s - test loss: %s - prediction offset: %s\"%(avg_train_loss,avg_test_loss, avg_test_pred_offset))\n",
        "#   PATH=os.path.join(model_dir, \"model-%s.model\"%e0)\n",
        "  pickle_path=os.path.join(model_dir, \"model-%s.pickle\"%e0)\n",
        "  pickle_dict={}\n",
        "  pickle_dict[\"n_output\"]=n_output\n",
        "  pickle_dict[\"n_input\"]=n_input\n",
        "  pickle_dict[\"n_hidden\"]=n_hidden\n",
        "  pickle_dict[\"n_layers\"]=n_layers\n",
        "  #pickle_dict[\"out2labels\"]=out2labels\n",
        "  pickle_dict[\"labels\"]=mv_labels\n",
        "  pickle_dict[\"train_loss\"]=avg_train_loss\n",
        "  pickle_dict[\"test_loss\"]=avg_test_loss\n",
        "  #pickle_dict[\"pred_offset\"]=avg_test_pred_offset\n",
        "\n",
        "\n",
        "  numpy_state_dict={}\n",
        "  for a,b in rnn.state_dict().items():\n",
        "    numpy_state_dict[a]=b.numpy()\n",
        "  pickle_dict[\"state_dict\"]=numpy_state_dict\n",
        "  with open(pickle_path, 'wb') as f:\n",
        "    pickle.dump(pickle_dict, f, pickle.HIGHEST_PROTOCOL)\n",
        "    #n_input,n_hidden,n_layers,n_output,LR\n",
        "\n",
        "\n",
        "  torch.save({\n",
        "              'epoch': e0,\n",
        "              'n_input': n_input,\n",
        "              'n_hidden': n_hidden,\n",
        "              'n_layers': n_layers,\n",
        "              'n_output': n_output,\n",
        "              'LR': LR,\n",
        "              'model_state_dict': rnn.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              'train_loss': avg_train_loss,\n",
        "              'test_loss': avg_test_loss,\n",
        "              'train_size': len(cur_training_items),\n",
        "              'test_size': len(cur_testing_items),\n",
        "              'balance': balance\n",
        "              }, PATH)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7pB_ij0r95F"
      },
      "source": [
        "##Combined training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mWONn-wFrVZf",
        "outputId": "01514a2e-d976-41f8-f537-63fea259d109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_files 50 ['AAPL', 'GOOG', 'FB', 'AMZN', 'EA', 'IBM', 'MSFT', 'GM', 'UPS', 'PG', 'ABC', 'ADP', 'A', 'ABT', 'ABMD', 'ADI', 'ABBV', 'ADSK', 'ADM', 'ACN', 'AAP', 'AAL', 'ALGN', 'APH', 'AOS', 'AWK', 'ALLE', 'AME', 'APD', 'ARE', 'AIZ', 'ALB', 'APA', 'ALK', 'AEE', 'AMGN', 'ANTM', 'AEP', 'AON', 'AKAM', 'AXP', 'AMD', 'AMAT', 'AMP', 'ANET', 'AJG', 'AZO', 'ATVI', 'AMT', 'AVB']\n",
            "RNN(\n",
            "  (lstm): LSTM(7, 64, num_layers=3)\n",
            "  (hidden2out): Linear(in_features=64, out_features=70, bias=True)\n",
            ")\n",
            "epoch # 0\n",
            "loaded model for this epoch /content/drive/MyDrive/stocks/models/exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden/tmp/model-AAPL.model\n",
            "loaded model for this epoch /content/drive/MyDrive/stocks/models/exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden/tmp/model-GOOG.model\n",
            "loaded model for this epoch /content/drive/MyDrive/stocks/models/exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden/tmp/model-FB.model\n",
            "loaded model for this epoch /content/drive/MyDrive/stocks/models/exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden/tmp/model-AMZN.model\n",
            "loaded model for this epoch /content/drive/MyDrive/stocks/models/exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden/tmp/model-EA.model\n",
            "loaded model for this epoch /content/drive/MyDrive/stocks/models/exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden/tmp/model-IBM.model\n",
            "loaded model for this epoch /content/drive/MyDrive/stocks/models/exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden/tmp/model-MSFT.model\n",
            "loaded model for this epoch /content/drive/MyDrive/stocks/models/exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden/tmp/model-GM.model\n",
            "loaded model for this epoch /content/drive/MyDrive/stocks/models/exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden/tmp/model-UPS.model\n",
            "loaded model for this epoch /content/drive/MyDrive/stocks/models/exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden/tmp/model-PG.model\n",
            "loaded model for this epoch /content/drive/MyDrive/stocks/models/exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden/tmp/model-ABC.model\n",
            "loaded model for this epoch /content/drive/MyDrive/stocks/models/exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden/tmp/model-ADP.model\n",
            "loaded model for this epoch /content/drive/MyDrive/stocks/models/exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden/tmp/model-A.model\n",
            "loaded model for this epoch /content/drive/MyDrive/stocks/models/exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden/tmp/model-ABT.model\n",
            "loaded model for this epoch /content/drive/MyDrive/stocks/models/exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden/tmp/model-ABMD.model\n",
            "loaded model for this epoch /content/drive/MyDrive/stocks/models/exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden/tmp/model-ADI.model\n",
            "loaded model for this epoch /content/drive/MyDrive/stocks/models/exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden/tmp/model-ABBV.model\n",
            "loaded model for this epoch /content/drive/MyDrive/stocks/models/exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden/tmp/model-ADSK.model\n",
            "loaded model for this epoch /content/drive/MyDrive/stocks/models/exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden/tmp/model-ADM.model\n",
            "loaded model for this epoch /content/drive/MyDrive/stocks/models/exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden/tmp/model-ACN.model\n",
            "AAP all_training 50 all_testing 50\n",
            "input_list [-11, -9, -12, -15, -6, -7, -6, -6, -6, -10, -10, -13, -12, -12, -12, -10, -3, -2, -2, 0]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0066, 0.0212, 0.1595, 0.5388, 0.2101, 0.0248, 0.0131, 0.0185, 0.0464,\n",
            "        0.1622, 0.4298, 0.2231, 0.0608, 0.0234, 0.0364, 0.0337, 0.1846, 0.3799,\n",
            "        0.2170, 0.0861, 0.0343, 0.0362, 0.0472, 0.1888, 0.3080, 0.2311, 0.1054,\n",
            "        0.0483, 0.0466, 0.0498, 0.1553, 0.3179, 0.2038, 0.1232, 0.0612, 0.0554,\n",
            "        0.0474, 0.1598, 0.2779, 0.2074, 0.1047, 0.0941, 0.0601, 0.0604, 0.1446,\n",
            "        0.2562, 0.2351, 0.0760, 0.1381, 0.0606, 0.0594, 0.1425, 0.2578, 0.2185,\n",
            "        0.0958, 0.1207, 0.0715, 0.0544, 0.1338, 0.2412, 0.2093, 0.1051, 0.1357,\n",
            "        0.0821, 0.0540, 0.1174, 0.2263, 0.2257, 0.1075, 0.1497],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.13825802505016327\n",
            "------\n",
            "input_list [-13, -16, -20, -11, -12, -11, -11, -12, -14, -15, -17, -17, -17, -17, -14, -8, -7, -7, -5, -5]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0066, 0.0212, 0.1589, 0.5390, 0.2114, 0.0249, 0.0132, 0.0185, 0.0463,\n",
            "        0.1617, 0.4309, 0.2241, 0.0607, 0.0235, 0.0364, 0.0337, 0.1851, 0.3788,\n",
            "        0.2188, 0.0858, 0.0344, 0.0362, 0.0475, 0.1882, 0.3073, 0.2326, 0.1052,\n",
            "        0.0486, 0.0470, 0.0497, 0.1548, 0.3173, 0.2052, 0.1236, 0.0615, 0.0558,\n",
            "        0.0474, 0.1591, 0.2769, 0.2089, 0.1047, 0.0950, 0.0606, 0.0603, 0.1441,\n",
            "        0.2560, 0.2355, 0.0762, 0.1404, 0.0611, 0.0592, 0.1421, 0.2570, 0.2191,\n",
            "        0.0959, 0.1229, 0.0713, 0.0547, 0.1334, 0.2400, 0.2090, 0.1053, 0.1386,\n",
            "        0.0817, 0.0543, 0.1170, 0.2256, 0.2249, 0.1080, 0.1533],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.1547374278306961\n",
            "------\n",
            "input_list [-13, -16, -7, -8, -7, -8, -8, -11, -12, -14, -14, -14, -14, -11, -5, -4, -3, -1, -1, 4]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0066, 0.0213, 0.1592, 0.5384, 0.2123, 0.0250, 0.0133, 0.0186, 0.0469,\n",
            "        0.1611, 0.4313, 0.2247, 0.0606, 0.0236, 0.0369, 0.0337, 0.1854, 0.3775,\n",
            "        0.2203, 0.0855, 0.0346, 0.0365, 0.0478, 0.1875, 0.3065, 0.2338, 0.1049,\n",
            "        0.0488, 0.0478, 0.0496, 0.1542, 0.3166, 0.2064, 0.1238, 0.0618, 0.0567,\n",
            "        0.0474, 0.1583, 0.2758, 0.2101, 0.1046, 0.0958, 0.0616, 0.0602, 0.1434,\n",
            "        0.2555, 0.2357, 0.0764, 0.1422, 0.0620, 0.0591, 0.1417, 0.2561, 0.2196,\n",
            "        0.0959, 0.1248, 0.0717, 0.0549, 0.1330, 0.2387, 0.2087, 0.1055, 0.1412,\n",
            "        0.0814, 0.0547, 0.1166, 0.2248, 0.2240, 0.1084, 0.1564],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.1488070785999298\n",
            "------\n",
            "input_list [-12, -2, -3, -2, -3, -3, -6, -7, -9, -9, -9, -9, -6, 0, 1, 1, 3, 3, 9, 5]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0067, 0.0213, 0.1603, 0.5371, 0.2130, 0.0251, 0.0133, 0.0189, 0.0474,\n",
            "        0.1604, 0.4312, 0.2251, 0.0605, 0.0238, 0.0377, 0.0337, 0.1857, 0.3760,\n",
            "        0.2216, 0.0853, 0.0347, 0.0371, 0.0481, 0.1868, 0.3056, 0.2347, 0.1047,\n",
            "        0.0490, 0.0490, 0.0495, 0.1536, 0.3157, 0.2073, 0.1240, 0.0620, 0.0581,\n",
            "        0.0474, 0.1576, 0.2747, 0.2112, 0.1045, 0.0966, 0.0626, 0.0605, 0.1428,\n",
            "        0.2550, 0.2358, 0.0766, 0.1437, 0.0634, 0.0590, 0.1413, 0.2552, 0.2199,\n",
            "        0.0959, 0.1265, 0.0720, 0.0551, 0.1330, 0.2373, 0.2083, 0.1055, 0.1435,\n",
            "        0.0810, 0.0552, 0.1162, 0.2247, 0.2230, 0.1087, 0.1591],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.13875439763069153\n",
            "------\n",
            "input_list [3, 2, 3, 3, 2, 0, -1, -3, -3, -3, -3, 0, 6, 7, 8, 10, 10, 17, 12, 6]\n",
            "input_tensor tensor([[0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0067, 0.0215, 0.1610, 0.5353, 0.2130, 0.0251, 0.0134, 0.0191, 0.0483,\n",
            "        0.1595, 0.4306, 0.2251, 0.0603, 0.0239, 0.0384, 0.0339, 0.1857, 0.3742,\n",
            "        0.2223, 0.0849, 0.0348, 0.0376, 0.0486, 0.1861, 0.3042, 0.2353, 0.1043,\n",
            "        0.0492, 0.0500, 0.0497, 0.1529, 0.3145, 0.2079, 0.1238, 0.0622, 0.0593,\n",
            "        0.0473, 0.1572, 0.2733, 0.2119, 0.1042, 0.0971, 0.0633, 0.0606, 0.1425,\n",
            "        0.2541, 0.2354, 0.0766, 0.1448, 0.0645, 0.0587, 0.1407, 0.2548, 0.2198,\n",
            "        0.0958, 0.1278, 0.0722, 0.0552, 0.1329, 0.2359, 0.2083, 0.1055, 0.1453,\n",
            "        0.0806, 0.0555, 0.1157, 0.2244, 0.2226, 0.1088, 0.1613],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.11038818210363388\n",
            "------\n",
            "input_list [4, 5, 4, 4, 1, 0, -2, -1, -1, -1, 1, 8, 9, 10, 12, 12, 19, 14, 8, 1]\n",
            "input_tensor tensor([[0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0067, 0.0218, 0.1617, 0.5343, 0.2130, 0.0252, 0.0134, 0.0192, 0.0492,\n",
            "        0.1595, 0.4295, 0.2249, 0.0601, 0.0240, 0.0390, 0.0341, 0.1863, 0.3726,\n",
            "        0.2230, 0.0845, 0.0349, 0.0381, 0.0492, 0.1852, 0.3039, 0.2357, 0.1039,\n",
            "        0.0493, 0.0510, 0.0499, 0.1522, 0.3132, 0.2091, 0.1236, 0.0623, 0.0604,\n",
            "        0.0472, 0.1569, 0.2729, 0.2126, 0.1039, 0.0975, 0.0639, 0.0607, 0.1422,\n",
            "        0.2532, 0.2350, 0.0771, 0.1457, 0.0656, 0.0586, 0.1403, 0.2545, 0.2197,\n",
            "        0.0958, 0.1299, 0.0724, 0.0554, 0.1328, 0.2345, 0.2084, 0.1054, 0.1479,\n",
            "        0.0802, 0.0558, 0.1153, 0.2240, 0.2222, 0.1089, 0.1642],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.1020868718624115\n",
            "------\n",
            "input_list [7, 6, 6, 2, 1, 0, 0, 0, 0, 2, 10, 11, 11, 14, 14, 21, 16, 10, 3, 1]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0067, 0.0220, 0.1622, 0.5340, 0.2126, 0.0252, 0.0135, 0.0194, 0.0500,\n",
            "        0.1593, 0.4291, 0.2244, 0.0600, 0.0240, 0.0396, 0.0343, 0.1868, 0.3717,\n",
            "        0.2234, 0.0841, 0.0349, 0.0385, 0.0496, 0.1843, 0.3032, 0.2366, 0.1035,\n",
            "        0.0494, 0.0519, 0.0501, 0.1515, 0.3118, 0.2108, 0.1233, 0.0624, 0.0614,\n",
            "        0.0472, 0.1566, 0.2721, 0.2129, 0.1035, 0.0986, 0.0645, 0.0608, 0.1419,\n",
            "        0.2522, 0.2344, 0.0774, 0.1476, 0.0665, 0.0585, 0.1398, 0.2540, 0.2194,\n",
            "        0.0956, 0.1327, 0.0725, 0.0555, 0.1327, 0.2330, 0.2083, 0.1053, 0.1512,\n",
            "        0.0798, 0.0561, 0.1149, 0.2235, 0.2217, 0.1090, 0.1677],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.11600634455680847\n",
            "------\n",
            "input_list [6, 6, 2, 1, 0, 0, 0, 0, 2, 10, 11, 11, 13, 14, 20, 15, 9, 3, 1, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flat_rnn_ouput tensor([0.0067, 0.0222, 0.1625, 0.5343, 0.2121, 0.0253, 0.0135, 0.0195, 0.0507,\n",
            "        0.1591, 0.4283, 0.2248, 0.0598, 0.0241, 0.0401, 0.0345, 0.1872, 0.3707,\n",
            "        0.2246, 0.0836, 0.0350, 0.0389, 0.0501, 0.1834, 0.3023, 0.2381, 0.1031,\n",
            "        0.0494, 0.0526, 0.0503, 0.1508, 0.3102, 0.2122, 0.1229, 0.0629, 0.0622,\n",
            "        0.0471, 0.1562, 0.2713, 0.2131, 0.1032, 0.1003, 0.0650, 0.0608, 0.1416,\n",
            "        0.2511, 0.2337, 0.0777, 0.1506, 0.0674, 0.0583, 0.1394, 0.2535, 0.2190,\n",
            "        0.0955, 0.1361, 0.0726, 0.0556, 0.1326, 0.2314, 0.2081, 0.1051, 0.1552,\n",
            "        0.0794, 0.0564, 0.1145, 0.2230, 0.2211, 0.1089, 0.1719],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.1300303339958191\n",
            "------\n",
            "input_list [3, 0, 0, -2, -2, -2, -2, 0, 7, 8, 9, 11, 11, 18, 13, 7, 0, 0, -2, -2]\n",
            "input_tensor tensor([[0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0068, 0.0223, 0.1626, 0.5339, 0.2126, 0.0253, 0.0135, 0.0197, 0.0513,\n",
            "        0.1588, 0.4271, 0.2259, 0.0597, 0.0242, 0.0406, 0.0346, 0.1874, 0.3694,\n",
            "        0.2263, 0.0832, 0.0351, 0.0392, 0.0505, 0.1825, 0.3012, 0.2392, 0.1027,\n",
            "        0.0499, 0.0533, 0.0504, 0.1502, 0.3085, 0.2135, 0.1224, 0.0639, 0.0630,\n",
            "        0.0471, 0.1557, 0.2702, 0.2132, 0.1028, 0.1028, 0.0656, 0.0609, 0.1413,\n",
            "        0.2500, 0.2329, 0.0779, 0.1546, 0.0681, 0.0581, 0.1390, 0.2528, 0.2186,\n",
            "        0.0953, 0.1402, 0.0727, 0.0557, 0.1325, 0.2298, 0.2078, 0.1049, 0.1598,\n",
            "        0.0791, 0.0566, 0.1141, 0.2224, 0.2204, 0.1089, 0.1768],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.12923768162727356\n",
            "------\n",
            "input_list [-2, -3, -5, -5, -5, -5, -2, 4, 5, 5, 7, 8, 14, 9, 4, -2, -3, -5, -5, -3]\n",
            "input_tensor tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0068, 0.0225, 0.1627, 0.5327, 0.2142, 0.0254, 0.0136, 0.0199, 0.0519,\n",
            "        0.1584, 0.4266, 0.2267, 0.0596, 0.0243, 0.0411, 0.0348, 0.1875, 0.3680,\n",
            "        0.2278, 0.0835, 0.0352, 0.0396, 0.0508, 0.1816, 0.3000, 0.2401, 0.1023,\n",
            "        0.0508, 0.0540, 0.0506, 0.1496, 0.3069, 0.2145, 0.1220, 0.0652, 0.0637,\n",
            "        0.0471, 0.1552, 0.2691, 0.2131, 0.1025, 0.1058, 0.0660, 0.0609, 0.1409,\n",
            "        0.2490, 0.2321, 0.0782, 0.1597, 0.0688, 0.0580, 0.1386, 0.2521, 0.2182,\n",
            "        0.0951, 0.1449, 0.0728, 0.0558, 0.1324, 0.2283, 0.2074, 0.1053, 0.1638,\n",
            "        0.0788, 0.0568, 0.1137, 0.2218, 0.2197, 0.1089, 0.1823],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.12806950509548187\n",
            "------\n",
            "input_list [-2, -4, -4, -4, -4, -1, 5, 6, 7, 9, 9, 15, 11, 5, 0, -2, -4, -3, -1, 1]\n",
            "input_tensor tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0069, 0.0227, 0.1625, 0.5324, 0.2154, 0.0255, 0.0137, 0.0200, 0.0525,\n",
            "        0.1581, 0.4256, 0.2283, 0.0595, 0.0244, 0.0415, 0.0350, 0.1875, 0.3663,\n",
            "        0.2290, 0.0845, 0.0352, 0.0399, 0.0512, 0.1806, 0.2988, 0.2406, 0.1027,\n",
            "        0.0515, 0.0546, 0.0507, 0.1491, 0.3052, 0.2152, 0.1225, 0.0665, 0.0644,\n",
            "        0.0471, 0.1547, 0.2679, 0.2130, 0.1028, 0.1085, 0.0665, 0.0610, 0.1405,\n",
            "        0.2479, 0.2312, 0.0789, 0.1641, 0.0694, 0.0578, 0.1382, 0.2513, 0.2176,\n",
            "        0.0954, 0.1491, 0.0729, 0.0559, 0.1322, 0.2267, 0.2069, 0.1062, 0.1674,\n",
            "        0.0785, 0.0570, 0.1134, 0.2212, 0.2189, 0.1094, 0.1872],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.15009300410747528\n",
            "------\n",
            "input_list [-11, -10, -10, -10, -8, -1, 0, 0, 2, 2, 8, 3, -1, -7, -9, -10, -10, -8, -5, -6]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0069, 0.0229, 0.1622, 0.5314, 0.2164, 0.0258, 0.0137, 0.0202, 0.0529,\n",
            "        0.1577, 0.4243, 0.2296, 0.0600, 0.0245, 0.0419, 0.0351, 0.1874, 0.3643,\n",
            "        0.2299, 0.0854, 0.0356, 0.0402, 0.0515, 0.1797, 0.2974, 0.2409, 0.1030,\n",
            "        0.0526, 0.0552, 0.0508, 0.1485, 0.3033, 0.2156, 0.1237, 0.0677, 0.0649,\n",
            "        0.0471, 0.1542, 0.2666, 0.2127, 0.1038, 0.1110, 0.0668, 0.0610, 0.1400,\n",
            "        0.2468, 0.2302, 0.0799, 0.1678, 0.0699, 0.0577, 0.1379, 0.2503, 0.2169,\n",
            "        0.0962, 0.1527, 0.0729, 0.0560, 0.1319, 0.2251, 0.2063, 0.1076, 0.1704,\n",
            "        0.0782, 0.0571, 0.1129, 0.2205, 0.2180, 0.1105, 0.1914],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.09252864867448807\n",
            "------\n",
            "input_list [-12, -12, -12, -9, -3, -2, -1, 0, 0, 6, 1, -3, -9, -10, -12, -12, -10, -7, -8, -1]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0069, 0.0230, 0.1617, 0.5311, 0.2169, 0.0261, 0.0138, 0.0203, 0.0533,\n",
            "        0.1573, 0.4227, 0.2315, 0.0604, 0.0246, 0.0422, 0.0352, 0.1872, 0.3621,\n",
            "        0.2313, 0.0861, 0.0359, 0.0405, 0.0517, 0.1788, 0.2968, 0.2409, 0.1032,\n",
            "        0.0536, 0.0557, 0.0509, 0.1479, 0.3022, 0.2158, 0.1248, 0.0687, 0.0653,\n",
            "        0.0471, 0.1537, 0.2660, 0.2123, 0.1045, 0.1131, 0.0671, 0.0610, 0.1395,\n",
            "        0.2462, 0.2291, 0.0808, 0.1710, 0.0703, 0.0575, 0.1375, 0.2500, 0.2161,\n",
            "        0.0968, 0.1558, 0.0729, 0.0560, 0.1316, 0.2243, 0.2057, 0.1088, 0.1729,\n",
            "        0.0778, 0.0572, 0.1126, 0.2205, 0.2171, 0.1113, 0.1949],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.08335195481777191\n",
            "------\n",
            "input_list [-13, -13, -10, -3, -2, -2, 0, 0, 5, 1, -4, -9, -11, -12, -12, -10, -7, -9, -2, 0]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0069, 0.0231, 0.1611, 0.5315, 0.2170, 0.0263, 0.0138, 0.0204, 0.0535,\n",
            "        0.1568, 0.4220, 0.2330, 0.0606, 0.0246, 0.0424, 0.0352, 0.1868, 0.3607,\n",
            "        0.2323, 0.0866, 0.0362, 0.0407, 0.0518, 0.1779, 0.2968, 0.2407, 0.1031,\n",
            "        0.0544, 0.0561, 0.0509, 0.1473, 0.3018, 0.2156, 0.1255, 0.0695, 0.0656,\n",
            "        0.0471, 0.1530, 0.2660, 0.2117, 0.1051, 0.1148, 0.0671, 0.0610, 0.1391,\n",
            "        0.2462, 0.2279, 0.0815, 0.1734, 0.0705, 0.0574, 0.1370, 0.2502, 0.2151,\n",
            "        0.0973, 0.1584, 0.0728, 0.0559, 0.1312, 0.2241, 0.2050, 0.1098, 0.1749,\n",
            "        0.0774, 0.0573, 0.1122, 0.2210, 0.2160, 0.1120, 0.1979],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.08682020008563995\n",
            "------\n",
            "input_list [-13, -10, -4, -3, -2, 0, 0, 5, 1, -4, -10, -11, -13, -12, -10, -8, -9, -2, 0, 0]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0069, 0.0232, 0.1603, 0.5325, 0.2167, 0.0265, 0.0138, 0.0205, 0.0536,\n",
            "        0.1563, 0.4220, 0.2341, 0.0608, 0.0246, 0.0425, 0.0352, 0.1862, 0.3600,\n",
            "        0.2328, 0.0870, 0.0363, 0.0408, 0.0518, 0.1776, 0.2966, 0.2403, 0.1030,\n",
            "        0.0550, 0.0563, 0.0508, 0.1466, 0.3019, 0.2152, 0.1261, 0.0701, 0.0658,\n",
            "        0.0470, 0.1524, 0.2666, 0.2110, 0.1056, 0.1162, 0.0671, 0.0609, 0.1386,\n",
            "        0.2465, 0.2266, 0.0820, 0.1753, 0.0706, 0.0571, 0.1364, 0.2508, 0.2141,\n",
            "        0.0977, 0.1605, 0.0726, 0.0558, 0.1308, 0.2244, 0.2042, 0.1107, 0.1763,\n",
            "        0.0769, 0.0572, 0.1119, 0.2219, 0.2148, 0.1124, 0.2002],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.09591633826494217\n",
            "------\n",
            "input_list [-9, -2, -1, -1, 0, 0, 6, 2, -2, -8, -10, -11, -11, -9, -6, -8, -1, 0, 1, 1]\n",
            "input_tensor tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0069, 0.0232, 0.1594, 0.5340, 0.2161, 0.0266, 0.0138, 0.0205, 0.0537,\n",
            "        0.1556, 0.4225, 0.2347, 0.0608, 0.0245, 0.0426, 0.0352, 0.1861, 0.3589,\n",
            "        0.2330, 0.0873, 0.0365, 0.0409, 0.0518, 0.1772, 0.2969, 0.2397, 0.1027,\n",
            "        0.0556, 0.0565, 0.0508, 0.1464, 0.3018, 0.2146, 0.1264, 0.0706, 0.0659,\n",
            "        0.0469, 0.1518, 0.2676, 0.2101, 0.1059, 0.1174, 0.0669, 0.0608, 0.1381,\n",
            "        0.2473, 0.2253, 0.0825, 0.1765, 0.0707, 0.0569, 0.1358, 0.2519, 0.2130,\n",
            "        0.0980, 0.1621, 0.0723, 0.0557, 0.1303, 0.2253, 0.2034, 0.1115, 0.1774,\n",
            "        0.0764, 0.0572, 0.1119, 0.2226, 0.2135, 0.1128, 0.2020],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.08324113488197327\n",
            "------\n",
            "input_list [-3, -2, -1, 0, 0, 6, 1, -3, -9, -10, -12, -12, -10, -7, -8, -1, 0, 0, 0, 0]\n",
            "input_tensor tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0069, 0.0232, 0.1584, 0.5359, 0.2153, 0.0267, 0.0137, 0.0205, 0.0536,\n",
            "        0.1550, 0.4237, 0.2351, 0.0607, 0.0245, 0.0425, 0.0351, 0.1859, 0.3585,\n",
            "        0.2329, 0.0874, 0.0365, 0.0410, 0.0517, 0.1767, 0.2978, 0.2390, 0.1023,\n",
            "        0.0560, 0.0566, 0.0506, 0.1461, 0.3022, 0.2138, 0.1266, 0.0710, 0.0659,\n",
            "        0.0468, 0.1512, 0.2691, 0.2092, 0.1061, 0.1182, 0.0667, 0.0607, 0.1377,\n",
            "        0.2485, 0.2239, 0.0828, 0.1773, 0.0706, 0.0567, 0.1351, 0.2534, 0.2119,\n",
            "        0.0982, 0.1634, 0.0720, 0.0555, 0.1298, 0.2267, 0.2025, 0.1121, 0.1780,\n",
            "        0.0758, 0.0571, 0.1119, 0.2237, 0.2121, 0.1130, 0.2033],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.08895356953144073\n",
            "------\n",
            "input_list [0, 0, 1, 1, 7, 3, -2, -8, -9, -11, -10, -8, -5, -7, 0, 1, 2, 2, 0, 1]\n",
            "input_tensor tensor([[0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0069, 0.0232, 0.1574, 0.5383, 0.2143, 0.0267, 0.0137, 0.0205, 0.0535,\n",
            "        0.1543, 0.4254, 0.2352, 0.0606, 0.0244, 0.0425, 0.0351, 0.1856, 0.3588,\n",
            "        0.2325, 0.0875, 0.0366, 0.0411, 0.0516, 0.1761, 0.2992, 0.2381, 0.1018,\n",
            "        0.0563, 0.0567, 0.0505, 0.1457, 0.3033, 0.2129, 0.1266, 0.0713, 0.0659,\n",
            "        0.0467, 0.1506, 0.2709, 0.2082, 0.1062, 0.1189, 0.0664, 0.0605, 0.1373,\n",
            "        0.2500, 0.2225, 0.0830, 0.1776, 0.0704, 0.0565, 0.1343, 0.2553, 0.2107,\n",
            "        0.0983, 0.1643, 0.0717, 0.0554, 0.1297, 0.2279, 0.2017, 0.1126, 0.1783,\n",
            "        0.0752, 0.0570, 0.1122, 0.2246, 0.2107, 0.1131, 0.2041],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.08587135374546051\n",
            "------\n",
            "input_list [-1, 0, 0, 6, 1, -3, -9, -10, -12, -12, -10, -7, -8, -1, 0, 0, 0, 0, 0, -1]\n",
            "input_tensor tensor([[0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0068, 0.0231, 0.1563, 0.5411, 0.2129, 0.0267, 0.0136, 0.0204, 0.0533,\n",
            "        0.1536, 0.4276, 0.2349, 0.0603, 0.0243, 0.0423, 0.0349, 0.1851, 0.3597,\n",
            "        0.2318, 0.0874, 0.0365, 0.0410, 0.0514, 0.1753, 0.3008, 0.2370, 0.1012,\n",
            "        0.0565, 0.0566, 0.0503, 0.1452, 0.3047, 0.2119, 0.1264, 0.0713, 0.0658,\n",
            "        0.0465, 0.1499, 0.2731, 0.2070, 0.1061, 0.1192, 0.0659, 0.0602, 0.1368,\n",
            "        0.2516, 0.2210, 0.0831, 0.1773, 0.0701, 0.0562, 0.1334, 0.2575, 0.2093,\n",
            "        0.0982, 0.1648, 0.0712, 0.0551, 0.1295, 0.2295, 0.2007, 0.1129, 0.1782,\n",
            "        0.0745, 0.0569, 0.1128, 0.2251, 0.2092, 0.1130, 0.2045],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.0951276496052742\n",
            "------\n",
            "input_list [1, 1, 7, 3, -2, -8, -9, -11, -11, -9, -6, -7, 0, 1, 1, 2, 0, 1, 0, 1]\n",
            "input_tensor tensor([[0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0068, 0.0230, 0.1551, 0.5443, 0.2115, 0.0266, 0.0135, 0.0204, 0.0530,\n",
            "        0.1529, 0.4302, 0.2345, 0.0601, 0.0241, 0.0421, 0.0348, 0.1846, 0.3611,\n",
            "        0.2308, 0.0872, 0.0364, 0.0410, 0.0512, 0.1745, 0.3029, 0.2359, 0.1005,\n",
            "        0.0566, 0.0565, 0.0501, 0.1447, 0.3066, 0.2107, 0.1261, 0.0713, 0.0656,\n",
            "        0.0463, 0.1493, 0.2755, 0.2058, 0.1060, 0.1193, 0.0654, 0.0599, 0.1369,\n",
            "        0.2529, 0.2195, 0.0831, 0.1767, 0.0698, 0.0560, 0.1329, 0.2592, 0.2079,\n",
            "        0.0982, 0.1650, 0.0708, 0.0548, 0.1297, 0.2309, 0.1998, 0.1131, 0.1778,\n",
            "        0.0738, 0.0567, 0.1136, 0.2254, 0.2076, 0.1129, 0.2045],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.08828723430633545\n",
            "------\n",
            "input_list [1, 7, 3, -2, -8, -9, -11, -11, -9, -6, -7, 0, 1, 1, 2, 0, 1, 0, 1, 0]\n",
            "input_tensor tensor([[0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0067, 0.0229, 0.1539, 0.5477, 0.2098, 0.0266, 0.0134, 0.0203, 0.0527,\n",
            "        0.1521, 0.4331, 0.2339, 0.0598, 0.0240, 0.0419, 0.0346, 0.1839, 0.3631,\n",
            "        0.2296, 0.0869, 0.0363, 0.0409, 0.0510, 0.1736, 0.3053, 0.2346, 0.0998,\n",
            "        0.0567, 0.0562, 0.0499, 0.1441, 0.3089, 0.2094, 0.1256, 0.0713, 0.0654,\n",
            "        0.0462, 0.1487, 0.2783, 0.2045, 0.1057, 0.1192, 0.0649, 0.0596, 0.1369,\n",
            "        0.2545, 0.2180, 0.0831, 0.1757, 0.0694, 0.0557, 0.1328, 0.2604, 0.2064,\n",
            "        0.0980, 0.1650, 0.0702, 0.0546, 0.1301, 0.2321, 0.1988, 0.1131, 0.1772,\n",
            "        0.0731, 0.0566, 0.1143, 0.2263, 0.2060, 0.1126, 0.2041],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.09120260924100876\n",
            "------\n",
            "input_list [6, 2, -2, -8, -10, -11, -11, -9, -6, -8, -1, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0067, 0.0228, 0.1527, 0.5514, 0.2080, 0.0265, 0.0133, 0.0201, 0.0523,\n",
            "        0.1513, 0.4364, 0.2332, 0.0594, 0.0238, 0.0416, 0.0344, 0.1831, 0.3655,\n",
            "        0.2282, 0.0865, 0.0362, 0.0408, 0.0507, 0.1727, 0.3080, 0.2334, 0.0991,\n",
            "        0.0567, 0.0560, 0.0496, 0.1434, 0.3115, 0.2081, 0.1250, 0.0711, 0.0652,\n",
            "        0.0460, 0.1481, 0.2814, 0.2031, 0.1054, 0.1190, 0.0643, 0.0593, 0.1373,\n",
            "        0.2557, 0.2164, 0.0830, 0.1744, 0.0690, 0.0555, 0.1329, 0.2612, 0.2048,\n",
            "        0.0978, 0.1647, 0.0697, 0.0543, 0.1309, 0.2329, 0.1978, 0.1131, 0.1763,\n",
            "        0.0724, 0.0564, 0.1150, 0.2276, 0.2043, 0.1123, 0.2035],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.09961927682161331\n",
            "------\n",
            "input_list [1, -3, -9, -10, -12, -12, -10, -7, -8, -1, 0, 0, 0, 0, 0, -1, 0, -1, -1, 0]\n",
            "input_tensor tensor([[0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0066, 0.0227, 0.1514, 0.5554, 0.2062, 0.0264, 0.0132, 0.0200, 0.0519,\n",
            "        0.1505, 0.4400, 0.2323, 0.0590, 0.0236, 0.0413, 0.0342, 0.1822, 0.3684,\n",
            "        0.2266, 0.0860, 0.0361, 0.0407, 0.0505, 0.1717, 0.3109, 0.2320, 0.0983,\n",
            "        0.0566, 0.0557, 0.0494, 0.1432, 0.3136, 0.2067, 0.1244, 0.0709, 0.0649,\n",
            "        0.0458, 0.1479, 0.2839, 0.2017, 0.1050, 0.1186, 0.0638, 0.0589, 0.1380,\n",
            "        0.2565, 0.2149, 0.0828, 0.1729, 0.0685, 0.0553, 0.1334, 0.2616, 0.2032,\n",
            "        0.0975, 0.1642, 0.0691, 0.0540, 0.1314, 0.2344, 0.1968, 0.1129, 0.1752,\n",
            "        0.0716, 0.0561, 0.1159, 0.2285, 0.2026, 0.1119, 0.2025],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.10780441015958786\n",
            "------\n",
            "input_list [-3, -9, -11, -12, -12, -10, -7, -8, -2, 0, 0, 0, 0, 0, -1, 0, -1, -1, 0, 0]\n",
            "input_tensor tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0066, 0.0226, 0.1500, 0.5597, 0.2042, 0.0263, 0.0131, 0.0199, 0.0515,\n",
            "        0.1496, 0.4439, 0.2311, 0.0586, 0.0235, 0.0410, 0.0340, 0.1819, 0.3706,\n",
            "        0.2250, 0.0855, 0.0359, 0.0405, 0.0501, 0.1714, 0.3132, 0.2306, 0.0976,\n",
            "        0.0565, 0.0553, 0.0492, 0.1434, 0.3152, 0.2053, 0.1236, 0.0706, 0.0645,\n",
            "        0.0456, 0.1482, 0.2860, 0.2003, 0.1046, 0.1181, 0.0631, 0.0585, 0.1390,\n",
            "        0.2570, 0.2134, 0.0825, 0.1711, 0.0680, 0.0550, 0.1336, 0.2625, 0.2015,\n",
            "        0.0971, 0.1635, 0.0685, 0.0537, 0.1324, 0.2356, 0.1957, 0.1127, 0.1740,\n",
            "        0.0709, 0.0559, 0.1171, 0.2292, 0.2009, 0.1115, 0.2012],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.11626014858484268\n",
            "------\n",
            "input_list [-8, -9, -11, -11, -9, -6, -7, 0, 1, 1, 2, 0, 1, 0, 1, 0, 0, 0, 1, 1]\n",
            "input_tensor tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0065, 0.0224, 0.1486, 0.5642, 0.2022, 0.0261, 0.0130, 0.0197, 0.0510,\n",
            "        0.1493, 0.4469, 0.2298, 0.0582, 0.0233, 0.0407, 0.0338, 0.1821, 0.3721,\n",
            "        0.2235, 0.0849, 0.0358, 0.0403, 0.0498, 0.1716, 0.3149, 0.2291, 0.0968,\n",
            "        0.0563, 0.0549, 0.0489, 0.1440, 0.3164, 0.2040, 0.1229, 0.0703, 0.0641,\n",
            "        0.0453, 0.1488, 0.2876, 0.1989, 0.1041, 0.1174, 0.0625, 0.0582, 0.1398,\n",
            "        0.2580, 0.2118, 0.0823, 0.1692, 0.0674, 0.0547, 0.1342, 0.2630, 0.1998,\n",
            "        0.0967, 0.1626, 0.0678, 0.0534, 0.1336, 0.2364, 0.1945, 0.1124, 0.1725,\n",
            "        0.0701, 0.0557, 0.1184, 0.2296, 0.1992, 0.1110, 0.1997],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.10693372040987015\n",
            "------\n",
            "input_list [-8, -10, -10, -8, -5, -6, 0, 2, 2, 3, 1, 2, 0, 2, 0, 1, 1, 2, 2, 0]\n",
            "input_tensor tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0064, 0.0223, 0.1471, 0.5689, 0.2003, 0.0260, 0.0129, 0.0196, 0.0506,\n",
            "        0.1489, 0.4502, 0.2285, 0.0577, 0.0232, 0.0404, 0.0337, 0.1828, 0.3730,\n",
            "        0.2219, 0.0844, 0.0357, 0.0401, 0.0495, 0.1725, 0.3163, 0.2277, 0.0961,\n",
            "        0.0562, 0.0545, 0.0487, 0.1450, 0.3172, 0.2026, 0.1222, 0.0700, 0.0637,\n",
            "        0.0451, 0.1493, 0.2897, 0.1975, 0.1037, 0.1167, 0.0620, 0.0579, 0.1410,\n",
            "        0.2589, 0.2104, 0.0820, 0.1672, 0.0669, 0.0544, 0.1351, 0.2632, 0.1981,\n",
            "        0.0964, 0.1616, 0.0672, 0.0531, 0.1351, 0.2370, 0.1934, 0.1120, 0.1710,\n",
            "        0.0694, 0.0555, 0.1199, 0.2298, 0.1976, 0.1106, 0.1980],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.10606715083122253\n",
            "------\n",
            "input_list [-10, -9, -7, -4, -6, 0, 2, 3, 3, 2, 2, 1, 2, 1, 1, 2, 2, 3, 1, 0]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0064, 0.0222, 0.1456, 0.5738, 0.1982, 0.0259, 0.0128, 0.0195, 0.0501,\n",
            "        0.1490, 0.4526, 0.2270, 0.0572, 0.0230, 0.0400, 0.0335, 0.1840, 0.3735,\n",
            "        0.2202, 0.0838, 0.0355, 0.0399, 0.0492, 0.1731, 0.3180, 0.2263, 0.0952,\n",
            "        0.0560, 0.0540, 0.0485, 0.1457, 0.3185, 0.2012, 0.1214, 0.0696, 0.0633,\n",
            "        0.0449, 0.1496, 0.2921, 0.1960, 0.1032, 0.1159, 0.0614, 0.0576, 0.1424,\n",
            "        0.2592, 0.2088, 0.0816, 0.1650, 0.0663, 0.0541, 0.1362, 0.2632, 0.1963,\n",
            "        0.0960, 0.1605, 0.0665, 0.0528, 0.1367, 0.2374, 0.1922, 0.1115, 0.1693,\n",
            "        0.0687, 0.0553, 0.1216, 0.2298, 0.1960, 0.1100, 0.1960],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.10782212764024734\n",
            "------\n",
            "input_list [-7, -5, -2, -4, 2, 4, 5, 5, 4, 4, 3, 4, 3, 3, 4, 4, 5, 3, 2, 2]\n",
            "input_tensor tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0063, 0.0221, 0.1452, 0.5773, 0.1963, 0.0258, 0.0128, 0.0194, 0.0496,\n",
            "        0.1491, 0.4553, 0.2256, 0.0568, 0.0229, 0.0397, 0.0334, 0.1851, 0.3746,\n",
            "        0.2185, 0.0832, 0.0354, 0.0397, 0.0489, 0.1734, 0.3203, 0.2249, 0.0945,\n",
            "        0.0558, 0.0536, 0.0483, 0.1463, 0.3206, 0.1998, 0.1206, 0.0693, 0.0629,\n",
            "        0.0447, 0.1504, 0.2941, 0.1947, 0.1027, 0.1152, 0.0609, 0.0574, 0.1441,\n",
            "        0.2594, 0.2074, 0.0814, 0.1628, 0.0658, 0.0539, 0.1376, 0.2630, 0.1947,\n",
            "        0.0956, 0.1593, 0.0659, 0.0525, 0.1387, 0.2377, 0.1911, 0.1111, 0.1678,\n",
            "        0.0680, 0.0552, 0.1236, 0.2296, 0.1944, 0.1096, 0.1942],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.08270807564258575\n",
            "------\n",
            "input_list [-6, -2, -4, 2, 4, 5, 5, 4, 4, 3, 4, 3, 3, 4, 4, 5, 3, 2, 2, 0]\n",
            "input_tensor tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0062, 0.0219, 0.1446, 0.5810, 0.1941, 0.0256, 0.0127, 0.0192, 0.0491,\n",
            "        0.1491, 0.4585, 0.2240, 0.0563, 0.0227, 0.0394, 0.0332, 0.1859, 0.3753,\n",
            "        0.2176, 0.0826, 0.0353, 0.0395, 0.0486, 0.1736, 0.3228, 0.2234, 0.0937,\n",
            "        0.0556, 0.0532, 0.0480, 0.1468, 0.3228, 0.1984, 0.1197, 0.0688, 0.0625,\n",
            "        0.0445, 0.1510, 0.2965, 0.1932, 0.1021, 0.1142, 0.0602, 0.0571, 0.1457,\n",
            "        0.2600, 0.2059, 0.0810, 0.1606, 0.0652, 0.0536, 0.1387, 0.2633, 0.1930,\n",
            "        0.0951, 0.1580, 0.0653, 0.0522, 0.1403, 0.2386, 0.1899, 0.1106, 0.1660,\n",
            "        0.0673, 0.0550, 0.1253, 0.2300, 0.1928, 0.1090, 0.1921],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.08453309535980225\n",
            "------\n",
            "input_list [-4, -5, 1, 3, 3, 4, 2, 3, 1, 3, 1, 2, 2, 3, 3, 2, 1, 0, -1, -1]\n",
            "input_tensor tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0062, 0.0218, 0.1438, 0.5849, 0.1919, 0.0255, 0.0126, 0.0191, 0.0486,\n",
            "        0.1489, 0.4609, 0.2232, 0.0558, 0.0225, 0.0390, 0.0330, 0.1864, 0.3766,\n",
            "        0.2164, 0.0819, 0.0351, 0.0393, 0.0482, 0.1737, 0.3256, 0.2218, 0.0928,\n",
            "        0.0553, 0.0527, 0.0477, 0.1471, 0.3253, 0.1969, 0.1187, 0.0683, 0.0620,\n",
            "        0.0443, 0.1513, 0.2992, 0.1917, 0.1015, 0.1132, 0.0596, 0.0567, 0.1470,\n",
            "        0.2609, 0.2043, 0.0805, 0.1582, 0.0646, 0.0534, 0.1396, 0.2641, 0.1914,\n",
            "        0.0946, 0.1566, 0.0646, 0.0519, 0.1417, 0.2399, 0.1888, 0.1100, 0.1642,\n",
            "        0.0666, 0.0547, 0.1269, 0.2309, 0.1912, 0.1084, 0.1899],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.0848308876156807\n",
            "------\n",
            "input_list [-7, 0, 1, 2, 2, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, -1, -3, -3, -1]\n",
            "input_tensor tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0061, 0.0216, 0.1431, 0.5890, 0.1898, 0.0253, 0.0125, 0.0189, 0.0481,\n",
            "        0.1487, 0.4636, 0.2223, 0.0553, 0.0223, 0.0386, 0.0328, 0.1867, 0.3784,\n",
            "        0.2151, 0.0812, 0.0349, 0.0390, 0.0478, 0.1736, 0.3288, 0.2202, 0.0919,\n",
            "        0.0549, 0.0522, 0.0475, 0.1472, 0.3283, 0.1954, 0.1178, 0.0678, 0.0616,\n",
            "        0.0441, 0.1521, 0.3015, 0.1903, 0.1009, 0.1123, 0.0590, 0.0564, 0.1487,\n",
            "        0.2615, 0.2028, 0.0801, 0.1558, 0.0640, 0.0531, 0.1402, 0.2654, 0.1897,\n",
            "        0.0941, 0.1552, 0.0640, 0.0516, 0.1430, 0.2417, 0.1878, 0.1095, 0.1624,\n",
            "        0.0660, 0.0545, 0.1283, 0.2322, 0.1895, 0.1078, 0.1878],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.13050547242164612\n",
            "------\n",
            "input_list [2, 4, 4, 5, 3, 4, 2, 4, 2, 3, 3, 4, 4, 2, 1, 1, 0, 0, 0, 2]\n",
            "input_tensor tensor([[0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0061, 0.0216, 0.1434, 0.5919, 0.1879, 0.0252, 0.0124, 0.0189, 0.0477,\n",
            "        0.1491, 0.4655, 0.2216, 0.0549, 0.0222, 0.0383, 0.0327, 0.1878, 0.3796,\n",
            "        0.2139, 0.0807, 0.0348, 0.0389, 0.0476, 0.1740, 0.3317, 0.2188, 0.0912,\n",
            "        0.0548, 0.0519, 0.0473, 0.1478, 0.3309, 0.1939, 0.1170, 0.0674, 0.0613,\n",
            "        0.0440, 0.1534, 0.3032, 0.1891, 0.1004, 0.1115, 0.0585, 0.0561, 0.1506,\n",
            "        0.2619, 0.2015, 0.0798, 0.1535, 0.0635, 0.0530, 0.1413, 0.2666, 0.1882,\n",
            "        0.0938, 0.1539, 0.0636, 0.0514, 0.1446, 0.2433, 0.1870, 0.1091, 0.1608,\n",
            "        0.0654, 0.0544, 0.1300, 0.2334, 0.1881, 0.1074, 0.1858],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.07642120867967606\n",
            "------\n",
            "input_list [5, 5, 5, 4, 5, 3, 5, 3, 3, 4, 4, 5, 3, 2, 2, 0, 0, 1, 3, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0060, 0.0215, 0.1434, 0.5951, 0.1859, 0.0251, 0.0124, 0.0187, 0.0473,\n",
            "        0.1494, 0.4678, 0.2206, 0.0545, 0.0221, 0.0380, 0.0325, 0.1886, 0.3814,\n",
            "        0.2126, 0.0801, 0.0346, 0.0388, 0.0474, 0.1743, 0.3348, 0.2174, 0.0905,\n",
            "        0.0545, 0.0516, 0.0471, 0.1482, 0.3338, 0.1924, 0.1161, 0.0669, 0.0610,\n",
            "        0.0439, 0.1544, 0.3055, 0.1878, 0.0999, 0.1107, 0.0580, 0.0559, 0.1525,\n",
            "        0.2628, 0.2001, 0.0795, 0.1513, 0.0630, 0.0528, 0.1422, 0.2682, 0.1867,\n",
            "        0.0934, 0.1525, 0.0631, 0.0512, 0.1460, 0.2453, 0.1861, 0.1086, 0.1591,\n",
            "        0.0649, 0.0543, 0.1316, 0.2351, 0.1867, 0.1069, 0.1837],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.0759253203868866\n",
            "------\n",
            "input_list [5, 6, 4, 5, 3, 5, 3, 3, 4, 5, 5, 3, 2, 2, 0, 0, 1, 3, 0, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0060, 0.0213, 0.1433, 0.5984, 0.1839, 0.0250, 0.0123, 0.0186, 0.0468,\n",
            "        0.1495, 0.4705, 0.2195, 0.0541, 0.0220, 0.0377, 0.0324, 0.1891, 0.3837,\n",
            "        0.2110, 0.0794, 0.0344, 0.0386, 0.0471, 0.1744, 0.3382, 0.2158, 0.0897,\n",
            "        0.0542, 0.0512, 0.0468, 0.1485, 0.3369, 0.1909, 0.1152, 0.0665, 0.0606,\n",
            "        0.0438, 0.1552, 0.3082, 0.1865, 0.0993, 0.1097, 0.0574, 0.0556, 0.1540,\n",
            "        0.2640, 0.1987, 0.0791, 0.1490, 0.0625, 0.0526, 0.1429, 0.2701, 0.1852,\n",
            "        0.0930, 0.1510, 0.0626, 0.0509, 0.1471, 0.2477, 0.1852, 0.1081, 0.1574,\n",
            "        0.0643, 0.0541, 0.1331, 0.2371, 0.1852, 0.1063, 0.1816],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.07535390555858612\n",
            "------\n",
            "input_list [6, 4, 5, 3, 5, 4, 4, 4, 5, 5, 4, 3, 2, 0, 0, 2, 3, 1, 0, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0059, 0.0212, 0.1431, 0.6019, 0.1819, 0.0248, 0.0122, 0.0185, 0.0464,\n",
            "        0.1496, 0.4734, 0.2183, 0.0536, 0.0218, 0.0374, 0.0322, 0.1894, 0.3864,\n",
            "        0.2095, 0.0788, 0.0343, 0.0385, 0.0468, 0.1744, 0.3419, 0.2143, 0.0890,\n",
            "        0.0539, 0.0508, 0.0466, 0.1486, 0.3404, 0.1894, 0.1143, 0.0660, 0.0603,\n",
            "        0.0436, 0.1560, 0.3112, 0.1852, 0.0987, 0.1088, 0.0569, 0.0553, 0.1554,\n",
            "        0.2655, 0.1973, 0.0787, 0.1467, 0.0620, 0.0525, 0.1434, 0.2725, 0.1838,\n",
            "        0.0925, 0.1495, 0.0622, 0.0507, 0.1480, 0.2505, 0.1844, 0.1077, 0.1556,\n",
            "        0.0637, 0.0539, 0.1343, 0.2395, 0.1837, 0.1058, 0.1795],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.07471557706594467\n",
            "------\n",
            "input_list [5, 6, 4, 6, 4, 4, 5, 5, 6, 4, 3, 3, 1, 1, 2, 4, 1, 1, 0, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0059, 0.0211, 0.1429, 0.6055, 0.1800, 0.0247, 0.0121, 0.0184, 0.0459,\n",
            "        0.1496, 0.4767, 0.2170, 0.0532, 0.0217, 0.0371, 0.0321, 0.1895, 0.3894,\n",
            "        0.2078, 0.0782, 0.0341, 0.0383, 0.0465, 0.1742, 0.3459, 0.2128, 0.0882,\n",
            "        0.0536, 0.0505, 0.0464, 0.1486, 0.3441, 0.1878, 0.1133, 0.0655, 0.0599,\n",
            "        0.0435, 0.1566, 0.3145, 0.1839, 0.0982, 0.1079, 0.0563, 0.0550, 0.1567,\n",
            "        0.2674, 0.1959, 0.0783, 0.1444, 0.0615, 0.0523, 0.1437, 0.2752, 0.1824,\n",
            "        0.0921, 0.1480, 0.0617, 0.0505, 0.1488, 0.2537, 0.1835, 0.1072, 0.1539,\n",
            "        0.0632, 0.0538, 0.1355, 0.2422, 0.1823, 0.1052, 0.1774],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.0822824016213417\n",
            "------\n",
            "input_list [5, 4, 5, 4, 4, 5, 5, 6, 4, 3, 2, 0, 0, 2, 4, 1, 0, 0, 0, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0059, 0.0210, 0.1425, 0.6091, 0.1780, 0.0245, 0.0120, 0.0183, 0.0455,\n",
            "        0.1495, 0.4803, 0.2156, 0.0528, 0.0215, 0.0368, 0.0319, 0.1894, 0.3928,\n",
            "        0.2061, 0.0776, 0.0339, 0.0382, 0.0463, 0.1740, 0.3491, 0.2120, 0.0875,\n",
            "        0.0533, 0.0502, 0.0461, 0.1485, 0.3470, 0.1870, 0.1124, 0.0649, 0.0596,\n",
            "        0.0434, 0.1571, 0.3181, 0.1826, 0.0976, 0.1070, 0.0558, 0.0548, 0.1578,\n",
            "        0.2697, 0.1946, 0.0779, 0.1422, 0.0610, 0.0522, 0.1439, 0.2781, 0.1811,\n",
            "        0.0917, 0.1464, 0.0613, 0.0502, 0.1494, 0.2571, 0.1827, 0.1067, 0.1521,\n",
            "        0.0627, 0.0536, 0.1365, 0.2453, 0.1808, 0.1046, 0.1754],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.07878609001636505\n",
            "------\n",
            "input_list [3, 4, 3, 3, 3, 4, 4, 3, 2, 1, 0, 0, 1, 2, 0, 0, 0, 0, -1, -1]\n",
            "input_tensor tensor([[0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0058, 0.0209, 0.1421, 0.6129, 0.1761, 0.0244, 0.0120, 0.0182, 0.0451,\n",
            "        0.1493, 0.4840, 0.2142, 0.0523, 0.0214, 0.0365, 0.0318, 0.1892, 0.3965,\n",
            "        0.2043, 0.0770, 0.0337, 0.0380, 0.0460, 0.1737, 0.3527, 0.2112, 0.0868,\n",
            "        0.0530, 0.0498, 0.0459, 0.1483, 0.3503, 0.1860, 0.1114, 0.0644, 0.0592,\n",
            "        0.0432, 0.1575, 0.3220, 0.1813, 0.0970, 0.1060, 0.0552, 0.0545, 0.1587,\n",
            "        0.2722, 0.1933, 0.0774, 0.1400, 0.0605, 0.0520, 0.1440, 0.2814, 0.1798,\n",
            "        0.0913, 0.1448, 0.0609, 0.0500, 0.1498, 0.2609, 0.1818, 0.1062, 0.1504,\n",
            "        0.0621, 0.0536, 0.1374, 0.2478, 0.1794, 0.1040, 0.1733],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.10178026556968689\n",
            "------\n",
            "input_list [4, 2, 3, 3, 4, 4, 2, 1, 1, 0, 0, 0, 2, 0, 0, 0, -1, -1, -1, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0058, 0.0208, 0.1415, 0.6168, 0.1742, 0.0242, 0.0119, 0.0180, 0.0447,\n",
            "        0.1491, 0.4881, 0.2127, 0.0519, 0.0213, 0.0362, 0.0316, 0.1888, 0.4005,\n",
            "        0.2025, 0.0763, 0.0335, 0.0378, 0.0457, 0.1732, 0.3564, 0.2102, 0.0861,\n",
            "        0.0526, 0.0494, 0.0457, 0.1486, 0.3528, 0.1851, 0.1105, 0.0639, 0.0588,\n",
            "        0.0431, 0.1583, 0.3252, 0.1801, 0.0964, 0.1050, 0.0547, 0.0542, 0.1599,\n",
            "        0.2743, 0.1920, 0.0770, 0.1378, 0.0600, 0.0519, 0.1445, 0.2840, 0.1785,\n",
            "        0.0908, 0.1432, 0.0604, 0.0500, 0.1501, 0.2641, 0.1809, 0.1057, 0.1486,\n",
            "        0.0616, 0.0539, 0.1381, 0.2499, 0.1781, 0.1034, 0.1712],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.10934431850910187\n",
            "------\n",
            "input_list [2, 2, 3, 3, 4, 2, 1, 1, 0, 0, 0, 2, 0, 0, -1, -1, -1, -1, 0, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0057, 0.0206, 0.1408, 0.6208, 0.1723, 0.0241, 0.0118, 0.0179, 0.0443,\n",
            "        0.1487, 0.4923, 0.2112, 0.0514, 0.0211, 0.0359, 0.0314, 0.1882, 0.4047,\n",
            "        0.2007, 0.0757, 0.0333, 0.0376, 0.0454, 0.1733, 0.3593, 0.2092, 0.0854,\n",
            "        0.0523, 0.0490, 0.0455, 0.1491, 0.3547, 0.1841, 0.1096, 0.0634, 0.0584,\n",
            "        0.0429, 0.1594, 0.3278, 0.1788, 0.0957, 0.1039, 0.0542, 0.0539, 0.1615,\n",
            "        0.2760, 0.1907, 0.0766, 0.1356, 0.0594, 0.0520, 0.1448, 0.2860, 0.1771,\n",
            "        0.0903, 0.1415, 0.0600, 0.0503, 0.1502, 0.2667, 0.1799, 0.1050, 0.1468,\n",
            "        0.0611, 0.0543, 0.1387, 0.2515, 0.1767, 0.1027, 0.1691],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.118320032954216\n",
            "------\n",
            "input_list [2, 3, 3, 4, 2, 1, 1, 0, 0, 0, 2, 0, 0, -1, -1, -1, -1, 0, 0, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0057, 0.0205, 0.1400, 0.6249, 0.1703, 0.0239, 0.0117, 0.0178, 0.0439,\n",
            "        0.1483, 0.4968, 0.2096, 0.0509, 0.0210, 0.0355, 0.0312, 0.1881, 0.4080,\n",
            "        0.1990, 0.0750, 0.0331, 0.0374, 0.0451, 0.1739, 0.3616, 0.2080, 0.0847,\n",
            "        0.0519, 0.0486, 0.0452, 0.1501, 0.3560, 0.1832, 0.1086, 0.0628, 0.0579,\n",
            "        0.0427, 0.1609, 0.3299, 0.1775, 0.0951, 0.1027, 0.0536, 0.0539, 0.1627,\n",
            "        0.2773, 0.1894, 0.0761, 0.1335, 0.0589, 0.0523, 0.1450, 0.2874, 0.1757,\n",
            "        0.0898, 0.1398, 0.0595, 0.0508, 0.1502, 0.2689, 0.1788, 0.1043, 0.1450,\n",
            "        0.0605, 0.0549, 0.1391, 0.2527, 0.1754, 0.1020, 0.1669],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.1314411461353302\n",
            "------\n",
            "input_list [4, 4, 5, 3, 2, 2, 0, 0, 1, 3, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0056, 0.0203, 0.1390, 0.6291, 0.1683, 0.0237, 0.0116, 0.0176, 0.0435,\n",
            "        0.1483, 0.5002, 0.2079, 0.0504, 0.0208, 0.0352, 0.0311, 0.1886, 0.4104,\n",
            "        0.1973, 0.0742, 0.0330, 0.0371, 0.0448, 0.1751, 0.3632, 0.2068, 0.0839,\n",
            "        0.0515, 0.0481, 0.0450, 0.1514, 0.3567, 0.1822, 0.1077, 0.0623, 0.0575,\n",
            "        0.0427, 0.1621, 0.3314, 0.1762, 0.0944, 0.1015, 0.0531, 0.0542, 0.1636,\n",
            "        0.2782, 0.1881, 0.0756, 0.1313, 0.0583, 0.0529, 0.1451, 0.2883, 0.1743,\n",
            "        0.0893, 0.1380, 0.0589, 0.0514, 0.1501, 0.2705, 0.1776, 0.1036, 0.1431,\n",
            "        0.0600, 0.0557, 0.1393, 0.2534, 0.1741, 0.1013, 0.1647],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.14593610167503357\n",
            "------\n",
            "input_list [6, 7, 5, 4, 4, 1, 2, 3, 5, 2, 1, 1, 1, 0, 1, 2, 2, 2, 2, 2]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0056, 0.0203, 0.1391, 0.6322, 0.1668, 0.0236, 0.0116, 0.0176, 0.0432,\n",
            "        0.1490, 0.5025, 0.2065, 0.0500, 0.0207, 0.0350, 0.0310, 0.1898, 0.4121,\n",
            "        0.1958, 0.0738, 0.0329, 0.0370, 0.0446, 0.1767, 0.3648, 0.2057, 0.0834,\n",
            "        0.0513, 0.0478, 0.0452, 0.1526, 0.3574, 0.1812, 0.1070, 0.0620, 0.0571,\n",
            "        0.0431, 0.1633, 0.3326, 0.1752, 0.0940, 0.1006, 0.0528, 0.0549, 0.1644,\n",
            "        0.2790, 0.1870, 0.0753, 0.1293, 0.0579, 0.0538, 0.1453, 0.2891, 0.1730,\n",
            "        0.0890, 0.1365, 0.0586, 0.0525, 0.1501, 0.2718, 0.1767, 0.1031, 0.1416,\n",
            "        0.0595, 0.0564, 0.1400, 0.2541, 0.1730, 0.1008, 0.1628],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.09728764742612839\n",
            "------\n",
            "input_list [7, 5, 4, 4, 1, 2, 3, 5, 2, 1, 1, 1, 0, 1, 2, 2, 2, 2, 2, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0056, 0.0201, 0.1387, 0.6355, 0.1648, 0.0234, 0.0115, 0.0175, 0.0427,\n",
            "        0.1494, 0.5054, 0.2047, 0.0495, 0.0206, 0.0346, 0.0308, 0.1905, 0.4145,\n",
            "        0.1941, 0.0730, 0.0327, 0.0367, 0.0446, 0.1780, 0.3655, 0.2044, 0.0827,\n",
            "        0.0509, 0.0474, 0.0452, 0.1540, 0.3572, 0.1802, 0.1061, 0.0615, 0.0566,\n",
            "        0.0432, 0.1647, 0.3333, 0.1738, 0.0934, 0.0993, 0.0523, 0.0553, 0.1655,\n",
            "        0.2792, 0.1856, 0.0748, 0.1274, 0.0574, 0.0545, 0.1457, 0.2894, 0.1716,\n",
            "        0.0884, 0.1348, 0.0581, 0.0532, 0.1498, 0.2735, 0.1755, 0.1023, 0.1398,\n",
            "        0.0590, 0.0570, 0.1405, 0.2550, 0.1717, 0.1000, 0.1606],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.0999579131603241\n",
            "------\n",
            "input_list [6, 5, 4, 2, 2, 3, 5, 2, 2, 2, 1, 1, 1, 2, 2, 3, 3, 2, 0, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0055, 0.0200, 0.1382, 0.6388, 0.1629, 0.0233, 0.0114, 0.0173, 0.0423,\n",
            "        0.1496, 0.5086, 0.2030, 0.0491, 0.0204, 0.0343, 0.0308, 0.1909, 0.4161,\n",
            "        0.1924, 0.0723, 0.0326, 0.0365, 0.0446, 0.1797, 0.3656, 0.2031, 0.0820,\n",
            "        0.0506, 0.0469, 0.0453, 0.1557, 0.3567, 0.1792, 0.1051, 0.0610, 0.0562,\n",
            "        0.0433, 0.1664, 0.3337, 0.1726, 0.0927, 0.0982, 0.0518, 0.0557, 0.1670,\n",
            "        0.2791, 0.1843, 0.0743, 0.1255, 0.0568, 0.0551, 0.1459, 0.2901, 0.1702,\n",
            "        0.0879, 0.1331, 0.0576, 0.0539, 0.1495, 0.2758, 0.1743, 0.1016, 0.1380,\n",
            "        0.0585, 0.0575, 0.1409, 0.2565, 0.1705, 0.0993, 0.1585],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.10752324014902115\n",
            "------\n",
            "input_list [5, 4, 2, 2, 4, 5, 3, 2, 2, 2, 1, 1, 2, 3, 3, 3, 2, 0, 0, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0055, 0.0199, 0.1376, 0.6423, 0.1611, 0.0231, 0.0113, 0.0172, 0.0424,\n",
            "        0.1496, 0.5108, 0.2011, 0.0486, 0.0203, 0.0340, 0.0309, 0.1918, 0.4169,\n",
            "        0.1908, 0.0716, 0.0324, 0.0362, 0.0445, 0.1819, 0.3655, 0.2018, 0.0814,\n",
            "        0.0502, 0.0465, 0.0453, 0.1578, 0.3558, 0.1783, 0.1042, 0.0604, 0.0557,\n",
            "        0.0434, 0.1684, 0.3337, 0.1713, 0.0921, 0.0970, 0.0513, 0.0561, 0.1682,\n",
            "        0.2798, 0.1830, 0.0738, 0.1237, 0.0563, 0.0557, 0.1461, 0.2914, 0.1689,\n",
            "        0.0874, 0.1315, 0.0571, 0.0545, 0.1492, 0.2784, 0.1732, 0.1009, 0.1363,\n",
            "        0.0581, 0.0580, 0.1412, 0.2576, 0.1698, 0.0986, 0.1564],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.12017207592725754\n",
            "------\n",
            "input_list [11, 9, 9, 11, 12, 10, 9, 9, 8, 8, 8, 9, 10, 10, 10, 9, 7, 7, 6, 6]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0054, 0.0200, 0.1371, 0.6447, 0.1596, 0.0230, 0.0113, 0.0172, 0.0426,\n",
            "        0.1502, 0.5122, 0.1996, 0.0482, 0.0202, 0.0338, 0.0310, 0.1933, 0.4170,\n",
            "        0.1893, 0.0712, 0.0324, 0.0361, 0.0445, 0.1846, 0.3652, 0.2006, 0.0810,\n",
            "        0.0500, 0.0463, 0.0454, 0.1602, 0.3549, 0.1773, 0.1036, 0.0601, 0.0553,\n",
            "        0.0436, 0.1703, 0.3343, 0.1704, 0.0918, 0.0962, 0.0510, 0.0566, 0.1691,\n",
            "        0.2812, 0.1819, 0.0735, 0.1219, 0.0559, 0.0562, 0.1464, 0.2933, 0.1678,\n",
            "        0.0871, 0.1300, 0.0568, 0.0551, 0.1490, 0.2806, 0.1727, 0.1005, 0.1348,\n",
            "        0.0577, 0.0584, 0.1414, 0.2585, 0.1697, 0.0980, 0.1545],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.11678115278482437\n",
            "------\n",
            "input_list [7, 7, 9, 11, 8, 7, 7, 7, 6, 6, 8, 8, 8, 8, 7, 5, 5, 5, 5, -1]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0054, 0.0201, 0.1365, 0.6472, 0.1580, 0.0229, 0.0112, 0.0171, 0.0427,\n",
            "        0.1508, 0.5129, 0.1987, 0.0478, 0.0201, 0.0336, 0.0311, 0.1946, 0.4168,\n",
            "        0.1888, 0.0706, 0.0323, 0.0359, 0.0446, 0.1869, 0.3656, 0.1994, 0.0804,\n",
            "        0.0497, 0.0459, 0.0455, 0.1623, 0.3536, 0.1769, 0.1029, 0.0597, 0.0549,\n",
            "        0.0437, 0.1718, 0.3347, 0.1693, 0.0917, 0.0952, 0.0506, 0.0569, 0.1700,\n",
            "        0.2820, 0.1808, 0.0735, 0.1204, 0.0555, 0.0567, 0.1466, 0.2950, 0.1667,\n",
            "        0.0867, 0.1296, 0.0564, 0.0556, 0.1486, 0.2823, 0.1722, 0.1005, 0.1333,\n",
            "        0.0574, 0.0589, 0.1415, 0.2591, 0.1696, 0.0979, 0.1526],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.10941419750452042\n",
            "------\n",
            "input_list [6, 8, 10, 7, 6, 6, 5, 5, 5, 6, 7, 7, 7, 6, 4, 4, 4, 3, -2, -1]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0054, 0.0202, 0.1358, 0.6500, 0.1565, 0.0227, 0.0112, 0.0170, 0.0428,\n",
            "        0.1512, 0.5142, 0.1977, 0.0474, 0.0200, 0.0333, 0.0311, 0.1955, 0.4172,\n",
            "        0.1879, 0.0700, 0.0322, 0.0357, 0.0445, 0.1888, 0.3653, 0.1988, 0.0799,\n",
            "        0.0494, 0.0456, 0.0455, 0.1641, 0.3519, 0.1764, 0.1027, 0.0593, 0.0545,\n",
            "        0.0437, 0.1730, 0.3347, 0.1682, 0.0922, 0.0941, 0.0503, 0.0572, 0.1706,\n",
            "        0.2825, 0.1796, 0.0738, 0.1189, 0.0551, 0.0570, 0.1466, 0.2959, 0.1656,\n",
            "        0.0867, 0.1289, 0.0560, 0.0560, 0.1481, 0.2835, 0.1715, 0.1010, 0.1318,\n",
            "        0.0571, 0.0591, 0.1415, 0.2593, 0.1693, 0.0981, 0.1506],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.10744694620370865\n",
            "------\n",
            "input_list [8, 10, 7, 6, 6, 6, 5, 6, 7, 7, 7, 7, 7, 5, 5, 4, 4, -2, 0, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0054, 0.0203, 0.1350, 0.6529, 0.1549, 0.0226, 0.0111, 0.0169, 0.0428,\n",
            "        0.1514, 0.5159, 0.1967, 0.0470, 0.0199, 0.0331, 0.0311, 0.1961, 0.4171,\n",
            "        0.1878, 0.0695, 0.0321, 0.0355, 0.0444, 0.1904, 0.3647, 0.1988, 0.0793,\n",
            "        0.0491, 0.0452, 0.0455, 0.1657, 0.3502, 0.1765, 0.1026, 0.0589, 0.0540,\n",
            "        0.0438, 0.1740, 0.3343, 0.1671, 0.0931, 0.0931, 0.0499, 0.0574, 0.1710,\n",
            "        0.2829, 0.1784, 0.0744, 0.1174, 0.0547, 0.0573, 0.1466, 0.2965, 0.1650,\n",
            "        0.0867, 0.1282, 0.0556, 0.0564, 0.1477, 0.2844, 0.1712, 0.1013, 0.1302,\n",
            "        0.0567, 0.0594, 0.1414, 0.2593, 0.1695, 0.0983, 0.1487],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.12397468835115433\n",
            "------\n",
            "TESTING: 50\n",
            "Epoch: 0 - item: 0\n",
            "input_list [4, 4, 4, 2, 3, 3, 2, 1, 3, 5, 4, 3, 4, 4, 2, 2, 2, 1, 0, 0]\n",
            "input_oh [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]]\n",
            "act0 0 pred: [('0', 0.6558672189712524), ('3', 0.15354694426059723), ('-3', 0.13420039415359497), ('7', 0.022519998252391815), ('-7', 0.02036987617611885), ('10', 0.011122810654342175), ('-10', 0.005349442828446627)]\n",
            "act0 0 pred: [('0', 0.5167840719223022), ('3', 0.19659045338630676), ('-3', 0.1516038477420807), ('7', 0.04670146480202675), ('-7', 0.04280603304505348), ('10', 0.019875237718224525), ('-10', 0.016865134239196777)]\n",
            "act0 0 pred: [('0', 0.4165287911891937), ('-3', 0.19653241336345673), ('3', 0.18766270577907562), ('7', 0.06957446038722992), ('-10', 0.0329279750585556), ('10', 0.032050151377916336), ('-7', 0.03116656467318535)]\n",
            "act0 0 pred: [('0', 0.3638662099838257), ('3', 0.19933661818504333), ('-3', 0.1917709857225418), ('7', 0.07886940240859985), ('10', 0.04882500693202019), ('-7', 0.04440170153975487), ('-10', 0.03539416939020157)]\n",
            "act0 0 pred: [('0', 0.3483213484287262), ('3', 0.17642973363399506), ('-3', 0.16710303723812103), ('7', 0.10311660170555115), ('10', 0.05858343467116356), ('-7', 0.045587509870529175), ('-10', 0.04496695101261139)]\n",
            "act0 -3 pred: [('0', 0.33369651436805725), ('-3', 0.1748669147491455), ('3', 0.16609206795692444), ('7', 0.09442096203565598), ('10', 0.09214666485786438), ('-10', 0.053655121475458145), ('-7', 0.04382320120930672)]\n",
            "act0 0 pred: [('0', 0.28304341435432434), ('3', 0.17737895250320435), ('-3', 0.17128479480743408), ('10', 0.11597057431936264), ('7', 0.07531559467315674), ('-7', 0.05764198675751686), ('-10', 0.04962790384888649)]\n",
            "act0 0 pred: [('0', 0.29688364267349243), ('3', 0.16484598815441132), ('-3', 0.1466052383184433), ('10', 0.1275612711906433), ('7', 0.08666011691093445), ('-7', 0.05753457173705101), ('-10', 0.05435779690742493)]\n",
            "act0 0 pred: [('0', 0.2849152088165283), ('3', 0.17148399353027344), ('-3', 0.147213876247406), ('10', 0.1288604885339737), ('7', 0.10162881016731262), ('-7', 0.05676580220460892), ('-10', 0.05533769354224205)]\n",
            "act0 0 pred: [('0', 0.2591075599193573), ('3', 0.16968031227588654), ('10', 0.14696131646633148), ('-3', 0.14120294153690338), ('7', 0.09896371513605118), ('-7', 0.05961485952138901), ('-10', 0.05642277002334595)]\n",
            "--------\n",
            "Epoch: 0 - item: 1\n",
            "input_list [5, 4, 2, 3, 3, 2, 1, 3, 5, 4, 3, 4, 4, 2, 3, 2, 1, 0, 0, 0]\n",
            "input_oh [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]]\n",
            "act0 0 pred: [('0', 0.6558642983436584), ('3', 0.15350310504436493), ('-3', 0.13416466116905212), ('7', 0.02251373417675495), ('-7', 0.02035888284444809), ('10', 0.01111646555364132), ('-10', 0.005346236750483513)]\n",
            "act0 0 pred: [('0', 0.5167986154556274), ('3', 0.19655217230319977), ('-3', 0.1515713334083557), ('7', 0.046685222536325455), ('-7', 0.04278883337974548), ('10', 0.01986420527100563), ('-10', 0.01685420237481594)]\n",
            "act0 0 pred: [('0', 0.41653329133987427), ('-3', 0.19650201499462128), ('3', 0.18763314187526703), ('7', 0.06955063343048096), ('-10', 0.03291288763284683), ('10', 0.03203928470611572), ('-7', 0.031153034418821335)]\n",
            "act0 0 pred: [('0', 0.36381736397743225), ('3', 0.1993102729320526), ('-3', 0.1917608231306076), ('7', 0.07884930819272995), ('10', 0.0488099604845047), ('-7', 0.04438084363937378), ('-10', 0.03537651151418686)]\n",
            "act0 -3 pred: [('0', 0.3482905924320221), ('3', 0.1764279305934906), ('-3', 0.16708466410636902), ('7', 0.10308115184307098), ('10', 0.05856052786111832), ('-7', 0.04557155817747116), ('-10', 0.04494646191596985)]\n",
            "act0 0 pred: [('0', 0.33368563652038574), ('-3', 0.17484036087989807), ('3', 0.1660614013671875), ('7', 0.09439301490783691), ('10', 0.09211590141057968), ('-10', 0.05363888666033745), ('-7', 0.043805673718452454)]\n",
            "act0 0 pred: [('0', 0.28302067518234253), ('3', 0.17734649777412415), ('-3', 0.17126892507076263), ('10', 0.11595377326011658), ('7', 0.07528899610042572), ('-7', 0.057624246925115585), ('-10', 0.04960762336850166)]\n",
            "act0 0 pred: [('0', 0.2968467175960541), ('3', 0.1648271530866623), ('-3', 0.14658120274543762), ('10', 0.12753267586231232), ('7', 0.08663370460271835), ('-7', 0.05751216039061546), ('-10', 0.054335884749889374)]\n",
            "act0 0 pred: [('0', 0.2848975658416748), ('3', 0.1714458167552948), ('-3', 0.14719796180725098), ('10', 0.12883318960666656), ('7', 0.10159911960363388), ('-7', 0.05674552172422409), ('-10', 0.05531561002135277)]\n",
            "act0 0 pred: [('0', 0.25907406210899353), ('3', 0.16965089738368988), ('10', 0.14693203568458557), ('-3', 0.14118266105651855), ('7', 0.09893761575222015), ('-7', 0.059599123895168304), ('-10', 0.056407630443573)]\n",
            "--------\n",
            "Epoch: 0 - item: 2\n",
            "input_list [4, 2, 3, 3, 2, 1, 3, 5, 4, 3, 4, 4, 2, 3, 2, 1, 0, 0, 0, 0]\n",
            "input_oh [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]]\n",
            "act0 0 pred: [('0', 0.6558619141578674), ('3', 0.1534714698791504), ('-3', 0.13413922488689423), ('7', 0.022508908063173294), ('-7', 0.020350631326436996), ('10', 0.011111801490187645), ('-10', 0.00534377247095108)]\n",
            "act0 0 pred: [('0', 0.5168094038963318), ('3', 0.19652332365512848), ('-3', 0.1515466719865799), ('7', 0.04667309671640396), ('-7', 0.042776092886924744), ('10', 0.019855884835124016), ('-10', 0.01684620790183544)]\n",
            "act0 0 pred: [('0', 0.4165349304676056), ('-3', 0.19647935032844543), ('3', 0.18761077523231506), ('7', 0.06953301280736923), ('-10', 0.03290175646543503), ('10', 0.03203113004565239), ('-7', 0.031143277883529663)]\n",
            "act0 -3 pred: [('0', 0.36378219723701477), ('3', 0.199290469288826), ('-3', 0.1917518675327301), ('7', 0.0788341760635376), ('10', 0.04879893362522125), ('-7', 0.04436521232128143), ('-10', 0.03536342456936836)]\n",
            "act0 0 pred: [('0', 0.348270446062088), ('3', 0.17642523348331451), ('-3', 0.16707085072994232), ('7', 0.10305555909872055), ('10', 0.05854332074522972), ('-7', 0.045559220016002655), ('-10', 0.04493124410510063)]\n",
            "act0 0 pred: [('0', 0.3336760997772217), ('-3', 0.1748199760913849), ('3', 0.16603855788707733), ('7', 0.09437185525894165), ('10', 0.09209375083446503), ('-10', 0.053626421838998795), ('-7', 0.043792594224214554)]\n",
            "act0 0 pred: [('0', 0.2830045223236084), ('3', 0.17732276022434235), ('-3', 0.1712556928396225), ('10', 0.1159408763051033), ('7', 0.07526934146881104), ('-7', 0.05761090666055679), ('-10', 0.04959256574511528)]\n",
            "act0 0 pred: [('0', 0.2968197166919708), ('3', 0.16481398046016693), ('-3', 0.14656268060207367), ('10', 0.12751132249832153), ('7', 0.08661354333162308), ('-7', 0.057494811713695526), ('-10', 0.054319728165864944)]\n",
            "act0 0 pred: [('0', 0.28488343954086304), ('3', 0.1714172512292862), ('-3', 0.14718571305274963), ('10', 0.1288127303123474), ('7', 0.10157699882984161), ('-7', 0.056730300188064575), ('-10', 0.05529920384287834)]\n",
            "act0 -3 pred: [('0', 0.2590470612049103), ('3', 0.1696288287639618), ('10', 0.14691032469272614), ('-3', 0.14116664230823517), ('7', 0.09891798347234726), ('-7', 0.05958735570311546), ('-10', 0.056396301835775375)]\n",
            "--------\n",
            "Epoch: 0 - item: 3\n",
            "input_list [2, 3, 3, 1, 1, 3, 4, 4, 3, 4, 4, 2, 2, 2, 1, 0, 0, 0, 0, 0]\n",
            "input_oh [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]]\n",
            "act0 0 pred: [('0', 0.6558564305305481), ('3', 0.15344898402690887), ('-3', 0.1341223418712616), ('7', 0.022506138309836388), ('-7', 0.020345663651823997), ('10', 0.011108972132205963), ('-10', 0.005342366173863411)]\n",
            "act0 0 pred: [('0', 0.5168151259422302), ('3', 0.1965060830116272), ('-3', 0.15153147280216217), ('7', 0.04666568338871002), ('-7', 0.042768217623233795), ('10', 0.01985081285238266), ('-10', 0.016841422766447067)]\n",
            "act0 -3 pred: [('0', 0.4165349006652832), ('-3', 0.19646655023097992), ('3', 0.18759649991989136), ('7', 0.069522924721241), ('-10', 0.03289458155632019), ('10', 0.03202654793858528), ('-7', 0.031137079000473022)]\n",
            "act0 0 pred: [('0', 0.36375778913497925), ('3', 0.19927816092967987), ('-3', 0.19174902141094208), ('7', 0.07882554084062576), ('10', 0.04879261925816536), ('-7', 0.044354863464832306), ('-10', 0.035354986786842346)]\n",
            "act0 0 pred: [('0', 0.34825587272644043), ('3', 0.17642506957054138), ('-3', 0.16706278920173645), ('7', 0.10303830355405807), ('10', 0.058532439172267914), ('-7', 0.04555191472172737), ('-10', 0.044922035187482834)]\n",
            "act0 -3 pred: [('0', 0.33366861939430237), ('-3', 0.17480742931365967), ('3', 0.16602422297000885), ('7', 0.09435950219631195), ('10', 0.09208016842603683), ('-10', 0.05361861735582352), ('-7', 0.04378444701433182)]\n",
            "act0 0 pred: [('0', 0.2829955220222473), ('3', 0.17730675637722015), ('-3', 0.17124901711940765), ('10', 0.1159333884716034), ('7', 0.07525679469108582), ('-7', 0.05760325491428375), ('-10', 0.049583569169044495)]\n",
            "act0 -3 pred: [('0', 0.29680225253105164), ('3', 0.16480477154254913), ('-3', 0.14655131101608276), ('10', 0.12749874591827393), ('7', 0.08660194277763367), ('-7', 0.05748451128602028), ('-10', 0.05430944263935089)]\n",
            "act0 -3 pred: [('0', 0.28487685322761536), ('3', 0.17139945924282074), ('-3', 0.1471792459487915), ('10', 0.12880074977874756), ('7', 0.10156309604644775), ('-7', 0.05672132223844528), ('-10', 0.0552893802523613)]\n",
            "act0 -3 pred: [('0', 0.2590324282646179), ('3', 0.1696147471666336), ('10', 0.14689600467681885), ('-3', 0.14115802943706512), ('7', 0.09890644252300262), ('-7', 0.05957987532019615), ('-10', 0.05639045685529709)]\n",
            "--------\n",
            "Epoch: 0 - item: 4\n",
            "input_list [4, 4, 3, 2, 4, 6, 5, 4, 5, 5, 3, 4, 3, 2, 1, 1, 1, 0, 0, 1]\n",
            "input_oh [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]]\n",
            "act0 0 pred: [('0', 0.6558582782745361), ('3', 0.15344929695129395), ('-3', 0.13412219285964966), ('7', 0.02250583842396736), ('-7', 0.020345406606793404), ('10', 0.011108815670013428), ('-10', 0.005342237185686827)]\n",
            "act0 -3 pred: [('0', 0.516815721988678), ('3', 0.19650529325008392), ('-3', 0.1515306979417801), ('7', 0.04666529968380928), ('-7', 0.042767833918333054), ('10', 0.019850539043545723), ('-10', 0.016841234639286995)]\n",
            "act0 0 pred: [('0', 0.4165347218513489), ('-3', 0.1964654177427292), ('3', 0.18759594857692719), ('7', 0.06952224671840668), ('-10', 0.03289441391825676), ('10', 0.032026082277297974), ('-7', 0.031136861070990562)]\n",
            "act0 0 pred: [('0', 0.3637579083442688), ('3', 0.19927743077278137), ('-3', 0.19174757599830627), ('7', 0.07882478088140488), ('10', 0.04879220202565193), ('-7', 0.04435466229915619), ('-10', 0.03535480797290802)]\n",
            "act0 0 pred: [('0', 0.34825649857521057), ('3', 0.17642390727996826), ('-3', 0.1670619696378708), ('7', 0.10303839296102524), ('10', 0.05853220447897911), ('-7', 0.04555134102702141), ('-10', 0.04492160677909851)]\n",
            "act0 0 pred: [('0', 0.33366867899894714), ('-3', 0.17480672895908356), ('3', 0.16602389514446259), ('7', 0.09435883164405823), ('10', 0.09207955747842789), ('-10', 0.05361824110150337), ('-7', 0.04378403723239899)]\n",
            "act0 0 pred: [('0', 0.28299498558044434), ('3', 0.1773066371679306), ('-3', 0.1712479591369629), ('10', 0.1159326434135437), ('7', 0.07525644451379776), ('-7', 0.05760263279080391), ('-10', 0.04958310350775719)]\n",
            "act0 0 pred: [('0', 0.2968018352985382), ('3', 0.16480444371700287), ('-3', 0.14655065536499023), ('10', 0.12749792635440826), ('7', 0.08660096675157547), ('-7', 0.05748381093144417), ('-10', 0.054309096187353134)]\n",
            "act0 0 pred: [('0', 0.28487563133239746), ('3', 0.17139896750450134), ('-3', 0.14717841148376465), ('10', 0.12879982590675354), ('7', 0.10156257450580597), ('-7', 0.05672072246670723), ('-10', 0.055288784205913544)]\n",
            "act0 0 pred: [('0', 0.2590309679508209), ('3', 0.16961415112018585), ('10', 0.14689575135707855), ('-3', 0.1411568820476532), ('7', 0.09890575706958771), ('-7', 0.059579476714134216), ('-10', 0.05638952553272247)]\n",
            "--------\n",
            "Epoch: 0 - item: 5\n",
            "input_list [5, 3, 3, 5, 6, 6, 5, 6, 6, 4, 4, 4, 3, 2, 1, 1, 1, 1, 2, 0]\n",
            "input_oh [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]]\n",
            "act0 0 pred: [('0', 0.6558593511581421), ('3', 0.1535552591085434), ('-3', 0.13421288132667542), ('7', 0.02252046763896942), ('-7', 0.02037244848906994), ('10', 0.011124935001134872), ('-10', 0.005349988583475351)]\n",
            "act0 0 pred: [('0', 0.5167875289916992), ('3', 0.19659967720508575), ('-3', 0.15160100162029266), ('7', 0.046704042702913284), ('-7', 0.04281117394566536), ('10', 0.019877132028341293), ('-10', 0.01687025837600231)]\n",
            "act0 0 pred: [('0', 0.4165101647377014), ('-3', 0.19653984904289246), ('3', 0.1876627504825592), ('7', 0.06958547979593277), ('-10', 0.032932501286268234), ('10', 0.03205295279622078), ('-7', 0.031170295551419258)]\n",
            "act0 0 pred: [('0', 0.36386817693710327), ('3', 0.19933751225471497), ('-3', 0.19177034497261047), ('7', 0.07887504994869232), ('10', 0.04883308708667755), ('-7', 0.0444018729031086), ('-10', 0.035398758947849274)]\n",
            "act0 0 pred: [('0', 0.34834417700767517), ('3', 0.1764250546693802), ('-3', 0.16710489988327026), ('7', 0.10312771797180176), ('10', 0.058587606996297836), ('-7', 0.04558919742703438), ('-10', 0.04497247189283371)]\n",
            "act0 0 pred: [('0', 0.33368125557899475), ('-3', 0.17486919462680817), ('3', 0.1661001741886139), ('7', 0.09443002939224243), ('10', 0.09216198325157166), ('-10', 0.05365542322397232), ('-7', 0.04382481053471565)]\n",
            "act0 0 pred: [('0', 0.28305765986442566), ('3', 0.17738540470600128), ('-3', 0.171285018324852), ('10', 0.11596810072660446), ('7', 0.07532153278589249), ('-7', 0.05764498561620712), ('-10', 0.04963371530175209)]\n",
            "act0 0 pred: [('0', 0.29688721895217896), ('3', 0.16484621167182922), ('-3', 0.1466033011674881), ('10', 0.12756668031215668), ('7', 0.08666561543941498), ('-7', 0.05753619596362114), ('-10', 0.054362669587135315)]\n",
            "act0 0 pred: [('0', 0.28492119908332825), ('3', 0.17149105668067932), ('-3', 0.14721931517124176), ('10', 0.12886567413806915), ('7', 0.10163591802120209), ('-7', 0.05677036568522453), ('-10', 0.055341508239507675)]\n",
            "act0 0 pred: [('0', 0.25911110639572144), ('3', 0.16968069970607758), ('10', 0.14696843922138214), ('-3', 0.1412033885717392), ('7', 0.09897314757108688), ('-7', 0.059615712612867355), ('-10', 0.05642646178603172)]\n",
            "--------\n",
            "Epoch: 0 - item: 6\n",
            "input_list [5, 4, 7, 8, 7, 6, 8, 7, 5, 6, 6, 5, 3, 3, 3, 3, 3, 3, 2, 1]\n",
            "input_oh [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]]\n",
            "act0 3 pred: [('0', 0.6558709144592285), ('3', 0.15370675921440125), ('-3', 0.13433575630187988), ('7', 0.022541925311088562), ('-7', 0.020410336554050446), ('10', 0.01114682573825121), ('-10', 0.005361057817935944)]\n",
            "act0 3 pred: [('0', 0.5167391300201416), ('3', 0.19673283398151398), ('-3', 0.15171363949775696), ('7', 0.04675972834229469), ('-7', 0.04287032037973404), ('10', 0.019915195181965828), ('-10', 0.016908079385757446)]\n",
            "act0 0 pred: [('0', 0.41649577021598816), ('-3', 0.1966438889503479), ('3', 0.18776443600654602), ('7', 0.069667749106884), ('-10', 0.03298451378941536), ('10', 0.03209010139107704), ('-7', 0.031216664239764214)]\n",
            "act0 0 pred: [('0', 0.36403629183769226), ('3', 0.1994277536869049), ('-3', 0.19180521368980408), ('7', 0.07894368469715118), ('10', 0.04888501018285751), ('-7', 0.04447372257709503), ('-10', 0.035459596663713455)]\n",
            "act0 0 pred: [('0', 0.34844982624053955), ('3', 0.17643068730831146), ('-3', 0.16716738045215607), ('7', 0.10324998944997787), ('10', 0.05866684392094612), ('-7', 0.04564463719725609), ('-10', 0.04504283517599106)]\n",
            "act0 0 pred: [('0', 0.3337174654006958), ('-3', 0.1749608963727951), ('3', 0.16620716452598572), ('7', 0.0945274829864502), ('10', 0.09226725995540619), ('-10', 0.05371151864528656), ('-7', 0.043885182589292526)]\n",
            "act0 0 pred: [('0', 0.28313571214675903), ('3', 0.17749638855457306), ('-3', 0.17134015262126923), ('10', 0.11602547019720078), ('7', 0.07541331648826599), ('-7', 0.057705964893102646), ('-10', 0.049703728407621384)]\n",
            "act0 0 pred: [('0', 0.29701393842697144), ('3', 0.1649094969034195), ('-3', 0.14668555557727814), ('10', 0.12766459584236145), ('7', 0.08675570785999298), ('-7', 0.057613760232925415), ('-10', 0.05443807691335678)]\n",
            "act0 0 pred: [('0', 0.28498217463493347), ('3', 0.1716238111257553), ('-3', 0.14727412164211273), ('10', 0.12895919382572174), ('7', 0.10173855721950531), ('-7', 0.0568402037024498), ('-10', 0.055417392402887344)]\n",
            "act0 0 pred: [('0', 0.25922515988349915), ('3', 0.16978183388710022), ('10', 0.1470702439546585), ('-3', 0.14127330482006073), ('7', 0.09906355291604996), ('-7', 0.059669870883226395), ('-10', 0.05647839605808258)]\n",
            "--------\n",
            "Epoch: 0 - item: 7\n",
            "input_list [2, 4, 6, 5, 4, 5, 5, 3, 4, 3, 2, 1, 1, 1, 0, 0, 1, 0, 0, -2]\n",
            "input_oh [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]]\n",
            "act0 0 pred: [('0', 0.6558464765548706), ('3', 0.15341445803642273), ('-3', 0.13408879935741425), ('7', 0.022501187399029732), ('-7', 0.020335882902145386), ('10', 0.011105766519904137), ('-10', 0.0053391242399811745)]\n",
            "act0 0 pred: [('0', 0.5168558955192566), ('3', 0.196477472782135), ('-3', 0.1514817625284195), ('7', 0.046649329364299774), ('-7', 0.04275279492139816), ('10', 0.01984025351703167), ('-10', 0.016834696754813194)]\n",
            "act0 0 pred: [('0', 0.4165038764476776), ('-3', 0.19641520082950592), ('3', 0.18754559755325317), ('7', 0.06950987875461578), ('-10', 0.03288476914167404), ('10', 0.03201684728264809), ('-7', 0.03112248331308365)]\n",
            "act0 0 pred: [('0', 0.3637012541294098), ('3', 0.19923582673072815), ('-3', 0.19174055755138397), ('7', 0.07880886644124985), ('10', 0.04878782853484154), ('-7', 0.04432934522628784), ('-10', 0.035336755216121674)]\n",
            "act0 0 pred: [('0', 0.3482207953929901), ('3', 0.17641721665859222), ('-3', 0.1670447736978531), ('7', 0.10300596803426743), ('10', 0.05851045995950699), ('-7', 0.04553357884287834), ('-10', 0.044903505593538284)]\n",
            "act0 0 pred: [('0', 0.3336389660835266), ('-3', 0.1747768223285675), ('3', 0.16600041091442108), ('7', 0.0943368673324585), ('10', 0.09205358475446701), ('-10', 0.05359874293208122), ('-7', 0.04376150295138359)]\n",
            "act0 0 pred: [('0', 0.28299614787101746), ('3', 0.17727141082286835), ('-3', 0.17122015357017517), ('10', 0.1158977672457695), ('7', 0.07522926479578018), ('-7', 0.05758200213313103), ('-10', 0.04956645146012306)]\n",
            "act0 0 pred: [('0', 0.29673266410827637), ('3', 0.16477647423744202), ('-3', 0.146523579955101), ('10', 0.12746334075927734), ('7', 0.08657346665859222), ('-7', 0.05745706334710121), ('-10', 0.054291605949401855)]\n",
            "act0 -3 pred: [('0', 0.2848621606826782), ('3', 0.17136584222316742), ('-3', 0.1471676379442215), ('10', 0.12876762449741364), ('7', 0.10153844952583313), ('-7', 0.05669798329472542), ('-10', 0.05526416748762131)]\n",
            "act0 -3 pred: [('0', 0.25899380445480347), ('3', 0.16957268118858337), ('10', 0.1468726545572281), ('-3', 0.14112859964370728), ('7', 0.09888464212417603), ('-7', 0.05956504866480827), ('-10', 0.05637265369296074)]\n",
            "--------\n",
            "Epoch: 0 - item: 8\n",
            "input_list [4, 6, 5, 4, 5, 5, 3, 4, 3, 2, 1, 1, 1, 0, 0, 1, 0, 0, -2, 0]\n",
            "input_oh [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]]\n",
            "act0 0 pred: [('0', 0.6558470726013184), ('3', 0.15341603755950928), ('-3', 0.13409218192100525), ('7', 0.022500505670905113), ('-7', 0.02033562958240509), ('10', 0.011103992350399494), ('-10', 0.005339840892702341)]\n",
            "act0 0 pred: [('0', 0.5168347954750061), ('3', 0.19647268950939178), ('-3', 0.15150541067123413), ('7', 0.046651311218738556), ('-7', 0.042754512280225754), ('10', 0.01984095387160778), ('-10', 0.016832616180181503)]\n",
            "act0 0 pred: [('0', 0.41653749346733093), ('-3', 0.19643662869930267), ('3', 0.18757086992263794), ('7', 0.06950245052576065), ('-10', 0.032880865037441254), ('10', 0.032018031924963), ('-7', 0.031125089153647423)]\n",
            "act0 0 pred: [('0', 0.3637200593948364), ('3', 0.19925343990325928), ('-3', 0.19173601269721985), ('7', 0.07880838215351105), ('10', 0.048780910670757294), ('-7', 0.04433684051036835), ('-10', 0.035338692367076874)]\n",
            "act0 0 pred: [('0', 0.3482198715209961), ('3', 0.1764257699251175), ('-3', 0.16704712808132172), ('7', 0.10300634056329727), ('10', 0.058511510491371155), ('-7', 0.045538291335105896), ('-10', 0.04490506649017334)]\n",
            "act0 0 pred: [('0', 0.3336610794067383), ('-3', 0.17478607594966888), ('3', 0.1660013049840927), ('7', 0.09433440864086151), ('10', 0.09205364435911179), ('-10', 0.05360269919037819), ('-7', 0.043767720460891724)]\n",
            "act0 0 pred: [('0', 0.2829812467098236), ('3', 0.17727717757225037), ('-3', 0.17123359441757202), ('10', 0.11591842025518417), ('7', 0.07523467391729355), ('-7', 0.05758552625775337), ('-10', 0.0495658814907074)]\n",
            "act0 -3 pred: [('0', 0.29677093029022217), ('3', 0.16479282081127167), ('-3', 0.14653131365776062), ('10', 0.12747256457805634), ('7', 0.08657978475093842), ('-7', 0.05746341869235039), ('-10', 0.05429409071803093)]\n",
            "act0 -3 pred: [('0', 0.28486374020576477), ('3', 0.1713690161705017), ('-3', 0.14716219902038574), ('10', 0.1287737637758255), ('7', 0.10154031962156296), ('-7', 0.05670475214719772), ('-10', 0.05527110397815704)]\n",
            "act0 -3 pred: [('0', 0.25899893045425415), ('3', 0.16958929598331451), ('10', 0.14687013626098633), ('-3', 0.14113947749137878), ('7', 0.09888185560703278), ('-7', 0.05956760793924332), ('-10', 0.05638021230697632)]\n",
            "--------\n",
            "Epoch: 0 - item: 9\n",
            "input_list [7, 6, 5, 6, 6, 4, 4, 4, 3, 2, 2, 1, 1, 1, 2, 0, 0, -1, 0, 0]\n",
            "input_oh [[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]]\n",
            "act0 0 pred: [('0', 0.655856192111969), ('3', 0.15343785285949707), ('-3', 0.13411390781402588), ('7', 0.022504091262817383), ('-7', 0.020342571660876274), ('10', 0.011107244528830051), ('-10', 0.005341352894902229)]\n",
            "act0 0 pred: [('0', 0.5168184638023376), ('3', 0.19649551808834076), ('-3', 0.15152201056480408), ('7', 0.0466611348092556), ('-7', 0.04276341199874878), ('10', 0.01984754204750061), ('-10', 0.01683865301311016)]\n",
            "act0 0 pred: [('0', 0.41653308272361755), ('-3', 0.19645839929580688), ('3', 0.18758805096149445), ('7', 0.0695163682103157), ('-10', 0.032890405505895615), ('10', 0.0320233479142189), ('-7', 0.03113371692597866)]\n",
            "act0 0 pred: [('0', 0.36374586820602417), ('3', 0.19927038252353668), ('-3', 0.1917441338300705), ('7', 0.07881952077150345), ('10', 0.04878872260451317), ('-7', 0.04434889182448387), ('-10', 0.03535015881061554)]\n",
            "act0 0 pred: [('0', 0.3482506573200226), ('3', 0.17642228305339813), ('-3', 0.1670570820569992), ('7', 0.10302944481372833), ('10', 0.058526214212179184), ('-7', 0.045546822249889374), ('-10', 0.044916536659002304)]\n",
            "act0 0 pred: [('0', 0.33366331458091736), ('-3', 0.1747991144657135), ('3', 0.16601592302322388), ('7', 0.09435149282217026), ('10', 0.09207233786582947), ('-10', 0.053613465279340744), ('-7', 0.043779466301202774)]\n",
            "act0 0 pred: [('0', 0.2829907238483429), ('3', 0.1772981733083725), ('-3', 0.17124271392822266), ('10', 0.1159282848238945), ('7', 0.07524949312210083), ('-7', 0.05759824812412262), ('-10', 0.04957795888185501)]\n",
            "act0 0 pred: [('0', 0.2967928946018219), ('3', 0.1648002713918686), ('-3', 0.14654402434825897), ('10', 0.12749074399471283), ('7', 0.08659396320581436), ('-7', 0.05747741460800171), ('-10', 0.054303526878356934)]\n",
            "act0 -3 pred: [('0', 0.28487104177474976), ('3', 0.17138910293579102), ('-3', 0.14717403054237366), ('10', 0.12879300117492676), ('7', 0.10155489295721054), ('-7', 0.056715529412031174), ('-10', 0.055283401161432266)]\n",
            "act0 -3 pred: [('0', 0.2590208351612091), ('3', 0.16960662603378296), ('10', 0.14688758552074432), ('-3', 0.1411510556936264), ('7', 0.09889908879995346), ('-7', 0.05957508087158203), ('-10', 0.05638603866100311)]\n",
            "--------\n",
            "Epoch # 0 - Stock: AAP -  train loss: 0.106354 - test loss: 0.085933 - elapsed: 2.38  - n_sells: 0 - balance: 0\n",
            "time elapsed: 2.38\n",
            "--------\n",
            "AAL all_training 50 all_testing 50\n",
            "input_list [-12, -6, -8, -4, -2, 0, 0, 2, 0, 0, 0, -1, -1, 1, 0, -2, -2, -4, 0, 1]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0053, 0.0203, 0.1341, 0.6558, 0.1534, 0.0225, 0.0111, 0.0168, 0.0427,\n",
            "        0.1515, 0.5168, 0.1964, 0.0466, 0.0198, 0.0329, 0.0311, 0.1964, 0.4165,\n",
            "        0.1875, 0.0695, 0.0320, 0.0353, 0.0443, 0.1917, 0.3637, 0.1992, 0.0788,\n",
            "        0.0488, 0.0449, 0.0455, 0.1670, 0.3482, 0.1764, 0.1030, 0.0585, 0.0536,\n",
            "        0.0438, 0.1748, 0.3336, 0.1660, 0.0943, 0.0920, 0.0495, 0.0576, 0.1712,\n",
            "        0.2830, 0.1772, 0.0752, 0.1159, 0.0543, 0.0574, 0.1465, 0.2967, 0.1648,\n",
            "        0.0866, 0.1275, 0.0553, 0.0567, 0.1472, 0.2848, 0.1713, 0.1015, 0.1288,\n",
            "        0.0564, 0.0596, 0.1411, 0.2590, 0.1696, 0.0989, 0.1468],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.1291862577199936\n",
            "------\n",
            "input_list [-8, -9, -5, -3, 0, 0, 1, 0, 0, -1, -2, -2, 0, -1, -3, -4, -5, -1, 0, -1]\n",
            "input_tensor tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0053, 0.0204, 0.1333, 0.6589, 0.1520, 0.0224, 0.0111, 0.0168, 0.0428,\n",
            "        0.1516, 0.5171, 0.1970, 0.0464, 0.0198, 0.0327, 0.0312, 0.1967, 0.4156,\n",
            "        0.1873, 0.0700, 0.0320, 0.0352, 0.0443, 0.1928, 0.3626, 0.1996, 0.0783,\n",
            "        0.0489, 0.0446, 0.0456, 0.1682, 0.3463, 0.1762, 0.1034, 0.0586, 0.0532,\n",
            "        0.0438, 0.1754, 0.3327, 0.1650, 0.0955, 0.0919, 0.0493, 0.0578, 0.1714,\n",
            "        0.2829, 0.1762, 0.0761, 0.1155, 0.0540, 0.0577, 0.1464, 0.2968, 0.1646,\n",
            "        0.0865, 0.1277, 0.0550, 0.0570, 0.1467, 0.2851, 0.1715, 0.1018, 0.1283,\n",
            "        0.0561, 0.0597, 0.1409, 0.2586, 0.1696, 0.0994, 0.1460],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.1345067173242569\n",
            "------\n",
            "input_list [-10, -6, -4, -1, -1, 0, -1, -1, -2, -3, -3, -1, -2, -4, -5, -6, -2, -1, -2, -1]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0053, 0.0205, 0.1325, 0.6620, 0.1508, 0.0223, 0.0111, 0.0167, 0.0428,\n",
            "        0.1515, 0.5167, 0.1973, 0.0465, 0.0197, 0.0326, 0.0312, 0.1969, 0.4144,\n",
            "        0.1870, 0.0705, 0.0322, 0.0351, 0.0443, 0.1937, 0.3612, 0.1998, 0.0779,\n",
            "        0.0495, 0.0444, 0.0456, 0.1692, 0.3442, 0.1760, 0.1037, 0.0592, 0.0529,\n",
            "        0.0438, 0.1758, 0.3316, 0.1641, 0.0966, 0.0924, 0.0491, 0.0579, 0.1714,\n",
            "        0.2825, 0.1751, 0.0768, 0.1160, 0.0537, 0.0578, 0.1463, 0.2967, 0.1643,\n",
            "        0.0864, 0.1287, 0.0547, 0.0572, 0.1463, 0.2849, 0.1716, 0.1019, 0.1285,\n",
            "        0.0558, 0.0599, 0.1406, 0.2581, 0.1695, 0.0999, 0.1461],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.14890526235103607\n",
            "------\n",
            "input_list [-12, -10, -7, -7, -5, -7, -7, -8, -8, -9, -6, -7, -10, -10, -12, -8, -6, -7, -6, -5]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0053, 0.0206, 0.1318, 0.6640, 0.1503, 0.0223, 0.0111, 0.0167, 0.0428,\n",
            "        0.1514, 0.5157, 0.1975, 0.0471, 0.0197, 0.0325, 0.0312, 0.1970, 0.4128,\n",
            "        0.1867, 0.0710, 0.0326, 0.0350, 0.0443, 0.1944, 0.3597, 0.1998, 0.0776,\n",
            "        0.0504, 0.0443, 0.0457, 0.1700, 0.3421, 0.1757, 0.1040, 0.0602, 0.0526,\n",
            "        0.0439, 0.1761, 0.3302, 0.1633, 0.0976, 0.0937, 0.0489, 0.0580, 0.1713,\n",
            "        0.2821, 0.1741, 0.0775, 0.1172, 0.0534, 0.0580, 0.1462, 0.2964, 0.1641,\n",
            "        0.0863, 0.1305, 0.0545, 0.0575, 0.1458, 0.2846, 0.1717, 0.1021, 0.1296,\n",
            "        0.0556, 0.0600, 0.1402, 0.2576, 0.1695, 0.1004, 0.1470],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.14431972801685333\n",
            "------\n",
            "input_list [-12, -10, -10, -8, -10, -10, -10, -11, -12, -9, -10, -12, -13, -14, -11, -9, -10, -9, -8, -3]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0053, 0.0207, 0.1311, 0.6651, 0.1506, 0.0222, 0.0111, 0.0168, 0.0428,\n",
            "        0.1513, 0.5142, 0.1983, 0.0477, 0.0197, 0.0324, 0.0313, 0.1969, 0.4111,\n",
            "        0.1864, 0.0714, 0.0333, 0.0350, 0.0443, 0.1948, 0.3579, 0.1998, 0.0773,\n",
            "        0.0516, 0.0441, 0.0457, 0.1706, 0.3400, 0.1754, 0.1042, 0.0615, 0.0523,\n",
            "        0.0439, 0.1762, 0.3286, 0.1624, 0.0984, 0.0956, 0.0488, 0.0581, 0.1711,\n",
            "        0.2815, 0.1731, 0.0782, 0.1193, 0.0532, 0.0581, 0.1460, 0.2958, 0.1638,\n",
            "        0.0862, 0.1330, 0.0543, 0.0577, 0.1454, 0.2840, 0.1717, 0.1022, 0.1312,\n",
            "        0.0554, 0.0601, 0.1398, 0.2569, 0.1693, 0.1007, 0.1486],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.13426312804222107\n",
            "------\n",
            "input_list [-11, -11, -9, -11, -11, -12, -13, -13, -10, -11, -14, -14, -15, -12, -10, -12, -10, -9, -4, -1]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0053, 0.0208, 0.1303, 0.6664, 0.1507, 0.0222, 0.0111, 0.0167, 0.0428,\n",
            "        0.1509, 0.5123, 0.1988, 0.0481, 0.0199, 0.0323, 0.0313, 0.1968, 0.4091,\n",
            "        0.1859, 0.0717, 0.0342, 0.0349, 0.0442, 0.1951, 0.3560, 0.1995, 0.0769,\n",
            "        0.0531, 0.0440, 0.0457, 0.1711, 0.3377, 0.1750, 0.1042, 0.0631, 0.0521,\n",
            "        0.0440, 0.1762, 0.3269, 0.1616, 0.0991, 0.0979, 0.0487, 0.0582, 0.1707,\n",
            "        0.2806, 0.1721, 0.0787, 0.1219, 0.0530, 0.0581, 0.1457, 0.2951, 0.1635,\n",
            "        0.0860, 0.1362, 0.0541, 0.0578, 0.1450, 0.2832, 0.1715, 0.1021, 0.1335,\n",
            "        0.0552, 0.0602, 0.1393, 0.2560, 0.1690, 0.1010, 0.1508],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.15239053964614868\n",
            "------\n",
            "input_list [-19, -18, -19, -19, -20, -21, -21, -19, -19, -21, -22, -23, -20, -19, -20, -18, -18, -13, -10, -9]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0053, 0.0209, 0.1296, 0.6668, 0.1507, 0.0222, 0.0112, 0.0168, 0.0428,\n",
            "        0.1505, 0.5099, 0.1992, 0.0486, 0.0202, 0.0323, 0.0313, 0.1965, 0.4069,\n",
            "        0.1855, 0.0720, 0.0353, 0.0348, 0.0442, 0.1953, 0.3539, 0.1992, 0.0767,\n",
            "        0.0550, 0.0439, 0.0457, 0.1714, 0.3355, 0.1746, 0.1042, 0.0651, 0.0518,\n",
            "        0.0440, 0.1760, 0.3250, 0.1608, 0.0997, 0.1009, 0.0486, 0.0582, 0.1702,\n",
            "        0.2797, 0.1711, 0.0792, 0.1252, 0.0528, 0.0582, 0.1455, 0.2943, 0.1631,\n",
            "        0.0859, 0.1400, 0.0539, 0.0580, 0.1445, 0.2822, 0.1714, 0.1021, 0.1363,\n",
            "        0.0551, 0.0603, 0.1388, 0.2552, 0.1688, 0.1012, 0.1536],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.12292753159999847\n",
            "------\n",
            "input_list [-18, -20, -20, -21, -21, -22, -20, -20, -22, -23, -24, -21, -19, -21, -19, -19, -14, -11, -10, -1]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0053, 0.0209, 0.1288, 0.6675, 0.1505, 0.0222, 0.0114, 0.0168, 0.0428,\n",
            "        0.1501, 0.5072, 0.2000, 0.0490, 0.0204, 0.0322, 0.0313, 0.1962, 0.4045,\n",
            "        0.1857, 0.0721, 0.0363, 0.0348, 0.0442, 0.1952, 0.3516, 0.1987, 0.0768,\n",
            "        0.0567, 0.0437, 0.0457, 0.1716, 0.3332, 0.1742, 0.1040, 0.0674, 0.0516,\n",
            "        0.0439, 0.1757, 0.3229, 0.1600, 0.1001, 0.1043, 0.0485, 0.0582, 0.1697,\n",
            "        0.2786, 0.1700, 0.0795, 0.1292, 0.0526, 0.0582, 0.1451, 0.2932, 0.1627,\n",
            "        0.0856, 0.1443, 0.0537, 0.0580, 0.1441, 0.2809, 0.1711, 0.1020, 0.1397,\n",
            "        0.0549, 0.0603, 0.1383, 0.2541, 0.1684, 0.1013, 0.1570],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.13752299547195435\n",
            "------\n",
            "input_list [-23, -22, -23, -24, -24, -22, -23, -25, -25, -27, -23, -22, -23, -22, -21, -17, -14, -13, -4, -3]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0053, 0.0210, 0.1281, 0.6673, 0.1510, 0.0222, 0.0115, 0.0168, 0.0428,\n",
            "        0.1496, 0.5043, 0.2015, 0.0493, 0.0207, 0.0322, 0.0313, 0.1957, 0.4019,\n",
            "        0.1864, 0.0723, 0.0372, 0.0347, 0.0442, 0.1951, 0.3492, 0.1981, 0.0770,\n",
            "        0.0587, 0.0436, 0.0456, 0.1717, 0.3308, 0.1738, 0.1039, 0.0700, 0.0514,\n",
            "        0.0439, 0.1753, 0.3208, 0.1592, 0.1005, 0.1084, 0.0484, 0.0582, 0.1691,\n",
            "        0.2774, 0.1690, 0.0799, 0.1338, 0.0524, 0.0581, 0.1448, 0.2921, 0.1623,\n",
            "        0.0854, 0.1493, 0.0535, 0.0581, 0.1437, 0.2795, 0.1708, 0.1018, 0.1436,\n",
            "        0.0548, 0.0603, 0.1377, 0.2531, 0.1680, 0.1014, 0.1609],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.12509845197200775\n",
            "------\n",
            "input_list [-23, -24, -24, -24, -23, -23, -25, -26, -27, -24, -22, -23, -22, -22, -17, -14, -13, -4, -3, 0]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0054, 0.0211, 0.1274, 0.6676, 0.1514, 0.0222, 0.0116, 0.0168, 0.0428,\n",
            "        0.1491, 0.5010, 0.2036, 0.0497, 0.0209, 0.0321, 0.0313, 0.1953, 0.3993,\n",
            "        0.1871, 0.0730, 0.0380, 0.0347, 0.0442, 0.1948, 0.3467, 0.1975, 0.0771,\n",
            "        0.0611, 0.0435, 0.0456, 0.1717, 0.3285, 0.1733, 0.1037, 0.0731, 0.0512,\n",
            "        0.0440, 0.1748, 0.3185, 0.1585, 0.1008, 0.1129, 0.0484, 0.0581, 0.1684,\n",
            "        0.2761, 0.1681, 0.0802, 0.1391, 0.0522, 0.0581, 0.1445, 0.2910, 0.1619,\n",
            "        0.0852, 0.1550, 0.0534, 0.0582, 0.1432, 0.2780, 0.1705, 0.1016, 0.1481,\n",
            "        0.0547, 0.0603, 0.1371, 0.2520, 0.1677, 0.1015, 0.1654],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.12946633994579315\n",
            "------\n",
            "input_list [-25, -26, -26, -24, -24, -26, -27, -28, -25, -24, -25, -24, -23, -18, -16, -14, -6, -5, -2, -1]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0054, 0.0212, 0.1267, 0.6681, 0.1516, 0.0222, 0.0117, 0.0168, 0.0428,\n",
            "        0.1485, 0.4974, 0.2052, 0.0505, 0.0211, 0.0321, 0.0313, 0.1948, 0.3966,\n",
            "        0.1876, 0.0736, 0.0391, 0.0346, 0.0442, 0.1944, 0.3441, 0.1968, 0.0772,\n",
            "        0.0639, 0.0435, 0.0456, 0.1716, 0.3261, 0.1728, 0.1034, 0.0765, 0.0510,\n",
            "        0.0440, 0.1743, 0.3162, 0.1578, 0.1011, 0.1181, 0.0484, 0.0581, 0.1677,\n",
            "        0.2747, 0.1671, 0.0804, 0.1450, 0.0520, 0.0580, 0.1441, 0.2897, 0.1615,\n",
            "        0.0850, 0.1612, 0.0532, 0.0582, 0.1428, 0.2763, 0.1702, 0.1014, 0.1530,\n",
            "        0.0546, 0.0603, 0.1365, 0.2509, 0.1672, 0.1015, 0.1704],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.14912545680999756\n",
            "------\n",
            "input_list [-30, -30, -28, -29, -31, -31, -32, -29, -28, -29, -28, -27, -23, -21, -20, -11, -10, -7, -7, -5]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0054, 0.0212, 0.1261, 0.6678, 0.1518, 0.0224, 0.0118, 0.0169, 0.0428,\n",
            "        0.1479, 0.4936, 0.2066, 0.0512, 0.0215, 0.0321, 0.0313, 0.1942, 0.3937,\n",
            "        0.1880, 0.0741, 0.0405, 0.0346, 0.0442, 0.1940, 0.3415, 0.1960, 0.0773,\n",
            "        0.0671, 0.0434, 0.0455, 0.1714, 0.3238, 0.1722, 0.1031, 0.0803, 0.0508,\n",
            "        0.0440, 0.1737, 0.3138, 0.1572, 0.1013, 0.1239, 0.0484, 0.0580, 0.1669,\n",
            "        0.2733, 0.1661, 0.0807, 0.1516, 0.0519, 0.0579, 0.1438, 0.2884, 0.1610,\n",
            "        0.0848, 0.1681, 0.0531, 0.0582, 0.1424, 0.2746, 0.1698, 0.1018, 0.1575,\n",
            "        0.0545, 0.0603, 0.1359, 0.2497, 0.1668, 0.1015, 0.1761],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.14036060869693756\n",
            "------\n",
            "input_list [-33, -32, -32, -34, -34, -35, -33, -31, -32, -31, -31, -27, -24, -23, -16, -15, -12, -11, -10, -4]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0054, 0.0213, 0.1254, 0.6669, 0.1526, 0.0226, 0.0120, 0.0170, 0.0428,\n",
            "        0.1472, 0.4897, 0.2076, 0.0524, 0.0219, 0.0322, 0.0313, 0.1936, 0.3906,\n",
            "        0.1882, 0.0752, 0.0418, 0.0346, 0.0442, 0.1934, 0.3389, 0.1952, 0.0779,\n",
            "        0.0701, 0.0434, 0.0455, 0.1712, 0.3215, 0.1717, 0.1035, 0.0839, 0.0507,\n",
            "        0.0440, 0.1731, 0.3113, 0.1566, 0.1020, 0.1292, 0.0484, 0.0580, 0.1661,\n",
            "        0.2720, 0.1658, 0.0809, 0.1575, 0.0518, 0.0578, 0.1434, 0.2869, 0.1611,\n",
            "        0.0845, 0.1743, 0.0530, 0.0582, 0.1420, 0.2729, 0.1699, 0.1021, 0.1614,\n",
            "        0.0545, 0.0603, 0.1352, 0.2486, 0.1668, 0.1015, 0.1811],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.09760825335979462\n",
            "------\n",
            "input_list [-33, -33, -35, -35, -36, -34, -33, -34, -33, -32, -28, -25, -24, -17, -16, -13, -13, -11, -6, -1]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0055, 0.0214, 0.1247, 0.6664, 0.1533, 0.0229, 0.0121, 0.0170, 0.0428,\n",
            "        0.1467, 0.4856, 0.2093, 0.0534, 0.0223, 0.0322, 0.0314, 0.1929, 0.3875,\n",
            "        0.1891, 0.0761, 0.0430, 0.0346, 0.0443, 0.1929, 0.3363, 0.1951, 0.0784,\n",
            "        0.0728, 0.0434, 0.0455, 0.1709, 0.3190, 0.1717, 0.1038, 0.0871, 0.0505,\n",
            "        0.0440, 0.1724, 0.3099, 0.1559, 0.1027, 0.1340, 0.0484, 0.0580, 0.1659,\n",
            "        0.2705, 0.1653, 0.0811, 0.1629, 0.0517, 0.0578, 0.1431, 0.2864, 0.1611,\n",
            "        0.0843, 0.1798, 0.0529, 0.0582, 0.1416, 0.2720, 0.1700, 0.1024, 0.1649,\n",
            "        0.0544, 0.0603, 0.1346, 0.2481, 0.1668, 0.1014, 0.1854],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.08373987674713135\n",
            "------\n",
            "input_list [-34, -36, -36, -37, -34, -33, -34, -33, -33, -29, -26, -25, -18, -17, -14, -14, -12, -7, -2, -1]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0055, 0.0215, 0.1241, 0.6663, 0.1537, 0.0230, 0.0121, 0.0170, 0.0428,\n",
            "        0.1460, 0.4826, 0.2105, 0.0543, 0.0226, 0.0322, 0.0314, 0.1921, 0.3854,\n",
            "        0.1896, 0.0769, 0.0441, 0.0345, 0.0442, 0.1922, 0.3336, 0.1955, 0.0789,\n",
            "        0.0753, 0.0434, 0.0455, 0.1704, 0.3175, 0.1715, 0.1039, 0.0900, 0.0503,\n",
            "        0.0439, 0.1724, 0.3082, 0.1553, 0.1032, 0.1383, 0.0484, 0.0579, 0.1664,\n",
            "        0.2689, 0.1649, 0.0812, 0.1677, 0.0516, 0.0577, 0.1427, 0.2865, 0.1610,\n",
            "        0.0841, 0.1846, 0.0528, 0.0582, 0.1412, 0.2719, 0.1700, 0.1025, 0.1678,\n",
            "        0.0544, 0.0602, 0.1341, 0.2483, 0.1666, 0.1013, 0.1890],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.09554573893547058\n",
            "------\n",
            "input_list [-36, -36, -37, -35, -34, -35, -34, -33, -29, -27, -26, -18, -17, -14, -14, -13, -7, -3, -1, 0]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0055, 0.0215, 0.1233, 0.6666, 0.1539, 0.0232, 0.0122, 0.0170, 0.0427,\n",
            "        0.1453, 0.4806, 0.2114, 0.0551, 0.0228, 0.0321, 0.0313, 0.1912, 0.3842,\n",
            "        0.1899, 0.0776, 0.0450, 0.0345, 0.0442, 0.1921, 0.3308, 0.1957, 0.0792,\n",
            "        0.0775, 0.0433, 0.0455, 0.1705, 0.3158, 0.1713, 0.1040, 0.0926, 0.0502,\n",
            "        0.0438, 0.1728, 0.3065, 0.1546, 0.1036, 0.1419, 0.0483, 0.0577, 0.1672,\n",
            "        0.2672, 0.1644, 0.0813, 0.1717, 0.0514, 0.0575, 0.1427, 0.2862, 0.1607,\n",
            "        0.0838, 0.1887, 0.0527, 0.0581, 0.1408, 0.2724, 0.1698, 0.1026, 0.1702,\n",
            "        0.0542, 0.0602, 0.1340, 0.2482, 0.1663, 0.1011, 0.1921],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.09747748076915741\n",
            "------\n",
            "input_list [-36, -37, -34, -33, -34, -33, -32, -28, -26, -25, -18, -17, -14, -13, -12, -6, -2, 0, 0, 0]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0055, 0.0215, 0.1225, 0.6673, 0.1540, 0.0233, 0.0123, 0.0170, 0.0426,\n",
            "        0.1446, 0.4794, 0.2121, 0.0558, 0.0230, 0.0321, 0.0313, 0.1909, 0.3826,\n",
            "        0.1900, 0.0781, 0.0459, 0.0344, 0.0441, 0.1927, 0.3279, 0.1958, 0.0795,\n",
            "        0.0795, 0.0431, 0.0454, 0.1711, 0.3140, 0.1711, 0.1039, 0.0948, 0.0500,\n",
            "        0.0438, 0.1738, 0.3047, 0.1539, 0.1039, 0.1451, 0.0482, 0.0576, 0.1685,\n",
            "        0.2655, 0.1639, 0.0813, 0.1752, 0.0513, 0.0574, 0.1427, 0.2866, 0.1604,\n",
            "        0.0835, 0.1922, 0.0525, 0.0580, 0.1409, 0.2727, 0.1696, 0.1026, 0.1722,\n",
            "        0.0541, 0.0601, 0.1339, 0.2488, 0.1660, 0.1009, 0.1946],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.10790258646011353\n",
            "------\n",
            "input_list [-38, -36, -34, -35, -34, -34, -30, -28, -27, -19, -18, -16, -15, -14, -8, -4, -2, -1, -1, -2]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0055, 0.0215, 0.1217, 0.6671, 0.1548, 0.0234, 0.0124, 0.0170, 0.0425,\n",
            "        0.1438, 0.4790, 0.2124, 0.0564, 0.0232, 0.0320, 0.0313, 0.1913, 0.3807,\n",
            "        0.1901, 0.0786, 0.0467, 0.0344, 0.0440, 0.1939, 0.3251, 0.1958, 0.0797,\n",
            "        0.0813, 0.0430, 0.0454, 0.1716, 0.3129, 0.1709, 0.1039, 0.0968, 0.0498,\n",
            "        0.0437, 0.1752, 0.3029, 0.1532, 0.1041, 0.1478, 0.0481, 0.0575, 0.1695,\n",
            "        0.2647, 0.1634, 0.0813, 0.1781, 0.0511, 0.0572, 0.1431, 0.2866, 0.1602,\n",
            "        0.0832, 0.1950, 0.0524, 0.0579, 0.1409, 0.2736, 0.1693, 0.1026, 0.1737,\n",
            "        0.0540, 0.0601, 0.1337, 0.2491, 0.1661, 0.1007, 0.1967],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.12562885880470276\n",
            "------\n",
            "input_list [-33, -32, -33, -32, -31, -27, -25, -24, -16, -15, -12, -12, -10, -5, 0, 0, 2, 2, 1, 3]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0055, 0.0216, 0.1217, 0.6663, 0.1555, 0.0235, 0.0125, 0.0171, 0.0430,\n",
            "        0.1432, 0.4780, 0.2128, 0.0571, 0.0235, 0.0320, 0.0313, 0.1924, 0.3785,\n",
            "        0.1901, 0.0791, 0.0475, 0.0344, 0.0440, 0.1957, 0.3225, 0.1959, 0.0801,\n",
            "        0.0830, 0.0430, 0.0454, 0.1726, 0.3120, 0.1706, 0.1040, 0.0986, 0.0497,\n",
            "        0.0437, 0.1771, 0.3010, 0.1527, 0.1044, 0.1503, 0.0481, 0.0576, 0.1711,\n",
            "        0.2638, 0.1631, 0.0814, 0.1805, 0.0510, 0.0572, 0.1439, 0.2866, 0.1600,\n",
            "        0.0831, 0.1974, 0.0524, 0.0580, 0.1410, 0.2751, 0.1690, 0.1028, 0.1751,\n",
            "        0.0540, 0.0601, 0.1336, 0.2502, 0.1664, 0.1006, 0.1984],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.09968546777963638\n",
            "------\n",
            "input_list [-30, -31, -30, -29, -25, -22, -21, -13, -12, -9, -9, -8, -2, 2, 4, 5, 5, 5, 7, 3]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0055, 0.0217, 0.1222, 0.6647, 0.1561, 0.0236, 0.0125, 0.0172, 0.0434,\n",
            "        0.1425, 0.4777, 0.2129, 0.0576, 0.0237, 0.0321, 0.0314, 0.1932, 0.3773,\n",
            "        0.1900, 0.0795, 0.0483, 0.0344, 0.0439, 0.1971, 0.3208, 0.1958, 0.0803,\n",
            "        0.0844, 0.0430, 0.0454, 0.1734, 0.3117, 0.1702, 0.1039, 0.1001, 0.0495,\n",
            "        0.0437, 0.1787, 0.3001, 0.1521, 0.1046, 0.1523, 0.0481, 0.0576, 0.1725,\n",
            "        0.2637, 0.1627, 0.0814, 0.1824, 0.0510, 0.0572, 0.1447, 0.2864, 0.1602,\n",
            "        0.0830, 0.1992, 0.0523, 0.0580, 0.1410, 0.2764, 0.1693, 0.1028, 0.1761,\n",
            "        0.0540, 0.0602, 0.1339, 0.2509, 0.1665, 0.1005, 0.1998],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.11249121278524399\n",
            "------\n",
            "input_list [-32, -31, -30, -26, -24, -23, -15, -14, -11, -10, -9, -3, 0, 2, 3, 4, 3, 5, 1, -1]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0055, 0.0216, 0.1224, 0.6637, 0.1561, 0.0237, 0.0126, 0.0172, 0.0437,\n",
            "        0.1418, 0.4771, 0.2134, 0.0579, 0.0238, 0.0319, 0.0313, 0.1936, 0.3758,\n",
            "        0.1903, 0.0796, 0.0488, 0.0342, 0.0438, 0.1982, 0.3188, 0.1961, 0.0804,\n",
            "        0.0855, 0.0428, 0.0454, 0.1739, 0.3109, 0.1704, 0.1036, 0.1012, 0.0493,\n",
            "        0.0435, 0.1799, 0.2989, 0.1518, 0.1045, 0.1536, 0.0479, 0.0575, 0.1736,\n",
            "        0.2632, 0.1621, 0.0817, 0.1838, 0.0508, 0.0570, 0.1452, 0.2858, 0.1603,\n",
            "        0.0831, 0.2003, 0.0521, 0.0578, 0.1408, 0.2780, 0.1691, 0.1027, 0.1766,\n",
            "        0.0539, 0.0601, 0.1340, 0.2511, 0.1668, 0.1001, 0.2004],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.09638276696205139\n",
            "------\n",
            "input_list [-32, -31, -27, -25, -24, -16, -15, -12, -12, -10, -5, 0, 0, 2, 2, 1, 3, 0, -3, -1]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0055, 0.0216, 0.1226, 0.6631, 0.1562, 0.0237, 0.0126, 0.0172, 0.0439,\n",
            "        0.1410, 0.4771, 0.2138, 0.0582, 0.0239, 0.0319, 0.0313, 0.1938, 0.3740,\n",
            "        0.1912, 0.0798, 0.0493, 0.0341, 0.0437, 0.1990, 0.3176, 0.1962, 0.0804,\n",
            "        0.0864, 0.0427, 0.0453, 0.1744, 0.3099, 0.1711, 0.1033, 0.1022, 0.0491,\n",
            "        0.0435, 0.1810, 0.2976, 0.1521, 0.1044, 0.1546, 0.0478, 0.0574, 0.1744,\n",
            "        0.2627, 0.1620, 0.0819, 0.1847, 0.0506, 0.0569, 0.1456, 0.2859, 0.1602,\n",
            "        0.0832, 0.2010, 0.0520, 0.0577, 0.1405, 0.2792, 0.1695, 0.1025, 0.1769,\n",
            "        0.0538, 0.0601, 0.1341, 0.2512, 0.1677, 0.0998, 0.2008],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.08838386088609695\n",
            "------\n",
            "input_list [-31, -27, -24, -23, -16, -15, -12, -11, -10, -4, 0, 1, 2, 3, 2, 4, 0, -2, -1, 0]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0056, 0.0216, 0.1228, 0.6630, 0.1561, 0.0238, 0.0127, 0.0172, 0.0442,\n",
            "        0.1403, 0.4776, 0.2141, 0.0584, 0.0240, 0.0318, 0.0312, 0.1939, 0.3731,\n",
            "        0.1919, 0.0798, 0.0498, 0.0341, 0.0437, 0.1996, 0.3172, 0.1963, 0.0805,\n",
            "        0.0871, 0.0425, 0.0452, 0.1746, 0.3089, 0.1720, 0.1030, 0.1030, 0.0489,\n",
            "        0.0434, 0.1818, 0.2961, 0.1527, 0.1043, 0.1553, 0.0477, 0.0573, 0.1757,\n",
            "        0.2619, 0.1619, 0.0821, 0.1852, 0.0505, 0.0568, 0.1460, 0.2867, 0.1601,\n",
            "        0.0833, 0.2013, 0.0519, 0.0576, 0.1403, 0.2801, 0.1705, 0.1023, 0.1770,\n",
            "        0.0536, 0.0601, 0.1341, 0.2519, 0.1684, 0.0994, 0.2009],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.099216528236866\n",
            "------\n",
            "input_list [-28, -26, -25, -17, -16, -13, -13, -11, -6, -1, 0, 1, 1, 0, 2, -1, -4, -2, -1, -1]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0056, 0.0216, 0.1228, 0.6632, 0.1559, 0.0238, 0.0127, 0.0172, 0.0443,\n",
            "        0.1396, 0.4788, 0.2140, 0.0586, 0.0241, 0.0318, 0.0312, 0.1937, 0.3719,\n",
            "        0.1931, 0.0798, 0.0501, 0.0339, 0.0436, 0.2001, 0.3164, 0.1968, 0.0804,\n",
            "        0.0877, 0.0424, 0.0452, 0.1748, 0.3076, 0.1734, 0.1026, 0.1036, 0.0487,\n",
            "        0.0433, 0.1824, 0.2954, 0.1532, 0.1041, 0.1556, 0.0475, 0.0571, 0.1767,\n",
            "        0.2612, 0.1622, 0.0822, 0.1852, 0.0504, 0.0567, 0.1462, 0.2871, 0.1604,\n",
            "        0.0833, 0.2012, 0.0517, 0.0575, 0.1401, 0.2806, 0.1717, 0.1021, 0.1768,\n",
            "        0.0535, 0.0600, 0.1341, 0.2523, 0.1694, 0.0990, 0.2007],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.08708413690328598\n",
            "------\n",
            "input_list [-24, -23, -16, -15, -12, -12, -10, -4, 0, 1, 2, 2, 2, 4, 0, -2, -1, 0, 0, 1]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0056, 0.0216, 0.1227, 0.6638, 0.1556, 0.0239, 0.0127, 0.0172, 0.0445,\n",
            "        0.1389, 0.4804, 0.2139, 0.0587, 0.0242, 0.0317, 0.0311, 0.1934, 0.3703,\n",
            "        0.1949, 0.0798, 0.0504, 0.0339, 0.0436, 0.2004, 0.3156, 0.1978, 0.0804,\n",
            "        0.0881, 0.0422, 0.0451, 0.1756, 0.3062, 0.1746, 0.1023, 0.1041, 0.0485,\n",
            "        0.0432, 0.1829, 0.2954, 0.1536, 0.1038, 0.1556, 0.0474, 0.0571, 0.1776,\n",
            "        0.2611, 0.1625, 0.0824, 0.1851, 0.0502, 0.0566, 0.1465, 0.2881, 0.1607,\n",
            "        0.0833, 0.2007, 0.0516, 0.0574, 0.1398, 0.2817, 0.1726, 0.1019, 0.1764,\n",
            "        0.0534, 0.0600, 0.1340, 0.2533, 0.1704, 0.0986, 0.2002],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.11930821090936661\n",
            "------\n",
            "input_list [-25, -17, -17, -14, -13, -12, -6, -2, 0, 0, 0, 0, 2, -1, -4, -3, -1, -2, 0, -2]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0056, 0.0216, 0.1225, 0.6635, 0.1561, 0.0239, 0.0128, 0.0172, 0.0446,\n",
            "        0.1382, 0.4814, 0.2145, 0.0588, 0.0243, 0.0317, 0.0311, 0.1929, 0.3685,\n",
            "        0.1971, 0.0798, 0.0507, 0.0338, 0.0435, 0.2006, 0.3154, 0.1987, 0.0804,\n",
            "        0.0884, 0.0421, 0.0451, 0.1762, 0.3046, 0.1762, 0.1019, 0.1045, 0.0483,\n",
            "        0.0432, 0.1832, 0.2951, 0.1544, 0.1036, 0.1554, 0.0473, 0.0570, 0.1783,\n",
            "        0.2610, 0.1632, 0.0825, 0.1846, 0.0502, 0.0565, 0.1467, 0.2887, 0.1614,\n",
            "        0.0834, 0.2000, 0.0515, 0.0573, 0.1396, 0.2825, 0.1740, 0.1017, 0.1759,\n",
            "        0.0533, 0.0600, 0.1339, 0.2549, 0.1712, 0.0982, 0.1996],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.10195616632699966\n",
            "------\n",
            "input_list [-19, -18, -15, -15, -14, -8, -4, -2, -1, -1, -1, 0, -3, -6, -5, -3, -4, -2, -4, -2]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0056, 0.0216, 0.1224, 0.6626, 0.1572, 0.0240, 0.0129, 0.0173, 0.0448,\n",
            "        0.1377, 0.4817, 0.2158, 0.0589, 0.0244, 0.0317, 0.0311, 0.1933, 0.3666,\n",
            "        0.1989, 0.0798, 0.0510, 0.0338, 0.0435, 0.2007, 0.3161, 0.1994, 0.0804,\n",
            "        0.0886, 0.0421, 0.0451, 0.1767, 0.3039, 0.1775, 0.1016, 0.1047, 0.0481,\n",
            "        0.0432, 0.1834, 0.2956, 0.1551, 0.1034, 0.1551, 0.0473, 0.0570, 0.1790,\n",
            "        0.2615, 0.1638, 0.0827, 0.1839, 0.0502, 0.0565, 0.1469, 0.2901, 0.1621,\n",
            "        0.0834, 0.1991, 0.0514, 0.0573, 0.1393, 0.2839, 0.1753, 0.1016, 0.1753,\n",
            "        0.0533, 0.0600, 0.1338, 0.2570, 0.1719, 0.0979, 0.1989],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.09282764792442322\n",
            "------\n",
            "input_list [-18, -15, -15, -14, -8, -4, -2, -1, -1, -1, 0, -3, -6, -5, -3, -4, -2, -4, -2, 0]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0056, 0.0216, 0.1223, 0.6621, 0.1582, 0.0240, 0.0129, 0.0173, 0.0449,\n",
            "        0.1377, 0.4813, 0.2169, 0.0590, 0.0245, 0.0317, 0.0311, 0.1935, 0.3654,\n",
            "        0.2004, 0.0797, 0.0512, 0.0338, 0.0436, 0.2006, 0.3175, 0.2000, 0.0803,\n",
            "        0.0887, 0.0421, 0.0450, 0.1770, 0.3038, 0.1785, 0.1013, 0.1048, 0.0480,\n",
            "        0.0432, 0.1834, 0.2966, 0.1557, 0.1031, 0.1547, 0.0472, 0.0570, 0.1795,\n",
            "        0.2623, 0.1643, 0.0827, 0.1829, 0.0501, 0.0565, 0.1475, 0.2912, 0.1626,\n",
            "        0.0835, 0.1980, 0.0514, 0.0572, 0.1394, 0.2850, 0.1764, 0.1014, 0.1746,\n",
            "        0.0532, 0.0600, 0.1337, 0.2595, 0.1724, 0.0976, 0.1979],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.09905572980642319\n",
            "------\n",
            "input_list [-10, -10, -9, -3, 1, 3, 4, 4, 3, 6, 2, -1, 0, 2, 1, 3, 1, 3, 5, 5]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0056, 0.0217, 0.1230, 0.6609, 0.1593, 0.0241, 0.0130, 0.0174, 0.0451,\n",
            "        0.1378, 0.4815, 0.2179, 0.0591, 0.0246, 0.0318, 0.0312, 0.1938, 0.3650,\n",
            "        0.2017, 0.0798, 0.0515, 0.0339, 0.0437, 0.2004, 0.3196, 0.2006, 0.0803,\n",
            "        0.0889, 0.0421, 0.0450, 0.1773, 0.3046, 0.1792, 0.1012, 0.1050, 0.0480,\n",
            "        0.0433, 0.1835, 0.2982, 0.1564, 0.1031, 0.1544, 0.0473, 0.0571, 0.1806,\n",
            "        0.2631, 0.1648, 0.0830, 0.1818, 0.0503, 0.0567, 0.1486, 0.2920, 0.1631,\n",
            "        0.0837, 0.1968, 0.0515, 0.0573, 0.1395, 0.2867, 0.1776, 0.1015, 0.1739,\n",
            "        0.0532, 0.0601, 0.1337, 0.2619, 0.1735, 0.0975, 0.1971],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.1285637766122818\n",
            "------\n",
            "input_list [-13, -12, -6, -2, 0, 0, 0, 0, 2, -1, -4, -3, -1, -2, 0, -2, 0, 1, 1, -3]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0056, 0.0217, 0.1232, 0.6591, 0.1604, 0.0241, 0.0130, 0.0174, 0.0450,\n",
            "        0.1375, 0.4814, 0.2192, 0.0590, 0.0246, 0.0318, 0.0312, 0.1936, 0.3643,\n",
            "        0.2032, 0.0795, 0.0516, 0.0338, 0.0436, 0.2000, 0.3207, 0.2015, 0.0801,\n",
            "        0.0887, 0.0420, 0.0449, 0.1772, 0.3046, 0.1805, 0.1007, 0.1047, 0.0478,\n",
            "        0.0432, 0.1832, 0.2993, 0.1571, 0.1026, 0.1533, 0.0471, 0.0569, 0.1813,\n",
            "        0.2634, 0.1654, 0.0829, 0.1804, 0.0501, 0.0565, 0.1493, 0.2922, 0.1639,\n",
            "        0.0836, 0.1950, 0.0513, 0.0571, 0.1394, 0.2878, 0.1781, 0.1017, 0.1729,\n",
            "        0.0530, 0.0601, 0.1335, 0.2633, 0.1742, 0.0975, 0.1957],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.0838022530078888\n",
            "------\n",
            "input_list [-13, -7, -3, -1, 0, 0, -1, 1, -2, -5, -4, -2, -3, -1, -3, -1, 0, 0, -4, 0]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0057, 0.0217, 0.1235, 0.6578, 0.1616, 0.0242, 0.0131, 0.0174, 0.0451,\n",
            "        0.1374, 0.4818, 0.2203, 0.0590, 0.0247, 0.0317, 0.0312, 0.1935, 0.3643,\n",
            "        0.2046, 0.0793, 0.0516, 0.0337, 0.0436, 0.1994, 0.3226, 0.2023, 0.0799,\n",
            "        0.0886, 0.0419, 0.0448, 0.1772, 0.3054, 0.1816, 0.1003, 0.1045, 0.0476,\n",
            "        0.0432, 0.1830, 0.3010, 0.1578, 0.1022, 0.1524, 0.0470, 0.0569, 0.1820,\n",
            "        0.2644, 0.1661, 0.0829, 0.1789, 0.0501, 0.0565, 0.1501, 0.2924, 0.1652,\n",
            "        0.0836, 0.1932, 0.0513, 0.0571, 0.1393, 0.2886, 0.1792, 0.1020, 0.1719,\n",
            "        0.0529, 0.0601, 0.1332, 0.2646, 0.1754, 0.0977, 0.1944],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.09218638390302658\n",
            "------\n",
            "input_list [-7, -2, 0, 0, 0, 0, 1, -1, -4, -3, -1, -2, 0, -2, 0, 1, 1, -3, 0, 0]\n",
            "input_tensor tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0057, 0.0217, 0.1236, 0.6570, 0.1625, 0.0242, 0.0131, 0.0174, 0.0451,\n",
            "        0.1372, 0.4827, 0.2211, 0.0589, 0.0247, 0.0317, 0.0312, 0.1931, 0.3649,\n",
            "        0.2056, 0.0791, 0.0516, 0.0337, 0.0435, 0.1996, 0.3240, 0.2029, 0.0796,\n",
            "        0.0883, 0.0418, 0.0447, 0.1769, 0.3066, 0.1824, 0.0999, 0.1042, 0.0475,\n",
            "        0.0432, 0.1826, 0.3030, 0.1583, 0.1018, 0.1512, 0.0469, 0.0568, 0.1825,\n",
            "        0.2651, 0.1670, 0.0828, 0.1772, 0.0501, 0.0565, 0.1506, 0.2921, 0.1666,\n",
            "        0.0835, 0.1913, 0.0512, 0.0570, 0.1391, 0.2891, 0.1806, 0.1021, 0.1707,\n",
            "        0.0527, 0.0601, 0.1330, 0.2655, 0.1763, 0.0982, 0.1930],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.0948290079832077\n",
            "------\n",
            "input_list [-3, -1, 0, 0, 0, 1, -2, -5, -4, -2, -3, -1, -2, 0, 1, 1, -4, 0, 0, 0]\n",
            "input_tensor tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0057, 0.0216, 0.1236, 0.6566, 0.1631, 0.0242, 0.0131, 0.0174, 0.0450,\n",
            "        0.1369, 0.4841, 0.2217, 0.0588, 0.0248, 0.0317, 0.0311, 0.1927, 0.3661,\n",
            "        0.2063, 0.0788, 0.0516, 0.0336, 0.0435, 0.1995, 0.3258, 0.2032, 0.0794,\n",
            "        0.0880, 0.0417, 0.0446, 0.1766, 0.3083, 0.1830, 0.0994, 0.1038, 0.0473,\n",
            "        0.0432, 0.1822, 0.3046, 0.1591, 0.1014, 0.1500, 0.0467, 0.0567, 0.1828,\n",
            "        0.2654, 0.1683, 0.0827, 0.1753, 0.0500, 0.0565, 0.1509, 0.2916, 0.1683,\n",
            "        0.0834, 0.1891, 0.0511, 0.0569, 0.1388, 0.2893, 0.1818, 0.1027, 0.1694,\n",
            "        0.0526, 0.0600, 0.1327, 0.2660, 0.1770, 0.0991, 0.1916],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.09794444590806961\n",
            "------\n",
            "input_list [-1, 0, 0, 0, 1, -2, -5, -3, -2, -2, -1, -2, 0, 1, 1, -4, 0, 0, 0, 0]\n",
            "input_tensor tensor([[0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0057, 0.0216, 0.1236, 0.6567, 0.1635, 0.0242, 0.0131, 0.0175, 0.0449,\n",
            "        0.1366, 0.4860, 0.2220, 0.0586, 0.0248, 0.0316, 0.0311, 0.1922, 0.3678,\n",
            "        0.2067, 0.0785, 0.0515, 0.0335, 0.0434, 0.1992, 0.3280, 0.2033, 0.0791,\n",
            "        0.0876, 0.0416, 0.0445, 0.1761, 0.3095, 0.1840, 0.0989, 0.1034, 0.0471,\n",
            "        0.0431, 0.1817, 0.3058, 0.1603, 0.1009, 0.1486, 0.0466, 0.0566, 0.1830,\n",
            "        0.2656, 0.1699, 0.0825, 0.1733, 0.0499, 0.0564, 0.1512, 0.2909, 0.1697,\n",
            "        0.0837, 0.1869, 0.0510, 0.0568, 0.1385, 0.2892, 0.1828, 0.1038, 0.1681,\n",
            "        0.0524, 0.0599, 0.1323, 0.2663, 0.1776, 0.0999, 0.1914],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.10192903876304626\n",
            "------\n",
            "input_list [1, 1, 1, 3, 0, -3, -2, 0, -1, 0, -1, 1, 3, 3, -2, 1, 2, 1, 1, 1]\n",
            "input_tensor tensor([[0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0057, 0.0216, 0.1236, 0.6571, 0.1638, 0.0242, 0.0131, 0.0175, 0.0448,\n",
            "        0.1363, 0.4883, 0.2222, 0.0585, 0.0248, 0.0316, 0.0311, 0.1916, 0.3702,\n",
            "        0.2069, 0.0782, 0.0514, 0.0335, 0.0434, 0.1988, 0.3297, 0.2040, 0.0788,\n",
            "        0.0872, 0.0415, 0.0445, 0.1756, 0.3103, 0.1855, 0.0984, 0.1030, 0.0470,\n",
            "        0.0431, 0.1813, 0.3066, 0.1618, 0.1005, 0.1471, 0.0465, 0.0565, 0.1830,\n",
            "        0.2655, 0.1713, 0.0828, 0.1712, 0.0498, 0.0564, 0.1514, 0.2899, 0.1709,\n",
            "        0.0843, 0.1846, 0.0509, 0.0567, 0.1381, 0.2888, 0.1836, 0.1047, 0.1679,\n",
            "        0.0522, 0.0599, 0.1320, 0.2664, 0.1781, 0.1006, 0.1923],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.10881233215332031\n",
            "------\n",
            "input_list [1, 0, 2, -1, -4, -3, -1, -2, 0, -1, 0, 2, 2, -3, 0, 1, 0, 1, 0, 0]\n",
            "input_tensor tensor([[0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0057, 0.0216, 0.1233, 0.6578, 0.1639, 0.0242, 0.0131, 0.0175, 0.0447,\n",
            "        0.1359, 0.4910, 0.2220, 0.0583, 0.0248, 0.0315, 0.0310, 0.1907, 0.3719,\n",
            "        0.2078, 0.0778, 0.0513, 0.0333, 0.0433, 0.1982, 0.3307, 0.2043, 0.0790,\n",
            "        0.0867, 0.0413, 0.0444, 0.1751, 0.3107, 0.1867, 0.0984, 0.1024, 0.0469,\n",
            "        0.0431, 0.1807, 0.3069, 0.1629, 0.1005, 0.1455, 0.0463, 0.0563, 0.1828,\n",
            "        0.2653, 0.1724, 0.0830, 0.1707, 0.0497, 0.0563, 0.1514, 0.2887, 0.1719,\n",
            "        0.0848, 0.1838, 0.0507, 0.0565, 0.1377, 0.2881, 0.1841, 0.1054, 0.1687,\n",
            "        0.0520, 0.0598, 0.1317, 0.2662, 0.1784, 0.1011, 0.1942],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.11282838135957718\n",
            "------\n",
            "input_list [0, 2, -1, -4, -3, -1, -2, 0, -2, 0, 1, 1, -3, 0, 0, 0, 0, 0, -1, 0]\n",
            "input_tensor tensor([[0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0057, 0.0215, 0.1231, 0.6588, 0.1638, 0.0242, 0.0131, 0.0175, 0.0446,\n",
            "        0.1356, 0.4929, 0.2227, 0.0582, 0.0248, 0.0315, 0.0309, 0.1899, 0.3731,\n",
            "        0.2093, 0.0775, 0.0512, 0.0333, 0.0433, 0.1976, 0.3314, 0.2052, 0.0791,\n",
            "        0.0863, 0.0412, 0.0443, 0.1746, 0.3109, 0.1878, 0.0991, 0.1019, 0.0467,\n",
            "        0.0430, 0.1801, 0.3070, 0.1640, 0.1012, 0.1439, 0.0462, 0.0562, 0.1826,\n",
            "        0.2649, 0.1733, 0.0832, 0.1716, 0.0496, 0.0563, 0.1514, 0.2875, 0.1727,\n",
            "        0.0852, 0.1843, 0.0506, 0.0564, 0.1373, 0.2873, 0.1846, 0.1059, 0.1704,\n",
            "        0.0518, 0.0597, 0.1313, 0.2659, 0.1786, 0.1015, 0.1969],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.12912136316299438\n",
            "------\n",
            "input_list [-2, -5, -8, -7, -6, -6, -4, -6, -4, -2, -2, -7, -4, -3, -4, -3, -3, -5, -4, -4]\n",
            "input_tensor tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0057, 0.0216, 0.1229, 0.6589, 0.1646, 0.0242, 0.0132, 0.0175, 0.0446,\n",
            "        0.1353, 0.4941, 0.2240, 0.0581, 0.0248, 0.0315, 0.0309, 0.1891, 0.3738,\n",
            "        0.2114, 0.0772, 0.0511, 0.0332, 0.0433, 0.1970, 0.3318, 0.2058, 0.0798,\n",
            "        0.0858, 0.0411, 0.0443, 0.1741, 0.3109, 0.1887, 0.1003, 0.1014, 0.0466,\n",
            "        0.0431, 0.1795, 0.3067, 0.1649, 0.1018, 0.1437, 0.0462, 0.0561, 0.1824,\n",
            "        0.2646, 0.1741, 0.0834, 0.1739, 0.0495, 0.0562, 0.1514, 0.2863, 0.1735,\n",
            "        0.0856, 0.1861, 0.0506, 0.0563, 0.1370, 0.2863, 0.1849, 0.1065, 0.1731,\n",
            "        0.0517, 0.0597, 0.1309, 0.2655, 0.1788, 0.1020, 0.2005],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.11243871599435806\n",
            "------\n",
            "input_list [-6, -9, -7, -6, -6, -5, -6, -4, -2, -2, -8, -4, -3, -4, -3, -4, -5, -4, -4, 0]\n",
            "input_tensor tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0057, 0.0216, 0.1226, 0.6595, 0.1652, 0.0242, 0.0132, 0.0175, 0.0445,\n",
            "        0.1350, 0.4957, 0.2251, 0.0580, 0.0249, 0.0315, 0.0309, 0.1883, 0.3742,\n",
            "        0.2140, 0.0769, 0.0510, 0.0332, 0.0433, 0.1963, 0.3318, 0.2070, 0.0804,\n",
            "        0.0853, 0.0411, 0.0443, 0.1737, 0.3106, 0.1893, 0.1021, 0.1008, 0.0465,\n",
            "        0.0431, 0.1788, 0.3063, 0.1657, 0.1030, 0.1434, 0.0461, 0.0561, 0.1820,\n",
            "        0.2640, 0.1748, 0.0841, 0.1757, 0.0495, 0.0561, 0.1513, 0.2849, 0.1741,\n",
            "        0.0863, 0.1874, 0.0505, 0.0562, 0.1366, 0.2851, 0.1856, 0.1069, 0.1753,\n",
            "        0.0517, 0.0596, 0.1305, 0.2649, 0.1789, 0.1029, 0.2034],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.1204063817858696\n",
            "------\n",
            "input_list [-9, -7, -6, -6, -5, -6, -4, -2, -2, -8, -4, -3, -4, -4, -4, -5, -5, -4, 0, 0]\n",
            "input_tensor tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0057, 0.0216, 0.1222, 0.6604, 0.1656, 0.0242, 0.0132, 0.0176, 0.0445,\n",
            "        0.1347, 0.4967, 0.2268, 0.0579, 0.0249, 0.0315, 0.0308, 0.1874, 0.3740,\n",
            "        0.2170, 0.0767, 0.0509, 0.0332, 0.0433, 0.1955, 0.3315, 0.2079, 0.0814,\n",
            "        0.0848, 0.0410, 0.0443, 0.1732, 0.3101, 0.1898, 0.1043, 0.1003, 0.0464,\n",
            "        0.0431, 0.1780, 0.3056, 0.1664, 0.1046, 0.1428, 0.0461, 0.0560, 0.1816,\n",
            "        0.2634, 0.1753, 0.0851, 0.1771, 0.0494, 0.0561, 0.1512, 0.2835, 0.1751,\n",
            "        0.0869, 0.1884, 0.0505, 0.0561, 0.1363, 0.2838, 0.1861, 0.1078, 0.1771,\n",
            "        0.0516, 0.0595, 0.1301, 0.2642, 0.1789, 0.1036, 0.2072],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.13433067500591278\n",
            "------\n",
            "input_list [-10, -9, -10, -8, -9, -7, -6, -6, -11, -7, -7, -7, -7, -7, -8, -8, -7, -3, -3, -3]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0058, 0.0216, 0.1219, 0.6605, 0.1668, 0.0243, 0.0133, 0.0177, 0.0445,\n",
            "        0.1345, 0.4970, 0.2293, 0.0578, 0.0250, 0.0315, 0.0309, 0.1866, 0.3736,\n",
            "        0.2197, 0.0771, 0.0509, 0.0332, 0.0433, 0.1948, 0.3311, 0.2086, 0.0828,\n",
            "        0.0843, 0.0410, 0.0443, 0.1728, 0.3094, 0.1902, 0.1070, 0.0998, 0.0463,\n",
            "        0.0431, 0.1774, 0.3048, 0.1675, 0.1061, 0.1423, 0.0461, 0.0560, 0.1811,\n",
            "        0.2629, 0.1763, 0.0861, 0.1781, 0.0494, 0.0561, 0.1512, 0.2820, 0.1759,\n",
            "        0.0880, 0.1889, 0.0506, 0.0561, 0.1359, 0.2825, 0.1866, 0.1087, 0.1799,\n",
            "        0.0515, 0.0595, 0.1298, 0.2634, 0.1790, 0.1044, 0.2119],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.11088773608207703\n",
            "------\n",
            "input_list [-10, -10, -9, -10, -8, -6, -6, -12, -8, -7, -8, -8, -8, -9, -8, -8, -4, -4, -4, 0]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0058, 0.0217, 0.1216, 0.6610, 0.1678, 0.0243, 0.0134, 0.0177, 0.0445,\n",
            "        0.1343, 0.4968, 0.2323, 0.0577, 0.0251, 0.0316, 0.0309, 0.1857, 0.3728,\n",
            "        0.2228, 0.0774, 0.0508, 0.0332, 0.0434, 0.1940, 0.3305, 0.2099, 0.0841,\n",
            "        0.0838, 0.0410, 0.0443, 0.1722, 0.3085, 0.1911, 0.1094, 0.0993, 0.0462,\n",
            "        0.0432, 0.1766, 0.3047, 0.1684, 0.1074, 0.1416, 0.0461, 0.0560, 0.1806,\n",
            "        0.2622, 0.1777, 0.0870, 0.1788, 0.0494, 0.0560, 0.1511, 0.2805, 0.1766,\n",
            "        0.0893, 0.1891, 0.0506, 0.0561, 0.1355, 0.2809, 0.1868, 0.1100, 0.1822,\n",
            "        0.0515, 0.0595, 0.1293, 0.2625, 0.1789, 0.1055, 0.2157],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.10429587960243225\n",
            "------\n",
            "input_list [-12, -11, -12, -10, -9, -9, -14, -10, -10, -10, -10, -10, -11, -11, -10, -6, -6, -6, -3, -2]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0058, 0.0217, 0.1212, 0.6608, 0.1695, 0.0243, 0.0134, 0.0178, 0.0444,\n",
            "        0.1341, 0.4971, 0.2348, 0.0576, 0.0251, 0.0316, 0.0309, 0.1848, 0.3727,\n",
            "        0.2253, 0.0777, 0.0508, 0.0333, 0.0434, 0.1932, 0.3306, 0.2109, 0.0852,\n",
            "        0.0834, 0.0410, 0.0444, 0.1717, 0.3083, 0.1917, 0.1116, 0.0988, 0.0462,\n",
            "        0.0432, 0.1759, 0.3052, 0.1692, 0.1086, 0.1408, 0.0461, 0.0560, 0.1800,\n",
            "        0.2614, 0.1789, 0.0883, 0.1790, 0.0494, 0.0560, 0.1510, 0.2789, 0.1771,\n",
            "        0.0911, 0.1890, 0.0506, 0.0560, 0.1351, 0.2794, 0.1876, 0.1112, 0.1841,\n",
            "        0.0514, 0.0594, 0.1289, 0.2615, 0.1794, 0.1065, 0.2190],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.08662571012973785\n",
            "------\n",
            "input_list [-10, -12, -10, -8, -8, -13, -10, -9, -10, -9, -9, -11, -10, -10, -6, -5, -5, -2, -1, 0]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0059, 0.0217, 0.1208, 0.6609, 0.1707, 0.0244, 0.0134, 0.0178, 0.0443,\n",
            "        0.1338, 0.4980, 0.2368, 0.0575, 0.0252, 0.0316, 0.0309, 0.1839, 0.3734,\n",
            "        0.2273, 0.0779, 0.0506, 0.0333, 0.0434, 0.1922, 0.3313, 0.2116, 0.0861,\n",
            "        0.0828, 0.0410, 0.0444, 0.1710, 0.3086, 0.1921, 0.1134, 0.0982, 0.0461,\n",
            "        0.0433, 0.1752, 0.3054, 0.1703, 0.1095, 0.1399, 0.0461, 0.0560, 0.1793,\n",
            "        0.2604, 0.1804, 0.0893, 0.1789, 0.0494, 0.0560, 0.1508, 0.2772, 0.1779,\n",
            "        0.0926, 0.1885, 0.0506, 0.0560, 0.1346, 0.2778, 0.1888, 0.1121, 0.1855,\n",
            "        0.0513, 0.0593, 0.1285, 0.2613, 0.1796, 0.1073, 0.2217],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.0947888046503067\n",
            "------\n",
            "input_list [-12, -10, -8, -8, -13, -10, -9, -10, -9, -9, -11, -10, -10, -6, -5, -5, -2, -1, 0, 0]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0059, 0.0217, 0.1204, 0.6614, 0.1717, 0.0244, 0.0135, 0.0179, 0.0442,\n",
            "        0.1335, 0.4993, 0.2385, 0.0573, 0.0252, 0.0316, 0.0309, 0.1828, 0.3747,\n",
            "        0.2289, 0.0779, 0.0505, 0.0332, 0.0434, 0.1911, 0.3324, 0.2121, 0.0868,\n",
            "        0.0822, 0.0409, 0.0444, 0.1703, 0.3087, 0.1930, 0.1150, 0.0976, 0.0460,\n",
            "        0.0433, 0.1744, 0.3053, 0.1712, 0.1109, 0.1388, 0.0460, 0.0559, 0.1787,\n",
            "        0.2592, 0.1822, 0.0902, 0.1786, 0.0493, 0.0560, 0.1505, 0.2754, 0.1791,\n",
            "        0.0939, 0.1878, 0.0505, 0.0559, 0.1341, 0.2771, 0.1898, 0.1129, 0.1865,\n",
            "        0.0512, 0.0595, 0.1281, 0.2608, 0.1797, 0.1079, 0.2237],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.10212323814630508\n",
            "------\n",
            "input_list [-10, -8, -8, -13, -10, -9, -9, -9, -9, -11, -10, -10, -5, -5, -5, -2, -1, 0, 0, 0]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0059, 0.0217, 0.1199, 0.6622, 0.1724, 0.0243, 0.0135, 0.0179, 0.0441,\n",
            "        0.1331, 0.5011, 0.2397, 0.0571, 0.0252, 0.0316, 0.0308, 0.1817, 0.3765,\n",
            "        0.2301, 0.0779, 0.0503, 0.0332, 0.0434, 0.1900, 0.3332, 0.2130, 0.0875,\n",
            "        0.0816, 0.0408, 0.0444, 0.1696, 0.3084, 0.1936, 0.1171, 0.0970, 0.0459,\n",
            "        0.0433, 0.1737, 0.3050, 0.1724, 0.1122, 0.1376, 0.0459, 0.0558, 0.1779,\n",
            "        0.2580, 0.1842, 0.0909, 0.1779, 0.0493, 0.0560, 0.1501, 0.2743, 0.1800,\n",
            "        0.0951, 0.1868, 0.0505, 0.0561, 0.1335, 0.2761, 0.1906, 0.1135, 0.1871,\n",
            "        0.0510, 0.0599, 0.1277, 0.2601, 0.1796, 0.1084, 0.2253],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.11161543428897858\n",
            "------\n",
            "input_list [-7, -7, -12, -9, -8, -9, -8, -9, -10, -9, -9, -5, -5, -4, -1, 0, 1, 0, 0, 0]\n",
            "input_tensor tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0059, 0.0217, 0.1194, 0.6632, 0.1729, 0.0243, 0.0135, 0.0179, 0.0440,\n",
            "        0.1327, 0.5033, 0.2405, 0.0569, 0.0252, 0.0316, 0.0308, 0.1805, 0.3776,\n",
            "        0.2319, 0.0779, 0.0501, 0.0331, 0.0434, 0.1888, 0.3333, 0.2136, 0.0886,\n",
            "        0.0810, 0.0407, 0.0443, 0.1689, 0.3078, 0.1948, 0.1189, 0.0963, 0.0457,\n",
            "        0.0432, 0.1729, 0.3044, 0.1739, 0.1131, 0.1363, 0.0458, 0.0556, 0.1772,\n",
            "        0.2575, 0.1860, 0.0916, 0.1771, 0.0492, 0.0562, 0.1497, 0.2730, 0.1807,\n",
            "        0.0960, 0.1857, 0.0504, 0.0566, 0.1330, 0.2750, 0.1911, 0.1139, 0.1874,\n",
            "        0.0509, 0.0606, 0.1272, 0.2592, 0.1795, 0.1088, 0.2262],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.11937228590250015\n",
            "------\n",
            "input_list [-8, -13, -10, -9, -10, -9, -9, -11, -10, -10, -6, -5, -5, -2, -1, 0, 0, 0, 0, 0]\n",
            "input_tensor tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0059, 0.0217, 0.1187, 0.6645, 0.1731, 0.0243, 0.0134, 0.0179, 0.0438,\n",
            "        0.1322, 0.5048, 0.2420, 0.0567, 0.0252, 0.0316, 0.0307, 0.1793, 0.3781,\n",
            "        0.2333, 0.0784, 0.0499, 0.0330, 0.0433, 0.1878, 0.3332, 0.2148, 0.0895,\n",
            "        0.0803, 0.0405, 0.0443, 0.1682, 0.3070, 0.1963, 0.1204, 0.0956, 0.0455,\n",
            "        0.0431, 0.1721, 0.3045, 0.1751, 0.1139, 0.1349, 0.0457, 0.0558, 0.1763,\n",
            "        0.2569, 0.1874, 0.0921, 0.1760, 0.0490, 0.0564, 0.1498, 0.2716, 0.1813,\n",
            "        0.0968, 0.1843, 0.0503, 0.0573, 0.1324, 0.2737, 0.1913, 0.1141, 0.1874,\n",
            "        0.0510, 0.0611, 0.1267, 0.2581, 0.1793, 0.1090, 0.2266],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.14127592742443085\n",
            "------\n",
            "input_list [-17, -14, -13, -14, -13, -13, -15, -14, -14, -10, -10, -9, -6, -6, -3, -4, -4, -4, -5, -4]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0059, 0.0216, 0.1181, 0.6649, 0.1740, 0.0242, 0.0134, 0.0179, 0.0436,\n",
            "        0.1317, 0.5055, 0.2430, 0.0570, 0.0252, 0.0315, 0.0306, 0.1782, 0.3782,\n",
            "        0.2353, 0.0788, 0.0497, 0.0329, 0.0432, 0.1867, 0.3327, 0.2164, 0.0903,\n",
            "        0.0797, 0.0404, 0.0442, 0.1674, 0.3068, 0.1976, 0.1217, 0.0949, 0.0453,\n",
            "        0.0433, 0.1712, 0.3043, 0.1761, 0.1145, 0.1335, 0.0456, 0.0563, 0.1754,\n",
            "        0.2562, 0.1887, 0.0926, 0.1748, 0.0489, 0.0569, 0.1498, 0.2702, 0.1817,\n",
            "        0.0975, 0.1828, 0.0505, 0.0580, 0.1319, 0.2723, 0.1913, 0.1142, 0.1871,\n",
            "        0.0515, 0.0616, 0.1261, 0.2568, 0.1790, 0.1092, 0.2266],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.11909899115562439\n",
            "------\n",
            "input_list [-15, -14, -15, -14, -14, -16, -15, -15, -11, -11, -11, -8, -7, -4, -5, -5, -5, -6, -5, -1]\n",
            "input_tensor tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0059, 0.0215, 0.1174, 0.6657, 0.1746, 0.0242, 0.0134, 0.0178, 0.0434,\n",
            "        0.1312, 0.5066, 0.2437, 0.0572, 0.0251, 0.0314, 0.0306, 0.1770, 0.3789,\n",
            "        0.2369, 0.0790, 0.0494, 0.0328, 0.0431, 0.1862, 0.3319, 0.2177, 0.0909,\n",
            "        0.0791, 0.0405, 0.0441, 0.1666, 0.3064, 0.1986, 0.1227, 0.0941, 0.0455,\n",
            "        0.0434, 0.1703, 0.3038, 0.1768, 0.1149, 0.1320, 0.0457, 0.0566, 0.1744,\n",
            "        0.2552, 0.1895, 0.0928, 0.1733, 0.0491, 0.0572, 0.1496, 0.2686, 0.1819,\n",
            "        0.0979, 0.1811, 0.0509, 0.0585, 0.1313, 0.2707, 0.1912, 0.1141, 0.1864,\n",
            "        0.0522, 0.0620, 0.1255, 0.2554, 0.1786, 0.1092, 0.2262],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.13983562588691711\n",
            "------\n",
            "TESTING: 50\n",
            "Epoch: 0 - item: 0\n",
            "input_list [10, 16, 20, 19, 19, 20, 19, 19, 19, 12, 9, 9, 8, 8, 11, 10, 7, 2, 5, 5]\n",
            "input_oh [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]]\n",
            "act0 0 pred: [('0', 0.6668396592140198), ('3', 0.17520657181739807), ('-3', 0.11679105460643768), ('7', 0.024121154099702835), ('-7', 0.02152511291205883), ('10', 0.013388143852353096), ('-10', 0.005887534003704786)]\n",
            "act0 3 pred: [('0', 0.5068206191062927), ('3', 0.24417731165885925), ('-3', 0.13114653527736664), ('7', 0.057421810925006866), ('-7', 0.04323433339595795), ('10', 0.02513284608721733), ('-10', 0.017821718007326126)]\n",
            "act0 3 pred: [('0', 0.3791399598121643), ('3', 0.2381763458251953), ('-3', 0.17651347815990448), ('7', 0.07929092645645142), ('10', 0.04923754557967186), ('-10', 0.03135048970580101), ('-7', 0.030517032369971275)]\n",
            "act0 3 pred: [('0', 0.3311363160610199), ('3', 0.21865399181842804), ('-3', 0.185730442404747), ('7', 0.0914916917681694), ('10', 0.07851213216781616), ('-7', 0.04307650774717331), ('-10', 0.03304239362478256)]\n",
            "act0 7 pred: [('0', 0.30586570501327515), ('3', 0.19926689565181732), ('-3', 0.16577386856079102), ('7', 0.12365046888589859), ('10', 0.09344784170389175), ('-7', 0.0440211296081543), ('-10', 0.04102826490998268)]\n",
            "act0 7 pred: [('0', 0.3030955493450165), ('3', 0.17743955552577972), ('-3', 0.16939468681812286), ('10', 0.13060957193374634), ('7', 0.11531785130500793), ('-10', 0.04602847620844841), ('-7', 0.043495453894138336)]\n",
            "act0 7 pred: [('0', 0.25417107343673706), ('3', 0.19031766057014465), ('-3', 0.17333994805812836), ('10', 0.17173635959625244), ('7', 0.09316127002239227), ('-7', 0.05698160082101822), ('-10', 0.0462772510945797)]\n",
            "act0 7 pred: [('0', 0.2670277953147888), ('3', 0.18199752271175385), ('10', 0.17941203713417053), ('-3', 0.14947587251663208), ('7', 0.09842153638601303), ('-7', 0.057547759264707565), ('-10', 0.04960685968399048)]\n",
            "act0 7 pred: [('0', 0.2690652906894684), ('3', 0.19106419384479523), ('10', 0.18574096262454987), ('-3', 0.13070794939994812), ('7', 0.11408708244562149), ('-7', 0.05904055014252663), ('-10', 0.051649775356054306)]\n",
            "act0 7 pred: [('0', 0.25409623980522156), ('10', 0.2256203591823578), ('3', 0.1782081127166748), ('-3', 0.12491494417190552), ('7', 0.10929763317108154), ('-7', 0.0622795931994915), ('-10', 0.053136203438043594)]\n",
            "--------\n",
            "Epoch: 0 - item: 1\n",
            "input_list [16, 20, 19, 20, 20, 20, 20, 20, 13, 9, 9, 8, 8, 12, 11, 7, 2, 5, 6, 0]\n",
            "input_oh [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]]\n",
            "act0 3 pred: [('0', 0.6668551564216614), ('3', 0.17514263093471527), ('-3', 0.11673158407211304), ('7', 0.02411181852221489), ('-7', 0.021506350487470627), ('10', 0.013372807763516903), ('-10', 0.005882417783141136)]\n",
            "act0 3 pred: [('0', 0.506830096244812), ('3', 0.2440946102142334), ('-3', 0.1311226785182953), ('7', 0.05738966539502144), ('-7', 0.043210454285144806), ('10', 0.025111766532063484), ('-10', 0.01779671013355255)]\n",
            "act0 3 pred: [('0', 0.37918877601623535), ('3', 0.23815500736236572), ('-3', 0.17647437751293182), ('7', 0.0792328342795372), ('10', 0.04921521991491318), ('-10', 0.031323324888944626), ('-7', 0.030498428270220757)]\n",
            "act0 7 pred: [('0', 0.33107423782348633), ('3', 0.21864277124404907), ('-3', 0.18572163581848145), ('7', 0.0914572924375534), ('10', 0.07847090065479279), ('-7', 0.043051864951848984), ('-10', 0.033018480986356735)]\n",
            "act0 7 pred: [('0', 0.3057881295681), ('3', 0.19929815828800201), ('-3', 0.16574683785438538), ('7', 0.12358134984970093), ('10', 0.09338758885860443), ('-7', 0.04400108754634857), ('-10', 0.040998220443725586)]\n",
            "act0 7 pred: [('0', 0.303144633769989), ('3', 0.17737634479999542), ('-3', 0.16937415301799774), ('10', 0.13053134083747864), ('7', 0.11525066196918488), ('-10', 0.04601026698946953), ('-7', 0.04347250610589981)]\n",
            "act0 7 pred: [('0', 0.25411537289619446), ('3', 0.19027070701122284), ('-3', 0.17334264516830444), ('10', 0.17174652218818665), ('7', 0.09311234951019287), ('-7', 0.05695521458983421), ('-10', 0.04624347388744354)]\n",
            "act0 7 pred: [('0', 0.26701289415359497), ('3', 0.18199250102043152), ('10', 0.17937617003917694), ('-3', 0.14946024119853973), ('7', 0.09839186072349548), ('-7', 0.057521361857652664), ('-10', 0.04957731440663338)]\n",
            "act0 10 pred: [('0', 0.26906195282936096), ('3', 0.19099798798561096), ('10', 0.18569697439670563), ('-3', 0.13067631423473358), ('7', 0.1140434592962265), ('-7', 0.05901475250720978), ('-10', 0.05161997675895691)]\n",
            "act0 10 pred: [('0', 0.2540440261363983), ('10', 0.2255532294511795), ('3', 0.17817701399326324), ('-3', 0.12489908188581467), ('7', 0.10925204306840897), ('-7', 0.06226309388875961), ('-10', 0.05311695858836174)]\n",
            "--------\n",
            "Epoch: 0 - item: 2\n",
            "input_list [16, 15, 16, 16, 15, 15, 16, 9, 5, 5, 5, 4, 8, 7, 4, 0, 2, 2, -2, -3]\n",
            "input_oh [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]]\n",
            "act0 0 pred: [('0', 0.6668261885643005), ('3', 0.1750623881816864), ('-3', 0.1166803240776062), ('7', 0.024102337658405304), ('-7', 0.02148691564798355), ('10', 0.013363015837967396), ('-10', 0.0058770193718373775)]\n",
            "act0 0 pred: [('0', 0.5068815350532532), ('3', 0.2440279722213745), ('-3', 0.13107304275035858), ('7', 0.0573592446744442), ('-7', 0.04318089038133621), ('10', 0.025090061128139496), ('-10', 0.017778640612959862)]\n",
            "act0 3 pred: [('0', 0.3791727125644684), ('3', 0.23809078335762024), ('-3', 0.17641325294971466), ('7', 0.07919880747795105), ('10', 0.04919516295194626), ('-10', 0.03130154311656952), ('-7', 0.0304744690656662)]\n",
            "act0 3 pred: [('0', 0.3309873342514038), ('3', 0.21858710050582886), ('-3', 0.18569278717041016), ('7', 0.09142035245895386), ('10', 0.07844077050685883), ('-7', 0.04301447793841362), ('-10', 0.03298736363649368)]\n",
            "act0 3 pred: [('0', 0.3057134747505188), ('3', 0.19929654896259308), ('-3', 0.165726438164711), ('7', 0.123508520424366), ('10', 0.09333612024784088), ('-7', 0.04397113621234894), ('-10', 0.04096836596727371)]\n",
            "act0 3 pred: [('0', 0.3031153976917267), ('3', 0.17732363939285278), ('-3', 0.16932529211044312), ('10', 0.1304655820131302), ('7', 0.11520051956176758), ('-10', 0.04598298296332359), ('-7', 0.04344049096107483)]\n",
            "act0 3 pred: [('0', 0.2540842294692993), ('3', 0.19022136926651), ('-3', 0.17331106960773468), ('10', 0.17171378433704376), ('7', 0.093060702085495), ('-7', 0.0569223053753376), ('-10', 0.04620709270238876)]\n",
            "act0 7 pred: [('0', 0.26694053411483765), ('3', 0.18196064233779907), ('10', 0.1793229877948761), ('-3', 0.14942331612110138), ('7', 0.09834685921669006), ('-7', 0.05747699365019798), ('-10', 0.04954790323972702)]\n",
            "act0 7 pred: [('0', 0.2690311670303345), ('3', 0.190932497382164), ('10', 0.1856362372636795), ('-3', 0.13065387308597565), ('7', 0.11399079114198685), ('-7', 0.058976009488105774), ('-10', 0.05158225819468498)]\n",
            "act0 7 pred: [('0', 0.2539953887462616), ('10', 0.22549861669540405), ('3', 0.17812137305736542), ('-3', 0.12486808747053146), ('7', 0.10919809341430664), ('-7', 0.062238436192274094), ('-10', 0.053096622228622437)]\n",
            "--------\n",
            "Epoch: 0 - item: 3\n",
            "input_list [13, 14, 14, 14, 14, 14, 7, 4, 4, 3, 3, 6, 5, 2, -2, 0, 1, -4, -4, -1]\n",
            "input_oh [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]]\n",
            "act0 0 pred: [('0', 0.6668126583099365), ('3', 0.17494118213653564), ('-3', 0.11660782247781754), ('7', 0.024083789438009262), ('-7', 0.02145724557340145), ('10', 0.013340992853045464), ('-10', 0.005868700798600912)]\n",
            "act0 0 pred: [('0', 0.5068922638893127), ('3', 0.2439112663269043), ('-3', 0.1310187429189682), ('7', 0.05731411650776863), ('-7', 0.04313894733786583), ('10', 0.025056814774870872), ('-10', 0.01774805784225464)]\n",
            "act0 0 pred: [('0', 0.3792177736759186), ('3', 0.23803812265396118), ('-3', 0.1763647496700287), ('7', 0.07912494987249374), ('10', 0.04915986955165863), ('-10', 0.03125934302806854), ('-7', 0.030444743111729622)]\n",
            "act0 0 pred: [('0', 0.33088162541389465), ('3', 0.2185383290052414), ('-3', 0.1856619119644165), ('7', 0.09136492013931274), ('10', 0.07838189601898193), ('-7', 0.04296959564089775), ('-10', 0.0329473577439785)]\n",
            "act0 3 pred: [('0', 0.3056526184082031), ('3', 0.19930025935173035), ('-3', 0.16568174958229065), ('7', 0.12341207265853882), ('10', 0.09325724840164185), ('-7', 0.04393289238214493), ('-10', 0.04092120751738548)]\n",
            "act0 3 pred: [('0', 0.30310365557670593), ('3', 0.17724555730819702), ('-3', 0.1692708432674408), ('10', 0.1303754299879074), ('7', 0.1151190847158432), ('-10', 0.045953236520290375), ('-7', 0.043403707444667816)]\n",
            "act0 3 pred: [('0', 0.2540033161640167), ('3', 0.19013787806034088), ('-3', 0.17328369617462158), ('10', 0.171696737408638), ('7', 0.0929856151342392), ('-7', 0.056881505995988846), ('-10', 0.04615939036011696)]\n",
            "act0 7 pred: [('0', 0.2668907642364502), ('3', 0.18192945420742035), ('10', 0.1792721003293991), ('-3', 0.14936649799346924), ('7', 0.09828051924705505), ('-7', 0.05742451921105385), ('-10', 0.04949463903903961)]\n",
            "act0 7 pred: [('0', 0.2689911127090454), ('3', 0.1908395141363144), ('10', 0.18557168543338776), ('-3', 0.13061152398586273), ('7', 0.11390729248523712), ('-7', 0.058934494853019714), ('-10', 0.05153357982635498)]\n",
            "act0 7 pred: [('0', 0.25391334295272827), ('10', 0.22541509568691254), ('3', 0.17805570363998413), ('-3', 0.12483386695384979), ('7', 0.10912834852933884), ('-7', 0.062200453132390976), ('-10', 0.053066715598106384)]\n",
            "--------\n",
            "Epoch: 0 - item: 4\n",
            "input_list [13, 14, 13, 13, 14, 7, 3, 3, 3, 2, 6, 5, 2, -2, 0, 0, -4, -5, -1, 0]\n",
            "input_oh [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]]\n",
            "act0 0 pred: [('0', 0.6668137907981873), ('3', 0.17491160333156586), ('-3', 0.11659202724695206), ('7', 0.02407948672771454), ('-7', 0.02145138382911682), ('10', 0.01333675067871809), ('-10', 0.005866409279406071)]\n",
            "act0 0 pred: [('0', 0.5068947076797485), ('3', 0.24389027059078217), ('-3', 0.13099946081638336), ('7', 0.05730427801609039), ('-7', 0.043128348886966705), ('10', 0.025049541145563126), ('-10', 0.01774238981306553)]\n",
            "act0 0 pred: [('0', 0.3792106509208679), ('3', 0.23802123963832855), ('-3', 0.1763530671596527), ('7', 0.0791122168302536), ('10', 0.04915138706564903), ('-10', 0.031251322478055954), ('-7', 0.03043815679848194)]\n",
            "act0 3 pred: [('0', 0.33085256814956665), ('3', 0.21852394938468933), ('-3', 0.18565641343593597), ('7', 0.09135299175977707), ('10', 0.07837129384279251), ('-7', 0.04295741394162178), ('-10', 0.032938722521066666)]\n",
            "act0 3 pred: [('0', 0.30565014481544495), ('3', 0.19929231703281403), ('-3', 0.1656719446182251), ('7', 0.1233934834599495), ('10', 0.09324251115322113), ('-7', 0.043923016637563705), ('-10', 0.040910568088293076)]\n",
            "act0 3 pred: [('0', 0.30308812856674194), ('3', 0.17722757160663605), ('-3', 0.1692538559436798), ('10', 0.1303587555885315), ('7', 0.11510488390922546), ('-10', 0.04594562575221062), ('-7', 0.04339508339762688)]\n",
            "act0 7 pred: [('0', 0.25398898124694824), ('3', 0.19011923670768738), ('-3', 0.1732727736234665), ('10', 0.17168575525283813), ('7', 0.09296835958957672), ('-7', 0.05687350407242775), ('-10', 0.0461493581533432)]\n",
            "act0 7 pred: [('0', 0.26687097549438477), ('3', 0.18191678822040558), ('10', 0.1792600005865097), ('-3', 0.14934991300106049), ('7', 0.09826306998729706), ('-7', 0.05741099640727043), ('-10', 0.04948084428906441)]\n",
            "act0 7 pred: [('0', 0.2689793109893799), ('3', 0.19081734120845795), ('10', 0.18555863201618195), ('-3', 0.13060472905635834), ('7', 0.11388789862394333), ('-7', 0.058922890573740005), ('-10', 0.051521290093660355)]\n",
            "act0 3 pred: [('0', 0.25389590859413147), ('10', 0.22539837658405304), ('3', 0.17803820967674255), ('-3', 0.12482310831546783), ('7', 0.10911541432142258), ('-7', 0.06219034641981125), ('-10', 0.05305735394358635)]\n",
            "--------\n",
            "Epoch: 0 - item: 5\n",
            "input_list [12, 12, 12, 12, 6, 2, 2, 1, 1, 5, 4, 0, -3, 0, 0, -5, -6, -3, -1, -1]\n",
            "input_oh [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]]\n",
            "act0 0 pred: [('0', 0.6668102145195007), ('3', 0.17490164935588837), ('-3', 0.11658582836389542), ('7', 0.024077367037534714), ('-7', 0.021448573097586632), ('10', 0.01333486195653677), ('-10', 0.005865577608346939)]\n",
            "act0 0 pred: [('0', 0.5068953633308411), ('3', 0.2438805252313614), ('-3', 0.13099335134029388), ('7', 0.057299766689538956), ('-7', 0.043124325573444366), ('10', 0.02504654787480831), ('-10', 0.01774013787508011)]\n",
            "act0 3 pred: [('0', 0.3792090117931366), ('3', 0.23801574110984802), ('-3', 0.1763492375612259), ('7', 0.07910624146461487), ('10', 0.04914857819676399), ('-10', 0.0312473326921463), ('-7', 0.030435750260949135)]\n",
            "act0 3 pred: [('0', 0.33084365725517273), ('3', 0.21851888298988342), ('-3', 0.1856522560119629), ('7', 0.09134817868471146), ('10', 0.07836684584617615), ('-7', 0.042952761054039), ('-10', 0.03293493762612343)]\n",
            "act0 3 pred: [('0', 0.30564743280410767), ('3', 0.1992899626493454), ('-3', 0.1656683087348938), ('7', 0.1233857199549675), ('10', 0.09323588013648987), ('-7', 0.04391957074403763), ('-10', 0.04090636223554611)]\n",
            "act0 7 pred: [('0', 0.3030841052532196), ('3', 0.17722220718860626), ('-3', 0.16924868524074554), ('10', 0.13035161793231964), ('7', 0.11509878933429718), ('-10', 0.045942239463329315), ('-7', 0.04339129477739334)]\n",
            "act0 3 pred: [('0', 0.2539824843406677), ('3', 0.19011114537715912), ('-3', 0.17326900362968445), ('10', 0.1716834455728531), ('7', 0.0929623693227768), ('-7', 0.056869544088840485), ('-10', 0.046145178377628326)]\n",
            "act0 3 pred: [('0', 0.2668653428554535), ('3', 0.1819136142730713), ('10', 0.17925550043582916), ('-3', 0.14934372901916504), ('7', 0.09825649112462997), ('-7', 0.05740510672330856), ('-10', 0.04947645217180252)]\n",
            "act0 3 pred: [('0', 0.2689763307571411), ('3', 0.19080957770347595), ('10', 0.18555109202861786), ('-3', 0.13060088455677032), ('7', 0.1138807088136673), ('-7', 0.05891991779208183), ('-10', 0.05151718854904175)]\n",
            "act0 3 pred: [('0', 0.2538858652114868), ('10', 0.225388303399086), ('3', 0.17803117632865906), ('-3', 0.12481846660375595), ('7', 0.10910913348197937), ('-7', 0.06218624487519264), ('-10', 0.053054969757795334)]\n",
            "--------\n",
            "Epoch: 0 - item: 6\n",
            "input_list [12, 12, 13, 6, 2, 2, 2, 1, 5, 4, 1, -3, 0, 0, -5, -6, -2, -1, 0, 0]\n",
            "input_oh [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]]\n",
            "act0 0 pred: [('0', 0.6668111085891724), ('3', 0.17489607632160187), ('-3', 0.11658336967229843), ('7', 0.02407686412334442), ('-7', 0.021447980776429176), ('10', 0.013334379531443119), ('-10', 0.0058651939034461975)]\n",
            "act0 3 pred: [('0', 0.5068953037261963), ('3', 0.2438776195049286), ('-3', 0.130988210439682), ('7', 0.057298339903354645), ('-7', 0.04312286153435707), ('10', 0.02504536509513855), ('-10', 0.017739472910761833)]\n",
            "act0 3 pred: [('0', 0.37920406460762024), ('3', 0.23801228404045105), ('-3', 0.17634783685207367), ('7', 0.07910517603158951), ('10', 0.049147386103868484), ('-10', 0.03124653548002243), ('-7', 0.030434876680374146)]\n",
            "act0 3 pred: [('0', 0.33083710074424744), ('3', 0.21851706504821777), ('-3', 0.1856534481048584), ('7', 0.09134695678949356), ('10', 0.07836662232875824), ('-7', 0.04295015335083008), ('-10', 0.032933853566646576)]\n",
            "act0 7 pred: [('0', 0.3056490123271942), ('3', 0.19928856194019318), ('-3', 0.16566625237464905), ('7', 0.12338374555110931), ('10', 0.09323351830244064), ('-7', 0.04391767084598541), ('-10', 0.04090479761362076)]\n",
            "act0 3 pred: [('0', 0.30307984352111816), ('3', 0.17721818387508392), ('-3', 0.16924524307250977), ('10', 0.13035114109516144), ('7', 0.11509674787521362), ('-10', 0.045940738171339035), ('-7', 0.04338979721069336)]\n",
            "act0 3 pred: [('0', 0.2539815604686737), ('3', 0.19010844826698303), ('-3', 0.17326702177524567), ('10', 0.1716803014278412), ('7', 0.09295915067195892), ('-7', 0.05686895176768303), ('-10', 0.04614400491118431)]\n",
            "act0 3 pred: [('0', 0.2668610215187073), ('3', 0.18191088736057281), ('10', 0.17925336956977844), ('-3', 0.14934051036834717), ('7', 0.09825421124696732), ('-7', 0.05740302428603172), ('-10', 0.04947386309504509)]\n",
            "act0 3 pred: [('0', 0.2689746916294098), ('3', 0.1908046305179596), ('10', 0.18555109202861786), ('-3', 0.130600705742836), ('7', 0.11387766897678375), ('-7', 0.058917779475450516), ('-10', 0.05151507630944252)]\n",
            "act0 3 pred: [('0', 0.25388455390930176), ('10', 0.2253866046667099), ('3', 0.17802828550338745), ('-3', 0.12481653690338135), ('7', 0.10910844057798386), ('-7', 0.06218434125185013), ('-10', 0.05305306613445282)]\n",
            "--------\n",
            "Epoch: 0 - item: 7\n",
            "input_list [12, 12, 5, 2, 2, 1, 1, 5, 4, 0, -3, -1, 0, -6, -6, -3, -1, -1, 0, 0]\n",
            "input_oh [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]]\n",
            "act0 3 pred: [('0', 0.6668129563331604), ('3', 0.17489862442016602), ('-3', 0.11658500134944916), ('7', 0.02407725527882576), ('-7', 0.0214486513286829), ('10', 0.0133347287774086), ('-10', 0.00586528517305851)]\n",
            "act0 3 pred: [('0', 0.5068938732147217), ('3', 0.24387995898723602), ('-3', 0.13098903000354767), ('7', 0.05729923024773598), ('-7', 0.043123770505189896), ('10', 0.025045864284038544), ('-10', 0.017739947885274887)]\n",
            "act0 3 pred: [('0', 0.3792024850845337), ('3', 0.23801369965076447), ('-3', 0.17634929716587067), ('7', 0.07910637557506561), ('10', 0.04914792627096176), ('-10', 0.031247593462467194), ('-7', 0.030435848981142044)]\n",
            "act0 7 pred: [('0', 0.33083945512771606), ('3', 0.21851925551891327), ('-3', 0.1856548935174942), ('7', 0.09134799987077713), ('10', 0.07836794853210449), ('-7', 0.04295104369521141), ('-10', 0.032934848219156265)]\n",
            "act0 3 pred: [('0', 0.3056522607803345), ('3', 0.199288010597229), ('-3', 0.16566650569438934), ('7', 0.12338673323392868), ('10', 0.09323494881391525), ('-7', 0.04391824081540108), ('-10', 0.040905650705099106)]\n",
            "act0 3 pred: [('0', 0.30308032035827637), ('3', 0.17721879482269287), ('-3', 0.16924607753753662), ('10', 0.13035349547863007), ('7', 0.11509805917739868), ('-10', 0.04594126716256142), ('-7', 0.04339073970913887)]\n",
            "act0 3 pred: [('0', 0.2539830803871155), ('3', 0.19011090695858002), ('-3', 0.1732676923274994), ('10', 0.17168143391609192), ('7', 0.092960424721241), ('-7', 0.05687052384018898), ('-10', 0.046145033091306686)]\n",
            "act0 3 pred: [('0', 0.26686277985572815), ('3', 0.18191199004650116), ('10', 0.17925414443016052), ('-3', 0.14934216439723969), ('7', 0.09825552254915237), ('-7', 0.057404305785894394), ('-10', 0.04947454482316971)]\n",
            "act0 3 pred: [('0', 0.2689756751060486), ('3', 0.19080564379692078), ('10', 0.1855533868074417), ('-3', 0.13060137629508972), ('7', 0.11387912929058075), ('-7', 0.05891841650009155), ('-10', 0.05151616036891937)]\n",
            "act0 3 pred: [('0', 0.253885418176651), ('10', 0.22538863122463226), ('3', 0.17803025245666504), ('-3', 0.12481683492660522), ('7', 0.10911025106906891), ('-7', 0.062184881418943405), ('-10', 0.05305340141057968)]\n",
            "--------\n",
            "Epoch: 0 - item: 8\n",
            "input_list [10, 3, 0, 0, 0, 0, 2, 2, -1, -5, -3, -2, -7, -8, -5, -3, -3, -2, -2, -2]\n",
            "input_oh [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]]\n",
            "act0 0 pred: [('0', 0.6667948961257935), ('3', 0.17489966750144958), ('-3', 0.11657381802797318), ('7', 0.024077361449599266), ('-7', 0.021445630118250847), ('10', 0.013337007723748684), ('-10', 0.005864954553544521)]\n",
            "act0 0 pred: [('0', 0.5069373250007629), ('3', 0.2438744753599167), ('-3', 0.13096973299980164), ('7', 0.0572938546538353), ('-7', 0.04312147945165634), ('10', 0.02504371665418148), ('-10', 0.017740702256560326)]\n",
            "act0 3 pred: [('0', 0.37917375564575195), ('3', 0.23798133432865143), ('-3', 0.17631708085536957), ('7', 0.07911182194948196), ('10', 0.049147576093673706), ('-10', 0.03124786540865898), ('-7', 0.030428772792220116)]\n",
            "act0 3 pred: [('0', 0.3308224380016327), ('3', 0.21849432587623596), ('-3', 0.1856452226638794), ('7', 0.09134560823440552), ('10', 0.07837621122598648), ('-7', 0.04294139891862869), ('-10', 0.032927606254816055)]\n",
            "act0 3 pred: [('0', 0.3056178689002991), ('3', 0.19928893446922302), ('-3', 0.16566544771194458), ('7', 0.12337249517440796), ('10', 0.09322775155305862), ('-7', 0.04391254484653473), ('-10', 0.04090309515595436)]\n",
            "act0 0 pred: [('0', 0.30306753516197205), ('3', 0.1772184669971466), ('-3', 0.1692376285791397), ('10', 0.1303439438343048), ('7', 0.11509333550930023), ('-10', 0.04593250900506973), ('-7', 0.043379392474889755)]\n",
            "act0 0 pred: [('0', 0.25399917364120483), ('3', 0.1901015341281891), ('-3', 0.1732526421546936), ('10', 0.1716541200876236), ('7', 0.09295433014631271), ('-7', 0.05685792863368988), ('-10', 0.04613976180553436)]\n",
            "act0 0 pred: [('0', 0.26682138442993164), ('3', 0.18190190196037292), ('10', 0.17923416197299957), ('-3', 0.14933443069458008), ('7', 0.09824834764003754), ('-7', 0.057393185794353485), ('-10', 0.04947776347398758)]\n",
            "act0 0 pred: [('0', 0.2689724266529083), ('3', 0.19080102443695068), ('10', 0.18552739918231964), ('-3', 0.13059911131858826), ('7', 0.11388033628463745), ('-7', 0.058908894658088684), ('-10', 0.05150677636265755)]\n",
            "act0 3 pred: [('0', 0.2538766860961914), ('10', 0.22538791596889496), ('3', 0.1780100017786026), ('-3', 0.12480474263429642), ('7', 0.10910134762525558), ('-7', 0.0621839202940464), ('-10', 0.05304980278015137)]\n",
            "--------\n",
            "Epoch: 0 - item: 9\n",
            "input_list [3, 0, 0, 0, 0, 2, 1, -1, -6, -3, -2, -8, -8, -5, -3, -3, -2, -2, -2, 0]\n",
            "input_oh [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]]\n",
            "act0 0 pred: [('0', 0.6667987704277039), ('3', 0.17488732933998108), ('-3', 0.11657403409481049), ('7', 0.02407490834593773), ('-7', 0.0214435625821352), ('10', 0.013332685455679893), ('-10', 0.005864623934030533)]\n",
            "act0 3 pred: [('0', 0.5069118738174438), ('3', 0.2438613474369049), ('-3', 0.13098357617855072), ('7', 0.05729244276881218), ('-7', 0.0431191511452198), ('10', 0.025041505694389343), ('-10', 0.017736565321683884)]\n",
            "act0 3 pred: [('0', 0.37921127676963806), ('3', 0.23800194263458252), ('-3', 0.17633458971977234), ('7', 0.07909771054983139), ('10', 0.04914448782801628), ('-10', 0.031241321936249733), ('-7', 0.030429895967245102)]\n",
            "act0 3 pred: [('0', 0.3308272361755371), ('3', 0.21850641071796417), ('-3', 0.18564295768737793), ('7', 0.09134018421173096), ('10', 0.07836151123046875), ('-7', 0.04294449836015701), ('-10', 0.032927505671978)]\n",
            "act0 0 pred: [('0', 0.30562713742256165), ('3', 0.19929344952106476), ('-3', 0.16566252708435059), ('7', 0.12336832284927368), ('10', 0.09322229027748108), ('-7', 0.04391321539878845), ('-10', 0.04089999198913574)]\n",
            "act0 0 pred: [('0', 0.30308231711387634), ('3', 0.17721347510814667), ('-3', 0.16924048960208893), ('10', 0.13033737242221832), ('7', 0.11508598178625107), ('-10', 0.04593570902943611), ('-7', 0.04338318109512329)]\n",
            "act0 0 pred: [('0', 0.25397732853889465), ('3', 0.19009725749492645), ('-3', 0.17326237261295319), ('10', 0.17167572677135468), ('7', 0.09295158833265305), ('-7', 0.05686004087328911), ('-10', 0.046137433499097824)]\n",
            "act0 0 pred: [('0', 0.26685163378715515), ('3', 0.18191060423851013), ('10', 0.17924322187900543), ('-3', 0.14933477342128754), ('7', 0.09824670106172562), ('-7', 0.05739493668079376), ('-10', 0.049471933394670486)]\n",
            "act0 3 pred: [('0', 0.26897114515304565), ('3', 0.1907966434955597), ('10', 0.18553484976291656), ('-3', 0.13059335947036743), ('7', 0.11387109011411667), ('-7', 0.05891292169690132), ('-10', 0.05150889232754707)]\n",
            "act0 3 pred: [('0', 0.2538715600967407), ('10', 0.225377157330513), ('3', 0.1780177652835846), ('-3', 0.12481178343296051), ('7', 0.1090967133641243), ('-7', 0.06218208372592926), ('-10', 0.0530519112944603)]\n",
            "--------\n",
            "Epoch # 0 - Stock: AAL -  train loss: 0.11399 - test loss: 0.11182 - elapsed: 2.21  - n_sells: 0 - balance: 0\n",
            "time elapsed: 2.21\n",
            "--------\n",
            "ALGN all_training 50 all_testing 50\n",
            "input_list [125, 80, 89, 88, 88, 86, 74, 74, 60, 47, 52, 55, 70, 74, 70, 64, 61, 47, 20, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0059, 0.0215, 0.1167, 0.6669, 0.1751, 0.0241, 0.0134, 0.0178, 0.0432,\n",
            "        0.1311, 0.5069, 0.2440, 0.0574, 0.0251, 0.0313, 0.0305, 0.1764, 0.3792,\n",
            "        0.2381, 0.0792, 0.0492, 0.0330, 0.0430, 0.1857, 0.3310, 0.2186, 0.0914,\n",
            "        0.0785, 0.0410, 0.0440, 0.1657, 0.3058, 0.1993, 0.1235, 0.0933, 0.0460,\n",
            "        0.0434, 0.1693, 0.3031, 0.1773, 0.1152, 0.1305, 0.0462, 0.0569, 0.1733,\n",
            "        0.2541, 0.1902, 0.0931, 0.1717, 0.0495, 0.0575, 0.1494, 0.2669, 0.1820,\n",
            "        0.0983, 0.1793, 0.0516, 0.0590, 0.1307, 0.2690, 0.1909, 0.1140, 0.1857,\n",
            "        0.0531, 0.0622, 0.1249, 0.2540, 0.1781, 0.1092, 0.2255],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.10380932688713074\n",
            "------\n",
            "input_list [78, 87, 86, 86, 85, 72, 72, 58, 46, 51, 53, 69, 72, 68, 62, 60, 46, 19, 0, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0059, 0.0214, 0.1159, 0.6681, 0.1752, 0.0240, 0.0133, 0.0177, 0.0429,\n",
            "        0.1308, 0.5077, 0.2439, 0.0574, 0.0250, 0.0315, 0.0303, 0.1757, 0.3791,\n",
            "        0.2389, 0.0792, 0.0489, 0.0331, 0.0428, 0.1850, 0.3305, 0.2192, 0.0918,\n",
            "        0.0777, 0.0413, 0.0438, 0.1648, 0.3048, 0.2005, 0.1240, 0.0925, 0.0464,\n",
            "        0.0435, 0.1683, 0.3022, 0.1776, 0.1152, 0.1300, 0.0466, 0.0571, 0.1721,\n",
            "        0.2528, 0.1906, 0.0936, 0.1699, 0.0499, 0.0576, 0.1491, 0.2652, 0.1818,\n",
            "        0.0985, 0.1789, 0.0521, 0.0593, 0.1300, 0.2672, 0.1905, 0.1137, 0.1859,\n",
            "        0.0539, 0.0624, 0.1242, 0.2524, 0.1775, 0.1090, 0.2260],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.11223268508911133\n",
            "------\n",
            "input_list [89, 88, 88, 86, 74, 74, 60, 47, 52, 55, 70, 74, 70, 64, 61, 47, 20, 0, 0, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0058, 0.0213, 0.1152, 0.6697, 0.1751, 0.0239, 0.0132, 0.0178, 0.0426,\n",
            "        0.1305, 0.5078, 0.2436, 0.0575, 0.0249, 0.0316, 0.0302, 0.1750, 0.3799,\n",
            "        0.2394, 0.0792, 0.0486, 0.0332, 0.0427, 0.1843, 0.3298, 0.2202, 0.0920,\n",
            "        0.0771, 0.0416, 0.0436, 0.1639, 0.3038, 0.2014, 0.1243, 0.0925, 0.0467,\n",
            "        0.0435, 0.1673, 0.3010, 0.1777, 0.1159, 0.1295, 0.0469, 0.0572, 0.1709,\n",
            "        0.2514, 0.1908, 0.0940, 0.1696, 0.0502, 0.0578, 0.1487, 0.2634, 0.1816,\n",
            "        0.0987, 0.1796, 0.0526, 0.0596, 0.1294, 0.2654, 0.1900, 0.1133, 0.1872,\n",
            "        0.0546, 0.0625, 0.1236, 0.2508, 0.1769, 0.1088, 0.2276],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.12375285476446152\n",
            "------\n",
            "input_list [111, 111, 109, 95, 95, 79, 65, 71, 73, 91, 95, 90, 84, 81, 65, 34, 13, 12, 13, 12]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0059, 0.0213, 0.1145, 0.6703, 0.1750, 0.0239, 0.0132, 0.0179, 0.0424,\n",
            "        0.1303, 0.5085, 0.2431, 0.0575, 0.0249, 0.0318, 0.0301, 0.1744, 0.3800,\n",
            "        0.2407, 0.0792, 0.0483, 0.0333, 0.0426, 0.1835, 0.3288, 0.2210, 0.0923,\n",
            "        0.0773, 0.0419, 0.0435, 0.1630, 0.3027, 0.2022, 0.1255, 0.0926, 0.0471,\n",
            "        0.0435, 0.1663, 0.2997, 0.1778, 0.1166, 0.1302, 0.0473, 0.0573, 0.1698,\n",
            "        0.2502, 0.1909, 0.0945, 0.1705, 0.0505, 0.0579, 0.1483, 0.2617, 0.1813,\n",
            "        0.0987, 0.1815, 0.0531, 0.0599, 0.1289, 0.2635, 0.1895, 0.1130, 0.1896,\n",
            "        0.0553, 0.0627, 0.1230, 0.2493, 0.1763, 0.1086, 0.2305],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "loss: 0.14343512058258057\n",
            "------\n",
            "input_list [88, 86, 74, 74, 60, 47, 52, 55, 70, 74, 70, 64, 61, 47, 20, 0, 0, 0, 0, -10]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0060, 0.0212, 0.1138, 0.6700, 0.1745, 0.0238, 0.0134, 0.0180, 0.0422,\n",
            "        0.1298, 0.5086, 0.2422, 0.0575, 0.0250, 0.0319, 0.0300, 0.1736, 0.3799,\n",
            "        0.2417, 0.0791, 0.0486, 0.0333, 0.0424, 0.1827, 0.3274, 0.2215, 0.0925,\n",
            "        0.0782, 0.0421, 0.0433, 0.1621, 0.3014, 0.2028, 0.1262, 0.0934, 0.0473,\n",
            "        0.0435, 0.1653, 0.2982, 0.1777, 0.1170, 0.1316, 0.0475, 0.0574, 0.1686,\n",
            "        0.2488, 0.1908, 0.0947, 0.1727, 0.0507, 0.0579, 0.1478, 0.2599, 0.1810,\n",
            "        0.0987, 0.1842, 0.0534, 0.0601, 0.1283, 0.2615, 0.1887, 0.1125, 0.1928,\n",
            "        0.0558, 0.0627, 0.1223, 0.2477, 0.1756, 0.1083, 0.2342],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.1410660445690155\n",
            "------\n",
            "input_list [79, 67, 67, 53, 41, 46, 48, 64, 67, 63, 57, 55, 41, 15, -3, -4, -3, -4, -14, -4]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0061, 0.0211, 0.1132, 0.6690, 0.1750, 0.0238, 0.0135, 0.0181, 0.0421,\n",
            "        0.1295, 0.5081, 0.2412, 0.0576, 0.0254, 0.0320, 0.0299, 0.1730, 0.3794,\n",
            "        0.2425, 0.0796, 0.0488, 0.0333, 0.0423, 0.1818, 0.3261, 0.2218, 0.0927,\n",
            "        0.0798, 0.0424, 0.0432, 0.1613, 0.3001, 0.2034, 0.1270, 0.0949, 0.0476,\n",
            "        0.0435, 0.1643, 0.2968, 0.1777, 0.1173, 0.1341, 0.0479, 0.0574, 0.1675,\n",
            "        0.2475, 0.1907, 0.0950, 0.1760, 0.0509, 0.0579, 0.1474, 0.2583, 0.1807,\n",
            "        0.0986, 0.1880, 0.0538, 0.0603, 0.1278, 0.2595, 0.1881, 0.1120, 0.1970,\n",
            "        0.0564, 0.0629, 0.1217, 0.2461, 0.1750, 0.1087, 0.2372],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.13658790290355682\n",
            "------\n",
            "input_list [54, 54, 41, 30, 35, 37, 51, 54, 50, 45, 42, 30, 6, -10, -11, -10, -11, -21, -11, -7]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0062, 0.0211, 0.1128, 0.6675, 0.1754, 0.0240, 0.0137, 0.0183, 0.0420,\n",
            "        0.1292, 0.5069, 0.2412, 0.0577, 0.0259, 0.0322, 0.0299, 0.1724, 0.3786,\n",
            "        0.2431, 0.0808, 0.0490, 0.0334, 0.0423, 0.1810, 0.3248, 0.2221, 0.0929,\n",
            "        0.0821, 0.0427, 0.0431, 0.1605, 0.2989, 0.2038, 0.1276, 0.0973, 0.0479,\n",
            "        0.0435, 0.1634, 0.2952, 0.1776, 0.1176, 0.1376, 0.0482, 0.0575, 0.1664,\n",
            "        0.2462, 0.1912, 0.0953, 0.1787, 0.0512, 0.0580, 0.1470, 0.2567, 0.1804,\n",
            "        0.0987, 0.1927, 0.0542, 0.0606, 0.1274, 0.2576, 0.1881, 0.1116, 0.2007,\n",
            "        0.0570, 0.0630, 0.1212, 0.2447, 0.1749, 0.1090, 0.2397],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.1324051320552826\n",
            "------\n",
            "input_list [60, 47, 36, 40, 43, 57, 60, 56, 51, 49, 36, 10, -6, -7, -6, -7, -17, -7, -3, 4]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0063, 0.0211, 0.1128, 0.6653, 0.1755, 0.0243, 0.0138, 0.0184, 0.0419,\n",
            "        0.1287, 0.5066, 0.2409, 0.0577, 0.0262, 0.0323, 0.0299, 0.1717, 0.3776,\n",
            "        0.2433, 0.0818, 0.0497, 0.0334, 0.0422, 0.1800, 0.3231, 0.2220, 0.0930,\n",
            "        0.0850, 0.0429, 0.0430, 0.1596, 0.2975, 0.2040, 0.1279, 0.1002, 0.0481,\n",
            "        0.0435, 0.1631, 0.2935, 0.1774, 0.1178, 0.1405, 0.0485, 0.0576, 0.1653,\n",
            "        0.2449, 0.1921, 0.0954, 0.1810, 0.0514, 0.0581, 0.1471, 0.2550, 0.1799,\n",
            "        0.0986, 0.1967, 0.0545, 0.0607, 0.1273, 0.2556, 0.1879, 0.1111, 0.2036,\n",
            "        0.0574, 0.0634, 0.1206, 0.2431, 0.1748, 0.1092, 0.2415],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.13349859416484833\n",
            "------\n",
            "input_list [41, 30, 34, 36, 50, 53, 50, 44, 42, 30, 5, -11, -11, -11, -11, -21, -11, -8, 0, -4]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0064, 0.0211, 0.1127, 0.6627, 0.1762, 0.0245, 0.0139, 0.0185, 0.0417,\n",
            "        0.1282, 0.5058, 0.2402, 0.0577, 0.0268, 0.0324, 0.0298, 0.1709, 0.3761,\n",
            "        0.2432, 0.0827, 0.0508, 0.0334, 0.0421, 0.1791, 0.3212, 0.2218, 0.0930,\n",
            "        0.0885, 0.0431, 0.0428, 0.1588, 0.2968, 0.2042, 0.1280, 0.1027, 0.0482,\n",
            "        0.0435, 0.1626, 0.2918, 0.1771, 0.1185, 0.1429, 0.0487, 0.0576, 0.1642,\n",
            "        0.2442, 0.1928, 0.0955, 0.1828, 0.0516, 0.0580, 0.1471, 0.2540, 0.1794,\n",
            "        0.0984, 0.2000, 0.0547, 0.0608, 0.1276, 0.2536, 0.1876, 0.1106, 0.2059,\n",
            "        0.0578, 0.0637, 0.1204, 0.2414, 0.1745, 0.1093, 0.2427],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.14829899370670319\n",
            "------\n",
            "input_list [16, 20, 22, 34, 37, 34, 29, 27, 16, -5, -20, -21, -20, -21, -29, -21, -17, -10, -14, -10]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0064, 0.0210, 0.1125, 0.6596, 0.1768, 0.0246, 0.0142, 0.0186, 0.0416,\n",
            "        0.1276, 0.5045, 0.2393, 0.0576, 0.0276, 0.0325, 0.0298, 0.1702, 0.3743,\n",
            "        0.2430, 0.0834, 0.0523, 0.0334, 0.0420, 0.1788, 0.3192, 0.2215, 0.0930,\n",
            "        0.0917, 0.0432, 0.0427, 0.1580, 0.2960, 0.2048, 0.1281, 0.1050, 0.0483,\n",
            "        0.0434, 0.1626, 0.2899, 0.1767, 0.1191, 0.1451, 0.0489, 0.0576, 0.1636,\n",
            "        0.2436, 0.1933, 0.0955, 0.1840, 0.0517, 0.0583, 0.1469, 0.2529, 0.1789,\n",
            "        0.0983, 0.2028, 0.0549, 0.0613, 0.1279, 0.2517, 0.1871, 0.1100, 0.2077,\n",
            "        0.0586, 0.0640, 0.1201, 0.2397, 0.1741, 0.1094, 0.2434],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.1501401960849762\n",
            "------\n",
            "input_list [11, 13, 25, 27, 24, 20, 18, 7, -12, -26, -26, -26, -26, -34, -26, -23, -17, -20, -17, -7]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0065, 0.0210, 0.1123, 0.6560, 0.1770, 0.0250, 0.0145, 0.0187, 0.0414,\n",
            "        0.1271, 0.5039, 0.2382, 0.0576, 0.0282, 0.0329, 0.0297, 0.1694, 0.3725,\n",
            "        0.2426, 0.0840, 0.0537, 0.0334, 0.0421, 0.1784, 0.3171, 0.2210, 0.0930,\n",
            "        0.0945, 0.0437, 0.0425, 0.1572, 0.2949, 0.2054, 0.1279, 0.1069, 0.0487,\n",
            "        0.0433, 0.1625, 0.2881, 0.1763, 0.1194, 0.1467, 0.0494, 0.0575, 0.1630,\n",
            "        0.2427, 0.1936, 0.0955, 0.1850, 0.0522, 0.0585, 0.1468, 0.2517, 0.1784,\n",
            "        0.0980, 0.2048, 0.0554, 0.0616, 0.1280, 0.2497, 0.1865, 0.1094, 0.2089,\n",
            "        0.0596, 0.0643, 0.1197, 0.2380, 0.1737, 0.1093, 0.2434],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.16410157084465027\n",
            "------\n",
            "input_list [23, 35, 38, 35, 30, 28, 17, -4, -19, -20, -19, -20, -29, -20, -17, -10, -13, -9, 0, 8]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0065, 0.0211, 0.1119, 0.6521, 0.1769, 0.0254, 0.0147, 0.0189, 0.0412,\n",
            "        0.1263, 0.5029, 0.2368, 0.0574, 0.0288, 0.0335, 0.0295, 0.1684, 0.3703,\n",
            "        0.2418, 0.0845, 0.0549, 0.0335, 0.0421, 0.1779, 0.3148, 0.2202, 0.0928,\n",
            "        0.0970, 0.0444, 0.0423, 0.1562, 0.2936, 0.2056, 0.1276, 0.1084, 0.0494,\n",
            "        0.0432, 0.1622, 0.2861, 0.1757, 0.1196, 0.1478, 0.0502, 0.0573, 0.1621,\n",
            "        0.2417, 0.1936, 0.0953, 0.1854, 0.0529, 0.0585, 0.1464, 0.2503, 0.1776,\n",
            "        0.0976, 0.2063, 0.0561, 0.0619, 0.1280, 0.2476, 0.1857, 0.1086, 0.2096,\n",
            "        0.0609, 0.0644, 0.1192, 0.2361, 0.1731, 0.1090, 0.2430],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.1610465943813324\n",
            "------\n",
            "input_list [55, 58, 54, 49, 46, 34, 9, -8, -9, -8, -9, -18, -9, -5, 2, -1, 3, 15, 24, 14]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0067, 0.0212, 0.1115, 0.6478, 0.1767, 0.0257, 0.0149, 0.0191, 0.0410,\n",
            "        0.1260, 0.5012, 0.2353, 0.0572, 0.0294, 0.0344, 0.0294, 0.1675, 0.3680,\n",
            "        0.2410, 0.0848, 0.0560, 0.0340, 0.0421, 0.1774, 0.3125, 0.2194, 0.0927,\n",
            "        0.0992, 0.0455, 0.0420, 0.1553, 0.2922, 0.2057, 0.1271, 0.1097, 0.0504,\n",
            "        0.0430, 0.1618, 0.2841, 0.1750, 0.1196, 0.1487, 0.0513, 0.0572, 0.1613,\n",
            "        0.2406, 0.1934, 0.0951, 0.1855, 0.0539, 0.0585, 0.1461, 0.2489, 0.1769,\n",
            "        0.0972, 0.2072, 0.0572, 0.0621, 0.1279, 0.2456, 0.1849, 0.1079, 0.2098,\n",
            "        0.0626, 0.0644, 0.1187, 0.2343, 0.1725, 0.1087, 0.2422],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.1364728957414627\n",
            "------\n",
            "input_list [47, 43, 38, 36, 24, 1, -14, -15, -14, -15, -24, -15, -11, -4, -8, -4, 7, 15, 6, -7]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0068, 0.0213, 0.1110, 0.6431, 0.1763, 0.0262, 0.0150, 0.0192, 0.0408,\n",
            "        0.1257, 0.5003, 0.2337, 0.0570, 0.0298, 0.0352, 0.0293, 0.1665, 0.3667,\n",
            "        0.2400, 0.0850, 0.0569, 0.0343, 0.0424, 0.1766, 0.3101, 0.2184, 0.0924,\n",
            "        0.1011, 0.0464, 0.0418, 0.1549, 0.2907, 0.2057, 0.1265, 0.1107, 0.0514,\n",
            "        0.0430, 0.1613, 0.2820, 0.1743, 0.1195, 0.1491, 0.0526, 0.0569, 0.1603,\n",
            "        0.2394, 0.1931, 0.0948, 0.1853, 0.0548, 0.0589, 0.1457, 0.2474, 0.1762,\n",
            "        0.0968, 0.2077, 0.0585, 0.0622, 0.1277, 0.2436, 0.1840, 0.1071, 0.2097,\n",
            "        0.0645, 0.0644, 0.1182, 0.2324, 0.1718, 0.1083, 0.2410],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.16206835210323334\n",
            "------\n",
            "input_list [55, 50, 47, 35, 9, -7, -8, -7, -8, -18, -8, -4, 3, 0, 3, 16, 25, 15, 0, 8]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0069, 0.0216, 0.1104, 0.6382, 0.1756, 0.0267, 0.0151, 0.0193, 0.0410,\n",
            "        0.1251, 0.4990, 0.2319, 0.0568, 0.0302, 0.0362, 0.0291, 0.1654, 0.3649,\n",
            "        0.2388, 0.0851, 0.0577, 0.0349, 0.0426, 0.1758, 0.3075, 0.2172, 0.0921,\n",
            "        0.1026, 0.0475, 0.0415, 0.1544, 0.2890, 0.2054, 0.1258, 0.1115, 0.0526,\n",
            "        0.0430, 0.1607, 0.2798, 0.1735, 0.1193, 0.1493, 0.0542, 0.0567, 0.1591,\n",
            "        0.2381, 0.1925, 0.0944, 0.1847, 0.0560, 0.0591, 0.1451, 0.2456, 0.1753,\n",
            "        0.0963, 0.2077, 0.0599, 0.0622, 0.1275, 0.2415, 0.1829, 0.1062, 0.2091,\n",
            "        0.0667, 0.0642, 0.1175, 0.2304, 0.1710, 0.1078, 0.2394],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.13795359432697296\n",
            "------\n",
            "input_list [50, 47, 35, 9, -7, -8, -7, -8, -18, -8, -4, 3, 0, 3, 16, 25, 15, 0, 8, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0070, 0.0218, 0.1098, 0.6342, 0.1748, 0.0271, 0.0152, 0.0194, 0.0411,\n",
            "        0.1251, 0.4971, 0.2300, 0.0565, 0.0306, 0.0371, 0.0289, 0.1649, 0.3632,\n",
            "        0.2376, 0.0850, 0.0583, 0.0354, 0.0430, 0.1750, 0.3051, 0.2160, 0.0918,\n",
            "        0.1039, 0.0486, 0.0416, 0.1539, 0.2872, 0.2051, 0.1250, 0.1120, 0.0537,\n",
            "        0.0432, 0.1600, 0.2777, 0.1726, 0.1189, 0.1491, 0.0561, 0.0564, 0.1580,\n",
            "        0.2366, 0.1919, 0.0940, 0.1839, 0.0575, 0.0592, 0.1446, 0.2440, 0.1744,\n",
            "        0.0958, 0.2074, 0.0617, 0.0623, 0.1271, 0.2395, 0.1819, 0.1053, 0.2083,\n",
            "        0.0692, 0.0641, 0.1169, 0.2285, 0.1702, 0.1072, 0.2375],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.15610240399837494\n",
            "------\n",
            "input_list [56, 42, 16, -2, -3, -2, -3, -13, -3, 0, 9, 4, 9, 22, 32, 21, 6, 14, 5, 5]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0071, 0.0220, 0.1099, 0.6299, 0.1741, 0.0275, 0.0153, 0.0195, 0.0412,\n",
            "        0.1255, 0.4947, 0.2282, 0.0563, 0.0309, 0.0380, 0.0290, 0.1645, 0.3612,\n",
            "        0.2363, 0.0850, 0.0589, 0.0359, 0.0437, 0.1741, 0.3027, 0.2147, 0.0915,\n",
            "        0.1050, 0.0496, 0.0418, 0.1534, 0.2855, 0.2046, 0.1242, 0.1125, 0.0551,\n",
            "        0.0433, 0.1594, 0.2755, 0.1718, 0.1186, 0.1489, 0.0583, 0.0561, 0.1568,\n",
            "        0.2352, 0.1912, 0.0937, 0.1828, 0.0593, 0.0593, 0.1440, 0.2424, 0.1735,\n",
            "        0.0953, 0.2068, 0.0638, 0.0623, 0.1268, 0.2374, 0.1809, 0.1044, 0.2073,\n",
            "        0.0721, 0.0639, 0.1162, 0.2266, 0.1694, 0.1067, 0.2355],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.13338497281074524\n",
            "------\n",
            "input_list [41, 15, -3, -4, -3, -4, -14, -4, 0, 8, 4, 8, 21, 31, 20, 5, 13, 4, 4, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0072, 0.0222, 0.1096, 0.6265, 0.1731, 0.0278, 0.0153, 0.0195, 0.0412,\n",
            "        0.1261, 0.4919, 0.2261, 0.0559, 0.0311, 0.0386, 0.0290, 0.1644, 0.3591,\n",
            "        0.2348, 0.0848, 0.0593, 0.0362, 0.0442, 0.1738, 0.3001, 0.2133, 0.0910,\n",
            "        0.1057, 0.0504, 0.0423, 0.1527, 0.2835, 0.2039, 0.1232, 0.1127, 0.0564,\n",
            "        0.0436, 0.1585, 0.2734, 0.1708, 0.1181, 0.1482, 0.0602, 0.0561, 0.1555,\n",
            "        0.2336, 0.1903, 0.0932, 0.1814, 0.0613, 0.0593, 0.1434, 0.2406, 0.1725,\n",
            "        0.0947, 0.2057, 0.0661, 0.0622, 0.1264, 0.2353, 0.1798, 0.1035, 0.2058,\n",
            "        0.0752, 0.0636, 0.1155, 0.2245, 0.1685, 0.1060, 0.2330],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.15125304460525513\n",
            "------\n",
            "input_list [20, 0, 0, 0, 0, -10, 0, 4, 12, 8, 13, 26, 36, 25, 10, 18, 9, 9, 3, 4]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0073, 0.0224, 0.1100, 0.6227, 0.1721, 0.0281, 0.0154, 0.0196, 0.0412,\n",
            "        0.1270, 0.4888, 0.2241, 0.0556, 0.0313, 0.0393, 0.0291, 0.1649, 0.3568,\n",
            "        0.2333, 0.0846, 0.0596, 0.0365, 0.0450, 0.1733, 0.2977, 0.2119, 0.0905,\n",
            "        0.1063, 0.0511, 0.0430, 0.1521, 0.2817, 0.2032, 0.1224, 0.1128, 0.0575,\n",
            "        0.0441, 0.1578, 0.2712, 0.1699, 0.1176, 0.1475, 0.0625, 0.0561, 0.1542,\n",
            "        0.2321, 0.1893, 0.0928, 0.1799, 0.0637, 0.0592, 0.1427, 0.2389, 0.1715,\n",
            "        0.0942, 0.2045, 0.0688, 0.0621, 0.1259, 0.2332, 0.1787, 0.1026, 0.2043,\n",
            "        0.0788, 0.0634, 0.1148, 0.2225, 0.1677, 0.1054, 0.2306],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.118338942527771\n",
            "------\n",
            "input_list [2, 1, 2, 1, -9, 1, 5, 14, 9, 14, 28, 38, 27, 11, 19, 10, 10, 4, 5, 1]\n",
            "input_tensor tensor([[0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0073, 0.0225, 0.1100, 0.6197, 0.1709, 0.0283, 0.0154, 0.0196, 0.0412,\n",
            "        0.1278, 0.4865, 0.2219, 0.0552, 0.0315, 0.0398, 0.0291, 0.1658, 0.3544,\n",
            "        0.2318, 0.0843, 0.0599, 0.0368, 0.0457, 0.1735, 0.2951, 0.2105, 0.0900,\n",
            "        0.1066, 0.0517, 0.0436, 0.1519, 0.2796, 0.2024, 0.1213, 0.1125, 0.0590,\n",
            "        0.0445, 0.1569, 0.2691, 0.1688, 0.1170, 0.1465, 0.0651, 0.0560, 0.1529,\n",
            "        0.2304, 0.1882, 0.0922, 0.1782, 0.0663, 0.0591, 0.1420, 0.2371, 0.1704,\n",
            "        0.0936, 0.2030, 0.0716, 0.0620, 0.1254, 0.2311, 0.1775, 0.1016, 0.2025,\n",
            "        0.0827, 0.0631, 0.1141, 0.2205, 0.1668, 0.1047, 0.2278],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.14302176237106323\n",
            "------\n",
            "input_list [0, 0, 0, -11, 0, 3, 11, 7, 12, 25, 35, 24, 9, 17, 8, 8, 2, 3, 0, -2]\n",
            "input_tensor tensor([[0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0074, 0.0225, 0.1100, 0.6163, 0.1707, 0.0285, 0.0154, 0.0195, 0.0411,\n",
            "        0.1288, 0.4839, 0.2198, 0.0548, 0.0316, 0.0402, 0.0290, 0.1670, 0.3518,\n",
            "        0.2302, 0.0839, 0.0601, 0.0369, 0.0462, 0.1741, 0.2926, 0.2090, 0.0895,\n",
            "        0.1068, 0.0521, 0.0444, 0.1517, 0.2776, 0.2016, 0.1203, 0.1122, 0.0609,\n",
            "        0.0449, 0.1560, 0.2670, 0.1678, 0.1164, 0.1453, 0.0681, 0.0559, 0.1516,\n",
            "        0.2287, 0.1871, 0.0916, 0.1763, 0.0693, 0.0589, 0.1413, 0.2352, 0.1694,\n",
            "        0.0930, 0.2013, 0.0748, 0.0618, 0.1249, 0.2290, 0.1762, 0.1007, 0.2006,\n",
            "        0.0863, 0.0628, 0.1137, 0.2185, 0.1659, 0.1040, 0.2250],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.14706732332706451\n",
            "------\n",
            "input_list [4, 3, -7, 3, 7, 16, 12, 17, 31, 41, 30, 13, 22, 12, 12, 6, 7, 3, 2, 4]\n",
            "input_tensor tensor([[0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0074, 0.0227, 0.1107, 0.6124, 0.1705, 0.0287, 0.0155, 0.0196, 0.0410,\n",
            "        0.1302, 0.4808, 0.2178, 0.0546, 0.0318, 0.0406, 0.0291, 0.1688, 0.3492,\n",
            "        0.2287, 0.0837, 0.0603, 0.0375, 0.0468, 0.1746, 0.2903, 0.2076, 0.0890,\n",
            "        0.1070, 0.0532, 0.0452, 0.1514, 0.2758, 0.2006, 0.1194, 0.1120, 0.0633,\n",
            "        0.0452, 0.1551, 0.2649, 0.1669, 0.1158, 0.1444, 0.0716, 0.0559, 0.1503,\n",
            "        0.2271, 0.1860, 0.0912, 0.1745, 0.0728, 0.0588, 0.1407, 0.2336, 0.1684,\n",
            "        0.0925, 0.1996, 0.0778, 0.0618, 0.1248, 0.2270, 0.1752, 0.0999, 0.1987,\n",
            "        0.0905, 0.0626, 0.1134, 0.2167, 0.1651, 0.1034, 0.2223],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.12398820370435715\n",
            "------\n",
            "input_list [3, -7, 3, 7, 16, 12, 17, 31, 41, 30, 13, 22, 12, 12, 6, 7, 3, 2, 4, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0075, 0.0227, 0.1110, 0.6094, 0.1698, 0.0288, 0.0154, 0.0195, 0.0409,\n",
            "        0.1313, 0.4786, 0.2156, 0.0542, 0.0318, 0.0409, 0.0292, 0.1702, 0.3465,\n",
            "        0.2271, 0.0832, 0.0603, 0.0379, 0.0476, 0.1749, 0.2877, 0.2061, 0.0885,\n",
            "        0.1068, 0.0540, 0.0461, 0.1511, 0.2737, 0.1997, 0.1183, 0.1114, 0.0653,\n",
            "        0.0457, 0.1542, 0.2628, 0.1658, 0.1151, 0.1430, 0.0747, 0.0560, 0.1490,\n",
            "        0.2254, 0.1847, 0.0906, 0.1725, 0.0758, 0.0586, 0.1399, 0.2325, 0.1673,\n",
            "        0.0919, 0.1976, 0.0804, 0.0620, 0.1246, 0.2249, 0.1739, 0.0990, 0.1965,\n",
            "        0.0951, 0.0622, 0.1129, 0.2147, 0.1642, 0.1027, 0.2193],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.13575218617916107\n",
            "------\n",
            "input_list [-7, 3, 7, 16, 12, 17, 31, 41, 30, 13, 22, 12, 12, 6, 7, 3, 2, 4, 0, 0]\n",
            "input_tensor tensor([[0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0075, 0.0227, 0.1112, 0.6072, 0.1691, 0.0289, 0.0154, 0.0195, 0.0412,\n",
            "        0.1322, 0.4760, 0.2133, 0.0537, 0.0318, 0.0411, 0.0296, 0.1712, 0.3438,\n",
            "        0.2254, 0.0827, 0.0603, 0.0382, 0.0485, 0.1750, 0.2851, 0.2046, 0.0879,\n",
            "        0.1064, 0.0546, 0.0473, 0.1506, 0.2716, 0.1986, 0.1173, 0.1107, 0.0672,\n",
            "        0.0464, 0.1533, 0.2606, 0.1647, 0.1143, 0.1415, 0.0775, 0.0561, 0.1477,\n",
            "        0.2243, 0.1834, 0.0901, 0.1704, 0.0786, 0.0587, 0.1391, 0.2313, 0.1662,\n",
            "        0.0913, 0.1955, 0.0835, 0.0621, 0.1243, 0.2229, 0.1726, 0.0981, 0.1942,\n",
            "        0.1001, 0.0619, 0.1124, 0.2127, 0.1632, 0.1019, 0.2162],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.15001694858074188\n",
            "------\n",
            "input_list [12, 16, 26, 21, 27, 42, 53, 41, 23, 32, 22, 22, 15, 16, 12, 10, 13, 8, 8, 8]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0075, 0.0230, 0.1113, 0.6046, 0.1685, 0.0289, 0.0154, 0.0194, 0.0419,\n",
            "        0.1329, 0.4731, 0.2111, 0.0534, 0.0319, 0.0413, 0.0301, 0.1721, 0.3407,\n",
            "        0.2237, 0.0823, 0.0602, 0.0385, 0.0498, 0.1750, 0.2826, 0.2030, 0.0874,\n",
            "        0.1061, 0.0552, 0.0487, 0.1502, 0.2695, 0.1975, 0.1163, 0.1102, 0.0688,\n",
            "        0.0469, 0.1524, 0.2592, 0.1637, 0.1136, 0.1401, 0.0802, 0.0565, 0.1463,\n",
            "        0.2233, 0.1822, 0.0896, 0.1681, 0.0819, 0.0587, 0.1384, 0.2299, 0.1651,\n",
            "        0.0907, 0.1932, 0.0870, 0.0622, 0.1240, 0.2209, 0.1714, 0.0973, 0.1918,\n",
            "        0.1058, 0.0615, 0.1118, 0.2107, 0.1623, 0.1012, 0.2131],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.1053912416100502\n",
            "------\n",
            "input_list [19, 29, 23, 29, 44, 56, 43, 25, 35, 24, 24, 18, 19, 14, 12, 15, 10, 10, 10, 1]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0075, 0.0232, 0.1112, 0.6026, 0.1675, 0.0290, 0.0154, 0.0193, 0.0424,\n",
            "        0.1336, 0.4710, 0.2089, 0.0530, 0.0318, 0.0414, 0.0306, 0.1727, 0.3389,\n",
            "        0.2219, 0.0818, 0.0601, 0.0387, 0.0509, 0.1756, 0.2801, 0.2016, 0.0868,\n",
            "        0.1056, 0.0557, 0.0499, 0.1496, 0.2673, 0.1964, 0.1160, 0.1093, 0.0702,\n",
            "        0.0474, 0.1515, 0.2586, 0.1627, 0.1127, 0.1385, 0.0833, 0.0569, 0.1451,\n",
            "        0.2221, 0.1809, 0.0890, 0.1660, 0.0857, 0.0588, 0.1377, 0.2286, 0.1641,\n",
            "        0.0901, 0.1909, 0.0910, 0.0622, 0.1236, 0.2190, 0.1701, 0.0964, 0.1895,\n",
            "        0.1111, 0.0611, 0.1113, 0.2088, 0.1614, 0.1009, 0.2100],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.10643155127763748\n",
            "------\n",
            "input_list [29, 23, 29, 44, 56, 43, 25, 35, 24, 24, 18, 19, 14, 12, 15, 10, 10, 10, 1, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0075, 0.0234, 0.1112, 0.6013, 0.1666, 0.0290, 0.0153, 0.0193, 0.0429,\n",
            "        0.1341, 0.4698, 0.2068, 0.0526, 0.0318, 0.0414, 0.0310, 0.1731, 0.3379,\n",
            "        0.2202, 0.0812, 0.0600, 0.0389, 0.0519, 0.1759, 0.2775, 0.2000, 0.0868,\n",
            "        0.1050, 0.0561, 0.0511, 0.1490, 0.2658, 0.1952, 0.1157, 0.1085, 0.0715,\n",
            "        0.0481, 0.1507, 0.2578, 0.1616, 0.1119, 0.1369, 0.0870, 0.0572, 0.1439,\n",
            "        0.2208, 0.1796, 0.0884, 0.1638, 0.0900, 0.0587, 0.1369, 0.2272, 0.1630,\n",
            "        0.0896, 0.1884, 0.0947, 0.0622, 0.1232, 0.2171, 0.1689, 0.0955, 0.1885,\n",
            "        0.1158, 0.0608, 0.1108, 0.2069, 0.1604, 0.1012, 0.2070],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.11447381973266602\n",
            "------\n",
            "input_list [22, 28, 43, 54, 42, 24, 33, 23, 23, 16, 17, 13, 11, 14, 9, 9, 9, 0, 0, 0]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
            "flat_rnn_ouput tensor([0.0076, 0.0236, 0.1111, 0.6007, 0.1656, 0.0290, 0.0153, 0.0192, 0.0434,\n",
            "        0.1345, 0.4692, 0.2047, 0.0523, 0.0318, 0.0414, 0.0314, 0.1734, 0.3366,\n",
            "        0.2184, 0.0814, 0.0598, 0.0391, 0.0528, 0.1761, 0.2758, 0.1985, 0.0868,\n",
            "        0.1043, 0.0564, 0.0525, 0.1484, 0.2643, 0.1941, 0.1153, 0.1076, 0.0734,\n",
            "        0.0488, 0.1499, 0.2568, 0.1606, 0.1111, 0.1353, 0.0913, 0.0574, 0.1428,\n",
            "        0.2195, 0.1784, 0.0879, 0.1616, 0.0940, 0.0587, 0.1361, 0.2258, 0.1619,\n",
            "        0.0890, 0.1876, 0.0980, 0.0622, 0.1228, 0.2153, 0.1677, 0.0952, 0.1874,\n",
            "        0.1201, 0.0607, 0.1104, 0.2051, 0.1595, 0.1014, 0.2039],\n",
            "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
            "output_tensor tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "loss: 0.12479349225759506\n",
            "------\n",
            "input_list [29, 45, 56, 44, 25, 35, 24, 24, 18, 19, 14, 13, 15, 10, 10, 10, 2, 0, 0, 1]\n",
            "input_tensor tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-4676980107cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input_list\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input_tensor\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m       \u001b[0mrnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#predicted outcome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m       \u001b[0mflat_rnn_ouput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrnn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m       \u001b[0;31m#print(\"flat_ouput\",flat_ouput.shape,\"output_tensor\",output_tensor.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-da558ab3cad0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, feature_list)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcur_ft_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#.view([1,1,self.input_size])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mcur_ft_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_ft_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_ft_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mouts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mouts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#check this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 692\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#with feature extraction across multiple stock files\n",
        "## Training over multiple stocks\n",
        "#Then let's start iterating\n",
        "import os, time\n",
        "import pandas as pd\n",
        "import torch, random\n",
        "\n",
        "torch.manual_seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "\n",
        "prev_n,next_n=20,10\n",
        "\n",
        "root_dir='stock_market_data/sp500/csv'\n",
        "initial_files=[\"AAPL\",\"GOOG\",\"FB\",\"AMZN\",\"EA\",\"IBM\",\"MSFT\",\"GM\",\"UPS\",\"PG\"]\n",
        "all_files=[v.split(\".\")[0] for v in os.listdir(root_dir) if v.endswith(\".csv\")]\n",
        "additional_files=[v for v in all_files if not v in initial_files]\n",
        "test_files=initial_files+additional_files[:40]\n",
        "#test_files=test_files[:5]\n",
        "print(\"test_files\",len(test_files), test_files)\n",
        "\n",
        "n_epochs=100\n",
        "model_name=\"exp2-10stocks-128\"\n",
        "model_name=\"exp2-10stocks-64-3layer\"\n",
        "model_name=\"exp2-10stocks-64-3layer-new\"\n",
        "model_name=\"exp3-20stocks-64-3layer-new\"\n",
        "model_name=\"exp3-50stocks-64-3layer\"\n",
        "model_name=\"exp3-50stocks-64-3layer-lr5e8\"\n",
        "model_name=\"exp3-50stocks-64-3layer-lr1e8\"\n",
        "model_name=\"exp3-50stocks-64-3layer-5r1e8-30days\"\n",
        "model_name=\"exp3-100stocks-64-3layer-lr5e8\"\n",
        "model_name=\"exp3-20stocks-64-3layer-lr005-sig\"\n",
        "model_name=\"exp3-50stocks-64-3layer-lr0005-sig-test3\"\n",
        "model_name=\"exp3-50stocks-64-3layer-lr0005-sig-fixed-hidden\"\n",
        "\n",
        "#model_name=\"exp3-10stocks-64-3layer-5r1e8-test7\"\n",
        "model_dir=os.path.join(cwd,\"models\", model_name) \n",
        "tmp_model_dir=os.path.join(cwd,\"models\", model_name,\"tmp\") \n",
        "if not os.path.exists(tmp_model_dir): os.makedirs(tmp_model_dir)\n",
        "log_fpath=os.path.join(model_dir,\"log.txt\")\n",
        "\n",
        "cur_mv_labels=mv_labels2\n",
        "n_input=len(cur_mv_labels)\n",
        "n_output=next_n*len(cur_mv_labels)\n",
        "\n",
        "n_hidden =64 #64\n",
        "n_layers=3\n",
        "\n",
        "rnn = RNN(n_input, n_hidden, n_output,n_layers, matching_in_out=False).to(device)\n",
        "#rnn.to(device)\n",
        "max_train_size=50\n",
        "max_test_size=50\n",
        "# max_train_size=None\n",
        "# max_test_size=None\n",
        "\n",
        "\n",
        "print(rnn)\n",
        "# input_tensor=torch.rand((prev_n, n_input))\n",
        "# output = rnn(input_tensor)\n",
        "# print(output.shape)\n",
        "\n",
        "LR=0.0000001\n",
        "LR=0.00000005\n",
        "# LR=0.00000001\n",
        "LR=0.0005\n",
        "LR=0.5\n",
        "loss_func = nn.MSELoss()\n",
        "#loss_func = nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
        "\n",
        "tmp_params={}\n",
        "tmp_params[\"LR\"]=LR\n",
        "tmp_params[\"prev_n\"]=prev_n\n",
        "tmp_params[\"next_n\"]=next_n\n",
        "# tmp_params[\"n_training\"]=len(all_training)\n",
        "# tmp_params[\"n_testing\"]=len(all_testing)\n",
        "\n",
        "\n",
        "log_fopen=open(log_fpath,\"a\")\n",
        "log_fopen.write(str(rnn)+\"\\n\")\n",
        "log_fopen.write(str(tmp_params)+\"\\n\")\n",
        "log_fopen.close()\n",
        "\n",
        "\n",
        "for e0 in range(n_epochs):\n",
        "  print(\"epoch #\",e0)\n",
        "  t0=time.time()\n",
        "  PATH=os.path.join(model_dir, \"model-%s.model\"%e0)\n",
        "  \n",
        "  if os.path.exists(PATH):\n",
        "    checkpoint = torch.load(PATH)\n",
        "    rnn.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    print(\"loaded model for this epoch\",PATH)\n",
        "    for a,b in  checkpoint.items():\n",
        "      if \"loss\" in a.lower(): print(a,round(b,6))\n",
        "    continue\n",
        "\n",
        "  for fname in test_files:\n",
        "    t0=time.time()\n",
        "    tmp_path=os.path.join(tmp_model_dir, \"model-%s.model\"%fname)\n",
        "    if os.path.exists(tmp_path):\n",
        "      checkpoint = torch.load(tmp_path)\n",
        "      rnn.load_state_dict(checkpoint['model_state_dict'])\n",
        "      optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "      print(\"loaded model for this epoch\",tmp_path)\n",
        "      continue\n",
        "\n",
        "    cur_fpath=os.path.join(root_dir,fname+\".csv\")\n",
        "    all_training,all_testing=get_norm_close(cur_fpath,prev_n,next_n)\n",
        "    #print(fname)\n",
        "\n",
        "    total_train_loss=0\n",
        "    total_test_loss=0\n",
        "    train_counter,test_counter=0,0\n",
        "    balance=0\n",
        "    n_sells=0\n",
        "    cur_training_items=all_training\n",
        "    if max_train_size!=None: cur_training_items=all_training[:max_train_size]\n",
        "    cur_testing_items=all_testing\n",
        "    if max_test_size!=None: cur_testing_items=all_testing[:max_test_size]\n",
        "    print(fname, \"all_training\",len(cur_training_items),\"all_testing\",len(cur_testing_items))\n",
        "\n",
        "    for i0,tr0 in enumerate(cur_training_items):\n",
        "      #if i0%5000==0: print(i0)\n",
        "      input_list,output_list=tr0\n",
        "      input_oh=list2one_hot2(input_list,cur_mv_labels)\n",
        "      output_oh=list2one_hot2(output_list,cur_mv_labels)\n",
        "      # input_oh=list2one_hot(input_list,cur_mv_labels)\n",
        "      # output_oh=list2one_hot(output_list,cur_mv_labels)\n",
        "\n",
        "      input_tensor,output_tensor=torch.tensor(input_oh) , torch.tensor(output_oh).ravel() #actual outcome\n",
        "      input_tensor=input_tensor.to(device)\n",
        "      output_tensor=output_tensor.to(device)\n",
        "      rnn.hidden = rnn.init_hidden()\n",
        "      rnn.zero_grad()\n",
        "      #rnn.to(device)\n",
        "      print(\"input_list\",input_list)\n",
        "      print(\"input_tensor\",input_tensor)\n",
        "      rnn_output = rnn(input_tensor) #predicted outcome\n",
        "      flat_rnn_ouput=rnn_output.ravel().to(device)\n",
        "      #print(\"flat_ouput\",flat_ouput.shape,\"output_tensor\",output_tensor.shape)\n",
        "\n",
        "      loss = loss_func(output_tensor, flat_rnn_ouput) #calculate the loss, difference between the output and the desired outcome tensors\n",
        "      loss.backward()\n",
        "      optimizer.step()  \n",
        "      total_train_loss+=loss.item()\n",
        "      train_counter+=1\n",
        "      print(\"flat_rnn_ouput\",flat_rnn_ouput)\n",
        "      print(\"output_tensor\",output_tensor)\n",
        "      print(\"loss:\",loss.item())\n",
        "      print(\"------\")\n",
        "\n",
        "    print(\"TESTING:\", len(cur_testing_items))\n",
        "    for i0,tr0 in enumerate(cur_testing_items):\n",
        "      #if i0%2000==0: print(i0)\n",
        "      input_list,output_list=tr0\n",
        "      input_oh=list2one_hot2(input_list,cur_mv_labels)\n",
        "      output_oh=list2one_hot2(output_list,cur_mv_labels)\n",
        "      # input_oh=list2one_hot(input_list,cur_mv_labels)\n",
        "      # output_oh=list2one_hot(output_list,cur_mv_labels)\n",
        "      input_tensor,output_tensor=torch.tensor(input_oh) , torch.tensor(output_oh).ravel()\n",
        "      input_tensor=input_tensor.to(device)\n",
        "      output_tensor=output_tensor.to(device)\n",
        "\n",
        "      rnn.hidden = rnn.init_hidden()\n",
        "      rnn.zero_grad()\n",
        "      rnn_output = rnn(input_tensor)\n",
        "      flat_rnn_ouput=rnn_output.ravel().to(device)\n",
        "\n",
        "      loss = loss_func(output_tensor, flat_rnn_ouput) #calculate the loss, difference between the output and the desired outcome tensors\n",
        "      total_test_loss+=loss.item()\n",
        "      test_counter+=1\n",
        "      #let's see the actual performance\n",
        "      #rnn_output\n",
        "      rnn_output2 = rnn_output.ravel().tolist()\n",
        "      predictions0=out2labels(rnn_output2,cur_mv_labels)\n",
        "      #print(\"mv_labels\",mv_labels)\n",
        "      outcome_str_list=[get_str_percent2(v) for v in output_list]\n",
        "      #print(\"output_list\",output_list, )\n",
        "      if i0<10:\n",
        "        print(\"Epoch:\", e0, \"- item:\", i0)\n",
        "        print(\"input_list\",input_list)\n",
        "        print(\"input_oh\",input_oh)\n",
        "        for act0,pd0 in zip(outcome_str_list,predictions0):\n",
        "          print(\"act0\",act0,\"pred:\", pd0)\n",
        "        print(\"--------\")\n",
        "      test_params={}\n",
        "      test_params[\"pos_threshold\"]=0.3\n",
        "      test_params[\"neg_threshold\"]=0.3\n",
        "      # test_params[\"diff_threshold\"]=-1\n",
        "      test_params[\"nofilter\"]=False\n",
        "      test_params[\"pos_ratio_threshold\"]=0.5\n",
        "      \n",
        "      cur_selling_pts=[]\n",
        "      #cur_selling_pts=check_selling(predictions0,output_list,test_params,nofilter=False, debug_vals=False)\n",
        "      if cur_selling_pts:\n",
        "        increment=cur_selling_pts[0][0]\n",
        "        actual0,i_,pos_ratio ,pos0,neg0,diff0=cur_selling_pts[0]\n",
        "        balance+=increment\n",
        "        n_sells+=1\n",
        "\n",
        "\n",
        "    avg_train_loss=round(total_train_loss/train_counter,6)\n",
        "    avg_test_loss=round(total_test_loss/test_counter, 6) \n",
        "\n",
        "    torch.save({\n",
        "            'epoch': e0,\n",
        "            'n_input': n_input,\n",
        "            'n_hidden': n_hidden,\n",
        "            'n_layers': n_layers,\n",
        "            'n_output': n_output,\n",
        "            'LR': LR,\n",
        "            'model_state_dict': rnn.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_loss': avg_train_loss,\n",
        "            'test_loss': avg_test_loss,\n",
        "            'train_size': len(cur_training_items),\n",
        "            'test_size': len(cur_testing_items),\n",
        "            'balance': balance\n",
        "            }, tmp_path)\n",
        "    t1=time.time()\n",
        "    elapsed=round(t1-t0,2) \n",
        "    t0=time.time()\n",
        "    \n",
        "    line=\"Epoch # %s - Stock: %s -  train loss: %s - test loss: %s - elapsed: %s  - n_sells: %s - balance: %s\"%(e0, fname, avg_train_loss,avg_test_loss, elapsed, n_sells,balance)\n",
        "    print(line)\n",
        "    print(\"time elapsed:\",elapsed)\n",
        "    print(\"--------\")\n",
        "    log_fopen=open(log_fpath,\"a\")\n",
        "    log_fopen.write(line+\"\\n\")\n",
        "    log_fopen.close() \n",
        "\n",
        "   \n",
        "    \n",
        "  # pickle_path=os.path.join(model_dir, \"model-%s.pickle\"%e0)\n",
        "  # pickle_dict={}\n",
        "  # pickle_dict[\"n_output\"]=n_output\n",
        "  # pickle_dict[\"n_input\"]=n_input\n",
        "  # pickle_dict[\"n_hidden\"]=n_hidden\n",
        "  # pickle_dict[\"n_layers\"]=n_layers\n",
        "  # #pickle_dict[\"out2labels\"]=out2labels\n",
        "  # pickle_dict[\"labels\"]=mv_labels\n",
        "  # pickle_dict[\"train_loss\"]=avg_train_loss\n",
        "  # pickle_dict[\"test_loss\"]=avg_test_loss\n",
        "  # #pickle_dict[\"pred_offset\"]=avg_test_pred_offset\n",
        "\n",
        "\n",
        "  # numpy_state_dict={}\n",
        "  # for a,b in rnn.state_dict().items():\n",
        "  #   numpy_state_dict[a]=b.numpy()\n",
        "  # pickle_dict[\"state_dict\"]=numpy_state_dict\n",
        "  # with open(pickle_path, 'wb') as f:\n",
        "  #   pickle.dump(pickle_dict, f, pickle.HIGHEST_PROTOCOL)\n",
        "    #n_input,n_hidden,n_layers,n_output,LR\n",
        "  # import glob\n",
        "  # files = glob.glob('/YOUR/PATH/*')\n",
        "  \n",
        "\n",
        "\n",
        "  torch.save({\n",
        "              'epoch': e0,\n",
        "              'n_input': n_input,\n",
        "              'n_hidden': n_hidden,\n",
        "              'n_layers': n_layers,\n",
        "              'n_output': n_output,\n",
        "              'LR': LR,\n",
        "              'model_state_dict': rnn.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              'train_loss': avg_train_loss,\n",
        "              'test_loss': avg_test_loss,\n",
        "              'train_size': len(cur_training_items),\n",
        "              'test_size': len(cur_testing_items),\n",
        "              'balance': balance\n",
        "              }, PATH)\n",
        "\n",
        "  print(\"finished processing epoch, saved model to\",PATH)\n",
        "  for f in os.listdir(tmp_model_dir):\n",
        "    tmp_fpath=os.path.join(tmp_model_dir,f)\n",
        "    os.remove(tmp_fpath)\n",
        "  print(\"deleted temporary files\")\n",
        "\n",
        "  print(\"==========\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm4uyfQO2W7n",
        "outputId": "2a4555fc-0081-4fb5-8a19-0a2a1488e538"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model-AAPL.model  model-GOOG.model\n"
          ]
        }
      ],
      "source": [
        " tmp_model_dir\n",
        "!ls /content/drive/MyDrive/stocks/models/exp2-10stocks-64-4layer-Multiple/tmp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRvG5dEzQVCQ"
      },
      "source": [
        "##Running Experiments with RNN models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTtXc3RoQ6fG",
        "outputId": "95b812f9-523c-4afa-ea11-0d3547fd93c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\n",
            "epoch: 0\n",
            "input: [4, 8, 6, 6, 7, 8, 7, 5, 5, 7, 6, 6, 8, 5, 2, 2, 1, 3, 2, 0]\n",
            "Actual: -1 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: -2 predicted: [('0', 0.5836), ('3', 0.21), ('-3', 0.1755), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: -3 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 0 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1921), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 0 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 1 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 3 predicted: [('0', 0.3891), ('3', 0.302), ('-3', 0.1903), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: 3 predicted: [('0', 0.3369), ('3', 0.317), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 4 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.1829), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [9, 7, 8, 9, 9, 9, 7, 7, 9, 8, 8, 10, 7, 4, 4, 2, 5, 4, 2, 1]\n",
            "Actual: 2 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: -1 predicted: [('0', 0.5836), ('3', 0.21), ('-3', 0.1755), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 1 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 1 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1921), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 3 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 5 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 5 predicted: [('0', 0.3891), ('3', 0.302), ('-3', 0.1903), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: 6 predicted: [('0', 0.3369), ('3', 0.317), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 5 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.1829), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [5, 6, 7, 7, 7, 5, 5, 7, 6, 6, 7, 4, 2, 2, 0, 3, 2, 0, 0, -1]\n",
            "Actual: -2 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: -3 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 0 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1755), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 0 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 1 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 3 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 3 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 4 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1903), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 3 predicted: [('0', 0.337), ('3', 0.317), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 3 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [9, 10, 10, 10, 8, 8, 9, 9, 8, 10, 7, 4, 4, 3, 5, 4, 2, 2, 0, 2]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 2 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 1 predicted: [('0', 0.5836), ('3', 0.21), ('-3', 0.1755), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 4 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 5 predicted: [('0', 0.4945), ('3', 0.2533), ('-3', 0.1921), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 6 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1901), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 7 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 6 predicted: [('0', 0.3891), ('3', 0.302), ('-3', 0.1903), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: 6 predicted: [('0', 0.3369), ('3', 0.317), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 6 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.1829), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [11, 11, 11, 9, 9, 10, 10, 9, 11, 8, 5, 5, 4, 6, 5, 3, 3, 1, 3, 0]\n",
            "Actual: 3 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 2 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 5 predicted: [('0', 0.5836), ('3', 0.21), ('-3', 0.1755), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 6 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 7 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1921), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 8 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 7 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 7 predicted: [('0', 0.3891), ('3', 0.302), ('-3', 0.1903), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: 7 predicted: [('0', 0.3369), ('3', 0.317), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 8 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.1829), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [7, 7, 5, 5, 7, 6, 6, 8, 5, 2, 2, 0, 3, 2, 0, 0, -1, 0, -2, -3]\n",
            "Actual: 0 predicted: [('0', 0.8366), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0046), ('-7', 0.0039)]\n",
            "Actual: 1 predicted: [('0', 0.7193), ('3', 0.1449), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 3 predicted: [('0', 0.5836), ('3', 0.2101), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 3 predicted: [('0', 0.5184), ('3', 0.2456), ('-3', 0.2033), ('7', 0.0334), ('-7', 0.0212)]\n",
            "Actual: 4 predicted: [('0', 0.4945), ('3', 0.2534), ('-3', 0.1922), ('7', 0.0478), ('-7', 0.0294)]\n",
            "Actual: 3 predicted: [('0', 0.5049), ('3', 0.2479), ('-3', 0.1903), ('7', 0.0497), ('-7', 0.0302)]\n",
            "Actual: 3 predicted: [('0', 0.4428), ('3', 0.2743), ('-3', 0.1974), ('7', 0.0513), ('-7', 0.0391)]\n",
            "Actual: 3 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0527)]\n",
            "Actual: 4 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0604)]\n",
            "Actual: 4 predicted: [('0', 0.3443), ('3', 0.3269), ('-3', 0.183), ('7', 0.0745), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [8, 6, 6, 8, 7, 7, 8, 5, 3, 3, 1, 4, 3, 1, 0, -1, 0, -1, -2, 0]\n",
            "Actual: 2 predicted: [('0', 0.8367), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 3 predicted: [('0', 0.7193), ('3', 0.1449), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 4 predicted: [('0', 0.5836), ('3', 0.21), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 5 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 4 predicted: [('0', 0.4945), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0294)]\n",
            "Actual: 4 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 4 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 5 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: 4 predicted: [('0', 0.3369), ('3', 0.317), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0603)]\n",
            "Actual: 4 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [3, 3, 5, 4, 4, 6, 3, 0, 0, 0, 1, 0, -1, -1, -3, -1, -3, -4, -1, -2]\n",
            "Actual: 1 predicted: [('0', 0.8366), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0046), ('-7', 0.0039)]\n",
            "Actual: 1 predicted: [('0', 0.7193), ('3', 0.1449), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 2 predicted: [('0', 0.5836), ('3', 0.2101), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 2 predicted: [('0', 0.5184), ('3', 0.2456), ('-3', 0.2033), ('7', 0.0334), ('-7', 0.0212)]\n",
            "Actual: 1 predicted: [('0', 0.4945), ('3', 0.2534), ('-3', 0.1923), ('7', 0.0478), ('-7', 0.0294)]\n",
            "Actual: 2 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1903), ('7', 0.0497), ('-7', 0.0302)]\n",
            "Actual: 2 predicted: [('0', 0.4428), ('3', 0.2743), ('-3', 0.1974), ('7', 0.0513), ('-7', 0.0391)]\n",
            "Actual: 2 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0527)]\n",
            "Actual: 1 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0604)]\n",
            "Actual: 0 predicted: [('0', 0.3443), ('3', 0.3269), ('-3', 0.183), ('7', 0.0745), ('-7', 0.0599)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [2, 3, 3, 3, 4, 1, 0, 0, -2, 0, 0, -2, -3, -4, -2, -5, -6, -3, -3, -1]\n",
            "Actual: 0 predicted: [('0', 0.8366), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0046), ('-7', 0.0039)]\n",
            "Actual: 1 predicted: [('0', 0.7193), ('3', 0.1449), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 0 predicted:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [('0', 0.5836), ('3', 0.2101), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 0 predicted: [('0', 0.5183), ('3', 0.2456), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 0 predicted: [('0', 0.4945), ('3', 0.2534), ('-3', 0.1922), ('7', 0.0478), ('-7', 0.0294)]\n",
            "Actual: 1 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0497), ('-7', 0.0301)]\n",
            "Actual: 1 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1974), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 0 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0527)]\n",
            "Actual: -1 predicted: [('0', 0.3369), ('3', 0.317), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0604)]\n",
            "Actual: -2 predicted: [('0', 0.3443), ('3', 0.3268), ('-3', 0.183), ('7', 0.0745), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [3, 2, 2, 4, 1, -1, -1, -2, 0, -1, -3, -3, -5, -3, -5, -6, -3, -4, -1, 0]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1449), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 0 predicted: [('0', 0.5836), ('3', 0.21), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 0 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 1 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0294)]\n",
            "Actual: 0 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 0 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1974), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: -2 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: -2 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0603)]\n",
            "Actual: -2 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [1, 1, 3, 0, -1, -2, -3, -1, -2, -3, -4, -6, -4, -6, -7, -4, -5, -2, -1, 0]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1449), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 0 predicted: [('0', 0.5836), ('3', 0.21), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 0 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 0 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0294)]\n",
            "Actual: -1 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: -3 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1974), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: -3 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: -3 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0603)]\n",
            "Actual: -2 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [2, 3, 1, -1, -1, -2, 0, -1, -3, -4, -5, -3, -6, -7, -3, -4, -2, 0, 0, 0]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 0 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 0 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 0 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: -2 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: -3 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: -2 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: -2 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 1 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [4, 1, 0, -1, -2, 0, -1, -3, -3, -5, -3, -5, -6, -3, -4, -1, 0, 0, 1, 0]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 1 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 0 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 0 predicted: [('0', 0.5184), ('3', 0.2454), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: -2 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: -2 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: -2 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: -1 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 1 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 1 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [1, -1, -1, -2, 0, -1, -3, -4, -5, -3, -6, -6, -3, -4, -2, 0, 0, 0, 0, 0]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 0 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: -2 predicted: [('0', 0.5184), ('3', 0.2454), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: -3 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: -2 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: -2 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 1 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 1 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 2 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-2, -2, -3, -1, -2, -4, -4, -6, -4, -6, -7, -4, -5, -2, -1, 0, 0, 0, -1, 0]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: -1 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: -3 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: -3 predicted: [('0', 0.5184), ('3', 0.2454), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: -3 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: -2 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 0 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 0 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 1 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 2 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-1, -3, 0, -1, -3, -4, -5, -3, -6, -7, -4, -4, -2, 0, 0, 0, 0, 0, 0, 0]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: -2 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: -3 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: -2 predicted: [('0', 0.5184), ('3', 0.2454), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: -2 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 1 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 1 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 1 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 2 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 3 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-2, 0, -1, -2, -3, -5, -3, -5, -6, -3, -4, -1, 0, 0, 1, 0, 0, 0, 1, 0]\n",
            "Actual: -2 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: -2 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: -2 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: -1 predicted: [('0', 0.5184), ('3', 0.2454), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 1 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 1 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 2 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 3 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 4 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 3 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [2, 1, 0, -1, -2, 0, -3, -4, -1, -1, 0, 2, 2, 3, 2, 2, 2, 3, 3, 2]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 0 predicted: [('0', 0.5836), ('3', 0.21), ('-3', 0.1755), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 4 predicted: [('0', 0.5183), ('3', 0.2455), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 4 predicted: [('0', 0.4945), ('3', 0.2533), ('-3', 0.1921), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 4 predicted: [('0', 0.5049), ('3', 0.2479), ('-3', 0.1901), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 6 predicted: [('0', 0.4426), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 6 predicted: [('0', 0.3891), ('3', 0.302), ('-3', 0.1902), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: 5 predicted: [('0', 0.3369), ('3', 0.317), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 6 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.1829), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [1, 0, -1, -2, 0, -3, -4, 0, -1, 0, 2, 2, 3, 3, 2, 3, 3, 3, 2, 0]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 4 predicted: [('0', 0.5836), ('3', 0.21), ('-3', 0.1755), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 4 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 5 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1921), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 6 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 7 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 6 predicted: [('0', 0.3891), ('3', 0.302), ('-3', 0.1903), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: 6 predicted: [('0', 0.3369), ('3', 0.317), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 6 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.1829), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [0, -1, -3, -1, -3, -4, -1, -2, 0, 1, 2, 3, 2, 2, 2, 3, 2, 2, 0, 0]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 3 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 4 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1755), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 4 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 5 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1921), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 6 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 5 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 6 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1903), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 6 predicted: [('0', 0.3369), ('3', 0.317), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 7 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.1829), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-1, -3, -1, -3, -4, -1, -2, 0, 1, 1, 2, 2, 1, 2, 2, 2, 1, 0, 0, 0]\n",
            "Actual: 3 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 3 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 4 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1755), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 5 predicted: [('0', 0.5184), ('3', 0.2454), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 6 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 5 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 5 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 5 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 7 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 8 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-6, -4, -7, -8, -5, -5, -3, -2, -1, 0, -1, -1, -1, 0, -1, -1, -3, -4, -3, -3]\n",
            "Actual: 0 predicted: [('0', 0.8366), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0046), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7193), ('3', 0.145), ('-3', 0.129), ('7', 0.0217), ('-7', 0.011)]\n",
            "Actual: 1 predicted: [('0', 0.5836), ('3', 0.2102), ('-3', 0.1757), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 2 predicted: [('0', 0.5184), ('3', 0.2456), ('-3', 0.2033), ('7', 0.0334), ('-7', 0.0212)]\n",
            "Actual: 1 predicted: [('0', 0.4945), ('3', 0.2534), ('-3', 0.1923), ('7', 0.0478), ('-7', 0.0294)]\n",
            "Actual: 2 predicted: [('0', 0.5049), ('3', 0.248), ('-3', 0.1903), ('7', 0.0497), ('-7', 0.0302)]\n",
            "Actual: 2 predicted: [('0', 0.4428), ('3', 0.2743), ('-3', 0.1974), ('7', 0.0513), ('-7', 0.0391)]\n",
            "Actual: 3 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1905), ('7', 0.062), ('-7', 0.0527)]\n",
            "Actual: 4 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0604)]\n",
            "Actual: 5 predicted: [('0', 0.3443), ('3', 0.3269), ('-3', 0.1831), ('7', 0.0745), ('-7', 0.0599)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-5, -7, -8, -5, -5, -3, -2, -1, 0, -1, -1, -1, 0, -1, -1, -4, -4, -3, -3, 0]\n",
            "Actual: 0 predicted: [('0', 0.8366), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 1 predicted: [('0', 0.7193), ('3', 0.1449), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 2 predicted: [('0', 0.5836), ('3', 0.2101), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 1 predicted: [('0', 0.5184), ('3', 0.2456), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 2 predicted: [('0', 0.4945), ('3', 0.2534), ('-3', 0.1922), ('7', 0.0478), ('-7', 0.0294)]\n",
            "Actual: 2 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0497), ('-7', 0.0301)]\n",
            "Actual: 3 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1974), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 4 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0527)]\n",
            "Actual: 5 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0604)]\n",
            "Actual: 6 predicted: [('0', 0.3443), ('3', 0.3268), ('-3', 0.183), ('7', 0.0745), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-7, -8, -5, -6, -4, -2, -2, -1, -1, -2, -1, -1, -1, -2, -4, -4, -4, -4, 0, 0]\n",
            "Actual: 1 predicted: [('0', 0.8367), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 2 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 1 predicted: [('0', 0.5836), ('3', 0.21), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 1 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 1 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0294)]\n",
            "Actual: 3 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 3 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1974), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 4 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: 5 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0603)]\n",
            "Actual: 5 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-9, -6, -7, -5, -3, -3, -2, -3, -3, -3, -2, -2, -3, -5, -6, -5, -5, -1, -1, -1]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 0 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 0 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 1 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 2 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 3 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 4 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: 4 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 4 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-7, -8, -5, -4, -4, -3, -3, -4, -3, -3, -3, -4, -6, -6, -6, -5, -2, -2, -1, 0]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1449), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 0 predicted: [('0', 0.5836), ('3', 0.21), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 1 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 1 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0294)]\n",
            "Actual: 2 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 3 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1974), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 3 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: 4 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0603)]\n",
            "Actual: 3 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-7, -5, -3, -3, -2, -2, -3, -2, -2, -2, -3, -5, -5, -5, -5, -1, -1, -1, 0, 0]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 2 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 2 predicted: [('0', 0.5184), ('3', 0.2454), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 3 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 4 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 4 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 5 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 4 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 4 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-5, -4, -3, -2, -3, -3, -3, -2, -3, -4, -6, -6, -5, -5, -2, -2, -1, 0, 0, 0]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 1 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 2 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 3 predicted: [('0', 0.5184), ('3', 0.2454), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 4 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 4 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 4 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 4 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 4 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 3 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-4, -3, -2, -3, -3, -3, -2, -3, -3, -6, -6, -5, -5, -2, -2, -1, 0, 0, 0, 0]\n",
            "Actual: 1 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 2 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 3 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 4 predicted: [('0', 0.5184), ('3', 0.2454), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 4 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 4 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 4 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 4 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 3 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 4 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-5, -4, -4, -5, -5, -4, -4, -5, -7, -7, -7, -7, -3, -3, -3, -1, -1, -2, -1, -1]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0793), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 1 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 2 predicted: [('0', 0.5836), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0188)]\n",
            "Actual: 2 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 2 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 2 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 2 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 2 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: 3 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0655), ('-7', 0.0603)]\n",
            "Actual: 4 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-4, -5, -5, -5, -4, -5, -5, -8, -8, -7, -7, -4, -4, -3, -2, -1, -2, -2, -2, 0]\n",
            "Actual: 1 predicted: [('0', 0.8366), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 2 predicted: [('0', 0.7193), ('3', 0.1449), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 2 predicted: [('0', 0.5836), ('3', 0.2101), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 2 predicted: [('0', 0.5184), ('3', 0.2456), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 2 predicted: [('0', 0.4945), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0478), ('-7', 0.0294)]\n",
            "Actual: 1 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0497), ('-7', 0.0301)]\n",
            "Actual: 1 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1974), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 2 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0527)]\n",
            "Actual: 3 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0604)]\n",
            "Actual: 3 predicted: [('0', 0.3443), ('3', 0.3268), ('-3', 0.183), ('7', 0.0745), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-6, -6, -6, -5, -6, -6, -9, -9, -8, -8, -5, -5, -4, -3, -2, -3, -3, -3, -1, -1]\n",
            "Actual: 1 predicted: [('0', 0.8367), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 1 predicted: [('0', 0.5836), ('3', 0.21), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 1 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 0 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0294)]\n",
            "Actual: 0 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 1 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1974), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 2 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: 2 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0603)]\n",
            "Actual: 0 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-7, -7, -6, -7, -7, -9, -10, -9, -9, -6, -6, -5, -4, -3, -4, -4, -4, -2, -2, -1]\n",
            "Actual: 0 predicted: [('0', 0.8366), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7193), ('3', 0.1449), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 0 predicted: [('0', 0.5836), ('3', 0.2101), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 0 predicted: [('0', 0.5184), ('3', 0.2456), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 0 predicted: [('0', 0.4945), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0478), ('-7', 0.0294)]\n",
            "Actual: 0 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0497), ('-7', 0.0301)]\n",
            "Actual: 1 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1974), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 1 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0527)]\n",
            "Actual: 0 predicted: [('0', 0.3369), ('3', 0.3171), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0604)]\n",
            "Actual: 1 predicted: [('0', 0.3443), ('3', 0.3268), ('-3', 0.183), ('7', 0.0745), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-7, -6, -7, -7, -9, -10, -9, -9, -6, -5, -5, -4, -3, -4, -3, -3, -2, -1, 0, 0]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 0 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 0 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 0 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 1 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 1 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 0 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 1 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 0 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-6, -7, -8, -10, -10, -9, -9, -6, -6, -5, -4, -3, -4, -4, -4, -2, -2, -1, 0, 0]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 0 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 0 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 1 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 1 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 0 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 0 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 0 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 5 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-7, -7, -10, -10, -9, -9, -6, -6, -5, -4, -3, -4, -4, -4, -2, -2, -1, 0, 0, 0]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 0 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 1 predicted: [('0', 0.5184), ('3', 0.2454), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 1 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 0 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 1 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 0 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 5 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 5 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-7, -9, -10, -9, -9, -6, -5, -5, -4, -3, -4, -3, -3, -2, -1, 0, 0, 0, 0, 0]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 1 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 1 predicted: [('0', 0.5184), ('3', 0.2454), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 0 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 1 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 0 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 5 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 5 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 6 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-9, -9, -9, -8, -5, -5, -5, -3, -3, -4, -3, -3, -2, -1, 0, 0, 0, 0, 0, 0]\n",
            "Actual: 1 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 2 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 1 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 0 predicted: [('0', 0.5184), ('3', 0.2454), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 1 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 0 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 6 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 5 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 6 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 7 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-10, -10, -10, -6, -6, -6, -5, -4, -5, -4, -4, -3, -2, -1, 0, 0, 0, 0, 0, -1]\n",
            "Actual: 1 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: -1 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 0 predicted: [('0', 0.5184), ('3', 0.2454), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: -1 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 5 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 4 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 5 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 6 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 7 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-11, -10, -7, -7, -7, -6, -5, -6, -5, -5, -4, -3, -2, -1, -1, -1, -1, -1, -2, -1]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: -2 predicted: [('0', 0.7193), ('3', 0.1448), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 0 predicted: [('0', 0.5836), ('3', 0.21), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: -2 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 4 predicted: [('0', 0.4945), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0294)]\n",
            "Actual: 3 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 4 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 5 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: 6 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0603)]\n",
            "Actual: 6 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-10, -7, -7, -6, -5, -4, -5, -5, -5, -3, -3, -2, -1, -1, -1, -1, -1, -1, 0, 0]\n",
            "Actual: -1 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: -1 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 4 predicted: [('0', 0.5184), ('3', 0.2454), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 3 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 4 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 5 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 6 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 6 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 6 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-5, -5, -5, -4, -3, -4, -3, -3, -2, -1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1]\n",
            "Actual: 1 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 6 predicted: [('0', 0.5836), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 5 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 6 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 7 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 8 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 8 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: 8 predicted: [('0', 0.337), ('3', 0.317), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 9 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-7, -6, -5, -4, -5, -5, -5, -3, -3, -2, -1, -1, 0, -1, -1, -1, 0, 0, 0, -1]\n",
            "Actual: -1 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 4 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 4 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 4 predicted: [('0', 0.5184), ('3', 0.2454), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 5 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 6 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 6 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 6 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 7 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 8 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-5, -4, -3, -4, -3, -3, -2, -1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 1]\n",
            "Actual: 6 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 5 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 6 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 7 predicted: [('0', 0.5184), ('3', 0.2454), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 8 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 8 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 8 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 9 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 10 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 11 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-9, -8, -9, -9, -9, -7, -7, -6, -5, -5, -5, -5, -5, -6, -4, -3, -4, -5, -4, -5]\n",
            "Actual: 0 predicted: [('0', 0.8366), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0046), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7193), ('3', 0.145), ('-3', 0.1289), ('7', 0.0217), ('-7', 0.011)]\n",
            "Actual: 1 predicted: [('0', 0.5836), ('3', 0.2102), ('-3', 0.1757), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 2 predicted: [('0', 0.5184), ('3', 0.2456), ('-3', 0.2033), ('7', 0.0334), ('-7', 0.0212)]\n",
            "Actual: 2 predicted: [('0', 0.4945), ('3', 0.2534), ('-3', 0.1922), ('7', 0.0478), ('-7', 0.0294)]\n",
            "Actual: 1 predicted: [('0', 0.5049), ('3', 0.248), ('-3', 0.1903), ('7', 0.0497), ('-7', 0.0302)]\n",
            "Actual: 2 predicted: [('0', 0.4428), ('3', 0.2743), ('-3', 0.1974), ('7', 0.0513), ('-7', 0.0391)]\n",
            "Actual: 3 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.062), ('-7', 0.0527)]\n",
            "Actual: 4 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0604)]\n",
            "Actual: 6 predicted: [('0', 0.3443), ('3', 0.3269), ('-3', 0.183), ('7', 0.0745), ('-7', 0.0599)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-8, -9, -8, -8, -7, -7, -5, -4, -5, -4, -4, -5, -5, -4, -3, -3, -5, -3, -5, 0]\n",
            "Actual: 0 predicted: [('0', 0.8366), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 1 predicted: [('0', 0.7193), ('3', 0.1449), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 2 predicted: [('0', 0.5836), ('3', 0.2101), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 2 predicted: [('0', 0.5184), ('3', 0.2456), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 2 predicted: [('0', 0.4945), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0478), ('-7', 0.0294)]\n",
            "Actual: 3 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0497), ('-7', 0.0301)]\n",
            "Actual: 4 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1974), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 5 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0527)]\n",
            "Actual: 7 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0604)]\n",
            "Actual: 10 predicted: [('0', 0.3443), ('3', 0.3268), ('-3', 0.183), ('7', 0.0745), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-9, -9, -9, -8, -7, -6, -5, -5, -5, -5, -5, -6, -5, -4, -4, -6, -4, -6, 0, 0]\n",
            "Actual: 1 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 2 predicted: [('0', 0.7194), ('3', 0.1449), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 1 predicted: [('0', 0.5836), ('3', 0.21), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 1 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 2 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0294)]\n",
            "Actual: 3 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 4 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1974), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 6 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: 10 predicted: [('0', 0.3369), ('3', 0.317), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0603)]\n",
            "Actual: 10 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-10, -10, -9, -8, -7, -6, -6, -6, -6, -6, -7, -6, -5, -5, -7, -5, -7, -1, -1, -1]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 0 predicted: [('0', 0.5836), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 1 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 2 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 3 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 5 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 8 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: 8 predicted: [('0', 0.3369), ('3', 0.317), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 10 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-11, -9, -9, -8, -7, -7, -7, -7, -7, -8, -6, -5, -6, -7, -6, -7, -2, -2, -2, 0]\n",
            "Actual: 0 predicted: [('0', 0.8366), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0046), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7193), ('3', 0.1449), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 0 predicted: [('0', 0.5836), ('3', 0.2101), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 1 predicted: [('0', 0.5184), ('3', 0.2456), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 2 predicted: [('0', 0.4945), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0478), ('-7', 0.0294)]\n",
            "Actual: 4 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0497), ('-7', 0.0301)]\n",
            "Actual: 8 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1974), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 8 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0527)]\n",
            "Actual: 10 predicted: [('0', 0.3369), ('3', 0.317), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0603)]\n",
            "Actual: 11 predicted: [('0', 0.3442), ('3', 0.3269), ('-3', 0.183), ('7', 0.0745), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-9, -9, -8, -7, -7, -7, -7, -7, -7, -6, -5, -6, -7, -6, -7, -2, -2, -1, 0, 0]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 1 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 2 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 4 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 8 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 8 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 10 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: 11 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 9 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-9, -8, -7, -7, -7, -7, -7, -7, -6, -5, -6, -7, -6, -7, -1, -2, -1, 0, 0, 0]\n",
            "Actual: 1 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 1 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 3 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 4 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 8 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 8 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 10 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 11 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 9 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 10 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-9, -8, -8, -7, -8, -8, -8, -7, -6, -6, -8, -7, -8, -2, -3, -2, -1, 0, 0, 0]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 1 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 3 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 7 predicted: [('0', 0.5184), ('3', 0.2454), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 7 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 9 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 10 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 8 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 9 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 9 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-8, -9, -8, -8, -9, -9, -8, -7, -7, -9, -7, -9, -3, -4, -3, -2, -1, -1, -1, 0]\n",
            "Actual: 1 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 2 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 6 predicted: [('0', 0.5837), ('3', 0.21), ('-3', 0.1756), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 6 predicted: [('0', 0.5184), ('3', 0.2454), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 8 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 9 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 7 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 8 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0618), ('-7', 0.0526)]\n",
            "Actual: 8 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 10 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-10, -9, -9, -10, -10, -9, -8, -8, -10, -8, -10, -4, -5, -4, -3, -2, -2, -2, -1, -1]\n",
            "Actual: 1 predicted: [('0', 0.8367), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 5 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 5 predicted: [('0', 0.5836), ('3', 0.21), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 7 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 8 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0294)]\n",
            "Actual: 6 predicted: [('0', 0.5048), ('3', 0.2478), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 7 predicted: [('0', 0.4428), ('3', 0.2742), ('-3', 0.1974), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 7 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: 9 predicted: [('0', 0.337), ('3', 0.3171), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0603)]\n",
            "Actual: 9 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-11, -11, -11, -11, -10, -9, -10, -11, -10, -11, -6, -6, -6, -4, -4, -4, -4, -3, -2, -1]\n",
            "Actual: 3 predicted: [('0', 0.8366), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 3 predicted: [('0', 0.7193), ('3', 0.1449), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 5 predicted: [('0', 0.5836), ('3', 0.2101), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 6 predicted: [('0', 0.5184), ('3', 0.2456), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 4 predicted: [('0', 0.4945), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0478), ('-7', 0.0294)]\n",
            "Actual: 5 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0497), ('-7', 0.0301)]\n",
            "Actual: 5 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1974), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 8 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0527)]\n",
            "Actual: 7 predicted: [('0', 0.3369), ('3', 0.317), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0603)]\n",
            "Actual: 8 predicted: [('0', 0.3443), ('3', 0.3268), ('-3', 0.183), ('7', 0.0745), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-14, -14, -14, -13, -12, -13, -14, -13, -14, -9, -9, -9, -8, -7, -7, -7, -6, -5, -4, -3]\n",
            "Actual: 0 predicted: [('0', 0.8366), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0046), ('-7', 0.004)]\n",
            "Actual: 1 predicted: [('0', 0.7193), ('3', 0.145), ('-3', 0.1289), ('7', 0.0217), ('-7', 0.011)]\n",
            "Actual: 3 predicted: [('0', 0.5836), ('3', 0.2101), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 0 predicted: [('0', 0.5184), ('3', 0.2456), ('-3', 0.2033), ('7', 0.0334), ('-7', 0.0212)]\n",
            "Actual: 1 predicted: [('0', 0.4945), ('3', 0.2534), ('-3', 0.1922), ('7', 0.0478), ('-7', 0.0294)]\n",
            "Actual: 1 predicted: [('0', 0.5049), ('3', 0.248), ('-3', 0.1902), ('7', 0.0497), ('-7', 0.0302)]\n",
            "Actual: 4 predicted: [('0', 0.4427), ('3', 0.2743), ('-3', 0.1974), ('7', 0.0513), ('-7', 0.0391)]\n",
            "Actual: 4 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.062), ('-7', 0.0527)]\n",
            "Actual: 4 predicted: [('0', 0.3369), ('3', 0.317), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0604)]\n",
            "Actual: 5 predicted: [('0', 0.3443), ('3', 0.3269), ('-3', 0.183), ('7', 0.0745), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-14, -14, -13, -13, -13, -14, -13, -14, -9, -9, -9, -8, -7, -7, -7, -6, -5, -4, -3, 0]\n",
            "Actual: 1 predicted: [('0', 0.8366), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0046), ('-7', 0.0039)]\n",
            "Actual: 3 predicted: [('0', 0.7193), ('3', 0.1449), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 0 predicted: [('0', 0.5836), ('3', 0.2101), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 1 predicted: [('0', 0.5184), ('3', 0.2456), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 1 predicted: [('0', 0.4945), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0478), ('-7', 0.0294)]\n",
            "Actual: 4 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0497), ('-7', 0.0301)]\n",
            "Actual: 3 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1974), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 4 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0527)]\n",
            "Actual: 5 predicted: [('0', 0.3369), ('3', 0.317), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0603)]\n",
            "Actual: 6 predicted: [('0', 0.3442), ('3', 0.3269), ('-3', 0.183), ('7', 0.0745), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-16, -15, -14, -14, -16, -14, -16, -11, -11, -11, -9, -9, -9, -9, -8, -7, -6, -5, -1, -1]\n",
            "Actual: 1 predicted: [('0', 0.8366), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1449), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 0 predicted: [('0', 0.5836), ('3', 0.2101), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 0 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 2 predicted: [('0', 0.4946), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0477), ('-7', 0.0294)]\n",
            "Actual: 2 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 2 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1974), ('7', 0.0512), ('-7', 0.0391)]\n",
            "Actual: 3 predicted: [('0', 0.3891), ('3', 0.3021), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: 4 predicted: [('0', 0.3369), ('3', 0.317), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0603)]\n",
            "Actual: 6 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-16, -15, -16, -17, -16, -17, -12, -12, -12, -11, -10, -10, -10, -9, -8, -7, -6, -3, -3, -1]\n",
            "Actual: -2 predicted: [('0', 0.8366), ('3', 0.0842), ('-3', 0.0793), ('7', 0.0046), ('-7', 0.0039)]\n",
            "Actual: -1 predicted: [('0', 0.7193), ('3', 0.1449), ('-3', 0.1289), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: -1 predicted: [('0', 0.5836), ('3', 0.2101), ('-3', 0.1756), ('7', 0.0267), ('-7', 0.0188)]\n",
            "Actual: 1 predicted: [('0', 0.5183), ('3', 0.2456), ('-3', 0.2032), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 0 predicted: [('0', 0.4945), ('3', 0.2533), ('-3', 0.1922), ('7', 0.0478), ('-7', 0.0294)]\n",
            "Actual: 1 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0497), ('-7', 0.0301)]\n",
            "Actual: 2 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1974), ('7', 0.0513), ('-7', 0.0391)]\n",
            "Actual: 3 predicted: [('0', 0.3891), ('3', 0.302), ('-3', 0.1904), ('7', 0.0619), ('-7', 0.0527)]\n",
            "Actual: 5 predicted: [('0', 0.3369), ('3', 0.317), ('-3', 0.1963), ('7', 0.0655), ('-7', 0.0603)]\n",
            "Actual: 6 predicted: [('0', 0.3442), ('3', 0.3269), ('-3', 0.183), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "epoch: 0\n",
            "input: [-13, -14, -15, -14, -15, -10, -10, -10, -8, -8, -8, -8, -7, -6, -5, -4, 0, 0, 0, 2]\n",
            "Actual: 0 predicted: [('0', 0.8367), ('3', 0.0841), ('-3', 0.0792), ('7', 0.0045), ('-7', 0.0039)]\n",
            "Actual: 0 predicted: [('0', 0.7194), ('3', 0.1448), ('-3', 0.1288), ('7', 0.0216), ('-7', 0.011)]\n",
            "Actual: 3 predicted: [('0', 0.5836), ('3', 0.21), ('-3', 0.1755), ('7', 0.0266), ('-7', 0.0187)]\n",
            "Actual: 3 predicted: [('0', 0.5184), ('3', 0.2455), ('-3', 0.2031), ('7', 0.0333), ('-7', 0.0211)]\n",
            "Actual: 3 predicted: [('0', 0.4945), ('3', 0.2533), ('-3', 0.1921), ('7', 0.0477), ('-7', 0.0293)]\n",
            "Actual: 4 predicted: [('0', 0.5048), ('3', 0.2479), ('-3', 0.1902), ('7', 0.0496), ('-7', 0.0301)]\n",
            "Actual: 5 predicted: [('0', 0.4427), ('3', 0.2742), ('-3', 0.1973), ('7', 0.0512), ('-7', 0.039)]\n",
            "Actual: 7 predicted: [('0', 0.3891), ('3', 0.302), ('-3', 0.1903), ('7', 0.0619), ('-7', 0.0526)]\n",
            "Actual: 8 predicted: [('0', 0.3369), ('3', 0.317), ('-3', 0.1962), ('7', 0.0654), ('-7', 0.0603)]\n",
            "Actual: 9 predicted: [('0', 0.3442), ('3', 0.3268), ('-3', 0.1829), ('7', 0.0744), ('-7', 0.0598)]\n",
            "-----\n",
            "--------\n",
            "pos_threshold 0.3\n",
            "neg_threshold 0.3\n",
            "diff_threshold 0\n",
            "n_top_preds 20\n",
            "sort_by_pos_wt True\n",
            "sort_by_diff_wt False\n",
            "pos_ratio_threshold 0.5\n",
            "dir exp3-20stocks-64-3layer-lr001-sig2\n",
            "epoch 30\n",
            "start_i 0\n",
            "n_test 60\n",
            "n_input 7\n",
            "n_hidden 64\n",
            "n_layers 3\n",
            "n_output 70\n",
            "LR 0.001\n",
            ">> Result:  balance 313\n",
            ">> Result:  n_sells 60\n",
            ">> Result:  good_sells 36\n",
            ">> Result:  bad_sells 0\n",
            "pos_ratio_threshold 0.5 Final Balance: 313\n",
            "=================\n"
          ]
        }
      ],
      "source": [
        "import torch, random\n",
        "import os\n",
        "\n",
        "torch.manual_seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "e0=30\n",
        "#dir_name=\"apple_models-history30\"\n",
        "model_name=\"exp1-3stocks\" #\"apple_models2\"\n",
        "model_name=\"exp2-3stocks-32\"\n",
        "#model_name=\"exp2-3stocks-128\"\n",
        "#model_name=\"exp2-10stocks-64\"\n",
        "#model_name=\"exp2-10stocks-128\"\n",
        "model_name=\"exp2-10stocks-64-3layer\"\n",
        "model_name=\"exp2-10stocks-64-4layer-TEST\"\n",
        "model_name=\"exp2-10stocks-64-3layer-new\"\n",
        "model_name=\"exp3-20stocks-64-3layer-new\"\n",
        "#model_name=\"exp3-50stocks-64-3layer\"\n",
        "# model_name=\"exp3-50stocks-64-3layer-lr5e8\"\n",
        "# model_name=\"exp3-100stocks-64-3layer-lr1e8\"\n",
        "# #model_name=\"exp3-50stocks-64-3layer\"\n",
        "# #model_name=\"exp3-50stocks-64-3layer-5r1e8-30days\"\n",
        "model_name=\"exp3-50stocks-64-3layer-lr1e8\"\n",
        "model_name=\"exp3-20stocks-64-3layer-lr001-sig2\"\n",
        "model_dir=os.path.join(cwd,\"models\", model_name) \n",
        "\n",
        "pos_threshold=0.3\n",
        "neg_threshold=0.3\n",
        "diff_threshold=0\n",
        "n_top_preds=20 #20\n",
        "sort_by_pos_wt=True\n",
        "sort_by_diff_wt=False\n",
        "cur_params={}\n",
        "cur_params[\"pos_threshold\"]=pos_threshold\n",
        "cur_params[\"neg_threshold\"]=neg_threshold\n",
        "cur_params[\"diff_threshold\"]=diff_threshold\n",
        "cur_params[\"n_top_preds\"]=n_top_preds\n",
        "cur_params[\"sort_by_pos_wt\"]=sort_by_pos_wt\n",
        "cur_params[\"sort_by_diff_wt\"]=sort_by_diff_wt\n",
        "pos_ratio_threshold=0.5\n",
        "cur_params[\"pos_ratio_threshold\"]=pos_ratio_threshold\n",
        "\n",
        "# test_params={}\n",
        "# test_params[\"pos_threshold\"]=0.3\n",
        "# test_params[\"neg_threshold\"]=0.4\n",
        "# test_params[\"diff_threshold\"]=-1\n",
        "# for a,b in test_params.items():cur_params[a]=b\n",
        "\n",
        "\n",
        "\n",
        "#now testing to see the output of the rnn on actual data\n",
        "\n",
        "\n",
        "\n",
        "#dir_name=\"apple_models-history10\"\n",
        "\n",
        "\n",
        "\n",
        "cur_params[\"dir\"]=model_name\n",
        "cur_params[\"epoch\"]=e0\n",
        "\n",
        "\n",
        "start_i=0#0\n",
        "n_test=60 #6000\n",
        "cur_params[\"start_i\"]=start_i\n",
        "cur_params[\"n_test\"]=min(n_test,len(all_testing))\n",
        "\n",
        "#pos_ratio_threshold=0.5\n",
        "#for pos_threshold in [0.2,0.25,0.3,0.35,0.4,0.45]:\n",
        "for e0 in range(100):\n",
        "   \n",
        "  PATH=os.path.join(model_dir, \"model-%s.model\"%e0)\n",
        "  if not os.path.exists(PATH): continue\n",
        "  print(\"epoch:\", e0) \n",
        "  checkpoint = torch.load(PATH)\n",
        "  rnn = RNN(checkpoint[\"n_input\"], checkpoint[\"n_hidden\"] , checkpoint[\"n_output\"] , checkpoint[\"n_layers\"] , matching_in_out=False).to(device)\n",
        "  rnn.load_state_dict(checkpoint['model_state_dict'])\n",
        "  rnn.eval()\n",
        "  for a,b in checkpoint.items():\n",
        "    if a.startswith(\"n_\") or a.lower()==\"lr\": cur_params[a]=b\n",
        "\n",
        "\n",
        "  #cur_params[\"pos_threshold\"]=pos_threshold\n",
        "  balance=0\n",
        "  n_sells=0\n",
        "  good_sells=0  #gained more than 5%\n",
        "  bad_sells=0  #lost more than 5%\n",
        "  correct_counter,incorrect_counter=0,0\n",
        "  exp_list=[]\n",
        "  #pos_ratio_threshold=0.5\n",
        "  for i0,tr0 in enumerate(all_testing[start_i:start_i+n_test]):\n",
        "    input_list,output_list0=tr0\n",
        "    input_oh=list2one_hot2(input_list,mv_labels2)\n",
        "    output_oh=list2one_hot2(output_list0,mv_labels2)\n",
        "    input_tensor,output_tensor=torch.tensor(input_oh) , torch.tensor(output_oh).ravel()\n",
        "    rnn.hidden = rnn.init_hidden()\n",
        "    rnn.zero_grad()\n",
        "    rnn_output = rnn(input_tensor).ravel().tolist()\n",
        "    predictions0=out2labels(rnn_output,mv_labels2)\n",
        "    print(\"epoch:\",e0)\n",
        "    print(\"input:\",input_list)\n",
        "    for actual0,pred0 in zip(output_list0,predictions0):\n",
        "      tmp_pred=[(v[0],round(v[1],4)) for v in pred0]\n",
        "      print(\"Actual:\",actual0, \"predicted:\",tmp_pred[:5])\n",
        "    print(\"-----\")\n",
        "    ## New module\n",
        "    # selling_pred_obj=selling_pred(predictions0)\n",
        "    # cur_sps=selling_pred_obj.selling_pts\n",
        "    # valid_pairs=[]\n",
        "    # for a,b in zip(output_list0,cur_sps):\n",
        "    #   tmp_above_dict=b[\"above_dict\"]\n",
        "    #   tmp_below_dict=b[\"below_dict\"]\n",
        "    #   pred_3=tmp_above_dict.get(3,0)\n",
        "    #   pred_pos_ratio=b[\"pred_pos_ratio\"]\n",
        "    #   valid_pairs.append((a,b,pred_3,pred_pos_ratio))\n",
        "    #   #if pred_3<0.5: continue\n",
        "    #   #valid_pairs.append((a,b))\n",
        "    # valid_pairs.sort(key=lambda x:(-x[-1],-x[-2]))\n",
        "    # if valid_pairs:\n",
        "    #   print(\"i0\",i0)\n",
        "    #   for a,b,c,d in valid_pairs[:1]:\n",
        "    #     #if d<0.5: continue\n",
        "    #     balance+=a\n",
        "    #     n_sells+=1\n",
        "    #     if a>=0:correct_counter+=1\n",
        "    #     else: incorrect_counter+=1\n",
        "        \n",
        "    #     tmp_above_dict=b[\"above_dict\"]\n",
        "    #     tmp_below_dict=b[\"below_dict\"]\n",
        "    #     pred_3=tmp_above_dict.get(3,0)\n",
        "        \n",
        "    #     print(\"actual:\", a, \"pred @ 3:\",pred_3,[c,d])\n",
        "    #     print(\"Top prediction:\", b[\"top\"])\n",
        "    #     print(\"pred_pos_ratio\", b[\"pred_pos_ratio\"])\n",
        "    #     print(sorted(list(tmp_above_dict.items())))\n",
        "    #     print(sorted(list(tmp_below_dict.items()),key=lambda x:-x[0]))\n",
        "    #     # for a1,b1 in b.items():\n",
        "    #     #   print(a1,b1)\n",
        "    #     print(\"--\")\n",
        "    #   print(\"==========\")\n",
        "    #End of new module\n",
        "    \n",
        "    #continue\n",
        "    cur_selling_pts=check_selling(predictions0,output_list0,cur_params,nofilter=False, debug_vals=False)\n",
        "    if cur_selling_pts:\n",
        "      increment=cur_selling_pts[0][0]\n",
        "      actual0,i_,pos_ratio ,pos0,neg0,diff0=cur_selling_pts[0]\n",
        "      exp_list.append(cur_selling_pts[0])\n",
        "      #pos_ratio=round(pos0/(pos0+neg0),2)\n",
        "      #if pos_ratio<0.55: continue\n",
        "      balance=balance+increment\n",
        "      n_sells+=1\n",
        "      # if increment<=0 or True:\n",
        "      #   actual0,i_,pos0,neg0,diff0=cur_selling_pts[0]\n",
        "      #   pos_ratio=round(pos0/(pos0+neg0),2)\n",
        "        #print(\">>> Actual:\",actual0, \"+ive:\",pos0, \"-ive:\",neg0,\"diff:\",diff0,\"pos_ratio\",pos_ratio)\n",
        "          \n",
        "      if increment>=5:good_sells+=1\n",
        "      if increment<-5:bad_sells+=1\n",
        "      \n",
        "      #print(\"i0\",i0, \"Increment:\",increment, \">> New Balance:\",balance)\n",
        "      #print(\"---------\")\n",
        "\n",
        "  results={}\n",
        "  results[\"balance\"]=balance\n",
        "  results[\"n_sells\"]=n_sells\n",
        "  results[\"good_sells\"]=good_sells\n",
        "  results[\"bad_sells\"]=bad_sells\n",
        "  # results[\"correct_counter\"]=correct_counter\n",
        "  # results[\"incorrect_counter\"]=incorrect_counter\n",
        "  #correct_counter,incorrect_counter=0,0\n",
        "\n",
        "  #print(\"start_i\",start_i, \"n_test\",n_test, \"n_top_preds\",n_top_preds, \"pos_threshold\",pos_threshold, \"neg_threshold\",neg_threshold,\"diff_threshold\",diff_threshold)\n",
        "  print(\"--------\")\n",
        "  for a,b in cur_params.items():\n",
        "    print(a,b)\n",
        "  for a,b in results.items():\n",
        "    print(\">> Result: \",a,b)\n",
        "  #print(\"number of sells:\",n_sells, \"good:\",good_sells,\"bad\",bad_sells)\n",
        "  print(\"pos_ratio_threshold\",pos_ratio_threshold, \"Final Balance:\",balance)\n",
        "  print(\"=================\")\n",
        "\n",
        "                "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L5pLthVqqOf"
      },
      "source": [
        "##further check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5LdtQmrBo-n",
        "outputId": "e2588093-2577-4bd0-8e6d-274b0f87cdcd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i0 0 Increment: 12 >> New Balance: 12\n",
            "i0 1 Increment: 10 >> New Balance: 22\n",
            "i0 3 Increment: 14 >> New Balance: 36\n",
            "i0 4 Increment: 14 >> New Balance: 50\n",
            "i0 5 Increment: 14 >> New Balance: 64\n",
            "i0 6 Increment: 9 >> New Balance: 73\n",
            "i0 15 Increment: 2 >> New Balance: 75\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.23 diff: 0.28\n",
            "i0 16 Increment: 0 >> New Balance: 75\n",
            "i0 18 Increment: 15 >> New Balance: 90\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.22 diff: 0.33\n",
            "i0 19 Increment: 0 >> New Balance: 90\n",
            ">>> Actual: 0 +ive: 0.57 -ive: 0.27 diff: 0.3\n",
            "i0 20 Increment: 0 >> New Balance: 90\n",
            "i0 22 Increment: 22 >> New Balance: 112\n",
            "i0 24 Increment: 4 >> New Balance: 116\n",
            "i0 25 Increment: 5 >> New Balance: 121\n",
            ">>> Actual: -6 +ive: 0.62 -ive: 0.28 diff: 0.34\n",
            "i0 29 Increment: -6 >> New Balance: 115\n",
            "i0 32 Increment: 3 >> New Balance: 118\n",
            "i0 35 Increment: 2 >> New Balance: 120\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.29 diff: 0.24\n",
            "i0 36 Increment: 0 >> New Balance: 120\n",
            ">>> Actual: -3 +ive: 0.55 -ive: 0.25 diff: 0.3\n",
            "i0 41 Increment: -3 >> New Balance: 117\n",
            "i0 43 Increment: 2 >> New Balance: 119\n",
            "i0 49 Increment: 7 >> New Balance: 126\n",
            "i0 50 Increment: 7 >> New Balance: 133\n",
            "i0 51 Increment: 1 >> New Balance: 134\n",
            "i0 57 Increment: 1 >> New Balance: 135\n",
            "i0 64 Increment: 2 >> New Balance: 137\n",
            "i0 65 Increment: 2 >> New Balance: 139\n",
            "i0 66 Increment: 2 >> New Balance: 141\n",
            "i0 73 Increment: 1 >> New Balance: 142\n",
            "i0 78 Increment: 12 >> New Balance: 154\n",
            "i0 79 Increment: 13 >> New Balance: 167\n",
            "i0 80 Increment: 8 >> New Balance: 175\n",
            "i0 81 Increment: 6 >> New Balance: 181\n",
            "i0 85 Increment: 1 >> New Balance: 182\n",
            "i0 86 Increment: 3 >> New Balance: 185\n",
            ">>> Actual: -9 +ive: 0.57 -ive: 0.27 diff: 0.3\n",
            "i0 91 Increment: -9 >> New Balance: 176\n",
            ">>> Actual: -8 +ive: 0.55 -ive: 0.24 diff: 0.31\n",
            "i0 92 Increment: -8 >> New Balance: 168\n",
            "i0 96 Increment: 1 >> New Balance: 169\n",
            "i0 97 Increment: 7 >> New Balance: 176\n",
            "i0 98 Increment: 2 >> New Balance: 178\n",
            "i0 100 Increment: 5 >> New Balance: 183\n",
            ">>> Actual: -4 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 104 Increment: -4 >> New Balance: 179\n",
            ">>> Actual: -1 +ive: 0.54 -ive: 0.25 diff: 0.29\n",
            "i0 108 Increment: -1 >> New Balance: 178\n",
            ">>> Actual: -3 +ive: 0.55 -ive: 0.26 diff: 0.29\n",
            "i0 109 Increment: -3 >> New Balance: 175\n",
            "i0 110 Increment: 4 >> New Balance: 179\n",
            "i0 114 Increment: 2 >> New Balance: 181\n",
            ">>> Actual: -5 +ive: 0.6 -ive: 0.2 diff: 0.4\n",
            "i0 117 Increment: -5 >> New Balance: 176\n",
            ">>> Actual: -14 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 118 Increment: -14 >> New Balance: 162\n",
            "i0 123 Increment: 2 >> New Balance: 164\n",
            "i0 124 Increment: 2 >> New Balance: 166\n",
            ">>> Actual: 0 +ive: 0.62 -ive: 0.1 diff: 0.52\n",
            "i0 126 Increment: 0 >> New Balance: 166\n",
            "i0 128 Increment: 1 >> New Balance: 167\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.21 diff: 0.3\n",
            "i0 131 Increment: 0 >> New Balance: 167\n",
            "i0 134 Increment: 1 >> New Balance: 168\n",
            ">>> Actual: -3 +ive: 0.66 -ive: 0.12 diff: 0.54\n",
            "i0 135 Increment: -3 >> New Balance: 165\n",
            "i0 147 Increment: 8 >> New Balance: 173\n",
            "i0 148 Increment: 8 >> New Balance: 181\n",
            ">>> Actual: 0 +ive: 0.64 -ive: 0.14 diff: 0.5\n",
            "i0 149 Increment: 0 >> New Balance: 181\n",
            ">>> Actual: 0 +ive: 0.64 -ive: 0.14 diff: 0.5\n",
            "i0 150 Increment: 0 >> New Balance: 181\n",
            ">>> Actual: -7 +ive: 0.64 -ive: 0.25 diff: 0.39\n",
            "i0 152 Increment: -7 >> New Balance: 174\n",
            ">>> Actual: -8 +ive: 0.63 -ive: 0.16 diff: 0.47\n",
            "i0 153 Increment: -8 >> New Balance: 166\n",
            ">>> Actual: -11 +ive: 0.51 -ive: 0.27 diff: 0.24\n",
            "i0 155 Increment: -11 >> New Balance: 155\n",
            ">>> Actual: -8 +ive: 0.64 -ive: 0.22 diff: 0.42\n",
            "i0 156 Increment: -8 >> New Balance: 147\n",
            ">>> Actual: -6 +ive: 0.53 -ive: 0.26 diff: 0.27\n",
            "i0 157 Increment: -6 >> New Balance: 141\n",
            ">>> Actual: -2 +ive: 0.58 -ive: 0.28 diff: 0.3\n",
            "i0 158 Increment: -2 >> New Balance: 139\n",
            "i0 159 Increment: 4 >> New Balance: 143\n",
            "i0 162 Increment: 5 >> New Balance: 148\n",
            "i0 163 Increment: 5 >> New Balance: 153\n",
            "i0 164 Increment: 4 >> New Balance: 157\n",
            "i0 165 Increment: 1 >> New Balance: 158\n",
            ">>> Actual: -3 +ive: 0.65 -ive: 0.29 diff: 0.36\n",
            "i0 167 Increment: -3 >> New Balance: 155\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.27 diff: 0.26\n",
            "i0 174 Increment: 0 >> New Balance: 155\n",
            "i0 185 Increment: 1 >> New Balance: 156\n",
            "i0 187 Increment: 3 >> New Balance: 159\n",
            "i0 190 Increment: 1 >> New Balance: 160\n",
            ">>> Actual: 0 +ive: 0.58 -ive: 0.14 diff: 0.44\n",
            "i0 191 Increment: 0 >> New Balance: 160\n",
            ">>> Actual: -1 +ive: 0.53 -ive: 0.22 diff: 0.31\n",
            "i0 195 Increment: -1 >> New Balance: 159\n",
            "i0 197 Increment: 11 >> New Balance: 170\n",
            "i0 198 Increment: 6 >> New Balance: 176\n",
            "i0 199 Increment: 10 >> New Balance: 186\n",
            "i0 200 Increment: 10 >> New Balance: 196\n",
            "i0 201 Increment: 6 >> New Balance: 202\n",
            "i0 202 Increment: 8 >> New Balance: 210\n",
            "i0 203 Increment: 4 >> New Balance: 214\n",
            "i0 215 Increment: 5 >> New Balance: 219\n",
            "i0 216 Increment: 12 >> New Balance: 231\n",
            "i0 217 Increment: 11 >> New Balance: 242\n",
            "i0 219 Increment: 8 >> New Balance: 250\n",
            "i0 222 Increment: 5 >> New Balance: 255\n",
            "i0 223 Increment: 1 >> New Balance: 256\n",
            ">>> Actual: 0 +ive: 0.73 -ive: 0.12 diff: 0.61\n",
            "i0 226 Increment: 0 >> New Balance: 256\n",
            "i0 229 Increment: 6 >> New Balance: 262\n",
            "i0 232 Increment: 1 >> New Balance: 263\n",
            "i0 235 Increment: 1 >> New Balance: 264\n",
            "i0 237 Increment: 1 >> New Balance: 265\n",
            "i0 238 Increment: 1 >> New Balance: 266\n",
            ">>> Actual: -5 +ive: 0.59 -ive: 0.21 diff: 0.38\n",
            "i0 241 Increment: -5 >> New Balance: 261\n",
            "i0 245 Increment: 7 >> New Balance: 268\n",
            "i0 251 Increment: 5 >> New Balance: 273\n",
            "i0 258 Increment: 5 >> New Balance: 278\n",
            "i0 260 Increment: 13 >> New Balance: 291\n",
            ">>> Actual: -1 +ive: 0.67 -ive: 0.09 diff: 0.58\n",
            "i0 265 Increment: -1 >> New Balance: 290\n",
            "i0 267 Increment: 11 >> New Balance: 301\n",
            "i0 268 Increment: 8 >> New Balance: 309\n",
            "i0 269 Increment: 8 >> New Balance: 317\n",
            "i0 271 Increment: 9 >> New Balance: 326\n",
            "i0 273 Increment: 2 >> New Balance: 328\n",
            "i0 276 Increment: 6 >> New Balance: 334\n",
            "i0 280 Increment: 6 >> New Balance: 340\n",
            "i0 285 Increment: 3 >> New Balance: 343\n",
            ">>> Actual: -3 +ive: 0.51 -ive: 0.27 diff: 0.24\n",
            "i0 289 Increment: -3 >> New Balance: 340\n",
            ">>> Actual: -4 +ive: 0.71 -ive: 0.18 diff: 0.53\n",
            "i0 290 Increment: -4 >> New Balance: 336\n",
            ">>> Actual: -4 +ive: 0.64 -ive: 0.12 diff: 0.52\n",
            "i0 291 Increment: -4 >> New Balance: 332\n",
            "i0 294 Increment: 5 >> New Balance: 337\n",
            ">>> Actual: 0 +ive: 0.57 -ive: 0.26 diff: 0.31\n",
            "i0 295 Increment: 0 >> New Balance: 337\n",
            "i0 299 Increment: 10 >> New Balance: 347\n",
            "i0 301 Increment: 14 >> New Balance: 361\n",
            "i0 307 Increment: 3 >> New Balance: 364\n",
            ">>> Actual: -5 +ive: 0.56 -ive: 0.26 diff: 0.3\n",
            "i0 310 Increment: -5 >> New Balance: 359\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.13 diff: 0.39\n",
            "i0 311 Increment: 0 >> New Balance: 359\n",
            ">>> Actual: -6 +ive: 0.56 -ive: 0.25 diff: 0.31\n",
            "i0 313 Increment: -6 >> New Balance: 353\n",
            ">>> Actual: -4 +ive: 0.56 -ive: 0.16 diff: 0.4\n",
            "i0 316 Increment: -4 >> New Balance: 349\n",
            ">>> Actual: -2 +ive: 0.62 -ive: 0.27 diff: 0.35\n",
            "i0 319 Increment: -2 >> New Balance: 347\n",
            "i0 320 Increment: 4 >> New Balance: 351\n",
            "i0 321 Increment: 4 >> New Balance: 355\n",
            ">>> Actual: -8 +ive: 0.51 -ive: 0.27 diff: 0.24\n",
            "i0 322 Increment: -8 >> New Balance: 347\n",
            "i0 327 Increment: 2 >> New Balance: 349\n",
            ">>> Actual: -3 +ive: 0.69 -ive: 0.24 diff: 0.45\n",
            "i0 328 Increment: -3 >> New Balance: 346\n",
            "i0 329 Increment: 4 >> New Balance: 350\n",
            ">>> Actual: 0 +ive: 0.69 -ive: 0.26 diff: 0.43\n",
            "i0 330 Increment: 0 >> New Balance: 350\n",
            "i0 332 Increment: 5 >> New Balance: 355\n",
            "i0 350 Increment: 2 >> New Balance: 357\n",
            ">>> Actual: -7 +ive: 0.53 -ive: 0.25 diff: 0.28\n",
            "i0 354 Increment: -7 >> New Balance: 350\n",
            ">>> Actual: -8 +ive: 0.53 -ive: 0.26 diff: 0.27\n",
            "i0 356 Increment: -8 >> New Balance: 342\n",
            ">>> Actual: -2 +ive: 0.61 -ive: 0.17 diff: 0.44\n",
            "i0 359 Increment: -2 >> New Balance: 340\n",
            "i0 362 Increment: 6 >> New Balance: 346\n",
            "i0 365 Increment: 7 >> New Balance: 353\n",
            "i0 366 Increment: 3 >> New Balance: 356\n",
            ">>> Actual: -6 +ive: 0.71 -ive: 0.17 diff: 0.54\n",
            "i0 369 Increment: -6 >> New Balance: 350\n",
            ">>> Actual: -4 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 372 Increment: -4 >> New Balance: 346\n",
            "i0 375 Increment: 4 >> New Balance: 350\n",
            "i0 377 Increment: 6 >> New Balance: 356\n",
            "i0 378 Increment: 2 >> New Balance: 358\n",
            "i0 383 Increment: 2 >> New Balance: 360\n",
            "i0 384 Increment: 1 >> New Balance: 361\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.25 diff: 0.29\n",
            "i0 386 Increment: 0 >> New Balance: 361\n",
            ">>> Actual: -8 +ive: 0.52 -ive: 0.28 diff: 0.24\n",
            "i0 388 Increment: -8 >> New Balance: 353\n",
            ">>> Actual: -7 +ive: 0.53 -ive: 0.29 diff: 0.24\n",
            "i0 392 Increment: -7 >> New Balance: 346\n",
            ">>> Actual: -5 +ive: 0.57 -ive: 0.25 diff: 0.32\n",
            "i0 393 Increment: -5 >> New Balance: 341\n",
            ">>> Actual: -6 +ive: 0.67 -ive: 0.24 diff: 0.43\n",
            "i0 394 Increment: -6 >> New Balance: 335\n",
            ">>> Actual: -5 +ive: 0.61 -ive: 0.22 diff: 0.39\n",
            "i0 395 Increment: -5 >> New Balance: 330\n",
            ">>> Actual: -2 +ive: 0.56 -ive: 0.29 diff: 0.27\n",
            "i0 397 Increment: -2 >> New Balance: 328\n",
            ">>> Actual: 0 +ive: 0.81 -ive: 0.14 diff: 0.67\n",
            "i0 398 Increment: 0 >> New Balance: 328\n",
            ">>> Actual: -6 +ive: 0.57 -ive: 0.26 diff: 0.31\n",
            "i0 399 Increment: -6 >> New Balance: 322\n",
            ">>> Actual: -5 +ive: 0.67 -ive: 0.14 diff: 0.53\n",
            "i0 400 Increment: -5 >> New Balance: 317\n",
            ">>> Actual: -3 +ive: 0.67 -ive: 0.19 diff: 0.48\n",
            "i0 401 Increment: -3 >> New Balance: 314\n",
            ">>> Actual: -1 +ive: 0.7 -ive: 0.15 diff: 0.55\n",
            "i0 402 Increment: -1 >> New Balance: 313\n",
            ">>> Actual: -6 +ive: 0.53 -ive: 0.26 diff: 0.27\n",
            "i0 404 Increment: -6 >> New Balance: 307\n",
            ">>> Actual: -4 +ive: 0.62 -ive: 0.26 diff: 0.36\n",
            "i0 409 Increment: -4 >> New Balance: 303\n",
            "i0 414 Increment: 4 >> New Balance: 307\n",
            ">>> Actual: -2 +ive: 0.57 -ive: 0.25 diff: 0.32\n",
            "i0 418 Increment: -2 >> New Balance: 305\n",
            "i0 419 Increment: 3 >> New Balance: 308\n",
            ">>> Actual: 0 +ive: 0.6 -ive: 0.24 diff: 0.36\n",
            "i0 420 Increment: 0 >> New Balance: 308\n",
            "i0 434 Increment: 9 >> New Balance: 317\n",
            "i0 435 Increment: 14 >> New Balance: 331\n",
            "i0 436 Increment: 18 >> New Balance: 349\n",
            "i0 437 Increment: 25 >> New Balance: 374\n",
            "i0 438 Increment: 18 >> New Balance: 392\n",
            "i0 439 Increment: 17 >> New Balance: 409\n",
            "i0 440 Increment: 17 >> New Balance: 426\n",
            "i0 441 Increment: 8 >> New Balance: 434\n",
            "i0 447 Increment: 3 >> New Balance: 437\n",
            ">>> Actual: -2 +ive: 0.62 -ive: 0.24 diff: 0.38\n",
            "i0 460 Increment: -2 >> New Balance: 435\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.26 diff: 0.25\n",
            "i0 461 Increment: 0 >> New Balance: 435\n",
            "i0 462 Increment: 1 >> New Balance: 436\n",
            "i0 467 Increment: 1 >> New Balance: 437\n",
            "i0 471 Increment: 9 >> New Balance: 446\n",
            "i0 472 Increment: 8 >> New Balance: 454\n",
            "i0 474 Increment: 3 >> New Balance: 457\n",
            "i0 478 Increment: 1 >> New Balance: 458\n",
            "i0 482 Increment: 3 >> New Balance: 461\n",
            "i0 483 Increment: 4 >> New Balance: 465\n",
            ">>> Actual: -3 +ive: 0.51 -ive: 0.21 diff: 0.3\n",
            "i0 484 Increment: -3 >> New Balance: 462\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.25 diff: 0.28\n",
            "i0 485 Increment: 0 >> New Balance: 462\n",
            ">>> Actual: -4 +ive: 0.68 -ive: 0.23 diff: 0.45\n",
            "i0 488 Increment: -4 >> New Balance: 458\n",
            "i0 495 Increment: 5 >> New Balance: 463\n",
            "i0 496 Increment: 1 >> New Balance: 464\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.26 diff: 0.29\n",
            "i0 497 Increment: 0 >> New Balance: 464\n",
            "i0 499 Increment: 11 >> New Balance: 475\n",
            "i0 502 Increment: 9 >> New Balance: 484\n",
            "i0 505 Increment: 4 >> New Balance: 488\n",
            ">>> Actual: -3 +ive: 0.66 -ive: 0.18 diff: 0.48\n",
            "i0 513 Increment: -3 >> New Balance: 485\n",
            "i0 518 Increment: 6 >> New Balance: 491\n",
            "i0 519 Increment: 3 >> New Balance: 494\n",
            "i0 526 Increment: 6 >> New Balance: 500\n",
            "i0 527 Increment: 5 >> New Balance: 505\n",
            "i0 528 Increment: 1 >> New Balance: 506\n",
            ">>> Actual: -2 +ive: 0.53 -ive: 0.28 diff: 0.25\n",
            "i0 532 Increment: -2 >> New Balance: 504\n",
            ">>> Actual: -5 +ive: 0.6 -ive: 0.25 diff: 0.35\n",
            "i0 533 Increment: -5 >> New Balance: 499\n",
            ">>> Actual: -3 +ive: 0.61 -ive: 0.24 diff: 0.37\n",
            "i0 534 Increment: -3 >> New Balance: 496\n",
            "i0 539 Increment: 1 >> New Balance: 497\n",
            ">>> Actual: -7 +ive: 0.52 -ive: 0.28 diff: 0.24\n",
            "i0 545 Increment: -7 >> New Balance: 490\n",
            ">>> Actual: -4 +ive: 0.54 -ive: 0.27 diff: 0.27\n",
            "i0 548 Increment: -4 >> New Balance: 486\n",
            "i0 550 Increment: 18 >> New Balance: 504\n",
            "i0 552 Increment: 18 >> New Balance: 522\n",
            "i0 558 Increment: 12 >> New Balance: 534\n",
            ">>> Actual: -8 +ive: 0.6 -ive: 0.13 diff: 0.47\n",
            "i0 560 Increment: -8 >> New Balance: 526\n",
            ">>> Actual: -8 +ive: 0.57 -ive: 0.08 diff: 0.49\n",
            "i0 562 Increment: -8 >> New Balance: 518\n",
            ">>> Actual: -8 +ive: 0.52 -ive: 0.28 diff: 0.24\n",
            "i0 564 Increment: -8 >> New Balance: 510\n",
            ">>> Actual: -2 +ive: 0.57 -ive: 0.14 diff: 0.43\n",
            "i0 565 Increment: -2 >> New Balance: 508\n",
            ">>> Actual: -3 +ive: 0.58 -ive: 0.23 diff: 0.35\n",
            "i0 566 Increment: -3 >> New Balance: 505\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.26 diff: 0.25\n",
            "i0 570 Increment: 0 >> New Balance: 505\n",
            ">>> Actual: -1 +ive: 0.51 -ive: 0.25 diff: 0.26\n",
            "i0 571 Increment: -1 >> New Balance: 504\n",
            ">>> Actual: -1 +ive: 0.54 -ive: 0.25 diff: 0.29\n",
            "i0 572 Increment: -1 >> New Balance: 503\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.25 diff: 0.26\n",
            "i0 573 Increment: 0 >> New Balance: 503\n",
            ">>> Actual: 0 +ive: 0.66 -ive: 0.27 diff: 0.39\n",
            "i0 574 Increment: 0 >> New Balance: 503\n",
            ">>> Actual: 0 +ive: 0.63 -ive: 0.15 diff: 0.48\n",
            "i0 575 Increment: 0 >> New Balance: 503\n",
            ">>> Actual: 0 +ive: 0.65 -ive: 0.15 diff: 0.5\n",
            "i0 576 Increment: 0 >> New Balance: 503\n",
            "i0 577 Increment: 1 >> New Balance: 504\n",
            "i0 578 Increment: 1 >> New Balance: 505\n",
            "i0 580 Increment: 3 >> New Balance: 508\n",
            ">>> Actual: 0 +ive: 0.59 -ive: 0.21 diff: 0.38\n",
            "i0 594 Increment: 0 >> New Balance: 508\n",
            "i0 595 Increment: 5 >> New Balance: 513\n",
            "i0 596 Increment: 2 >> New Balance: 515\n",
            "i0 601 Increment: 4 >> New Balance: 519\n",
            "i0 603 Increment: 3 >> New Balance: 522\n",
            "i0 606 Increment: 3 >> New Balance: 525\n",
            "i0 607 Increment: 2 >> New Balance: 527\n",
            ">>> Actual: -1 +ive: 0.69 -ive: 0.27 diff: 0.42\n",
            "i0 611 Increment: -1 >> New Balance: 526\n",
            ">>> Actual: -1 +ive: 0.6 -ive: 0.28 diff: 0.32\n",
            "i0 612 Increment: -1 >> New Balance: 525\n",
            ">>> Actual: 0 +ive: 0.61 -ive: 0.24 diff: 0.37\n",
            "i0 615 Increment: 0 >> New Balance: 525\n",
            ">>> Actual: -3 +ive: 0.56 -ive: 0.27 diff: 0.29\n",
            "i0 616 Increment: -3 >> New Balance: 522\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.29 diff: 0.25\n",
            "i0 622 Increment: 0 >> New Balance: 522\n",
            "i0 623 Increment: 1 >> New Balance: 523\n",
            "i0 637 Increment: 8 >> New Balance: 531\n",
            "i0 638 Increment: 7 >> New Balance: 538\n",
            "i0 643 Increment: 5 >> New Balance: 543\n",
            ">>> Actual: 0 +ive: 0.58 -ive: 0.21 diff: 0.37\n",
            "i0 644 Increment: 0 >> New Balance: 543\n",
            "i0 647 Increment: 3 >> New Balance: 546\n",
            "i0 653 Increment: 10 >> New Balance: 556\n",
            ">>> Actual: 0 +ive: 0.61 -ive: 0.26 diff: 0.35\n",
            "i0 659 Increment: 0 >> New Balance: 556\n",
            ">>> Actual: 0 +ive: 0.58 -ive: 0.23 diff: 0.35\n",
            "i0 661 Increment: 0 >> New Balance: 556\n",
            ">>> Actual: -2 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 663 Increment: -2 >> New Balance: 554\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.24 diff: 0.31\n",
            "i0 664 Increment: 0 >> New Balance: 554\n",
            "i0 665 Increment: 2 >> New Balance: 556\n",
            "i0 666 Increment: 3 >> New Balance: 559\n",
            ">>> Actual: 0 +ive: 0.6 -ive: 0.27 diff: 0.33\n",
            "i0 667 Increment: 0 >> New Balance: 559\n",
            ">>> Actual: -4 +ive: 0.54 -ive: 0.28 diff: 0.26\n",
            "i0 669 Increment: -4 >> New Balance: 555\n",
            "i0 673 Increment: 7 >> New Balance: 562\n",
            "i0 674 Increment: 6 >> New Balance: 568\n",
            "i0 676 Increment: 8 >> New Balance: 576\n",
            "i0 678 Increment: 9 >> New Balance: 585\n",
            "i0 680 Increment: 4 >> New Balance: 589\n",
            "i0 681 Increment: 5 >> New Balance: 594\n",
            "i0 682 Increment: 8 >> New Balance: 602\n",
            "i0 683 Increment: 5 >> New Balance: 607\n",
            "i0 684 Increment: 8 >> New Balance: 615\n",
            "i0 685 Increment: 4 >> New Balance: 619\n",
            "i0 686 Increment: 7 >> New Balance: 626\n",
            ">>> Actual: -3 +ive: 0.59 -ive: 0.24 diff: 0.35\n",
            "i0 691 Increment: -3 >> New Balance: 623\n",
            "i0 695 Increment: 4 >> New Balance: 627\n",
            ">>> Actual: -7 +ive: 0.57 -ive: 0.23 diff: 0.34\n",
            "i0 696 Increment: -7 >> New Balance: 620\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.29 diff: 0.25\n",
            "i0 699 Increment: 0 >> New Balance: 620\n",
            ">>> Actual: -7 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 705 Increment: -7 >> New Balance: 613\n",
            ">>> Actual: -5 +ive: 0.6 -ive: 0.16 diff: 0.44\n",
            "i0 706 Increment: -5 >> New Balance: 608\n",
            "i0 710 Increment: 1 >> New Balance: 609\n",
            "i0 713 Increment: 17 >> New Balance: 626\n",
            "i0 717 Increment: 1 >> New Balance: 627\n",
            ">>> Actual: -4 +ive: 0.77 -ive: 0.22 diff: 0.55\n",
            "i0 723 Increment: -4 >> New Balance: 623\n",
            "i0 724 Increment: 3 >> New Balance: 626\n",
            "i0 725 Increment: 4 >> New Balance: 630\n",
            "i0 726 Increment: 2 >> New Balance: 632\n",
            "i0 728 Increment: 6 >> New Balance: 638\n",
            "i0 731 Increment: 10 >> New Balance: 648\n",
            "i0 733 Increment: 8 >> New Balance: 656\n",
            "i0 737 Increment: 3 >> New Balance: 659\n",
            "i0 738 Increment: 9 >> New Balance: 668\n",
            "i0 740 Increment: 5 >> New Balance: 673\n",
            ">>> Actual: -1 +ive: 0.6 -ive: 0.29 diff: 0.31\n",
            "i0 743 Increment: -1 >> New Balance: 672\n",
            "i0 744 Increment: 2 >> New Balance: 674\n",
            "i0 745 Increment: 6 >> New Balance: 680\n",
            ">>> Actual: 0 +ive: 0.71 -ive: 0.17 diff: 0.54\n",
            "i0 748 Increment: 0 >> New Balance: 680\n",
            "i0 749 Increment: 1 >> New Balance: 681\n",
            "i0 750 Increment: 4 >> New Balance: 685\n",
            "i0 751 Increment: 3 >> New Balance: 688\n",
            "i0 752 Increment: 2 >> New Balance: 690\n",
            "i0 756 Increment: 9 >> New Balance: 699\n",
            "i0 757 Increment: 7 >> New Balance: 706\n",
            "i0 760 Increment: 3 >> New Balance: 709\n",
            ">>> Actual: -10 +ive: 0.58 -ive: 0.23 diff: 0.35\n",
            "i0 764 Increment: -10 >> New Balance: 699\n",
            ">>> Actual: -9 +ive: 0.57 -ive: 0.22 diff: 0.35\n",
            "i0 766 Increment: -9 >> New Balance: 690\n",
            ">>> Actual: -11 +ive: 0.67 -ive: 0.19 diff: 0.48\n",
            "i0 767 Increment: -11 >> New Balance: 679\n",
            ">>> Actual: -13 +ive: 0.57 -ive: 0.27 diff: 0.3\n",
            "i0 768 Increment: -13 >> New Balance: 666\n",
            ">>> Actual: -11 +ive: 0.61 -ive: 0.24 diff: 0.37\n",
            "i0 769 Increment: -11 >> New Balance: 655\n",
            "i0 771 Increment: 2 >> New Balance: 657\n",
            "i0 773 Increment: 1 >> New Balance: 658\n",
            "i0 774 Increment: 3 >> New Balance: 661\n",
            "i0 775 Increment: 2 >> New Balance: 663\n",
            "i0 776 Increment: 8 >> New Balance: 671\n",
            "i0 777 Increment: 5 >> New Balance: 676\n",
            "i0 778 Increment: 3 >> New Balance: 679\n",
            "i0 779 Increment: 6 >> New Balance: 685\n",
            "i0 784 Increment: 5 >> New Balance: 690\n",
            "i0 786 Increment: 8 >> New Balance: 698\n",
            "i0 787 Increment: 8 >> New Balance: 706\n",
            ">>> Actual: 0 +ive: 0.62 -ive: 0.16 diff: 0.46\n",
            "i0 789 Increment: 0 >> New Balance: 706\n",
            ">>> Actual: -1 +ive: 0.51 -ive: 0.27 diff: 0.24\n",
            "i0 790 Increment: -1 >> New Balance: 705\n",
            ">>> Actual: -5 +ive: 0.54 -ive: 0.29 diff: 0.25\n",
            "i0 791 Increment: -5 >> New Balance: 700\n",
            ">>> Actual: -2 +ive: 0.53 -ive: 0.29 diff: 0.24\n",
            "i0 792 Increment: -2 >> New Balance: 698\n",
            ">>> Actual: -4 +ive: 0.55 -ive: 0.19 diff: 0.36\n",
            "i0 793 Increment: -4 >> New Balance: 694\n",
            "i0 794 Increment: 3 >> New Balance: 697\n",
            "i0 795 Increment: 4 >> New Balance: 701\n",
            "i0 799 Increment: 4 >> New Balance: 705\n",
            "i0 800 Increment: 2 >> New Balance: 707\n",
            ">>> Actual: 0 +ive: 0.61 -ive: 0.23 diff: 0.38\n",
            "i0 801 Increment: 0 >> New Balance: 707\n",
            ">>> Actual: -1 +ive: 0.51 -ive: 0.18 diff: 0.33\n",
            "i0 803 Increment: -1 >> New Balance: 706\n",
            ">>> Actual: -10 +ive: 0.57 -ive: 0.23 diff: 0.34\n",
            "i0 805 Increment: -10 >> New Balance: 696\n",
            ">>> Actual: -1 +ive: 0.57 -ive: 0.24 diff: 0.33\n",
            "i0 808 Increment: -1 >> New Balance: 695\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.25 diff: 0.27\n",
            "i0 809 Increment: 0 >> New Balance: 695\n",
            ">>> Actual: -6 +ive: 0.62 -ive: 0.24 diff: 0.38\n",
            "i0 810 Increment: -6 >> New Balance: 689\n",
            ">>> Actual: -12 +ive: 0.56 -ive: 0.28 diff: 0.28\n",
            "i0 812 Increment: -12 >> New Balance: 677\n",
            ">>> Actual: -21 +ive: 0.56 -ive: 0.17 diff: 0.39\n",
            "i0 815 Increment: -21 >> New Balance: 656\n",
            ">>> Actual: -16 +ive: 0.55 -ive: 0.28 diff: 0.27\n",
            "i0 819 Increment: -16 >> New Balance: 640\n",
            ">>> Actual: -6 +ive: 0.61 -ive: 0.22 diff: 0.39\n",
            "i0 820 Increment: -6 >> New Balance: 634\n",
            ">>> Actual: -2 +ive: 0.66 -ive: 0.2 diff: 0.46\n",
            "i0 821 Increment: -2 >> New Balance: 632\n",
            ">>> Actual: -6 +ive: 0.63 -ive: 0.2 diff: 0.43\n",
            "i0 822 Increment: -6 >> New Balance: 626\n",
            ">>> Actual: -6 +ive: 0.62 -ive: 0.18 diff: 0.44\n",
            "i0 823 Increment: -6 >> New Balance: 620\n",
            ">>> Actual: -7 +ive: 0.91 -ive: 0.15 diff: 0.76\n",
            "i0 824 Increment: -7 >> New Balance: 613\n",
            "i0 831 Increment: 2 >> New Balance: 615\n",
            "i0 842 Increment: 3 >> New Balance: 618\n",
            "i0 843 Increment: 2 >> New Balance: 620\n",
            "i0 849 Increment: 6 >> New Balance: 626\n",
            "i0 852 Increment: 11 >> New Balance: 637\n",
            "i0 856 Increment: 11 >> New Balance: 648\n",
            "i0 857 Increment: 12 >> New Balance: 660\n",
            "i0 858 Increment: 9 >> New Balance: 669\n",
            "i0 861 Increment: 11 >> New Balance: 680\n",
            "i0 864 Increment: 5 >> New Balance: 685\n",
            "i0 865 Increment: 9 >> New Balance: 694\n",
            "i0 866 Increment: 6 >> New Balance: 700\n",
            "i0 873 Increment: 6 >> New Balance: 706\n",
            "i0 875 Increment: 14 >> New Balance: 720\n",
            "i0 877 Increment: 14 >> New Balance: 734\n",
            "i0 881 Increment: 3 >> New Balance: 737\n",
            "i0 883 Increment: 7 >> New Balance: 744\n",
            "i0 885 Increment: 6 >> New Balance: 750\n",
            "i0 886 Increment: 4 >> New Balance: 754\n",
            "i0 888 Increment: 7 >> New Balance: 761\n",
            "i0 890 Increment: 4 >> New Balance: 765\n",
            ">>> Actual: 0 +ive: 0.57 -ive: 0.24 diff: 0.33\n",
            "i0 891 Increment: 0 >> New Balance: 765\n",
            "i0 893 Increment: 2 >> New Balance: 767\n",
            "i0 894 Increment: 2 >> New Balance: 769\n",
            "i0 895 Increment: 3 >> New Balance: 772\n",
            ">>> Actual: -5 +ive: 0.54 -ive: 0.28 diff: 0.26\n",
            "i0 896 Increment: -5 >> New Balance: 767\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.26 diff: 0.25\n",
            "i0 898 Increment: 0 >> New Balance: 767\n",
            "i0 903 Increment: 5 >> New Balance: 772\n",
            "i0 908 Increment: 1 >> New Balance: 773\n",
            ">>> Actual: -2 +ive: 0.52 -ive: 0.29 diff: 0.23\n",
            "i0 911 Increment: -2 >> New Balance: 771\n",
            ">>> Actual: -2 +ive: 0.53 -ive: 0.27 diff: 0.26\n",
            "i0 912 Increment: -2 >> New Balance: 769\n",
            ">>> Actual: -6 +ive: 0.54 -ive: 0.29 diff: 0.25\n",
            "i0 913 Increment: -6 >> New Balance: 763\n",
            "i0 918 Increment: 4 >> New Balance: 767\n",
            "i0 919 Increment: 5 >> New Balance: 772\n",
            ">>> Actual: -1 +ive: 0.52 -ive: 0.27 diff: 0.25\n",
            "i0 927 Increment: -1 >> New Balance: 771\n",
            "i0 929 Increment: 5 >> New Balance: 776\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.24 diff: 0.3\n",
            "i0 932 Increment: 0 >> New Balance: 776\n",
            ">>> Actual: -5 +ive: 0.52 -ive: 0.29 diff: 0.23\n",
            "i0 935 Increment: -5 >> New Balance: 771\n",
            ">>> Actual: -5 +ive: 0.53 -ive: 0.28 diff: 0.25\n",
            "i0 943 Increment: -5 >> New Balance: 766\n",
            ">>> Actual: -7 +ive: 0.53 -ive: 0.27 diff: 0.26\n",
            "i0 944 Increment: -7 >> New Balance: 759\n",
            "i0 949 Increment: 2 >> New Balance: 761\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.27 diff: 0.26\n",
            "i0 950 Increment: 0 >> New Balance: 761\n",
            "i0 952 Increment: 11 >> New Balance: 772\n",
            "i0 959 Increment: 1 >> New Balance: 773\n",
            ">>> Actual: -5 +ive: 0.52 -ive: 0.24 diff: 0.28\n",
            "i0 964 Increment: -5 >> New Balance: 768\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.26 diff: 0.25\n",
            "i0 965 Increment: 0 >> New Balance: 768\n",
            ">>> Actual: -8 +ive: 0.58 -ive: 0.29 diff: 0.29\n",
            "i0 966 Increment: -8 >> New Balance: 760\n",
            ">>> Actual: -4 +ive: 0.55 -ive: 0.23 diff: 0.32\n",
            "i0 967 Increment: -4 >> New Balance: 756\n",
            ">>> Actual: -9 +ive: 0.56 -ive: 0.28 diff: 0.28\n",
            "i0 971 Increment: -9 >> New Balance: 747\n",
            ">>> Actual: -7 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 972 Increment: -7 >> New Balance: 740\n",
            ">>> Actual: -10 +ive: 0.6 -ive: 0.22 diff: 0.38\n",
            "i0 975 Increment: -10 >> New Balance: 730\n",
            ">>> Actual: -7 +ive: 0.54 -ive: 0.24 diff: 0.3\n",
            "i0 977 Increment: -7 >> New Balance: 723\n",
            ">>> Actual: -11 +ive: 0.55 -ive: 0.21 diff: 0.34\n",
            "i0 978 Increment: -11 >> New Balance: 712\n",
            ">>> Actual: 0 +ive: 0.64 -ive: 0.29 diff: 0.35\n",
            "i0 979 Increment: 0 >> New Balance: 712\n",
            ">>> Actual: -13 +ive: 0.52 -ive: 0.28 diff: 0.24\n",
            "i0 981 Increment: -13 >> New Balance: 699\n",
            ">>> Actual: 0 +ive: 0.76 -ive: 0.21 diff: 0.55\n",
            "i0 983 Increment: 0 >> New Balance: 699\n",
            ">>> Actual: 0 +ive: 0.83 -ive: 0.14 diff: 0.69\n",
            "i0 985 Increment: 0 >> New Balance: 699\n",
            ">>> Actual: -19 +ive: 0.57 -ive: 0.2 diff: 0.37\n",
            "i0 988 Increment: -19 >> New Balance: 680\n",
            "i0 993 Increment: 4 >> New Balance: 684\n",
            ">>> Actual: -8 +ive: 0.67 -ive: 0.2 diff: 0.47\n",
            "i0 994 Increment: -8 >> New Balance: 676\n",
            ">>> Actual: -10 +ive: 0.55 -ive: 0.26 diff: 0.29\n",
            "i0 995 Increment: -10 >> New Balance: 666\n",
            ">>> Actual: -10 +ive: 0.61 -ive: 0.26 diff: 0.35\n",
            "i0 996 Increment: -10 >> New Balance: 656\n",
            ">>> Actual: 0 +ive: 0.62 -ive: 0.25 diff: 0.37\n",
            "i0 997 Increment: 0 >> New Balance: 656\n",
            "i0 999 Increment: 9 >> New Balance: 665\n",
            "i0 1000 Increment: 22 >> New Balance: 687\n",
            "i0 1001 Increment: 17 >> New Balance: 704\n",
            ">>> Actual: -11 +ive: 0.58 -ive: 0.26 diff: 0.32\n",
            "i0 1003 Increment: -11 >> New Balance: 693\n",
            ">>> Actual: -5 +ive: 0.76 -ive: 0.16 diff: 0.6\n",
            "i0 1005 Increment: -5 >> New Balance: 688\n",
            "i0 1008 Increment: 8 >> New Balance: 696\n",
            "i0 1009 Increment: 5 >> New Balance: 701\n",
            "i0 1010 Increment: 7 >> New Balance: 708\n",
            "i0 1013 Increment: 20 >> New Balance: 728\n",
            ">>> Actual: -9 +ive: 0.67 -ive: 0.17 diff: 0.5\n",
            "i0 1015 Increment: -9 >> New Balance: 719\n",
            ">>> Actual: -13 +ive: 0.56 -ive: 0.21 diff: 0.35\n",
            "i0 1016 Increment: -13 >> New Balance: 706\n",
            ">>> Actual: -16 +ive: 0.76 -ive: 0.22 diff: 0.54\n",
            "i0 1017 Increment: -16 >> New Balance: 690\n",
            ">>> Actual: -9 +ive: 0.64 -ive: 0.29 diff: 0.35\n",
            "i0 1018 Increment: -9 >> New Balance: 681\n",
            "i0 1025 Increment: 3 >> New Balance: 684\n",
            "i0 1028 Increment: 2 >> New Balance: 686\n",
            "i0 1032 Increment: 11 >> New Balance: 697\n",
            "i0 1037 Increment: 6 >> New Balance: 703\n",
            ">>> Actual: -4 +ive: 0.52 -ive: 0.25 diff: 0.27\n",
            "i0 1039 Increment: -4 >> New Balance: 699\n",
            ">>> Actual: -10 +ive: 0.54 -ive: 0.27 diff: 0.27\n",
            "i0 1048 Increment: -10 >> New Balance: 689\n",
            "i0 1049 Increment: 1 >> New Balance: 690\n",
            "i0 1050 Increment: 1 >> New Balance: 691\n",
            "i0 1051 Increment: 3 >> New Balance: 694\n",
            ">>> Actual: 0 +ive: 0.59 -ive: 0.19 diff: 0.4\n",
            "i0 1052 Increment: 0 >> New Balance: 694\n",
            ">>> Actual: -1 +ive: 0.67 -ive: 0.14 diff: 0.53\n",
            "i0 1053 Increment: -1 >> New Balance: 693\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 1055 Increment: 0 >> New Balance: 693\n",
            "i0 1056 Increment: 5 >> New Balance: 698\n",
            ">>> Actual: -2 +ive: 0.55 -ive: 0.23 diff: 0.32\n",
            "i0 1058 Increment: -2 >> New Balance: 696\n",
            ">>> Actual: -11 +ive: 0.74 -ive: 0.15 diff: 0.59\n",
            "i0 1060 Increment: -11 >> New Balance: 685\n",
            ">>> Actual: -5 +ive: 0.56 -ive: 0.26 diff: 0.3\n",
            "i0 1066 Increment: -5 >> New Balance: 680\n",
            "i0 1070 Increment: 15 >> New Balance: 695\n",
            "i0 1071 Increment: 12 >> New Balance: 707\n",
            "i0 1072 Increment: 6 >> New Balance: 713\n",
            "i0 1073 Increment: 5 >> New Balance: 718\n",
            "i0 1075 Increment: 6 >> New Balance: 724\n",
            "i0 1078 Increment: 7 >> New Balance: 731\n",
            ">>> Actual: 0 +ive: 0.59 -ive: 0.21 diff: 0.38\n",
            "i0 1082 Increment: 0 >> New Balance: 731\n",
            ">>> Actual: -11 +ive: 0.68 -ive: 0.16 diff: 0.52\n",
            "i0 1084 Increment: -11 >> New Balance: 720\n",
            ">>> Actual: -5 +ive: 0.51 -ive: 0.18 diff: 0.33\n",
            "i0 1086 Increment: -5 >> New Balance: 715\n",
            ">>> Actual: -8 +ive: 0.58 -ive: 0.29 diff: 0.29\n",
            "i0 1087 Increment: -8 >> New Balance: 707\n",
            ">>> Actual: -10 +ive: 0.58 -ive: 0.25 diff: 0.33\n",
            "i0 1088 Increment: -10 >> New Balance: 697\n",
            ">>> Actual: 0 +ive: 0.64 -ive: 0.22 diff: 0.42\n",
            "i0 1091 Increment: 0 >> New Balance: 697\n",
            ">>> Actual: -4 +ive: 0.64 -ive: 0.12 diff: 0.52\n",
            "i0 1093 Increment: -4 >> New Balance: 693\n",
            "i0 1097 Increment: 7 >> New Balance: 700\n",
            "i0 1102 Increment: 19 >> New Balance: 719\n",
            "i0 1105 Increment: 2 >> New Balance: 721\n",
            "i0 1108 Increment: 15 >> New Balance: 736\n",
            "i0 1112 Increment: 6 >> New Balance: 742\n",
            "i0 1115 Increment: 7 >> New Balance: 749\n",
            "i0 1116 Increment: 5 >> New Balance: 754\n",
            "i0 1119 Increment: 12 >> New Balance: 766\n",
            "i0 1122 Increment: 4 >> New Balance: 770\n",
            "i0 1125 Increment: 1 >> New Balance: 771\n",
            "i0 1126 Increment: 1 >> New Balance: 772\n",
            "i0 1129 Increment: 5 >> New Balance: 777\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 1131 Increment: 0 >> New Balance: 777\n",
            "i0 1133 Increment: 2 >> New Balance: 779\n",
            "i0 1134 Increment: 2 >> New Balance: 781\n",
            "i0 1136 Increment: 7 >> New Balance: 788\n",
            "i0 1137 Increment: 3 >> New Balance: 791\n",
            "i0 1140 Increment: 5 >> New Balance: 796\n",
            ">>> Actual: -9 +ive: 0.78 -ive: 0.12 diff: 0.66\n",
            "i0 1143 Increment: -9 >> New Balance: 787\n",
            ">>> Actual: -6 +ive: 0.7 -ive: 0.18 diff: 0.52\n",
            "i0 1144 Increment: -6 >> New Balance: 781\n",
            "i0 1148 Increment: 1 >> New Balance: 782\n",
            "i0 1149 Increment: 6 >> New Balance: 788\n",
            "i0 1150 Increment: 8 >> New Balance: 796\n",
            "i0 1157 Increment: 6 >> New Balance: 802\n",
            "i0 1160 Increment: 3 >> New Balance: 805\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.19 diff: 0.33\n",
            "i0 1163 Increment: 0 >> New Balance: 805\n",
            ">>> Actual: -4 +ive: 0.61 -ive: 0.22 diff: 0.39\n",
            "i0 1167 Increment: -4 >> New Balance: 801\n",
            ">>> Actual: -2 +ive: 0.55 -ive: 0.29 diff: 0.26\n",
            "i0 1169 Increment: -2 >> New Balance: 799\n",
            "i0 1170 Increment: 3 >> New Balance: 802\n",
            "i0 1171 Increment: 4 >> New Balance: 806\n",
            "i0 1172 Increment: 4 >> New Balance: 810\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.25 diff: 0.26\n",
            "i0 1173 Increment: 0 >> New Balance: 810\n",
            "i0 1174 Increment: 4 >> New Balance: 814\n",
            "i0 1175 Increment: 2 >> New Balance: 816\n",
            "i0 1186 Increment: 11 >> New Balance: 827\n",
            "i0 1188 Increment: 11 >> New Balance: 838\n",
            "i0 1194 Increment: 7 >> New Balance: 845\n",
            "i0 1195 Increment: 8 >> New Balance: 853\n",
            "i0 1196 Increment: 7 >> New Balance: 860\n",
            "i0 1197 Increment: 2 >> New Balance: 862\n",
            "i0 1199 Increment: 1 >> New Balance: 863\n",
            "i0 1200 Increment: 3 >> New Balance: 866\n",
            "i0 1201 Increment: 4 >> New Balance: 870\n",
            "i0 1202 Increment: 3 >> New Balance: 873\n",
            "i0 1204 Increment: 2 >> New Balance: 875\n",
            "i0 1207 Increment: 2 >> New Balance: 877\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.26 diff: 0.28\n",
            "i0 1209 Increment: 0 >> New Balance: 877\n",
            "i0 1210 Increment: 2 >> New Balance: 879\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.22 diff: 0.31\n",
            "i0 1219 Increment: 0 >> New Balance: 879\n",
            "i0 1222 Increment: 3 >> New Balance: 882\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 1223 Increment: 0 >> New Balance: 882\n",
            "i0 1224 Increment: 1 >> New Balance: 883\n",
            "i0 1227 Increment: 6 >> New Balance: 889\n",
            "i0 1231 Increment: 2 >> New Balance: 891\n",
            "i0 1233 Increment: 6 >> New Balance: 897\n",
            "i0 1236 Increment: 1 >> New Balance: 898\n",
            ">>> Actual: -1 +ive: 0.62 -ive: 0.11 diff: 0.51\n",
            "i0 1239 Increment: -1 >> New Balance: 897\n",
            ">>> Actual: 0 +ive: 0.73 -ive: 0.14 diff: 0.59\n",
            "i0 1240 Increment: 0 >> New Balance: 897\n",
            ">>> Actual: -2 +ive: 0.63 -ive: 0.15 diff: 0.48\n",
            "i0 1241 Increment: -2 >> New Balance: 895\n",
            "i0 1242 Increment: 3 >> New Balance: 898\n",
            "i0 1244 Increment: 2 >> New Balance: 900\n",
            "i0 1245 Increment: 2 >> New Balance: 902\n",
            "i0 1246 Increment: 2 >> New Balance: 904\n",
            "i0 1252 Increment: 5 >> New Balance: 909\n",
            "i0 1255 Increment: 7 >> New Balance: 916\n",
            "i0 1258 Increment: 2 >> New Balance: 918\n",
            "i0 1259 Increment: 3 >> New Balance: 921\n",
            ">>> Actual: -3 +ive: 0.64 -ive: 0.21 diff: 0.43\n",
            "i0 1263 Increment: -3 >> New Balance: 918\n",
            ">>> Actual: -5 +ive: 0.72 -ive: 0.18 diff: 0.54\n",
            "i0 1264 Increment: -5 >> New Balance: 913\n",
            ">>> Actual: 0 +ive: 0.59 -ive: 0.19 diff: 0.4\n",
            "i0 1266 Increment: 0 >> New Balance: 913\n",
            ">>> Actual: -2 +ive: 0.54 -ive: 0.28 diff: 0.26\n",
            "i0 1267 Increment: -2 >> New Balance: 911\n",
            "i0 1274 Increment: 1 >> New Balance: 912\n",
            ">>> Actual: 0 +ive: 0.56 -ive: 0.22 diff: 0.34\n",
            "i0 1276 Increment: 0 >> New Balance: 912\n",
            ">>> Actual: -3 +ive: 0.57 -ive: 0.28 diff: 0.29\n",
            "i0 1280 Increment: -3 >> New Balance: 909\n",
            ">>> Actual: 0 +ive: 0.63 -ive: 0.21 diff: 0.42\n",
            "i0 1283 Increment: 0 >> New Balance: 909\n",
            ">>> Actual: 0 +ive: 0.59 -ive: 0.24 diff: 0.35\n",
            "i0 1290 Increment: 0 >> New Balance: 909\n",
            ">>> Actual: -1 +ive: 0.55 -ive: 0.26 diff: 0.29\n",
            "i0 1291 Increment: -1 >> New Balance: 908\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.28 diff: 0.24\n",
            "i0 1292 Increment: 0 >> New Balance: 908\n",
            "i0 1294 Increment: 2 >> New Balance: 910\n",
            "i0 1304 Increment: 6 >> New Balance: 916\n",
            ">>> Actual: 0 +ive: 0.59 -ive: 0.25 diff: 0.34\n",
            "i0 1310 Increment: 0 >> New Balance: 916\n",
            ">>> Actual: 0 +ive: 0.59 -ive: 0.2 diff: 0.39\n",
            "i0 1314 Increment: 0 >> New Balance: 916\n",
            ">>> Actual: -2 +ive: 0.54 -ive: 0.29 diff: 0.25\n",
            "i0 1315 Increment: -2 >> New Balance: 914\n",
            ">>> Actual: -10 +ive: 0.51 -ive: 0.27 diff: 0.24\n",
            "i0 1321 Increment: -10 >> New Balance: 904\n",
            "i0 1329 Increment: 3 >> New Balance: 907\n",
            ">>> Actual: 0 +ive: 0.56 -ive: 0.27 diff: 0.29\n",
            "i0 1330 Increment: 0 >> New Balance: 907\n",
            "i0 1331 Increment: 1 >> New Balance: 908\n",
            "i0 1333 Increment: 3 >> New Balance: 911\n",
            "i0 1338 Increment: 1 >> New Balance: 912\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.27 diff: 0.28\n",
            "i0 1342 Increment: 0 >> New Balance: 912\n",
            "i0 1354 Increment: 3 >> New Balance: 915\n",
            "i0 1355 Increment: 1 >> New Balance: 916\n",
            "i0 1358 Increment: 1 >> New Balance: 917\n",
            "i0 1359 Increment: 3 >> New Balance: 920\n",
            "i0 1360 Increment: 2 >> New Balance: 922\n",
            "i0 1361 Increment: 3 >> New Balance: 925\n",
            "i0 1362 Increment: 5 >> New Balance: 930\n",
            "i0 1364 Increment: 6 >> New Balance: 936\n",
            "i0 1365 Increment: 1 >> New Balance: 937\n",
            "i0 1366 Increment: 2 >> New Balance: 939\n",
            "i0 1368 Increment: 3 >> New Balance: 942\n",
            "i0 1373 Increment: 4 >> New Balance: 946\n",
            "i0 1381 Increment: 8 >> New Balance: 954\n",
            "i0 1382 Increment: 5 >> New Balance: 959\n",
            ">>> Actual: 0 +ive: 0.59 -ive: 0.23 diff: 0.36\n",
            "i0 1385 Increment: 0 >> New Balance: 959\n",
            ">>> Actual: -1 +ive: 0.55 -ive: 0.27 diff: 0.28\n",
            "i0 1386 Increment: -1 >> New Balance: 958\n",
            ">>> Actual: -5 +ive: 0.74 -ive: 0.13 diff: 0.61\n",
            "i0 1387 Increment: -5 >> New Balance: 953\n",
            ">>> Actual: -5 +ive: 0.63 -ive: 0.27 diff: 0.36\n",
            "i0 1388 Increment: -5 >> New Balance: 948\n",
            ">>> Actual: -3 +ive: 0.52 -ive: 0.29 diff: 0.23\n",
            "i0 1391 Increment: -3 >> New Balance: 945\n",
            ">>> Actual: -11 +ive: 0.55 -ive: 0.25 diff: 0.3\n",
            "i0 1393 Increment: -11 >> New Balance: 934\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 1395 Increment: 0 >> New Balance: 934\n",
            "i0 1396 Increment: 4 >> New Balance: 938\n",
            "i0 1397 Increment: 11 >> New Balance: 949\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.26 diff: 0.26\n",
            "i0 1398 Increment: 0 >> New Balance: 949\n",
            "i0 1407 Increment: 8 >> New Balance: 957\n",
            ">>> Actual: -3 +ive: 0.57 -ive: 0.25 diff: 0.32\n",
            "i0 1413 Increment: -3 >> New Balance: 954\n",
            "i0 1424 Increment: 1 >> New Balance: 955\n",
            ">>> Actual: -8 +ive: 0.63 -ive: 0.26 diff: 0.37\n",
            "i0 1429 Increment: -8 >> New Balance: 947\n",
            ">>> Actual: -7 +ive: 0.55 -ive: 0.23 diff: 0.32\n",
            "i0 1430 Increment: -7 >> New Balance: 940\n",
            ">>> Actual: -3 +ive: 0.58 -ive: 0.26 diff: 0.32\n",
            "i0 1431 Increment: -3 >> New Balance: 937\n",
            ">>> Actual: -3 +ive: 0.57 -ive: 0.25 diff: 0.32\n",
            "i0 1432 Increment: -3 >> New Balance: 934\n",
            ">>> Actual: -1 +ive: 0.55 -ive: 0.21 diff: 0.34\n",
            "i0 1433 Increment: -1 >> New Balance: 933\n",
            "i0 1445 Increment: 3 >> New Balance: 936\n",
            "i0 1446 Increment: 5 >> New Balance: 941\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.29 diff: 0.23\n",
            "i0 1451 Increment: 0 >> New Balance: 941\n",
            ">>> Actual: -5 +ive: 0.61 -ive: 0.26 diff: 0.35\n",
            "i0 1458 Increment: -5 >> New Balance: 936\n",
            ">>> Actual: -3 +ive: 0.56 -ive: 0.28 diff: 0.28\n",
            "i0 1459 Increment: -3 >> New Balance: 933\n",
            ">>> Actual: -4 +ive: 0.51 -ive: 0.23 diff: 0.28\n",
            "i0 1460 Increment: -4 >> New Balance: 929\n",
            ">>> Actual: -3 +ive: 0.62 -ive: 0.25 diff: 0.37\n",
            "i0 1462 Increment: -3 >> New Balance: 926\n",
            ">>> Actual: -4 +ive: 0.57 -ive: 0.27 diff: 0.3\n",
            "i0 1468 Increment: -4 >> New Balance: 922\n",
            ">>> Actual: -2 +ive: 0.57 -ive: 0.24 diff: 0.33\n",
            "i0 1469 Increment: -2 >> New Balance: 920\n",
            ">>> Actual: 0 +ive: 0.66 -ive: 0.21 diff: 0.45\n",
            "i0 1470 Increment: 0 >> New Balance: 920\n",
            ">>> Actual: 0 +ive: 0.61 -ive: 0.14 diff: 0.47\n",
            "i0 1472 Increment: 0 >> New Balance: 920\n",
            "i0 1474 Increment: 7 >> New Balance: 927\n",
            "i0 1477 Increment: 9 >> New Balance: 936\n",
            "i0 1481 Increment: 6 >> New Balance: 942\n",
            "i0 1482 Increment: 1 >> New Balance: 943\n",
            "i0 1483 Increment: 7 >> New Balance: 950\n",
            "i0 1485 Increment: 3 >> New Balance: 953\n",
            "i0 1486 Increment: 7 >> New Balance: 960\n",
            "i0 1487 Increment: 6 >> New Balance: 966\n",
            "i0 1490 Increment: 2 >> New Balance: 968\n",
            "i0 1491 Increment: 1 >> New Balance: 969\n",
            ">>> Actual: 0 +ive: 0.57 -ive: 0.25 diff: 0.32\n",
            "i0 1493 Increment: 0 >> New Balance: 969\n",
            "i0 1498 Increment: 1 >> New Balance: 970\n",
            "i0 1499 Increment: 4 >> New Balance: 974\n",
            "i0 1507 Increment: 3 >> New Balance: 977\n",
            "i0 1513 Increment: 1 >> New Balance: 978\n",
            "i0 1515 Increment: 3 >> New Balance: 981\n",
            "i0 1518 Increment: 3 >> New Balance: 984\n",
            "i0 1522 Increment: 1 >> New Balance: 985\n",
            ">>> Actual: -3 +ive: 0.56 -ive: 0.29 diff: 0.27\n",
            "i0 1528 Increment: -3 >> New Balance: 982\n",
            "i0 1531 Increment: 4 >> New Balance: 986\n",
            "i0 1532 Increment: 5 >> New Balance: 991\n",
            "i0 1534 Increment: 2 >> New Balance: 993\n",
            "i0 1545 Increment: 1 >> New Balance: 994\n",
            "i0 1550 Increment: 1 >> New Balance: 995\n",
            "i0 1551 Increment: 1 >> New Balance: 996\n",
            "i0 1552 Increment: 1 >> New Balance: 997\n",
            ">>> Actual: 0 +ive: 0.6 -ive: 0.28 diff: 0.32\n",
            "i0 1553 Increment: 0 >> New Balance: 997\n",
            ">>> Actual: 0 +ive: 0.57 -ive: 0.28 diff: 0.29\n",
            "i0 1554 Increment: 0 >> New Balance: 997\n",
            "i0 1557 Increment: 3 >> New Balance: 1000\n",
            "i0 1562 Increment: 6 >> New Balance: 1006\n",
            ">>> Actual: -4 +ive: 0.56 -ive: 0.29 diff: 0.27\n",
            "i0 1568 Increment: -4 >> New Balance: 1002\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 1580 Increment: 0 >> New Balance: 1002\n",
            "i0 1582 Increment: 4 >> New Balance: 1006\n",
            ">>> Actual: -2 +ive: 0.55 -ive: 0.28 diff: 0.27\n",
            "i0 1591 Increment: -2 >> New Balance: 1004\n",
            "i0 1598 Increment: 2 >> New Balance: 1006\n",
            "i0 1599 Increment: 3 >> New Balance: 1009\n",
            "i0 1600 Increment: 1 >> New Balance: 1010\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.28 diff: 0.24\n",
            "i0 1602 Increment: 0 >> New Balance: 1010\n",
            ">>> Actual: -2 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 1606 Increment: -2 >> New Balance: 1008\n",
            ">>> Actual: -5 +ive: 0.57 -ive: 0.25 diff: 0.32\n",
            "i0 1607 Increment: -5 >> New Balance: 1003\n",
            "i0 1613 Increment: 5 >> New Balance: 1008\n",
            ">>> Actual: -1 +ive: 0.56 -ive: 0.23 diff: 0.33\n",
            "i0 1628 Increment: -1 >> New Balance: 1007\n",
            ">>> Actual: 0 +ive: 0.59 -ive: 0.2 diff: 0.39\n",
            "i0 1629 Increment: 0 >> New Balance: 1007\n",
            "i0 1632 Increment: 6 >> New Balance: 1013\n",
            "i0 1636 Increment: 5 >> New Balance: 1018\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.29 diff: 0.23\n",
            "i0 1642 Increment: 0 >> New Balance: 1018\n",
            ">>> Actual: 0 +ive: 0.58 -ive: 0.29 diff: 0.29\n",
            "i0 1643 Increment: 0 >> New Balance: 1018\n",
            ">>> Actual: 0 +ive: 0.6 -ive: 0.22 diff: 0.38\n",
            "i0 1645 Increment: 0 >> New Balance: 1018\n",
            ">>> Actual: -3 +ive: 0.53 -ive: 0.29 diff: 0.24\n",
            "i0 1646 Increment: -3 >> New Balance: 1015\n",
            ">>> Actual: -4 +ive: 0.55 -ive: 0.27 diff: 0.28\n",
            "i0 1653 Increment: -4 >> New Balance: 1011\n",
            ">>> Actual: -1 +ive: 0.53 -ive: 0.28 diff: 0.25\n",
            "i0 1654 Increment: -1 >> New Balance: 1010\n",
            "i0 1655 Increment: 1 >> New Balance: 1011\n",
            ">>> Actual: 0 +ive: 0.67 -ive: 0.24 diff: 0.43\n",
            "i0 1656 Increment: 0 >> New Balance: 1011\n",
            "i0 1658 Increment: 1 >> New Balance: 1012\n",
            "i0 1660 Increment: 2 >> New Balance: 1014\n",
            ">>> Actual: 0 +ive: 0.6 -ive: 0.23 diff: 0.37\n",
            "i0 1661 Increment: 0 >> New Balance: 1014\n",
            ">>> Actual: -1 +ive: 0.55 -ive: 0.28 diff: 0.27\n",
            "i0 1671 Increment: -1 >> New Balance: 1013\n",
            ">>> Actual: -1 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 1673 Increment: -1 >> New Balance: 1012\n",
            "i0 1678 Increment: 3 >> New Balance: 1015\n",
            "i0 1693 Increment: 9 >> New Balance: 1024\n",
            "i0 1694 Increment: 9 >> New Balance: 1033\n",
            "i0 1695 Increment: 11 >> New Balance: 1044\n",
            "i0 1696 Increment: 9 >> New Balance: 1053\n",
            "i0 1697 Increment: 9 >> New Balance: 1062\n",
            "i0 1699 Increment: 5 >> New Balance: 1067\n",
            "i0 1700 Increment: 4 >> New Balance: 1071\n",
            "i0 1701 Increment: 2 >> New Balance: 1073\n",
            ">>> Actual: -1 +ive: 0.55 -ive: 0.25 diff: 0.3\n",
            "i0 1703 Increment: -1 >> New Balance: 1072\n",
            ">>> Actual: -9 +ive: 0.63 -ive: 0.19 diff: 0.44\n",
            "i0 1707 Increment: -9 >> New Balance: 1063\n",
            ">>> Actual: -3 +ive: 0.55 -ive: 0.28 diff: 0.27\n",
            "i0 1709 Increment: -3 >> New Balance: 1060\n",
            "i0 1713 Increment: 5 >> New Balance: 1065\n",
            "i0 1715 Increment: 2 >> New Balance: 1067\n",
            "i0 1720 Increment: 2 >> New Balance: 1069\n",
            "i0 1721 Increment: 4 >> New Balance: 1073\n",
            "i0 1723 Increment: 6 >> New Balance: 1079\n",
            "i0 1725 Increment: 2 >> New Balance: 1081\n",
            "i0 1735 Increment: 7 >> New Balance: 1088\n",
            "i0 1737 Increment: 5 >> New Balance: 1093\n",
            "i0 1739 Increment: 3 >> New Balance: 1096\n",
            ">>> Actual: -9 +ive: 0.59 -ive: 0.27 diff: 0.32\n",
            "i0 1744 Increment: -9 >> New Balance: 1087\n",
            ">>> Actual: -6 +ive: 0.58 -ive: 0.26 diff: 0.32\n",
            "i0 1748 Increment: -6 >> New Balance: 1081\n",
            ">>> Actual: -4 +ive: 0.53 -ive: 0.28 diff: 0.25\n",
            "i0 1749 Increment: -4 >> New Balance: 1077\n",
            "i0 1755 Increment: 3 >> New Balance: 1080\n",
            "i0 1758 Increment: 4 >> New Balance: 1084\n",
            "i0 1760 Increment: 2 >> New Balance: 1086\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.28 diff: 0.25\n",
            "i0 1765 Increment: 0 >> New Balance: 1086\n",
            ">>> Actual: 0 +ive: 0.56 -ive: 0.26 diff: 0.3\n",
            "i0 1769 Increment: 0 >> New Balance: 1086\n",
            ">>> Actual: 0 +ive: 0.81 -ive: 0.21 diff: 0.6\n",
            "i0 1787 Increment: 0 >> New Balance: 1086\n",
            "i0 1788 Increment: 1 >> New Balance: 1087\n",
            "i0 1789 Increment: 10 >> New Balance: 1097\n",
            "i0 1801 Increment: 2 >> New Balance: 1099\n",
            "i0 1803 Increment: 8 >> New Balance: 1107\n",
            "i0 1807 Increment: 15 >> New Balance: 1122\n",
            "i0 1808 Increment: 32 >> New Balance: 1154\n",
            "i0 1810 Increment: 29 >> New Balance: 1183\n",
            "i0 1812 Increment: 1 >> New Balance: 1184\n",
            "i0 1813 Increment: 7 >> New Balance: 1191\n",
            "i0 1814 Increment: 5 >> New Balance: 1196\n",
            ">>> Actual: 0 +ive: 0.66 -ive: 0.14 diff: 0.52\n",
            "i0 1815 Increment: 0 >> New Balance: 1196\n",
            ">>> Actual: -11 +ive: 0.72 -ive: 0.26 diff: 0.46\n",
            "i0 1816 Increment: -11 >> New Balance: 1185\n",
            "i0 1821 Increment: 1 >> New Balance: 1186\n",
            ">>> Actual: 0 +ive: 0.64 -ive: 0.17 diff: 0.47\n",
            "i0 1822 Increment: 0 >> New Balance: 1186\n",
            "i0 1823 Increment: 9 >> New Balance: 1195\n",
            "i0 1824 Increment: 2 >> New Balance: 1197\n",
            ">>> Actual: -7 +ive: 0.6 -ive: 0.2 diff: 0.4\n",
            "i0 1826 Increment: -7 >> New Balance: 1190\n",
            ">>> Actual: -6 +ive: 0.52 -ive: 0.29 diff: 0.23\n",
            "i0 1827 Increment: -6 >> New Balance: 1184\n",
            "i0 1828 Increment: 4 >> New Balance: 1188\n",
            "i0 1829 Increment: 4 >> New Balance: 1192\n",
            "i0 1832 Increment: 3 >> New Balance: 1195\n",
            "i0 1834 Increment: 2 >> New Balance: 1197\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.16 diff: 0.39\n",
            "i0 1835 Increment: 0 >> New Balance: 1197\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.28 diff: 0.27\n",
            "i0 1837 Increment: 0 >> New Balance: 1197\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.23 diff: 0.28\n",
            "i0 1840 Increment: 0 >> New Balance: 1197\n",
            "i0 1843 Increment: 9 >> New Balance: 1206\n",
            ">>> Actual: 0 +ive: 0.58 -ive: 0.28 diff: 0.3\n",
            "i0 1856 Increment: 0 >> New Balance: 1206\n",
            "i0 1857 Increment: 1 >> New Balance: 1207\n",
            ">>> Actual: -4 +ive: 0.56 -ive: 0.23 diff: 0.33\n",
            "i0 1858 Increment: -4 >> New Balance: 1203\n",
            ">>> Actual: 0 +ive: 0.58 -ive: 0.23 diff: 0.35\n",
            "i0 1861 Increment: 0 >> New Balance: 1203\n",
            "i0 1862 Increment: 1 >> New Balance: 1204\n",
            ">>> Actual: -3 +ive: 0.56 -ive: 0.26 diff: 0.3\n",
            "i0 1867 Increment: -3 >> New Balance: 1201\n",
            ">>> Actual: -3 +ive: 0.6 -ive: 0.19 diff: 0.41\n",
            "i0 1868 Increment: -3 >> New Balance: 1198\n",
            ">>> Actual: -5 +ive: 0.57 -ive: 0.25 diff: 0.32\n",
            "i0 1869 Increment: -5 >> New Balance: 1193\n",
            "i0 1875 Increment: 6 >> New Balance: 1199\n",
            ">>> Actual: -2 +ive: 0.52 -ive: 0.27 diff: 0.25\n",
            "i0 1880 Increment: -2 >> New Balance: 1197\n",
            ">>> Actual: -8 +ive: 0.78 -ive: 0.15 diff: 0.63\n",
            "i0 1883 Increment: -8 >> New Balance: 1189\n",
            ">>> Actual: -3 +ive: 0.53 -ive: 0.26 diff: 0.27\n",
            "i0 1889 Increment: -3 >> New Balance: 1186\n",
            ">>> Actual: -2 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 1895 Increment: -2 >> New Balance: 1184\n",
            "i0 1907 Increment: 1 >> New Balance: 1185\n",
            "i0 1908 Increment: 2 >> New Balance: 1187\n",
            "i0 1909 Increment: 1 >> New Balance: 1188\n",
            "i0 1912 Increment: 2 >> New Balance: 1190\n",
            "i0 1922 Increment: 3 >> New Balance: 1193\n",
            "i0 1931 Increment: 3 >> New Balance: 1196\n",
            "i0 1934 Increment: 10 >> New Balance: 1206\n",
            "i0 1935 Increment: 11 >> New Balance: 1217\n",
            "i0 1936 Increment: 5 >> New Balance: 1222\n",
            "i0 1937 Increment: 2 >> New Balance: 1224\n",
            "i0 1939 Increment: 1 >> New Balance: 1225\n",
            "i0 1940 Increment: 3 >> New Balance: 1228\n",
            "i0 1941 Increment: 3 >> New Balance: 1231\n",
            "i0 1942 Increment: 2 >> New Balance: 1233\n",
            "i0 1943 Increment: 2 >> New Balance: 1235\n",
            "i0 1945 Increment: 2 >> New Balance: 1237\n",
            "i0 1946 Increment: 5 >> New Balance: 1242\n",
            "i0 1951 Increment: 4 >> New Balance: 1246\n",
            "i0 1952 Increment: 4 >> New Balance: 1250\n",
            "i0 1957 Increment: 8 >> New Balance: 1258\n",
            "i0 1958 Increment: 14 >> New Balance: 1272\n",
            "i0 1959 Increment: 7 >> New Balance: 1279\n",
            "i0 1960 Increment: 11 >> New Balance: 1290\n",
            "i0 1962 Increment: 5 >> New Balance: 1295\n",
            ">>> Actual: 0 +ive: 0.67 -ive: 0.16 diff: 0.51\n",
            "i0 1968 Increment: 0 >> New Balance: 1295\n",
            "i0 1971 Increment: 2 >> New Balance: 1297\n",
            "i0 1972 Increment: 3 >> New Balance: 1300\n",
            "i0 1977 Increment: 4 >> New Balance: 1304\n",
            ">>> Actual: -2 +ive: 0.58 -ive: 0.26 diff: 0.32\n",
            "i0 1981 Increment: -2 >> New Balance: 1302\n",
            "i0 1985 Increment: 1 >> New Balance: 1303\n",
            "i0 1986 Increment: 1 >> New Balance: 1304\n",
            "i0 1990 Increment: 5 >> New Balance: 1309\n",
            ">>> Actual: -5 +ive: 0.61 -ive: 0.25 diff: 0.36\n",
            "i0 1998 Increment: -5 >> New Balance: 1304\n",
            ">>> Actual: -2 +ive: 0.59 -ive: 0.29 diff: 0.3\n",
            "i0 1999 Increment: -2 >> New Balance: 1302\n",
            "i0 2015 Increment: 1 >> New Balance: 1303\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.25 diff: 0.26\n",
            "i0 2017 Increment: 0 >> New Balance: 1303\n",
            "i0 2020 Increment: 3 >> New Balance: 1306\n",
            "i0 2031 Increment: 1 >> New Balance: 1307\n",
            "i0 2032 Increment: 1 >> New Balance: 1308\n",
            ">>> Actual: -1 +ive: 0.53 -ive: 0.21 diff: 0.32\n",
            "i0 2043 Increment: -1 >> New Balance: 1307\n",
            "i0 2044 Increment: 1 >> New Balance: 1308\n",
            ">>> Actual: -1 +ive: 0.53 -ive: 0.24 diff: 0.29\n",
            "i0 2045 Increment: -1 >> New Balance: 1307\n",
            ">>> Actual: -1 +ive: 0.52 -ive: 0.29 diff: 0.23\n",
            "i0 2051 Increment: -1 >> New Balance: 1306\n",
            ">>> Actual: -4 +ive: 0.57 -ive: 0.25 diff: 0.32\n",
            "i0 2052 Increment: -4 >> New Balance: 1302\n",
            ">>> Actual: -5 +ive: 0.55 -ive: 0.28 diff: 0.27\n",
            "i0 2053 Increment: -5 >> New Balance: 1297\n",
            ">>> Actual: -2 +ive: 0.59 -ive: 0.23 diff: 0.36\n",
            "i0 2054 Increment: -2 >> New Balance: 1295\n",
            "i0 2063 Increment: 3 >> New Balance: 1298\n",
            "i0 2064 Increment: 10 >> New Balance: 1308\n",
            "i0 2066 Increment: 9 >> New Balance: 1317\n",
            "i0 2069 Increment: 6 >> New Balance: 1323\n",
            "i0 2081 Increment: 7 >> New Balance: 1330\n",
            "i0 2082 Increment: 2 >> New Balance: 1332\n",
            "i0 2085 Increment: 1 >> New Balance: 1333\n",
            ">>> Actual: -5 +ive: 0.58 -ive: 0.27 diff: 0.31\n",
            "i0 2087 Increment: -5 >> New Balance: 1328\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.27 diff: 0.26\n",
            "i0 2089 Increment: 0 >> New Balance: 1328\n",
            "i0 2090 Increment: 1 >> New Balance: 1329\n",
            "i0 2096 Increment: 2 >> New Balance: 1331\n",
            "i0 2098 Increment: 4 >> New Balance: 1335\n",
            "i0 2099 Increment: 2 >> New Balance: 1337\n",
            "i0 2100 Increment: 1 >> New Balance: 1338\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 2103 Increment: 0 >> New Balance: 1338\n",
            "i0 2109 Increment: 5 >> New Balance: 1343\n",
            "i0 2115 Increment: 1 >> New Balance: 1344\n",
            "i0 2124 Increment: 8 >> New Balance: 1352\n",
            ">>> Actual: -2 +ive: 0.54 -ive: 0.23 diff: 0.31\n",
            "i0 2133 Increment: -2 >> New Balance: 1350\n",
            ">>> Actual: -10 +ive: 0.84 -ive: 0.26 diff: 0.58\n",
            "i0 2134 Increment: -10 >> New Balance: 1340\n",
            "i0 2138 Increment: 2 >> New Balance: 1342\n",
            "i0 2139 Increment: 1 >> New Balance: 1343\n",
            "i0 2140 Increment: 5 >> New Balance: 1348\n",
            "i0 2143 Increment: 2 >> New Balance: 1350\n",
            ">>> Actual: -1 +ive: 0.83 -ive: 0.2 diff: 0.63\n",
            "i0 2144 Increment: -1 >> New Balance: 1349\n",
            ">>> Actual: 0 +ive: 0.83 -ive: 0.15 diff: 0.68\n",
            "i0 2145 Increment: 0 >> New Balance: 1349\n",
            ">>> Actual: -3 +ive: 0.7 -ive: 0.29 diff: 0.41\n",
            "i0 2148 Increment: -3 >> New Balance: 1346\n",
            ">>> Actual: -2 +ive: 0.52 -ive: 0.29 diff: 0.23\n",
            "i0 2150 Increment: -2 >> New Balance: 1344\n",
            ">>> Actual: 0 +ive: 0.6 -ive: 0.29 diff: 0.31\n",
            "i0 2157 Increment: 0 >> New Balance: 1344\n",
            "i0 2163 Increment: 7 >> New Balance: 1351\n",
            "i0 2164 Increment: 11 >> New Balance: 1362\n",
            "i0 2165 Increment: 10 >> New Balance: 1372\n",
            "i0 2166 Increment: 14 >> New Balance: 1386\n",
            "i0 2167 Increment: 18 >> New Balance: 1404\n",
            "i0 2168 Increment: 12 >> New Balance: 1416\n",
            "i0 2169 Increment: 5 >> New Balance: 1421\n",
            "i0 2170 Increment: 7 >> New Balance: 1428\n",
            "i0 2173 Increment: 6 >> New Balance: 1434\n",
            "i0 2174 Increment: 4 >> New Balance: 1438\n",
            "i0 2176 Increment: 1 >> New Balance: 1439\n",
            ">>> Actual: 0 +ive: 0.75 -ive: 0.19 diff: 0.56\n",
            "i0 2179 Increment: 0 >> New Balance: 1439\n",
            "i0 2180 Increment: 4 >> New Balance: 1443\n",
            "i0 2181 Increment: 7 >> New Balance: 1450\n",
            "i0 2182 Increment: 8 >> New Balance: 1458\n",
            "i0 2184 Increment: 3 >> New Balance: 1461\n",
            "i0 2185 Increment: 3 >> New Balance: 1464\n",
            ">>> Actual: -4 +ive: 0.61 -ive: 0.27 diff: 0.34\n",
            "i0 2186 Increment: -4 >> New Balance: 1460\n",
            ">>> Actual: -9 +ive: 0.56 -ive: 0.24 diff: 0.32\n",
            "i0 2187 Increment: -9 >> New Balance: 1451\n",
            ">>> Actual: -10 +ive: 0.82 -ive: 0.27 diff: 0.55\n",
            "i0 2188 Increment: -10 >> New Balance: 1441\n",
            ">>> Actual: -6 +ive: 0.56 -ive: 0.28 diff: 0.28\n",
            "i0 2190 Increment: -6 >> New Balance: 1435\n",
            ">>> Actual: -6 +ive: 0.61 -ive: 0.22 diff: 0.39\n",
            "i0 2191 Increment: -6 >> New Balance: 1429\n",
            ">>> Actual: -3 +ive: 0.55 -ive: 0.27 diff: 0.28\n",
            "i0 2192 Increment: -3 >> New Balance: 1426\n",
            ">>> Actual: -8 +ive: 0.57 -ive: 0.25 diff: 0.32\n",
            "i0 2200 Increment: -8 >> New Balance: 1418\n",
            "i0 2202 Increment: 1 >> New Balance: 1419\n",
            ">>> Actual: -1 +ive: 0.64 -ive: 0.18 diff: 0.46\n",
            "i0 2203 Increment: -1 >> New Balance: 1418\n",
            "i0 2204 Increment: 1 >> New Balance: 1419\n",
            "i0 2205 Increment: 1 >> New Balance: 1420\n",
            "i0 2206 Increment: 3 >> New Balance: 1423\n",
            ">>> Actual: 0 +ive: 0.57 -ive: 0.29 diff: 0.28\n",
            "i0 2209 Increment: 0 >> New Balance: 1423\n",
            ">>> Actual: -1 +ive: 0.56 -ive: 0.25 diff: 0.31\n",
            "i0 2210 Increment: -1 >> New Balance: 1422\n",
            ">>> Actual: 0 +ive: 0.69 -ive: 0.25 diff: 0.44\n",
            "i0 2240 Increment: 0 >> New Balance: 1422\n",
            ">>> Actual: -2 +ive: 0.59 -ive: 0.28 diff: 0.31\n",
            "i0 2241 Increment: -2 >> New Balance: 1420\n",
            ">>> Actual: -1 +ive: 0.54 -ive: 0.22 diff: 0.32\n",
            "i0 2254 Increment: -1 >> New Balance: 1419\n",
            ">>> Actual: -2 +ive: 0.55 -ive: 0.26 diff: 0.29\n",
            "i0 2255 Increment: -2 >> New Balance: 1417\n",
            ">>> Actual: -3 +ive: 0.58 -ive: 0.26 diff: 0.32\n",
            "i0 2256 Increment: -3 >> New Balance: 1414\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.27 diff: 0.26\n",
            "i0 2257 Increment: 0 >> New Balance: 1414\n",
            "i0 2264 Increment: 1 >> New Balance: 1415\n",
            "i0 2275 Increment: 1 >> New Balance: 1416\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.29 diff: 0.25\n",
            "i0 2277 Increment: 0 >> New Balance: 1416\n",
            "i0 2278 Increment: 2 >> New Balance: 1418\n",
            "i0 2279 Increment: 7 >> New Balance: 1425\n",
            ">>> Actual: -2 +ive: 0.75 -ive: 0.19 diff: 0.56\n",
            "i0 2290 Increment: -2 >> New Balance: 1423\n",
            "i0 2295 Increment: 1 >> New Balance: 1424\n",
            "i0 2296 Increment: 4 >> New Balance: 1428\n",
            "i0 2302 Increment: 1 >> New Balance: 1429\n",
            "i0 2303 Increment: 2 >> New Balance: 1431\n",
            ">>> Actual: 0 +ive: 0.59 -ive: 0.24 diff: 0.35\n",
            "i0 2307 Increment: 0 >> New Balance: 1431\n",
            "i0 2311 Increment: 12 >> New Balance: 1443\n",
            "i0 2312 Increment: 16 >> New Balance: 1459\n",
            "i0 2313 Increment: 11 >> New Balance: 1470\n",
            "i0 2314 Increment: 2 >> New Balance: 1472\n",
            ">>> Actual: 0 +ive: 0.65 -ive: 0.17 diff: 0.48\n",
            "i0 2315 Increment: 0 >> New Balance: 1472\n",
            "i0 2326 Increment: 5 >> New Balance: 1477\n",
            "i0 2327 Increment: 4 >> New Balance: 1481\n",
            "i0 2328 Increment: 7 >> New Balance: 1488\n",
            "i0 2329 Increment: 6 >> New Balance: 1494\n",
            "i0 2330 Increment: 5 >> New Balance: 1499\n",
            ">>> Actual: -1 +ive: 0.56 -ive: 0.26 diff: 0.3\n",
            "i0 2334 Increment: -1 >> New Balance: 1498\n",
            ">>> Actual: -3 +ive: 0.54 -ive: 0.29 diff: 0.25\n",
            "i0 2338 Increment: -3 >> New Balance: 1495\n",
            ">>> Actual: 0 +ive: 0.6 -ive: 0.24 diff: 0.36\n",
            "i0 2339 Increment: 0 >> New Balance: 1495\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.24 diff: 0.28\n",
            "i0 2341 Increment: 0 >> New Balance: 1495\n",
            ">>> Actual: 0 +ive: 0.59 -ive: 0.17 diff: 0.42\n",
            "i0 2342 Increment: 0 >> New Balance: 1495\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.28 diff: 0.25\n",
            "i0 2343 Increment: 0 >> New Balance: 1495\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.17 diff: 0.38\n",
            "i0 2344 Increment: 0 >> New Balance: 1495\n",
            ">>> Actual: -1 +ive: 0.55 -ive: 0.26 diff: 0.29\n",
            "i0 2345 Increment: -1 >> New Balance: 1494\n",
            ">>> Actual: -1 +ive: 0.55 -ive: 0.26 diff: 0.29\n",
            "i0 2346 Increment: -1 >> New Balance: 1493\n",
            "i0 2356 Increment: 4 >> New Balance: 1497\n",
            "i0 2359 Increment: 6 >> New Balance: 1503\n",
            "i0 2360 Increment: 4 >> New Balance: 1507\n",
            "i0 2361 Increment: 8 >> New Balance: 1515\n",
            "i0 2362 Increment: 9 >> New Balance: 1524\n",
            "i0 2364 Increment: 3 >> New Balance: 1527\n",
            "i0 2365 Increment: 2 >> New Balance: 1529\n",
            ">>> Actual: -2 +ive: 0.58 -ive: 0.28 diff: 0.3\n",
            "i0 2368 Increment: -2 >> New Balance: 1527\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.29 diff: 0.23\n",
            "i0 2373 Increment: 0 >> New Balance: 1527\n",
            "i0 2376 Increment: 4 >> New Balance: 1531\n",
            ">>> Actual: -6 +ive: 0.51 -ive: 0.27 diff: 0.24\n",
            "i0 2381 Increment: -6 >> New Balance: 1525\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.24 diff: 0.31\n",
            "i0 2400 Increment: 0 >> New Balance: 1525\n",
            ">>> Actual: 0 +ive: 0.58 -ive: 0.25 diff: 0.33\n",
            "i0 2401 Increment: 0 >> New Balance: 1525\n",
            "i0 2411 Increment: 3 >> New Balance: 1528\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.24 diff: 0.3\n",
            "i0 2417 Increment: 0 >> New Balance: 1528\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.27 diff: 0.25\n",
            "i0 2418 Increment: 0 >> New Balance: 1528\n",
            "i0 2420 Increment: 1 >> New Balance: 1529\n",
            "i0 2421 Increment: 2 >> New Balance: 1531\n",
            "i0 2422 Increment: 2 >> New Balance: 1533\n",
            "i0 2423 Increment: 2 >> New Balance: 1535\n",
            "i0 2424 Increment: 1 >> New Balance: 1536\n",
            ">>> Actual: 0 +ive: 0.56 -ive: 0.27 diff: 0.29\n",
            "i0 2426 Increment: 0 >> New Balance: 1536\n",
            "i0 2428 Increment: 2 >> New Balance: 1538\n",
            "i0 2429 Increment: 1 >> New Balance: 1539\n",
            "i0 2430 Increment: 1 >> New Balance: 1540\n",
            "i0 2431 Increment: 3 >> New Balance: 1543\n",
            "i0 2433 Increment: 1 >> New Balance: 1544\n",
            "i0 2434 Increment: 1 >> New Balance: 1545\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.28 diff: 0.27\n",
            "i0 2435 Increment: 0 >> New Balance: 1545\n",
            ">>> Actual: 0 +ive: 0.63 -ive: 0.21 diff: 0.42\n",
            "i0 2436 Increment: 0 >> New Balance: 1545\n",
            ">>> Actual: -2 +ive: 0.53 -ive: 0.28 diff: 0.25\n",
            "i0 2437 Increment: -2 >> New Balance: 1543\n",
            ">>> Actual: -1 +ive: 0.59 -ive: 0.29 diff: 0.3\n",
            "i0 2439 Increment: -1 >> New Balance: 1542\n",
            ">>> Actual: -2 +ive: 0.59 -ive: 0.26 diff: 0.33\n",
            "i0 2442 Increment: -2 >> New Balance: 1540\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.29 diff: 0.26\n",
            "i0 2444 Increment: 0 >> New Balance: 1540\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.25 diff: 0.26\n",
            "i0 2448 Increment: 0 >> New Balance: 1540\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.25 diff: 0.26\n",
            "i0 2449 Increment: 0 >> New Balance: 1540\n",
            "i0 2463 Increment: 5 >> New Balance: 1545\n",
            "i0 2466 Increment: 2 >> New Balance: 1547\n",
            "i0 2467 Increment: 1 >> New Balance: 1548\n",
            ">>> Actual: 0 +ive: 0.56 -ive: 0.26 diff: 0.3\n",
            "i0 2472 Increment: 0 >> New Balance: 1548\n",
            "i0 2474 Increment: 4 >> New Balance: 1552\n",
            "i0 2478 Increment: 2 >> New Balance: 1554\n",
            "i0 2479 Increment: 4 >> New Balance: 1558\n",
            "i0 2480 Increment: 3 >> New Balance: 1561\n",
            "i0 2481 Increment: 3 >> New Balance: 1564\n",
            "i0 2488 Increment: 2 >> New Balance: 1566\n",
            ">>> Actual: -6 +ive: 0.55 -ive: 0.28 diff: 0.27\n",
            "i0 2493 Increment: -6 >> New Balance: 1560\n",
            ">>> Actual: -5 +ive: 0.55 -ive: 0.27 diff: 0.28\n",
            "i0 2496 Increment: -5 >> New Balance: 1555\n",
            "i0 2504 Increment: 1 >> New Balance: 1556\n",
            "i0 2507 Increment: 1 >> New Balance: 1557\n",
            ">>> Actual: 0 +ive: 0.6 -ive: 0.2 diff: 0.4\n",
            "i0 2508 Increment: 0 >> New Balance: 1557\n",
            ">>> Actual: 0 +ive: 0.65 -ive: 0.17 diff: 0.48\n",
            "i0 2509 Increment: 0 >> New Balance: 1557\n",
            ">>> Actual: -3 +ive: 0.54 -ive: 0.29 diff: 0.25\n",
            "i0 2511 Increment: -3 >> New Balance: 1554\n",
            "i0 2519 Increment: 3 >> New Balance: 1557\n",
            "i0 2521 Increment: 3 >> New Balance: 1560\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.27 diff: 0.25\n",
            "i0 2531 Increment: 0 >> New Balance: 1560\n",
            ">>> Actual: 0 +ive: 0.56 -ive: 0.28 diff: 0.28\n",
            "i0 2532 Increment: 0 >> New Balance: 1560\n",
            "i0 2534 Increment: 5 >> New Balance: 1565\n",
            "i0 2535 Increment: 2 >> New Balance: 1567\n",
            "i0 2538 Increment: 4 >> New Balance: 1571\n",
            "i0 2540 Increment: 6 >> New Balance: 1577\n",
            "i0 2541 Increment: 6 >> New Balance: 1583\n",
            "i0 2544 Increment: 1 >> New Balance: 1584\n",
            "i0 2550 Increment: 6 >> New Balance: 1590\n",
            "i0 2551 Increment: 9 >> New Balance: 1599\n",
            "i0 2552 Increment: 6 >> New Balance: 1605\n",
            "i0 2553 Increment: 6 >> New Balance: 1611\n",
            "i0 2554 Increment: 5 >> New Balance: 1616\n",
            "i0 2555 Increment: 3 >> New Balance: 1619\n",
            "i0 2556 Increment: 2 >> New Balance: 1621\n",
            "i0 2557 Increment: 2 >> New Balance: 1623\n",
            "i0 2558 Increment: 1 >> New Balance: 1624\n",
            "i0 2561 Increment: 5 >> New Balance: 1629\n",
            "i0 2562 Increment: 9 >> New Balance: 1638\n",
            "i0 2565 Increment: 8 >> New Balance: 1646\n",
            "i0 2568 Increment: 8 >> New Balance: 1654\n",
            "i0 2569 Increment: 4 >> New Balance: 1658\n",
            "i0 2570 Increment: 2 >> New Balance: 1660\n",
            ">>> Actual: -9 +ive: 0.58 -ive: 0.28 diff: 0.3\n",
            "i0 2571 Increment: -9 >> New Balance: 1651\n",
            ">>> Actual: -10 +ive: 0.56 -ive: 0.29 diff: 0.27\n",
            "i0 2576 Increment: -10 >> New Balance: 1641\n",
            ">>> Actual: -12 +ive: 0.67 -ive: 0.16 diff: 0.51\n",
            "i0 2577 Increment: -12 >> New Balance: 1629\n",
            "i0 2580 Increment: 5 >> New Balance: 1634\n",
            "i0 2582 Increment: 5 >> New Balance: 1639\n",
            "i0 2585 Increment: 5 >> New Balance: 1644\n",
            "i0 2586 Increment: 5 >> New Balance: 1649\n",
            "i0 2589 Increment: 7 >> New Balance: 1656\n",
            ">>> Actual: -2 +ive: 0.57 -ive: 0.25 diff: 0.32\n",
            "i0 2595 Increment: -2 >> New Balance: 1654\n",
            ">>> Actual: -2 +ive: 0.61 -ive: 0.24 diff: 0.37\n",
            "i0 2602 Increment: -2 >> New Balance: 1652\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.25 diff: 0.29\n",
            "i0 2603 Increment: 0 >> New Balance: 1652\n",
            "i0 2605 Increment: 5 >> New Balance: 1657\n",
            "i0 2606 Increment: 3 >> New Balance: 1660\n",
            ">>> Actual: -10 +ive: 0.52 -ive: 0.28 diff: 0.24\n",
            "i0 2612 Increment: -10 >> New Balance: 1650\n",
            "i0 2618 Increment: 1 >> New Balance: 1651\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.27 diff: 0.25\n",
            "i0 2621 Increment: 0 >> New Balance: 1651\n",
            ">>> Actual: -5 +ive: 0.52 -ive: 0.27 diff: 0.25\n",
            "i0 2623 Increment: -5 >> New Balance: 1646\n",
            ">>> Actual: -10 +ive: 0.69 -ive: 0.15 diff: 0.54\n",
            "i0 2624 Increment: -10 >> New Balance: 1636\n",
            ">>> Actual: -1 +ive: 0.64 -ive: 0.18 diff: 0.46\n",
            "i0 2627 Increment: -1 >> New Balance: 1635\n",
            ">>> Actual: -9 +ive: 0.55 -ive: 0.27 diff: 0.28\n",
            "i0 2628 Increment: -9 >> New Balance: 1626\n",
            ">>> Actual: -8 +ive: 0.51 -ive: 0.17 diff: 0.34\n",
            "i0 2632 Increment: -8 >> New Balance: 1618\n",
            ">>> Actual: -5 +ive: 0.65 -ive: 0.14 diff: 0.51\n",
            "i0 2633 Increment: -5 >> New Balance: 1613\n",
            ">>> Actual: -5 +ive: 0.52 -ive: 0.19 diff: 0.33\n",
            "i0 2634 Increment: -5 >> New Balance: 1608\n",
            "i0 2636 Increment: 1 >> New Balance: 1609\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.09 diff: 0.44\n",
            "i0 2639 Increment: 0 >> New Balance: 1609\n",
            ">>> Actual: -12 +ive: 0.54 -ive: 0.29 diff: 0.25\n",
            "i0 2646 Increment: -12 >> New Balance: 1597\n",
            ">>> Actual: -11 +ive: 0.59 -ive: 0.22 diff: 0.37\n",
            "i0 2649 Increment: -11 >> New Balance: 1586\n",
            ">>> Actual: -3 +ive: 0.94 -ive: 0.18 diff: 0.76\n",
            "i0 2651 Increment: -3 >> New Balance: 1583\n",
            ">>> Actual: -2 +ive: 0.53 -ive: 0.17 diff: 0.36\n",
            "i0 2656 Increment: -2 >> New Balance: 1581\n",
            "i0 2660 Increment: 11 >> New Balance: 1592\n",
            "i0 2662 Increment: 2 >> New Balance: 1594\n",
            ">>> Actual: 0 +ive: 0.59 -ive: 0.2 diff: 0.39\n",
            "i0 2664 Increment: 0 >> New Balance: 1594\n",
            "i0 2665 Increment: 10 >> New Balance: 1604\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.27 diff: 0.24\n",
            "i0 2676 Increment: 0 >> New Balance: 1604\n",
            ">>> Actual: 0 +ive: 0.58 -ive: 0.26 diff: 0.32\n",
            "i0 2678 Increment: 0 >> New Balance: 1604\n",
            ">>> Actual: -5 +ive: 0.54 -ive: 0.23 diff: 0.31\n",
            "i0 2679 Increment: -5 >> New Balance: 1599\n",
            ">>> Actual: 0 +ive: 0.57 -ive: 0.23 diff: 0.34\n",
            "i0 2688 Increment: 0 >> New Balance: 1599\n",
            "i0 2689 Increment: 3 >> New Balance: 1602\n",
            "i0 2691 Increment: 6 >> New Balance: 1608\n",
            "i0 2692 Increment: 6 >> New Balance: 1614\n",
            "i0 2693 Increment: 6 >> New Balance: 1620\n",
            "i0 2694 Increment: 5 >> New Balance: 1625\n",
            "i0 2695 Increment: 4 >> New Balance: 1629\n",
            ">>> Actual: -1 +ive: 0.55 -ive: 0.24 diff: 0.31\n",
            "i0 2700 Increment: -1 >> New Balance: 1628\n",
            ">>> Actual: -6 +ive: 0.54 -ive: 0.29 diff: 0.25\n",
            "i0 2704 Increment: -6 >> New Balance: 1622\n",
            ">>> Actual: -6 +ive: 0.65 -ive: 0.26 diff: 0.39\n",
            "i0 2705 Increment: -6 >> New Balance: 1616\n",
            "i0 2711 Increment: 6 >> New Balance: 1622\n",
            "i0 2712 Increment: 3 >> New Balance: 1625\n",
            "i0 2713 Increment: 2 >> New Balance: 1627\n",
            "i0 2714 Increment: 1 >> New Balance: 1628\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.28 diff: 0.26\n",
            "i0 2734 Increment: 0 >> New Balance: 1628\n",
            "i0 2738 Increment: 5 >> New Balance: 1633\n",
            "i0 2752 Increment: 1 >> New Balance: 1634\n",
            ">>> Actual: -1 +ive: 0.55 -ive: 0.2 diff: 0.35\n",
            "i0 2754 Increment: -1 >> New Balance: 1633\n",
            "i0 2755 Increment: 1 >> New Balance: 1634\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.15 diff: 0.36\n",
            "i0 2757 Increment: 0 >> New Balance: 1634\n",
            "i0 2759 Increment: 4 >> New Balance: 1638\n",
            "i0 2760 Increment: 5 >> New Balance: 1643\n",
            "i0 2761 Increment: 9 >> New Balance: 1652\n",
            "i0 2762 Increment: 10 >> New Balance: 1662\n",
            "i0 2763 Increment: 6 >> New Balance: 1668\n",
            ">>> Actual: -4 +ive: 0.67 -ive: 0.23 diff: 0.44\n",
            "i0 2771 Increment: -4 >> New Balance: 1664\n",
            ">>> Actual: -3 +ive: 0.51 -ive: 0.24 diff: 0.27\n",
            "i0 2773 Increment: -3 >> New Balance: 1661\n",
            ">>> Actual: -8 +ive: 0.56 -ive: 0.28 diff: 0.28\n",
            "i0 2776 Increment: -8 >> New Balance: 1653\n",
            ">>> Actual: -5 +ive: 0.52 -ive: 0.18 diff: 0.34\n",
            "i0 2785 Increment: -5 >> New Balance: 1648\n",
            "i0 2786 Increment: 4 >> New Balance: 1652\n",
            "i0 2787 Increment: 4 >> New Balance: 1656\n",
            "i0 2788 Increment: 6 >> New Balance: 1662\n",
            ">>> Actual: -4 +ive: 0.6 -ive: 0.27 diff: 0.33\n",
            "i0 2791 Increment: -4 >> New Balance: 1658\n",
            ">>> Actual: -2 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 2795 Increment: -2 >> New Balance: 1656\n",
            ">>> Actual: -9 +ive: 0.51 -ive: 0.24 diff: 0.27\n",
            "i0 2796 Increment: -9 >> New Balance: 1647\n",
            ">>> Actual: -4 +ive: 0.51 -ive: 0.27 diff: 0.24\n",
            "i0 2797 Increment: -4 >> New Balance: 1643\n",
            ">>> Actual: -11 +ive: 0.57 -ive: 0.23 diff: 0.34\n",
            "i0 2801 Increment: -11 >> New Balance: 1632\n",
            ">>> Actual: -17 +ive: 0.57 -ive: 0.21 diff: 0.36\n",
            "i0 2803 Increment: -17 >> New Balance: 1615\n",
            ">>> Actual: -14 +ive: 0.7 -ive: 0.27 diff: 0.43\n",
            "i0 2805 Increment: -14 >> New Balance: 1601\n",
            "i0 2807 Increment: 2 >> New Balance: 1603\n",
            "i0 2808 Increment: 5 >> New Balance: 1608\n",
            "i0 2809 Increment: 10 >> New Balance: 1618\n",
            "i0 2812 Increment: 2 >> New Balance: 1620\n",
            ">>> Actual: -2 +ive: 0.64 -ive: 0.17 diff: 0.47\n",
            "i0 2813 Increment: -2 >> New Balance: 1618\n",
            ">>> Actual: -3 +ive: 0.52 -ive: 0.28 diff: 0.24\n",
            "i0 2818 Increment: -3 >> New Balance: 1615\n",
            ">>> Actual: -2 +ive: 0.56 -ive: 0.21 diff: 0.35\n",
            "i0 2820 Increment: -2 >> New Balance: 1613\n",
            "i0 2821 Increment: 9 >> New Balance: 1622\n",
            ">>> Actual: -6 +ive: 0.66 -ive: 0.24 diff: 0.42\n",
            "i0 2822 Increment: -6 >> New Balance: 1616\n",
            "i0 2823 Increment: 2 >> New Balance: 1618\n",
            ">>> Actual: -8 +ive: 0.52 -ive: 0.27 diff: 0.25\n",
            "i0 2828 Increment: -8 >> New Balance: 1610\n",
            ">>> Actual: -8 +ive: 0.77 -ive: 0.19 diff: 0.58\n",
            "i0 2838 Increment: -8 >> New Balance: 1602\n",
            "i0 2840 Increment: 4 >> New Balance: 1606\n",
            "i0 2841 Increment: 18 >> New Balance: 1624\n",
            "i0 2842 Increment: 9 >> New Balance: 1633\n",
            "i0 2845 Increment: 5 >> New Balance: 1638\n",
            "i0 2847 Increment: 12 >> New Balance: 1650\n",
            "i0 2850 Increment: 4 >> New Balance: 1654\n",
            ">>> Actual: -8 +ive: 0.74 -ive: 0.2 diff: 0.54\n",
            "i0 2856 Increment: -8 >> New Balance: 1646\n",
            ">>> Actual: -2 +ive: 0.54 -ive: 0.22 diff: 0.32\n",
            "i0 2859 Increment: -2 >> New Balance: 1644\n",
            "i0 2860 Increment: 10 >> New Balance: 1654\n",
            "i0 2861 Increment: 12 >> New Balance: 1666\n",
            "i0 2863 Increment: 9 >> New Balance: 1675\n",
            "i0 2864 Increment: 5 >> New Balance: 1680\n",
            ">>> Actual: -8 +ive: 0.81 -ive: 0.23 diff: 0.58\n",
            "i0 2868 Increment: -8 >> New Balance: 1672\n",
            ">>> Actual: -10 +ive: 0.7 -ive: 0.12 diff: 0.58\n",
            "i0 2869 Increment: -10 >> New Balance: 1662\n",
            ">>> Actual: -5 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 2872 Increment: -5 >> New Balance: 1657\n",
            ">>> Actual: -4 +ive: 0.58 -ive: 0.26 diff: 0.32\n",
            "i0 2873 Increment: -4 >> New Balance: 1653\n",
            "i0 2874 Increment: 3 >> New Balance: 1656\n",
            "i0 2876 Increment: 13 >> New Balance: 1669\n",
            "i0 2877 Increment: 8 >> New Balance: 1677\n",
            "i0 2878 Increment: 21 >> New Balance: 1698\n",
            "i0 2879 Increment: 7 >> New Balance: 1705\n",
            "i0 2880 Increment: 11 >> New Balance: 1716\n",
            "i0 2881 Increment: 5 >> New Balance: 1721\n",
            "i0 2882 Increment: 4 >> New Balance: 1725\n",
            "i0 2883 Increment: 6 >> New Balance: 1731\n",
            "i0 2889 Increment: 10 >> New Balance: 1741\n",
            "i0 2890 Increment: 2 >> New Balance: 1743\n",
            ">>> Actual: -4 +ive: 0.86 -ive: 0.08 diff: 0.78\n",
            "i0 2892 Increment: -4 >> New Balance: 1739\n",
            ">>> Actual: -1 +ive: 0.51 -ive: 0.24 diff: 0.27\n",
            "i0 2893 Increment: -1 >> New Balance: 1738\n",
            ">>> Actual: -5 +ive: 0.64 -ive: 0.28 diff: 0.36\n",
            "i0 2895 Increment: -5 >> New Balance: 1733\n",
            ">>> Actual: -3 +ive: 0.56 -ive: 0.26 diff: 0.3\n",
            "i0 2896 Increment: -3 >> New Balance: 1730\n",
            ">>> Actual: -10 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 2902 Increment: -10 >> New Balance: 1720\n",
            ">>> Actual: -5 +ive: 0.51 -ive: 0.26 diff: 0.25\n",
            "i0 2905 Increment: -5 >> New Balance: 1715\n",
            ">>> Actual: -1 +ive: 0.53 -ive: 0.25 diff: 0.28\n",
            "i0 2907 Increment: -1 >> New Balance: 1714\n",
            "i0 2910 Increment: 6 >> New Balance: 1720\n",
            "i0 2912 Increment: 13 >> New Balance: 1733\n",
            "i0 2916 Increment: 9 >> New Balance: 1742\n",
            "i0 2919 Increment: 4 >> New Balance: 1746\n",
            "i0 2922 Increment: 6 >> New Balance: 1752\n",
            "i0 2924 Increment: 4 >> New Balance: 1756\n",
            "i0 2925 Increment: 1 >> New Balance: 1757\n",
            "i0 2928 Increment: 5 >> New Balance: 1762\n",
            "i0 2929 Increment: 4 >> New Balance: 1766\n",
            "i0 2930 Increment: 2 >> New Balance: 1768\n",
            "i0 2931 Increment: 6 >> New Balance: 1774\n",
            "i0 2934 Increment: 4 >> New Balance: 1778\n",
            "i0 2941 Increment: 2 >> New Balance: 1780\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.23 diff: 0.3\n",
            "i0 2942 Increment: 0 >> New Balance: 1780\n",
            "i0 2943 Increment: 2 >> New Balance: 1782\n",
            "i0 2945 Increment: 4 >> New Balance: 1786\n",
            "i0 2947 Increment: 1 >> New Balance: 1787\n",
            "i0 2959 Increment: 5 >> New Balance: 1792\n",
            "i0 2961 Increment: 4 >> New Balance: 1796\n",
            "i0 2962 Increment: 10 >> New Balance: 1806\n",
            "i0 2963 Increment: 8 >> New Balance: 1814\n",
            "i0 2965 Increment: 8 >> New Balance: 1822\n",
            "i0 2966 Increment: 9 >> New Balance: 1831\n",
            ">>> Actual: -4 +ive: 0.52 -ive: 0.25 diff: 0.27\n",
            "i0 2975 Increment: -4 >> New Balance: 1827\n",
            ">>> Actual: -3 +ive: 0.65 -ive: 0.21 diff: 0.44\n",
            "i0 2976 Increment: -3 >> New Balance: 1824\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 2984 Increment: 0 >> New Balance: 1824\n",
            "i0 2995 Increment: 2 >> New Balance: 1826\n",
            "i0 2998 Increment: 1 >> New Balance: 1827\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.28 diff: 0.25\n",
            "i0 2999 Increment: 0 >> New Balance: 1827\n",
            "i0 3003 Increment: 3 >> New Balance: 1830\n",
            "i0 3004 Increment: 4 >> New Balance: 1834\n",
            "i0 3005 Increment: 4 >> New Balance: 1838\n",
            "i0 3012 Increment: 3 >> New Balance: 1841\n",
            "i0 3015 Increment: 2 >> New Balance: 1843\n",
            "i0 3016 Increment: 2 >> New Balance: 1845\n",
            "i0 3019 Increment: 2 >> New Balance: 1847\n",
            "i0 3024 Increment: 5 >> New Balance: 1852\n",
            "i0 3025 Increment: 3 >> New Balance: 1855\n",
            "i0 3033 Increment: 2 >> New Balance: 1857\n",
            "i0 3034 Increment: 3 >> New Balance: 1860\n",
            "i0 3036 Increment: 6 >> New Balance: 1866\n",
            "i0 3037 Increment: 6 >> New Balance: 1872\n",
            "i0 3038 Increment: 7 >> New Balance: 1879\n",
            "i0 3040 Increment: 5 >> New Balance: 1884\n",
            "i0 3041 Increment: 5 >> New Balance: 1889\n",
            "i0 3043 Increment: 4 >> New Balance: 1893\n",
            "i0 3045 Increment: 1 >> New Balance: 1894\n",
            "i0 3051 Increment: 5 >> New Balance: 1899\n",
            "i0 3056 Increment: 13 >> New Balance: 1912\n",
            "i0 3057 Increment: 8 >> New Balance: 1920\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.29 diff: 0.24\n",
            "i0 3059 Increment: 0 >> New Balance: 1920\n",
            "i0 3060 Increment: 1 >> New Balance: 1921\n",
            "i0 3061 Increment: 3 >> New Balance: 1924\n",
            "i0 3063 Increment: 5 >> New Balance: 1929\n",
            "i0 3064 Increment: 2 >> New Balance: 1931\n",
            "i0 3065 Increment: 3 >> New Balance: 1934\n",
            ">>> Actual: -3 +ive: 0.64 -ive: 0.21 diff: 0.43\n",
            "i0 3068 Increment: -3 >> New Balance: 1931\n",
            ">>> Actual: -1 +ive: 0.56 -ive: 0.23 diff: 0.33\n",
            "i0 3069 Increment: -1 >> New Balance: 1930\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 3070 Increment: 0 >> New Balance: 1930\n",
            ">>> Actual: -2 +ive: 0.64 -ive: 0.28 diff: 0.36\n",
            "i0 3071 Increment: -2 >> New Balance: 1928\n",
            ">>> Actual: -1 +ive: 0.64 -ive: 0.28 diff: 0.36\n",
            "i0 3072 Increment: -1 >> New Balance: 1927\n",
            "i0 3073 Increment: 2 >> New Balance: 1929\n",
            "i0 3075 Increment: 2 >> New Balance: 1931\n",
            "i0 3077 Increment: 5 >> New Balance: 1936\n",
            "i0 3079 Increment: 6 >> New Balance: 1942\n",
            "i0 3082 Increment: 2 >> New Balance: 1944\n",
            "i0 3083 Increment: 1 >> New Balance: 1945\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.23 diff: 0.28\n",
            "i0 3085 Increment: 0 >> New Balance: 1945\n",
            "i0 3091 Increment: 3 >> New Balance: 1948\n",
            "i0 3096 Increment: 1 >> New Balance: 1949\n",
            "i0 3099 Increment: 1 >> New Balance: 1950\n",
            ">>> Actual: 0 +ive: 0.57 -ive: 0.24 diff: 0.33\n",
            "i0 3100 Increment: 0 >> New Balance: 1950\n",
            "i0 3101 Increment: 1 >> New Balance: 1951\n",
            "i0 3102 Increment: 1 >> New Balance: 1952\n",
            ">>> Actual: 0 +ive: 0.58 -ive: 0.27 diff: 0.31\n",
            "i0 3103 Increment: 0 >> New Balance: 1952\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 3104 Increment: 0 >> New Balance: 1952\n",
            "i0 3105 Increment: 1 >> New Balance: 1953\n",
            "i0 3109 Increment: 4 >> New Balance: 1957\n",
            ">>> Actual: -2 +ive: 0.53 -ive: 0.29 diff: 0.24\n",
            "i0 3113 Increment: -2 >> New Balance: 1955\n",
            ">>> Actual: -5 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 3120 Increment: -5 >> New Balance: 1950\n",
            ">>> Actual: -2 +ive: 0.55 -ive: 0.27 diff: 0.28\n",
            "i0 3121 Increment: -2 >> New Balance: 1948\n",
            ">>> Actual: -1 +ive: 0.57 -ive: 0.28 diff: 0.29\n",
            "i0 3122 Increment: -1 >> New Balance: 1947\n",
            ">>> Actual: -2 +ive: 0.62 -ive: 0.21 diff: 0.41\n",
            "i0 3124 Increment: -2 >> New Balance: 1945\n",
            ">>> Actual: -9 +ive: 0.51 -ive: 0.27 diff: 0.24\n",
            "i0 3129 Increment: -9 >> New Balance: 1936\n",
            ">>> Actual: -1 +ive: 0.54 -ive: 0.19 diff: 0.35\n",
            "i0 3132 Increment: -1 >> New Balance: 1935\n",
            ">>> Actual: 0 +ive: 0.56 -ive: 0.24 diff: 0.32\n",
            "i0 3138 Increment: 0 >> New Balance: 1935\n",
            ">>> Actual: 0 +ive: 0.89 -ive: 0.18 diff: 0.71\n",
            "i0 3139 Increment: 0 >> New Balance: 1935\n",
            ">>> Actual: 0 +ive: 0.6 -ive: 0.28 diff: 0.32\n",
            "i0 3140 Increment: 0 >> New Balance: 1935\n",
            "i0 3141 Increment: 3 >> New Balance: 1938\n",
            "i0 3143 Increment: 1 >> New Balance: 1939\n",
            "i0 3144 Increment: 1 >> New Balance: 1940\n",
            ">>> Actual: 0 +ive: 0.65 -ive: 0.21 diff: 0.44\n",
            "i0 3145 Increment: 0 >> New Balance: 1940\n",
            ">>> Actual: 0 +ive: 0.56 -ive: 0.28 diff: 0.28\n",
            "i0 3146 Increment: 0 >> New Balance: 1940\n",
            "i0 3147 Increment: 1 >> New Balance: 1941\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.25 diff: 0.29\n",
            "i0 3151 Increment: 0 >> New Balance: 1941\n",
            "i0 3156 Increment: 9 >> New Balance: 1950\n",
            "i0 3159 Increment: 3 >> New Balance: 1953\n",
            "i0 3160 Increment: 4 >> New Balance: 1957\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.27 diff: 0.25\n",
            "i0 3172 Increment: 0 >> New Balance: 1957\n",
            "i0 3177 Increment: 1 >> New Balance: 1958\n",
            "i0 3178 Increment: 1 >> New Balance: 1959\n",
            "i0 3179 Increment: 3 >> New Balance: 1962\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.27 diff: 0.24\n",
            "i0 3181 Increment: 0 >> New Balance: 1962\n",
            ">>> Actual: -3 +ive: 0.55 -ive: 0.29 diff: 0.26\n",
            "i0 3186 Increment: -3 >> New Balance: 1959\n",
            ">>> Actual: -3 +ive: 0.53 -ive: 0.29 diff: 0.24\n",
            "i0 3190 Increment: -3 >> New Balance: 1956\n",
            ">>> Actual: -3 +ive: 0.55 -ive: 0.26 diff: 0.29\n",
            "i0 3191 Increment: -3 >> New Balance: 1953\n",
            ">>> Actual: -4 +ive: 0.61 -ive: 0.18 diff: 0.43\n",
            "i0 3204 Increment: -4 >> New Balance: 1949\n",
            "i0 3205 Increment: 2 >> New Balance: 1951\n",
            ">>> Actual: -6 +ive: 0.59 -ive: 0.27 diff: 0.32\n",
            "i0 3208 Increment: -6 >> New Balance: 1945\n",
            ">>> Actual: -2 +ive: 0.55 -ive: 0.2 diff: 0.35\n",
            "i0 3213 Increment: -2 >> New Balance: 1943\n",
            "i0 3214 Increment: 2 >> New Balance: 1945\n",
            "i0 3217 Increment: 3 >> New Balance: 1948\n",
            "i0 3218 Increment: 2 >> New Balance: 1950\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.24 diff: 0.27\n",
            "i0 3221 Increment: 0 >> New Balance: 1950\n",
            ">>> Actual: -1 +ive: 0.53 -ive: 0.28 diff: 0.25\n",
            "i0 3229 Increment: -1 >> New Balance: 1949\n",
            ">>> Actual: -7 +ive: 0.53 -ive: 0.29 diff: 0.24\n",
            "i0 3237 Increment: -7 >> New Balance: 1942\n",
            ">>> Actual: -3 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 3241 Increment: -3 >> New Balance: 1939\n",
            "i0 3242 Increment: 11 >> New Balance: 1950\n",
            "i0 3243 Increment: 6 >> New Balance: 1956\n",
            "i0 3244 Increment: 4 >> New Balance: 1960\n",
            "i0 3245 Increment: 12 >> New Balance: 1972\n",
            "i0 3248 Increment: 5 >> New Balance: 1977\n",
            "i0 3256 Increment: 2 >> New Balance: 1979\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.25 diff: 0.27\n",
            "i0 3257 Increment: 0 >> New Balance: 1979\n",
            "i0 3258 Increment: 3 >> New Balance: 1982\n",
            "i0 3259 Increment: 3 >> New Balance: 1985\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 3260 Increment: 0 >> New Balance: 1985\n",
            "i0 3261 Increment: 4 >> New Balance: 1989\n",
            "i0 3262 Increment: 4 >> New Balance: 1993\n",
            ">>> Actual: -4 +ive: 0.58 -ive: 0.25 diff: 0.33\n",
            "i0 3274 Increment: -4 >> New Balance: 1989\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.24 diff: 0.31\n",
            "i0 3282 Increment: 0 >> New Balance: 1989\n",
            "i0 3285 Increment: 4 >> New Balance: 1993\n",
            "i0 3294 Increment: 9 >> New Balance: 2002\n",
            "i0 3297 Increment: 7 >> New Balance: 2009\n",
            "i0 3298 Increment: 3 >> New Balance: 2012\n",
            "i0 3300 Increment: 2 >> New Balance: 2014\n",
            "i0 3301 Increment: 4 >> New Balance: 2018\n",
            "i0 3302 Increment: 1 >> New Balance: 2019\n",
            "i0 3306 Increment: 1 >> New Balance: 2020\n",
            ">>> Actual: 0 +ive: 0.57 -ive: 0.26 diff: 0.31\n",
            "i0 3307 Increment: 0 >> New Balance: 2020\n",
            "i0 3308 Increment: 3 >> New Balance: 2023\n",
            "i0 3309 Increment: 11 >> New Balance: 2034\n",
            "i0 3310 Increment: 15 >> New Balance: 2049\n",
            "i0 3311 Increment: 13 >> New Balance: 2062\n",
            "i0 3316 Increment: 14 >> New Balance: 2076\n",
            "i0 3317 Increment: 1 >> New Balance: 2077\n",
            "i0 3319 Increment: 1 >> New Balance: 2078\n",
            "i0 3325 Increment: 1 >> New Balance: 2079\n",
            "i0 3327 Increment: 1 >> New Balance: 2080\n",
            ">>> Actual: -5 +ive: 0.71 -ive: 0.28 diff: 0.43\n",
            "i0 3335 Increment: -5 >> New Balance: 2075\n",
            ">>> Actual: -5 +ive: 0.56 -ive: 0.29 diff: 0.27\n",
            "i0 3336 Increment: -5 >> New Balance: 2070\n",
            ">>> Actual: -2 +ive: 0.59 -ive: 0.22 diff: 0.37\n",
            "i0 3340 Increment: -2 >> New Balance: 2068\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.25 diff: 0.27\n",
            "i0 3344 Increment: 0 >> New Balance: 2068\n",
            ">>> Actual: 0 +ive: 0.63 -ive: 0.19 diff: 0.44\n",
            "i0 3346 Increment: 0 >> New Balance: 2068\n",
            "i0 3348 Increment: 6 >> New Balance: 2074\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.29 diff: 0.24\n",
            "i0 3357 Increment: 0 >> New Balance: 2074\n",
            "i0 3358 Increment: 1 >> New Balance: 2075\n",
            "i0 3360 Increment: 1 >> New Balance: 2076\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.27 diff: 0.26\n",
            "i0 3362 Increment: 0 >> New Balance: 2076\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.23 diff: 0.28\n",
            "i0 3363 Increment: 0 >> New Balance: 2076\n",
            "i0 3364 Increment: 1 >> New Balance: 2077\n",
            "i0 3367 Increment: 2 >> New Balance: 2079\n",
            "i0 3369 Increment: 2 >> New Balance: 2081\n",
            "i0 3370 Increment: 3 >> New Balance: 2084\n",
            "i0 3372 Increment: 3 >> New Balance: 2087\n",
            "i0 3373 Increment: 1 >> New Balance: 2088\n",
            ">>> Actual: 0 +ive: 0.57 -ive: 0.27 diff: 0.3\n",
            "i0 3379 Increment: 0 >> New Balance: 2088\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.21 diff: 0.32\n",
            "i0 3386 Increment: 0 >> New Balance: 2088\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.25 diff: 0.29\n",
            "i0 3387 Increment: 0 >> New Balance: 2088\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.26 diff: 0.29\n",
            "i0 3388 Increment: 0 >> New Balance: 2088\n",
            "i0 3394 Increment: 2 >> New Balance: 2090\n",
            ">>> Actual: -3 +ive: 0.56 -ive: 0.29 diff: 0.27\n",
            "i0 3406 Increment: -3 >> New Balance: 2087\n",
            ">>> Actual: -5 +ive: 0.54 -ive: 0.24 diff: 0.3\n",
            "i0 3408 Increment: -5 >> New Balance: 2082\n",
            ">>> Actual: -7 +ive: 0.52 -ive: 0.27 diff: 0.25\n",
            "i0 3409 Increment: -7 >> New Balance: 2075\n",
            ">>> Actual: -2 +ive: 0.56 -ive: 0.29 diff: 0.27\n",
            "i0 3415 Increment: -2 >> New Balance: 2073\n",
            ">>> Actual: -5 +ive: 0.6 -ive: 0.26 diff: 0.34\n",
            "i0 3416 Increment: -5 >> New Balance: 2068\n",
            ">>> Actual: -3 +ive: 0.59 -ive: 0.21 diff: 0.38\n",
            "i0 3417 Increment: -3 >> New Balance: 2065\n",
            "i0 3418 Increment: 1 >> New Balance: 2066\n",
            "i0 3419 Increment: 1 >> New Balance: 2067\n",
            "i0 3420 Increment: 3 >> New Balance: 2070\n",
            ">>> Actual: 0 +ive: 0.63 -ive: 0.21 diff: 0.42\n",
            "i0 3421 Increment: 0 >> New Balance: 2070\n",
            "i0 3422 Increment: 2 >> New Balance: 2072\n",
            "i0 3423 Increment: 3 >> New Balance: 2075\n",
            "i0 3425 Increment: 2 >> New Balance: 2077\n",
            ">>> Actual: -9 +ive: 0.6 -ive: 0.26 diff: 0.34\n",
            "i0 3438 Increment: -9 >> New Balance: 2068\n",
            ">>> Actual: -9 +ive: 0.57 -ive: 0.28 diff: 0.29\n",
            "i0 3439 Increment: -9 >> New Balance: 2059\n",
            ">>> Actual: -1 +ive: 0.63 -ive: 0.24 diff: 0.39\n",
            "i0 3443 Increment: -1 >> New Balance: 2058\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.17 diff: 0.35\n",
            "i0 3444 Increment: 0 >> New Balance: 2058\n",
            "i0 3446 Increment: 1 >> New Balance: 2059\n",
            "i0 3447 Increment: 2 >> New Balance: 2061\n",
            "i0 3448 Increment: 2 >> New Balance: 2063\n",
            ">>> Actual: 0 +ive: 0.57 -ive: 0.28 diff: 0.29\n",
            "i0 3450 Increment: 0 >> New Balance: 2063\n",
            ">>> Actual: -2 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 3461 Increment: -2 >> New Balance: 2061\n",
            ">>> Actual: -2 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 3462 Increment: -2 >> New Balance: 2059\n",
            ">>> Actual: -1 +ive: 0.52 -ive: 0.29 diff: 0.23\n",
            "i0 3464 Increment: -1 >> New Balance: 2058\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.28 diff: 0.25\n",
            "i0 3465 Increment: 0 >> New Balance: 2058\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.27 diff: 0.27\n",
            "i0 3467 Increment: 0 >> New Balance: 2058\n",
            ">>> Actual: -3 +ive: 0.53 -ive: 0.28 diff: 0.25\n",
            "i0 3475 Increment: -3 >> New Balance: 2055\n",
            ">>> Actual: -2 +ive: 0.53 -ive: 0.23 diff: 0.3\n",
            "i0 3483 Increment: -2 >> New Balance: 2053\n",
            ">>> Actual: -1 +ive: 0.53 -ive: 0.28 diff: 0.25\n",
            "i0 3485 Increment: -1 >> New Balance: 2052\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.29 diff: 0.24\n",
            "i0 3486 Increment: 0 >> New Balance: 2052\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.27 diff: 0.28\n",
            "i0 3487 Increment: 0 >> New Balance: 2052\n",
            "i0 3492 Increment: 10 >> New Balance: 2062\n",
            "i0 3493 Increment: 6 >> New Balance: 2068\n",
            "i0 3497 Increment: 11 >> New Balance: 2079\n",
            "i0 3503 Increment: 12 >> New Balance: 2091\n",
            "i0 3505 Increment: 3 >> New Balance: 2094\n",
            "i0 3507 Increment: 3 >> New Balance: 2097\n",
            ">>> Actual: -3 +ive: 0.56 -ive: 0.24 diff: 0.32\n",
            "i0 3514 Increment: -3 >> New Balance: 2094\n",
            ">>> Actual: -4 +ive: 0.59 -ive: 0.17 diff: 0.42\n",
            "i0 3516 Increment: -4 >> New Balance: 2090\n",
            ">>> Actual: -7 +ive: 0.59 -ive: 0.29 diff: 0.3\n",
            "i0 3518 Increment: -7 >> New Balance: 2083\n",
            ">>> Actual: -12 +ive: 0.61 -ive: 0.24 diff: 0.37\n",
            "i0 3519 Increment: -12 >> New Balance: 2071\n",
            "i0 3521 Increment: 3 >> New Balance: 2074\n",
            ">>> Actual: -13 +ive: 0.51 -ive: 0.27 diff: 0.24\n",
            "i0 3522 Increment: -13 >> New Balance: 2061\n",
            "i0 3523 Increment: 1 >> New Balance: 2062\n",
            ">>> Actual: -10 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 3526 Increment: -10 >> New Balance: 2052\n",
            ">>> Actual: -2 +ive: 0.6 -ive: 0.08 diff: 0.52\n",
            "i0 3527 Increment: -2 >> New Balance: 2050\n",
            "i0 3530 Increment: 6 >> New Balance: 2056\n",
            "i0 3541 Increment: 1 >> New Balance: 2057\n",
            "i0 3542 Increment: 2 >> New Balance: 2059\n",
            "i0 3543 Increment: 2 >> New Balance: 2061\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.25 diff: 0.29\n",
            "i0 3546 Increment: 0 >> New Balance: 2061\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.25 diff: 0.3\n",
            "i0 3547 Increment: 0 >> New Balance: 2061\n",
            ">>> Actual: -1 +ive: 0.61 -ive: 0.25 diff: 0.36\n",
            "i0 3548 Increment: -1 >> New Balance: 2060\n",
            ">>> Actual: -3 +ive: 0.54 -ive: 0.29 diff: 0.25\n",
            "i0 3549 Increment: -3 >> New Balance: 2057\n",
            ">>> Actual: -1 +ive: 0.52 -ive: 0.28 diff: 0.24\n",
            "i0 3550 Increment: -1 >> New Balance: 2056\n",
            ">>> Actual: -3 +ive: 0.52 -ive: 0.21 diff: 0.31\n",
            "i0 3551 Increment: -3 >> New Balance: 2053\n",
            ">>> Actual: -4 +ive: 0.51 -ive: 0.27 diff: 0.24\n",
            "i0 3552 Increment: -4 >> New Balance: 2049\n",
            ">>> Actual: -3 +ive: 0.55 -ive: 0.27 diff: 0.28\n",
            "i0 3554 Increment: -3 >> New Balance: 2046\n",
            ">>> Actual: -4 +ive: 0.53 -ive: 0.28 diff: 0.25\n",
            "i0 3557 Increment: -4 >> New Balance: 2042\n",
            "i0 3560 Increment: 3 >> New Balance: 2045\n",
            "i0 3562 Increment: 15 >> New Balance: 2060\n",
            "i0 3566 Increment: 7 >> New Balance: 2067\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.16 diff: 0.39\n",
            "i0 3569 Increment: 0 >> New Balance: 2067\n",
            ">>> Actual: -1 +ive: 0.61 -ive: 0.27 diff: 0.34\n",
            "i0 3571 Increment: -1 >> New Balance: 2066\n",
            ">>> Actual: 0 +ive: 0.73 -ive: 0.14 diff: 0.59\n",
            "i0 3572 Increment: 0 >> New Balance: 2066\n",
            "i0 3573 Increment: 2 >> New Balance: 2068\n",
            ">>> Actual: -1 +ive: 0.64 -ive: 0.24 diff: 0.4\n",
            "i0 3575 Increment: -1 >> New Balance: 2067\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.26 diff: 0.29\n",
            "i0 3577 Increment: 0 >> New Balance: 2067\n",
            "i0 3578 Increment: 2 >> New Balance: 2069\n",
            ">>> Actual: 0 +ive: 0.56 -ive: 0.22 diff: 0.34\n",
            "i0 3579 Increment: 0 >> New Balance: 2069\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.27 diff: 0.26\n",
            "i0 3585 Increment: 0 >> New Balance: 2069\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 3587 Increment: 0 >> New Balance: 2069\n",
            "i0 3595 Increment: 7 >> New Balance: 2076\n",
            "i0 3596 Increment: 7 >> New Balance: 2083\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 3603 Increment: 0 >> New Balance: 2083\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.29 diff: 0.26\n",
            "i0 3610 Increment: 0 >> New Balance: 2083\n",
            "i0 3612 Increment: 1 >> New Balance: 2084\n",
            "i0 3614 Increment: 3 >> New Balance: 2087\n",
            "i0 3615 Increment: 1 >> New Balance: 2088\n",
            "i0 3616 Increment: 3 >> New Balance: 2091\n",
            "i0 3617 Increment: 4 >> New Balance: 2095\n",
            "i0 3618 Increment: 2 >> New Balance: 2097\n",
            ">>> Actual: -11 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 3625 Increment: -11 >> New Balance: 2086\n",
            "i0 3627 Increment: 1 >> New Balance: 2087\n",
            "i0 3628 Increment: 1 >> New Balance: 2088\n",
            ">>> Actual: -7 +ive: 0.53 -ive: 0.29 diff: 0.24\n",
            "i0 3629 Increment: -7 >> New Balance: 2081\n",
            ">>> Actual: -7 +ive: 0.62 -ive: 0.25 diff: 0.37\n",
            "i0 3630 Increment: -7 >> New Balance: 2074\n",
            ">>> Actual: -7 +ive: 0.52 -ive: 0.25 diff: 0.27\n",
            "i0 3632 Increment: -7 >> New Balance: 2067\n",
            ">>> Actual: -8 +ive: 0.52 -ive: 0.29 diff: 0.23\n",
            "i0 3633 Increment: -8 >> New Balance: 2059\n",
            ">>> Actual: -1 +ive: 0.51 -ive: 0.26 diff: 0.25\n",
            "i0 3635 Increment: -1 >> New Balance: 2058\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.15 diff: 0.39\n",
            "i0 3637 Increment: 0 >> New Balance: 2058\n",
            "i0 3638 Increment: 1 >> New Balance: 2059\n",
            "i0 3639 Increment: 2 >> New Balance: 2061\n",
            "i0 3644 Increment: 4 >> New Balance: 2065\n",
            "i0 3652 Increment: 1 >> New Balance: 2066\n",
            "i0 3653 Increment: 2 >> New Balance: 2068\n",
            ">>> Actual: 0 +ive: 0.57 -ive: 0.27 diff: 0.3\n",
            "i0 3660 Increment: 0 >> New Balance: 2068\n",
            ">>> Actual: -1 +ive: 0.62 -ive: 0.29 diff: 0.33\n",
            "i0 3662 Increment: -1 >> New Balance: 2067\n",
            "i0 3667 Increment: 4 >> New Balance: 2071\n",
            "i0 3668 Increment: 4 >> New Balance: 2075\n",
            "i0 3674 Increment: 3 >> New Balance: 2078\n",
            "i0 3677 Increment: 2 >> New Balance: 2080\n",
            ">>> Actual: -4 +ive: 0.58 -ive: 0.24 diff: 0.34\n",
            "i0 3682 Increment: -4 >> New Balance: 2076\n",
            ">>> Actual: -5 +ive: 0.54 -ive: 0.28 diff: 0.26\n",
            "i0 3686 Increment: -5 >> New Balance: 2071\n",
            ">>> Actual: -3 +ive: 0.54 -ive: 0.27 diff: 0.27\n",
            "i0 3688 Increment: -3 >> New Balance: 2068\n",
            ">>> Actual: -4 +ive: 0.54 -ive: 0.28 diff: 0.26\n",
            "i0 3689 Increment: -4 >> New Balance: 2064\n",
            ">>> Actual: -4 +ive: 0.59 -ive: 0.26 diff: 0.33\n",
            "i0 3690 Increment: -4 >> New Balance: 2060\n",
            ">>> Actual: -1 +ive: 0.52 -ive: 0.27 diff: 0.25\n",
            "i0 3694 Increment: -1 >> New Balance: 2059\n",
            "i0 3698 Increment: 1 >> New Balance: 2060\n",
            "i0 3699 Increment: 1 >> New Balance: 2061\n",
            ">>> Actual: -1 +ive: 0.57 -ive: 0.28 diff: 0.29\n",
            "i0 3702 Increment: -1 >> New Balance: 2060\n",
            ">>> Actual: -1 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 3703 Increment: -1 >> New Balance: 2059\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.27 diff: 0.25\n",
            "i0 3704 Increment: 0 >> New Balance: 2059\n",
            "i0 3705 Increment: 1 >> New Balance: 2060\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.29 diff: 0.25\n",
            "i0 3706 Increment: 0 >> New Balance: 2060\n",
            ">>> Actual: -2 +ive: 0.51 -ive: 0.25 diff: 0.26\n",
            "i0 3712 Increment: -2 >> New Balance: 2058\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.28 diff: 0.26\n",
            "i0 3714 Increment: 0 >> New Balance: 2058\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.27 diff: 0.24\n",
            "i0 3726 Increment: 0 >> New Balance: 2058\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 3727 Increment: 0 >> New Balance: 2058\n",
            ">>> Actual: -1 +ive: 0.52 -ive: 0.29 diff: 0.23\n",
            "i0 3732 Increment: -1 >> New Balance: 2057\n",
            "i0 3735 Increment: 2 >> New Balance: 2059\n",
            ">>> Actual: -2 +ive: 0.52 -ive: 0.27 diff: 0.25\n",
            "i0 3752 Increment: -2 >> New Balance: 2057\n",
            "i0 3753 Increment: 5 >> New Balance: 2062\n",
            "i0 3756 Increment: 5 >> New Balance: 2067\n",
            "i0 3759 Increment: 8 >> New Balance: 2075\n",
            "i0 3760 Increment: 6 >> New Balance: 2081\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.1 diff: 0.45\n",
            "i0 3761 Increment: 0 >> New Balance: 2081\n",
            ">>> Actual: 0 +ive: 0.58 -ive: 0.19 diff: 0.39\n",
            "i0 3762 Increment: 0 >> New Balance: 2081\n",
            "i0 3766 Increment: 1 >> New Balance: 2082\n",
            "i0 3774 Increment: 5 >> New Balance: 2087\n",
            "i0 3775 Increment: 4 >> New Balance: 2091\n",
            "i0 3776 Increment: 5 >> New Balance: 2096\n",
            "i0 3777 Increment: 2 >> New Balance: 2098\n",
            "i0 3788 Increment: 2 >> New Balance: 2100\n",
            "i0 3790 Increment: 1 >> New Balance: 2101\n",
            "i0 3792 Increment: 4 >> New Balance: 2105\n",
            "i0 3793 Increment: 4 >> New Balance: 2109\n",
            "i0 3794 Increment: 2 >> New Balance: 2111\n",
            "i0 3798 Increment: 3 >> New Balance: 2114\n",
            "i0 3802 Increment: 2 >> New Balance: 2116\n",
            "i0 3803 Increment: 4 >> New Balance: 2120\n",
            "i0 3804 Increment: 3 >> New Balance: 2123\n",
            "i0 3806 Increment: 2 >> New Balance: 2125\n",
            "i0 3807 Increment: 1 >> New Balance: 2126\n",
            ">>> Actual: 0 +ive: 0.58 -ive: 0.18 diff: 0.4\n",
            "i0 3808 Increment: 0 >> New Balance: 2126\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.18 diff: 0.33\n",
            "i0 3809 Increment: 0 >> New Balance: 2126\n",
            ">>> Actual: -1 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 3812 Increment: -1 >> New Balance: 2125\n",
            ">>> Actual: -2 +ive: 0.53 -ive: 0.22 diff: 0.31\n",
            "i0 3813 Increment: -2 >> New Balance: 2123\n",
            ">>> Actual: -9 +ive: 0.56 -ive: 0.27 diff: 0.29\n",
            "i0 3820 Increment: -9 >> New Balance: 2114\n",
            ">>> Actual: -8 +ive: 0.52 -ive: 0.24 diff: 0.28\n",
            "i0 3821 Increment: -8 >> New Balance: 2106\n",
            ">>> Actual: -9 +ive: 0.55 -ive: 0.24 diff: 0.31\n",
            "i0 3822 Increment: -9 >> New Balance: 2097\n",
            "i0 3828 Increment: 1 >> New Balance: 2098\n",
            ">>> Actual: -1 +ive: 0.78 -ive: 0.24 diff: 0.54\n",
            "i0 3829 Increment: -1 >> New Balance: 2097\n",
            "i0 3830 Increment: 1 >> New Balance: 2098\n",
            ">>> Actual: 0 +ive: 0.84 -ive: 0.11 diff: 0.73\n",
            "i0 3831 Increment: 0 >> New Balance: 2098\n",
            ">>> Actual: -2 +ive: 0.57 -ive: 0.23 diff: 0.34\n",
            "i0 3832 Increment: -2 >> New Balance: 2096\n",
            ">>> Actual: -5 +ive: 0.56 -ive: 0.27 diff: 0.29\n",
            "i0 3833 Increment: -5 >> New Balance: 2091\n",
            ">>> Actual: -5 +ive: 0.56 -ive: 0.26 diff: 0.3\n",
            "i0 3834 Increment: -5 >> New Balance: 2086\n",
            "i0 3848 Increment: 5 >> New Balance: 2091\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.26 diff: 0.28\n",
            "i0 3853 Increment: 0 >> New Balance: 2091\n",
            "i0 3855 Increment: 4 >> New Balance: 2095\n",
            "i0 3857 Increment: 5 >> New Balance: 2100\n",
            "i0 3858 Increment: 5 >> New Balance: 2105\n",
            "i0 3861 Increment: 2 >> New Balance: 2107\n",
            "i0 3862 Increment: 2 >> New Balance: 2109\n",
            "i0 3866 Increment: 2 >> New Balance: 2111\n",
            "i0 3868 Increment: 1 >> New Balance: 2112\n",
            "i0 3869 Increment: 2 >> New Balance: 2114\n",
            "i0 3870 Increment: 4 >> New Balance: 2118\n",
            "i0 3871 Increment: 5 >> New Balance: 2123\n",
            "i0 3880 Increment: 1 >> New Balance: 2124\n",
            "i0 3884 Increment: 5 >> New Balance: 2129\n",
            "i0 3890 Increment: 1 >> New Balance: 2130\n",
            "i0 3891 Increment: 2 >> New Balance: 2132\n",
            "i0 3892 Increment: 2 >> New Balance: 2134\n",
            "i0 3893 Increment: 3 >> New Balance: 2137\n",
            ">>> Actual: 0 +ive: 0.69 -ive: 0.2 diff: 0.49\n",
            "i0 3894 Increment: 0 >> New Balance: 2137\n",
            "i0 3896 Increment: 2 >> New Balance: 2139\n",
            "i0 3900 Increment: 2 >> New Balance: 2141\n",
            "i0 3901 Increment: 1 >> New Balance: 2142\n",
            "i0 3903 Increment: 2 >> New Balance: 2144\n",
            ">>> Actual: -1 +ive: 0.55 -ive: 0.26 diff: 0.29\n",
            "i0 3922 Increment: -1 >> New Balance: 2143\n",
            ">>> Actual: -1 +ive: 0.62 -ive: 0.21 diff: 0.41\n",
            "i0 3923 Increment: -1 >> New Balance: 2142\n",
            ">>> Actual: -1 +ive: 0.52 -ive: 0.27 diff: 0.25\n",
            "i0 3924 Increment: -1 >> New Balance: 2141\n",
            ">>> Actual: -1 +ive: 0.57 -ive: 0.23 diff: 0.34\n",
            "i0 3925 Increment: -1 >> New Balance: 2140\n",
            ">>> Actual: -2 +ive: 0.62 -ive: 0.17 diff: 0.45\n",
            "i0 3926 Increment: -2 >> New Balance: 2138\n",
            ">>> Actual: -1 +ive: 0.54 -ive: 0.23 diff: 0.31\n",
            "i0 3927 Increment: -1 >> New Balance: 2137\n",
            ">>> Actual: -1 +ive: 0.54 -ive: 0.25 diff: 0.29\n",
            "i0 3928 Increment: -1 >> New Balance: 2136\n",
            ">>> Actual: -4 +ive: 0.54 -ive: 0.25 diff: 0.29\n",
            "i0 3929 Increment: -4 >> New Balance: 2132\n",
            ">>> Actual: -4 +ive: 0.53 -ive: 0.25 diff: 0.28\n",
            "i0 3930 Increment: -4 >> New Balance: 2128\n",
            "i0 3939 Increment: 2 >> New Balance: 2130\n",
            "i0 3941 Increment: 2 >> New Balance: 2132\n",
            "i0 3942 Increment: 2 >> New Balance: 2134\n",
            "i0 3954 Increment: 6 >> New Balance: 2140\n",
            "i0 3958 Increment: 2 >> New Balance: 2142\n",
            "i0 3959 Increment: 6 >> New Balance: 2148\n",
            "i0 3960 Increment: 1 >> New Balance: 2149\n",
            "i0 3961 Increment: 4 >> New Balance: 2153\n",
            "i0 3974 Increment: 2 >> New Balance: 2155\n",
            "i0 3975 Increment: 1 >> New Balance: 2156\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.28 diff: 0.25\n",
            "i0 3976 Increment: 0 >> New Balance: 2156\n",
            "i0 3978 Increment: 1 >> New Balance: 2157\n",
            "i0 3979 Increment: 3 >> New Balance: 2160\n",
            "i0 3981 Increment: 2 >> New Balance: 2162\n",
            "i0 3983 Increment: 2 >> New Balance: 2164\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.27 diff: 0.24\n",
            "i0 3990 Increment: 0 >> New Balance: 2164\n",
            "i0 3993 Increment: 1 >> New Balance: 2165\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.25 diff: 0.27\n",
            "i0 3994 Increment: 0 >> New Balance: 2165\n",
            "i0 3998 Increment: 4 >> New Balance: 2169\n",
            "i0 3999 Increment: 3 >> New Balance: 2172\n",
            "i0 4001 Increment: 1 >> New Balance: 2173\n",
            ">>> Actual: 0 +ive: 0.62 -ive: 0.28 diff: 0.34\n",
            "i0 4002 Increment: 0 >> New Balance: 2173\n",
            ">>> Actual: -4 +ive: 0.54 -ive: 0.28 diff: 0.26\n",
            "i0 4006 Increment: -4 >> New Balance: 2169\n",
            ">>> Actual: -2 +ive: 0.51 -ive: 0.24 diff: 0.27\n",
            "i0 4009 Increment: -2 >> New Balance: 2167\n",
            ">>> Actual: -1 +ive: 0.56 -ive: 0.21 diff: 0.35\n",
            "i0 4013 Increment: -1 >> New Balance: 2166\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.29 diff: 0.23\n",
            "i0 4014 Increment: 0 >> New Balance: 2166\n",
            ">>> Actual: 0 +ive: 0.59 -ive: 0.25 diff: 0.34\n",
            "i0 4017 Increment: 0 >> New Balance: 2166\n",
            ">>> Actual: -2 +ive: 0.51 -ive: 0.27 diff: 0.24\n",
            "i0 4018 Increment: -2 >> New Balance: 2164\n",
            ">>> Actual: -1 +ive: 0.58 -ive: 0.27 diff: 0.31\n",
            "i0 4027 Increment: -1 >> New Balance: 2163\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.28 diff: 0.26\n",
            "i0 4031 Increment: 0 >> New Balance: 2163\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.25 diff: 0.29\n",
            "i0 4032 Increment: 0 >> New Balance: 2163\n",
            "i0 4036 Increment: 2 >> New Balance: 2165\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.28 diff: 0.27\n",
            "i0 4043 Increment: 0 >> New Balance: 2165\n",
            "i0 4044 Increment: 2 >> New Balance: 2167\n",
            ">>> Actual: 0 +ive: 0.59 -ive: 0.25 diff: 0.34\n",
            "i0 4045 Increment: 0 >> New Balance: 2167\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.28 diff: 0.24\n",
            "i0 4046 Increment: 0 >> New Balance: 2167\n",
            ">>> Actual: 0 +ive: 0.57 -ive: 0.26 diff: 0.31\n",
            "i0 4049 Increment: 0 >> New Balance: 2167\n",
            ">>> Actual: 0 +ive: 0.67 -ive: 0.27 diff: 0.4\n",
            "i0 4050 Increment: 0 >> New Balance: 2167\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.23 diff: 0.31\n",
            "i0 4056 Increment: 0 >> New Balance: 2167\n",
            ">>> Actual: -2 +ive: 0.57 -ive: 0.21 diff: 0.36\n",
            "i0 4058 Increment: -2 >> New Balance: 2165\n",
            ">>> Actual: -2 +ive: 0.61 -ive: 0.25 diff: 0.36\n",
            "i0 4059 Increment: -2 >> New Balance: 2163\n",
            ">>> Actual: 0 +ive: 0.58 -ive: 0.24 diff: 0.34\n",
            "i0 4060 Increment: 0 >> New Balance: 2163\n",
            "i0 4067 Increment: 17 >> New Balance: 2180\n",
            "i0 4073 Increment: 16 >> New Balance: 2196\n",
            ">>> Actual: 0 +ive: 0.56 -ive: 0.14 diff: 0.42\n",
            "i0 4074 Increment: 0 >> New Balance: 2196\n",
            ">>> Actual: 0 +ive: 0.8 -ive: 0.16 diff: 0.64\n",
            "i0 4076 Increment: 0 >> New Balance: 2196\n",
            "i0 4080 Increment: 1 >> New Balance: 2197\n",
            ">>> Actual: 0 +ive: 0.56 -ive: 0.24 diff: 0.32\n",
            "i0 4085 Increment: 0 >> New Balance: 2197\n",
            "i0 4087 Increment: 1 >> New Balance: 2198\n",
            "i0 4088 Increment: 1 >> New Balance: 2199\n",
            "i0 4092 Increment: 1 >> New Balance: 2200\n",
            "i0 4093 Increment: 2 >> New Balance: 2202\n",
            "i0 4094 Increment: 2 >> New Balance: 2204\n",
            "i0 4096 Increment: 2 >> New Balance: 2206\n",
            "i0 4097 Increment: 3 >> New Balance: 2209\n",
            "i0 4104 Increment: 2 >> New Balance: 2211\n",
            ">>> Actual: 0 +ive: 0.59 -ive: 0.23 diff: 0.36\n",
            "i0 4105 Increment: 0 >> New Balance: 2211\n",
            "i0 4113 Increment: 2 >> New Balance: 2213\n",
            "i0 4116 Increment: 3 >> New Balance: 2216\n",
            "i0 4117 Increment: 2 >> New Balance: 2218\n",
            "i0 4132 Increment: 3 >> New Balance: 2221\n",
            "i0 4135 Increment: 2 >> New Balance: 2223\n",
            "i0 4141 Increment: 6 >> New Balance: 2229\n",
            "i0 4143 Increment: 2 >> New Balance: 2231\n",
            "i0 4148 Increment: 4 >> New Balance: 2235\n",
            "i0 4149 Increment: 3 >> New Balance: 2238\n",
            "i0 4151 Increment: 2 >> New Balance: 2240\n",
            "i0 4153 Increment: 1 >> New Balance: 2241\n",
            ">>> Actual: 0 +ive: 0.57 -ive: 0.28 diff: 0.29\n",
            "i0 4164 Increment: 0 >> New Balance: 2241\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.22 diff: 0.29\n",
            "i0 4165 Increment: 0 >> New Balance: 2241\n",
            ">>> Actual: -2 +ive: 0.53 -ive: 0.29 diff: 0.24\n",
            "i0 4167 Increment: -2 >> New Balance: 2239\n",
            ">>> Actual: -3 +ive: 0.52 -ive: 0.29 diff: 0.23\n",
            "i0 4168 Increment: -3 >> New Balance: 2236\n",
            ">>> Actual: -3 +ive: 0.56 -ive: 0.25 diff: 0.31\n",
            "i0 4169 Increment: -3 >> New Balance: 2233\n",
            ">>> Actual: -1 +ive: 0.63 -ive: 0.2 diff: 0.43\n",
            "i0 4170 Increment: -1 >> New Balance: 2232\n",
            ">>> Actual: -1 +ive: 0.62 -ive: 0.27 diff: 0.35\n",
            "i0 4171 Increment: -1 >> New Balance: 2231\n",
            ">>> Actual: -4 +ive: 0.59 -ive: 0.24 diff: 0.35\n",
            "i0 4172 Increment: -4 >> New Balance: 2227\n",
            ">>> Actual: -4 +ive: 0.53 -ive: 0.23 diff: 0.3\n",
            "i0 4173 Increment: -4 >> New Balance: 2223\n",
            ">>> Actual: -3 +ive: 0.61 -ive: 0.26 diff: 0.35\n",
            "i0 4184 Increment: -3 >> New Balance: 2220\n",
            ">>> Actual: -3 +ive: 0.58 -ive: 0.24 diff: 0.34\n",
            "i0 4185 Increment: -3 >> New Balance: 2217\n",
            ">>> Actual: 0 +ive: 0.8 -ive: 0.1 diff: 0.7\n",
            "i0 4190 Increment: 0 >> New Balance: 2217\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.29 diff: 0.23\n",
            "i0 4206 Increment: 0 >> New Balance: 2217\n",
            "i0 4212 Increment: 1 >> New Balance: 2218\n",
            "i0 4220 Increment: 2 >> New Balance: 2220\n",
            "i0 4221 Increment: 4 >> New Balance: 2224\n",
            "i0 4229 Increment: 3 >> New Balance: 2227\n",
            "i0 4230 Increment: 2 >> New Balance: 2229\n",
            "i0 4237 Increment: 2 >> New Balance: 2231\n",
            "i0 4239 Increment: 3 >> New Balance: 2234\n",
            "i0 4246 Increment: 1 >> New Balance: 2235\n",
            ">>> Actual: -2 +ive: 0.52 -ive: 0.27 diff: 0.25\n",
            "i0 4251 Increment: -2 >> New Balance: 2233\n",
            "i0 4254 Increment: 1 >> New Balance: 2234\n",
            "i0 4257 Increment: 1 >> New Balance: 2235\n",
            "i0 4258 Increment: 1 >> New Balance: 2236\n",
            "i0 4260 Increment: 2 >> New Balance: 2238\n",
            ">>> Actual: -1 +ive: 0.51 -ive: 0.26 diff: 0.25\n",
            "i0 4264 Increment: -1 >> New Balance: 2237\n",
            ">>> Actual: -4 +ive: 0.67 -ive: 0.26 diff: 0.41\n",
            "i0 4265 Increment: -4 >> New Balance: 2233\n",
            ">>> Actual: -3 +ive: 0.54 -ive: 0.29 diff: 0.25\n",
            "i0 4269 Increment: -3 >> New Balance: 2230\n",
            "i0 4276 Increment: 2 >> New Balance: 2232\n",
            "i0 4277 Increment: 2 >> New Balance: 2234\n",
            "i0 4279 Increment: 1 >> New Balance: 2235\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.28 diff: 0.25\n",
            "i0 4280 Increment: 0 >> New Balance: 2235\n",
            "i0 4287 Increment: 1 >> New Balance: 2236\n",
            "i0 4288 Increment: 2 >> New Balance: 2238\n",
            "i0 4290 Increment: 2 >> New Balance: 2240\n",
            "i0 4291 Increment: 1 >> New Balance: 2241\n",
            ">>> Actual: 0 +ive: 0.56 -ive: 0.2 diff: 0.36\n",
            "i0 4294 Increment: 0 >> New Balance: 2241\n",
            ">>> Actual: -1 +ive: 0.52 -ive: 0.28 diff: 0.24\n",
            "i0 4295 Increment: -1 >> New Balance: 2240\n",
            ">>> Actual: -1 +ive: 0.6 -ive: 0.24 diff: 0.36\n",
            "i0 4296 Increment: -1 >> New Balance: 2239\n",
            "i0 4298 Increment: 1 >> New Balance: 2240\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.27 diff: 0.27\n",
            "i0 4299 Increment: 0 >> New Balance: 2240\n",
            ">>> Actual: -3 +ive: 0.54 -ive: 0.25 diff: 0.29\n",
            "i0 4305 Increment: -3 >> New Balance: 2237\n",
            ">>> Actual: -1 +ive: 0.56 -ive: 0.27 diff: 0.29\n",
            "i0 4308 Increment: -1 >> New Balance: 2236\n",
            ">>> Actual: 0 +ive: 0.57 -ive: 0.28 diff: 0.29\n",
            "i0 4310 Increment: 0 >> New Balance: 2236\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.26 diff: 0.27\n",
            "i0 4320 Increment: 0 >> New Balance: 2236\n",
            "i0 4322 Increment: 1 >> New Balance: 2237\n",
            ">>> Actual: -3 +ive: 0.52 -ive: 0.26 diff: 0.26\n",
            "i0 4337 Increment: -3 >> New Balance: 2234\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.26 diff: 0.25\n",
            "i0 4340 Increment: 0 >> New Balance: 2234\n",
            ">>> Actual: -1 +ive: 0.52 -ive: 0.25 diff: 0.27\n",
            "i0 4345 Increment: -1 >> New Balance: 2233\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 4348 Increment: 0 >> New Balance: 2233\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.27 diff: 0.26\n",
            "i0 4357 Increment: 0 >> New Balance: 2233\n",
            ">>> Actual: -3 +ive: 0.52 -ive: 0.28 diff: 0.24\n",
            "i0 4360 Increment: -3 >> New Balance: 2230\n",
            "i0 4367 Increment: 5 >> New Balance: 2235\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.18 diff: 0.33\n",
            "i0 4379 Increment: 0 >> New Balance: 2235\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.27 diff: 0.28\n",
            "i0 4380 Increment: 0 >> New Balance: 2235\n",
            "i0 4381 Increment: 3 >> New Balance: 2238\n",
            "i0 4383 Increment: 9 >> New Balance: 2247\n",
            "i0 4384 Increment: 4 >> New Balance: 2251\n",
            "i0 4387 Increment: 6 >> New Balance: 2257\n",
            "i0 4388 Increment: 5 >> New Balance: 2262\n",
            "i0 4395 Increment: 5 >> New Balance: 2267\n",
            "i0 4402 Increment: 2 >> New Balance: 2269\n",
            "i0 4403 Increment: 1 >> New Balance: 2270\n",
            "i0 4405 Increment: 2 >> New Balance: 2272\n",
            ">>> Actual: -2 +ive: 0.53 -ive: 0.29 diff: 0.24\n",
            "i0 4406 Increment: -2 >> New Balance: 2270\n",
            "i0 4410 Increment: 6 >> New Balance: 2276\n",
            ">>> Actual: 0 +ive: 0.61 -ive: 0.19 diff: 0.42\n",
            "i0 4416 Increment: 0 >> New Balance: 2276\n",
            "i0 4423 Increment: 1 >> New Balance: 2277\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.23 diff: 0.3\n",
            "i0 4424 Increment: 0 >> New Balance: 2277\n",
            ">>> Actual: 0 +ive: 0.59 -ive: 0.27 diff: 0.32\n",
            "i0 4426 Increment: 0 >> New Balance: 2277\n",
            ">>> Actual: 0 +ive: 0.62 -ive: 0.25 diff: 0.37\n",
            "i0 4427 Increment: 0 >> New Balance: 2277\n",
            ">>> Actual: -3 +ive: 0.52 -ive: 0.29 diff: 0.23\n",
            "i0 4430 Increment: -3 >> New Balance: 2274\n",
            ">>> Actual: -4 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 4431 Increment: -4 >> New Balance: 2270\n",
            ">>> Actual: -1 +ive: 0.62 -ive: 0.25 diff: 0.37\n",
            "i0 4437 Increment: -1 >> New Balance: 2269\n",
            ">>> Actual: -2 +ive: 0.53 -ive: 0.28 diff: 0.25\n",
            "i0 4438 Increment: -2 >> New Balance: 2267\n",
            "i0 4447 Increment: 4 >> New Balance: 2271\n",
            "i0 4448 Increment: 4 >> New Balance: 2275\n",
            ">>> Actual: -2 +ive: 0.54 -ive: 0.24 diff: 0.3\n",
            "i0 4456 Increment: -2 >> New Balance: 2273\n",
            ">>> Actual: -3 +ive: 0.53 -ive: 0.28 diff: 0.25\n",
            "i0 4457 Increment: -3 >> New Balance: 2270\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 4460 Increment: 0 >> New Balance: 2270\n",
            "i0 4469 Increment: 1 >> New Balance: 2271\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.29 diff: 0.26\n",
            "i0 4479 Increment: 0 >> New Balance: 2271\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.24 diff: 0.28\n",
            "i0 4482 Increment: 0 >> New Balance: 2271\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.28 diff: 0.27\n",
            "i0 4483 Increment: 0 >> New Balance: 2271\n",
            "i0 4485 Increment: 1 >> New Balance: 2272\n",
            "i0 4489 Increment: 1 >> New Balance: 2273\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.28 diff: 0.25\n",
            "i0 4490 Increment: 0 >> New Balance: 2273\n",
            "i0 4501 Increment: 7 >> New Balance: 2280\n",
            "i0 4502 Increment: 7 >> New Balance: 2287\n",
            "i0 4503 Increment: 28 >> New Balance: 2315\n",
            "i0 4504 Increment: 28 >> New Balance: 2343\n",
            "i0 4506 Increment: 27 >> New Balance: 2370\n",
            "i0 4511 Increment: 11 >> New Balance: 2381\n",
            ">>> Actual: -6 +ive: 0.65 -ive: 0.22 diff: 0.43\n",
            "i0 4512 Increment: -6 >> New Balance: 2375\n",
            ">>> Actual: 0 +ive: 0.84 -ive: 0.23 diff: 0.61\n",
            "i0 4513 Increment: 0 >> New Balance: 2375\n",
            "i0 4518 Increment: 1 >> New Balance: 2376\n",
            ">>> Actual: 0 +ive: 0.81 -ive: 0.15 diff: 0.66\n",
            "i0 4520 Increment: 0 >> New Balance: 2376\n",
            "i0 4521 Increment: 4 >> New Balance: 2380\n",
            "i0 4522 Increment: 5 >> New Balance: 2385\n",
            "i0 4523 Increment: 4 >> New Balance: 2389\n",
            "i0 4524 Increment: 4 >> New Balance: 2393\n",
            "i0 4525 Increment: 2 >> New Balance: 2395\n",
            "i0 4526 Increment: 2 >> New Balance: 2397\n",
            "i0 4538 Increment: 1 >> New Balance: 2398\n",
            "i0 4539 Increment: 5 >> New Balance: 2403\n",
            ">>> Actual: -1 +ive: 0.61 -ive: 0.27 diff: 0.34\n",
            "i0 4540 Increment: -1 >> New Balance: 2402\n",
            "i0 4544 Increment: 3 >> New Balance: 2405\n",
            "i0 4546 Increment: 3 >> New Balance: 2408\n",
            "i0 4547 Increment: 4 >> New Balance: 2412\n",
            ">>> Actual: 0 +ive: 0.56 -ive: 0.28 diff: 0.28\n",
            "i0 4552 Increment: 0 >> New Balance: 2412\n",
            "i0 4560 Increment: 3 >> New Balance: 2415\n",
            "i0 4565 Increment: 6 >> New Balance: 2421\n",
            "i0 4568 Increment: 1 >> New Balance: 2422\n",
            "i0 4569 Increment: 1 >> New Balance: 2423\n",
            "i0 4571 Increment: 2 >> New Balance: 2425\n",
            "i0 4572 Increment: 2 >> New Balance: 2427\n",
            "i0 4573 Increment: 7 >> New Balance: 2434\n",
            ">>> Actual: 0 +ive: 0.59 -ive: 0.28 diff: 0.31\n",
            "i0 4574 Increment: 0 >> New Balance: 2434\n",
            "i0 4575 Increment: 7 >> New Balance: 2441\n",
            "i0 4576 Increment: 7 >> New Balance: 2448\n",
            "i0 4577 Increment: 8 >> New Balance: 2456\n",
            "i0 4581 Increment: 3 >> New Balance: 2459\n",
            "i0 4582 Increment: 1 >> New Balance: 2460\n",
            "i0 4583 Increment: 2 >> New Balance: 2462\n",
            "i0 4584 Increment: 3 >> New Balance: 2465\n",
            "i0 4585 Increment: 1 >> New Balance: 2466\n",
            "i0 4586 Increment: 2 >> New Balance: 2468\n",
            ">>> Actual: 0 +ive: 0.58 -ive: 0.26 diff: 0.32\n",
            "i0 4587 Increment: 0 >> New Balance: 2468\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.25 diff: 0.26\n",
            "i0 4589 Increment: 0 >> New Balance: 2468\n",
            "i0 4592 Increment: 4 >> New Balance: 2472\n",
            "i0 4593 Increment: 3 >> New Balance: 2475\n",
            "i0 4595 Increment: 2 >> New Balance: 2477\n",
            "i0 4597 Increment: 2 >> New Balance: 2479\n",
            "i0 4598 Increment: 2 >> New Balance: 2481\n",
            ">>> Actual: 0 +ive: 0.56 -ive: 0.27 diff: 0.29\n",
            "i0 4606 Increment: 0 >> New Balance: 2481\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.29 diff: 0.25\n",
            "i0 4614 Increment: 0 >> New Balance: 2481\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.26 diff: 0.27\n",
            "i0 4615 Increment: 0 >> New Balance: 2481\n",
            "i0 4617 Increment: 2 >> New Balance: 2483\n",
            "i0 4619 Increment: 1 >> New Balance: 2484\n",
            ">>> Actual: -4 +ive: 0.52 -ive: 0.28 diff: 0.24\n",
            "i0 4644 Increment: -4 >> New Balance: 2480\n",
            "i0 4661 Increment: 1 >> New Balance: 2481\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.28 diff: 0.26\n",
            "i0 4663 Increment: 0 >> New Balance: 2481\n",
            ">>> Actual: -1 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 4665 Increment: -1 >> New Balance: 2480\n",
            ">>> Actual: -1 +ive: 0.56 -ive: 0.21 diff: 0.35\n",
            "i0 4668 Increment: -1 >> New Balance: 2479\n",
            "i0 4671 Increment: 2 >> New Balance: 2481\n",
            "i0 4685 Increment: 1 >> New Balance: 2482\n",
            "i0 4686 Increment: 1 >> New Balance: 2483\n",
            "i0 4691 Increment: 1 >> New Balance: 2484\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.29 diff: 0.23\n",
            "i0 4693 Increment: 0 >> New Balance: 2484\n",
            "i0 4694 Increment: 1 >> New Balance: 2485\n",
            "i0 4695 Increment: 1 >> New Balance: 2486\n",
            "i0 4696 Increment: 3 >> New Balance: 2489\n",
            ">>> Actual: -2 +ive: 0.51 -ive: 0.26 diff: 0.25\n",
            "i0 4697 Increment: -2 >> New Balance: 2487\n",
            ">>> Actual: -3 +ive: 0.55 -ive: 0.26 diff: 0.29\n",
            "i0 4698 Increment: -3 >> New Balance: 2484\n",
            ">>> Actual: -5 +ive: 0.62 -ive: 0.25 diff: 0.37\n",
            "i0 4699 Increment: -5 >> New Balance: 2479\n",
            ">>> Actual: -7 +ive: 0.56 -ive: 0.26 diff: 0.3\n",
            "i0 4702 Increment: -7 >> New Balance: 2472\n",
            ">>> Actual: -7 +ive: 0.57 -ive: 0.24 diff: 0.33\n",
            "i0 4704 Increment: -7 >> New Balance: 2465\n",
            "i0 4710 Increment: 2 >> New Balance: 2467\n",
            "i0 4711 Increment: 2 >> New Balance: 2469\n",
            "i0 4712 Increment: 2 >> New Balance: 2471\n",
            "i0 4713 Increment: 2 >> New Balance: 2473\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.29 diff: 0.25\n",
            "i0 4714 Increment: 0 >> New Balance: 2473\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.28 diff: 0.27\n",
            "i0 4727 Increment: 0 >> New Balance: 2473\n",
            ">>> Actual: -1 +ive: 0.58 -ive: 0.26 diff: 0.32\n",
            "i0 4728 Increment: -1 >> New Balance: 2472\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.25 diff: 0.26\n",
            "i0 4729 Increment: 0 >> New Balance: 2472\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.24 diff: 0.27\n",
            "i0 4733 Increment: 0 >> New Balance: 2472\n",
            ">>> Actual: -5 +ive: 0.53 -ive: 0.29 diff: 0.24\n",
            "i0 4741 Increment: -5 >> New Balance: 2467\n",
            ">>> Actual: -7 +ive: 0.55 -ive: 0.26 diff: 0.29\n",
            "i0 4742 Increment: -7 >> New Balance: 2460\n",
            ">>> Actual: -4 +ive: 0.57 -ive: 0.27 diff: 0.3\n",
            "i0 4743 Increment: -4 >> New Balance: 2456\n",
            "i0 4749 Increment: 3 >> New Balance: 2459\n",
            "i0 4750 Increment: 3 >> New Balance: 2462\n",
            "i0 4755 Increment: 3 >> New Balance: 2465\n",
            "i0 4758 Increment: 5 >> New Balance: 2470\n",
            "i0 4761 Increment: 2 >> New Balance: 2472\n",
            "i0 4762 Increment: 2 >> New Balance: 2474\n",
            "i0 4763 Increment: 2 >> New Balance: 2476\n",
            "i0 4764 Increment: 1 >> New Balance: 2477\n",
            "i0 4765 Increment: 4 >> New Balance: 2481\n",
            "i0 4766 Increment: 4 >> New Balance: 2485\n",
            "i0 4770 Increment: 6 >> New Balance: 2491\n",
            ">>> Actual: -1 +ive: 0.7 -ive: 0.24 diff: 0.46\n",
            "i0 4783 Increment: -1 >> New Balance: 2490\n",
            ">>> Actual: -1 +ive: 0.7 -ive: 0.24 diff: 0.46\n",
            "i0 4784 Increment: -1 >> New Balance: 2489\n",
            "i0 4791 Increment: 1 >> New Balance: 2490\n",
            "i0 4792 Increment: 1 >> New Balance: 2491\n",
            "i0 4807 Increment: 1 >> New Balance: 2492\n",
            "i0 4808 Increment: 1 >> New Balance: 2493\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.29 diff: 0.24\n",
            "i0 4809 Increment: 0 >> New Balance: 2493\n",
            ">>> Actual: -1 +ive: 0.63 -ive: 0.27 diff: 0.36\n",
            "i0 4811 Increment: -1 >> New Balance: 2492\n",
            ">>> Actual: -1 +ive: 0.58 -ive: 0.29 diff: 0.29\n",
            "i0 4812 Increment: -1 >> New Balance: 2491\n",
            "i0 4821 Increment: 3 >> New Balance: 2494\n",
            "i0 4822 Increment: 2 >> New Balance: 2496\n",
            "i0 4823 Increment: 1 >> New Balance: 2497\n",
            "i0 4825 Increment: 1 >> New Balance: 2498\n",
            "i0 4827 Increment: 2 >> New Balance: 2500\n",
            "i0 4828 Increment: 1 >> New Balance: 2501\n",
            ">>> Actual: -3 +ive: 0.55 -ive: 0.28 diff: 0.27\n",
            "i0 4832 Increment: -3 >> New Balance: 2498\n",
            ">>> Actual: -2 +ive: 0.53 -ive: 0.26 diff: 0.27\n",
            "i0 4834 Increment: -2 >> New Balance: 2496\n",
            ">>> Actual: -2 +ive: 0.54 -ive: 0.28 diff: 0.26\n",
            "i0 4835 Increment: -2 >> New Balance: 2494\n",
            ">>> Actual: -1 +ive: 0.67 -ive: 0.27 diff: 0.4\n",
            "i0 4837 Increment: -1 >> New Balance: 2493\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.25 diff: 0.26\n",
            "i0 4838 Increment: 0 >> New Balance: 2493\n",
            ">>> Actual: 0 +ive: 0.56 -ive: 0.24 diff: 0.32\n",
            "i0 4839 Increment: 0 >> New Balance: 2493\n",
            "i0 4848 Increment: 3 >> New Balance: 2496\n",
            "i0 4852 Increment: 1 >> New Balance: 2497\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.26 diff: 0.29\n",
            "i0 4855 Increment: 0 >> New Balance: 2497\n",
            "i0 4856 Increment: 1 >> New Balance: 2498\n",
            "i0 4865 Increment: 2 >> New Balance: 2500\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.27 diff: 0.26\n",
            "i0 4875 Increment: 0 >> New Balance: 2500\n",
            "i0 4877 Increment: 1 >> New Balance: 2501\n",
            "i0 4879 Increment: 2 >> New Balance: 2503\n",
            "i0 4882 Increment: 2 >> New Balance: 2505\n",
            "i0 4883 Increment: 1 >> New Balance: 2506\n",
            "i0 4885 Increment: 1 >> New Balance: 2507\n",
            "i0 4886 Increment: 2 >> New Balance: 2509\n",
            "i0 4887 Increment: 3 >> New Balance: 2512\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.25 diff: 0.3\n",
            "i0 4888 Increment: 0 >> New Balance: 2512\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.23 diff: 0.28\n",
            "i0 4893 Increment: 0 >> New Balance: 2512\n",
            "i0 4894 Increment: 1 >> New Balance: 2513\n",
            "i0 4900 Increment: 2 >> New Balance: 2515\n",
            "i0 4901 Increment: 1 >> New Balance: 2516\n",
            "i0 4902 Increment: 2 >> New Balance: 2518\n",
            "i0 4903 Increment: 2 >> New Balance: 2520\n",
            "i0 4905 Increment: 2 >> New Balance: 2522\n",
            "i0 4919 Increment: 1 >> New Balance: 2523\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.24 diff: 0.27\n",
            "i0 4921 Increment: 0 >> New Balance: 2523\n",
            "i0 4922 Increment: 1 >> New Balance: 2524\n",
            "i0 4923 Increment: 2 >> New Balance: 2526\n",
            "i0 4924 Increment: 2 >> New Balance: 2528\n",
            "i0 4925 Increment: 1 >> New Balance: 2529\n",
            "i0 4926 Increment: 1 >> New Balance: 2530\n",
            "i0 4937 Increment: 2 >> New Balance: 2532\n",
            "i0 4938 Increment: 1 >> New Balance: 2533\n",
            "i0 4939 Increment: 1 >> New Balance: 2534\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.27 diff: 0.24\n",
            "i0 4942 Increment: 0 >> New Balance: 2534\n",
            "i0 4954 Increment: 8 >> New Balance: 2542\n",
            "i0 4955 Increment: 10 >> New Balance: 2552\n",
            "i0 4956 Increment: 9 >> New Balance: 2561\n",
            "i0 4959 Increment: 6 >> New Balance: 2567\n",
            "i0 4960 Increment: 6 >> New Balance: 2573\n",
            "i0 4962 Increment: 1 >> New Balance: 2574\n",
            "i0 4963 Increment: 1 >> New Balance: 2575\n",
            ">>> Actual: -1 +ive: 0.63 -ive: 0.27 diff: 0.36\n",
            "i0 4965 Increment: -1 >> New Balance: 2574\n",
            ">>> Actual: 0 +ive: 0.59 -ive: 0.27 diff: 0.32\n",
            "i0 4967 Increment: 0 >> New Balance: 2574\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.28 diff: 0.24\n",
            "i0 4968 Increment: 0 >> New Balance: 2574\n",
            "i0 4969 Increment: 2 >> New Balance: 2576\n",
            "i0 4970 Increment: 1 >> New Balance: 2577\n",
            "i0 4971 Increment: 2 >> New Balance: 2579\n",
            "i0 4972 Increment: 3 >> New Balance: 2582\n",
            ">>> Actual: 0 +ive: 0.61 -ive: 0.17 diff: 0.44\n",
            "i0 4973 Increment: 0 >> New Balance: 2582\n",
            "i0 4976 Increment: 3 >> New Balance: 2585\n",
            "i0 4977 Increment: 3 >> New Balance: 2588\n",
            "i0 4978 Increment: 3 >> New Balance: 2591\n",
            "i0 4991 Increment: 2 >> New Balance: 2593\n",
            "i0 4992 Increment: 1 >> New Balance: 2594\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.26 diff: 0.27\n",
            "i0 4993 Increment: 0 >> New Balance: 2594\n",
            ">>> Actual: -1 +ive: 0.6 -ive: 0.26 diff: 0.34\n",
            "i0 4994 Increment: -1 >> New Balance: 2593\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.29 diff: 0.26\n",
            "i0 4995 Increment: 0 >> New Balance: 2593\n",
            ">>> Actual: -1 +ive: 0.53 -ive: 0.27 diff: 0.26\n",
            "i0 4997 Increment: -1 >> New Balance: 2592\n",
            "i0 5010 Increment: 4 >> New Balance: 2596\n",
            ">>> Actual: -5 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 5020 Increment: -5 >> New Balance: 2591\n",
            ">>> Actual: -1 +ive: 0.58 -ive: 0.24 diff: 0.34\n",
            "i0 5023 Increment: -1 >> New Balance: 2590\n",
            ">>> Actual: -2 +ive: 0.54 -ive: 0.28 diff: 0.26\n",
            "i0 5025 Increment: -2 >> New Balance: 2588\n",
            ">>> Actual: -1 +ive: 0.53 -ive: 0.26 diff: 0.27\n",
            "i0 5026 Increment: -1 >> New Balance: 2587\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.27 diff: 0.24\n",
            "i0 5027 Increment: 0 >> New Balance: 2587\n",
            "i0 5040 Increment: 3 >> New Balance: 2590\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.26 diff: 0.29\n",
            "i0 5052 Increment: 0 >> New Balance: 2590\n",
            ">>> Actual: 0 +ive: 0.63 -ive: 0.23 diff: 0.4\n",
            "i0 5055 Increment: 0 >> New Balance: 2590\n",
            ">>> Actual: -1 +ive: 0.62 -ive: 0.23 diff: 0.39\n",
            "i0 5056 Increment: -1 >> New Balance: 2589\n",
            "i0 5057 Increment: 2 >> New Balance: 2591\n",
            "i0 5058 Increment: 2 >> New Balance: 2593\n",
            "i0 5060 Increment: 4 >> New Balance: 2597\n",
            "i0 5063 Increment: 3 >> New Balance: 2600\n",
            "i0 5066 Increment: 3 >> New Balance: 2603\n",
            "i0 5069 Increment: 2 >> New Balance: 2605\n",
            "i0 5070 Increment: 2 >> New Balance: 2607\n",
            "i0 5071 Increment: 4 >> New Balance: 2611\n",
            "i0 5072 Increment: 1 >> New Balance: 2612\n",
            "i0 5073 Increment: 1 >> New Balance: 2613\n",
            "i0 5085 Increment: 6 >> New Balance: 2619\n",
            "i0 5086 Increment: 5 >> New Balance: 2624\n",
            "i0 5087 Increment: 6 >> New Balance: 2630\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.24 diff: 0.31\n",
            "i0 5088 Increment: 0 >> New Balance: 2630\n",
            "i0 5090 Increment: 3 >> New Balance: 2633\n",
            ">>> Actual: -2 +ive: 0.61 -ive: 0.24 diff: 0.37\n",
            "i0 5093 Increment: -2 >> New Balance: 2631\n",
            "i0 5098 Increment: 1 >> New Balance: 2632\n",
            ">>> Actual: 0 +ive: 0.56 -ive: 0.18 diff: 0.38\n",
            "i0 5099 Increment: 0 >> New Balance: 2632\n",
            ">>> Actual: -9 +ive: 0.54 -ive: 0.27 diff: 0.27\n",
            "i0 5100 Increment: -9 >> New Balance: 2623\n",
            ">>> Actual: -10 +ive: 0.54 -ive: 0.26 diff: 0.28\n",
            "i0 5101 Increment: -10 >> New Balance: 2613\n",
            "i0 5108 Increment: 2 >> New Balance: 2615\n",
            "i0 5109 Increment: 2 >> New Balance: 2617\n",
            ">>> Actual: -30 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 5111 Increment: -30 >> New Balance: 2587\n",
            ">>> Actual: -19 +ive: 0.55 -ive: 0.24 diff: 0.31\n",
            "i0 5112 Increment: -19 >> New Balance: 2568\n",
            ">>> Actual: -16 +ive: 0.53 -ive: 0.26 diff: 0.27\n",
            "i0 5114 Increment: -16 >> New Balance: 2552\n",
            ">>> Actual: -12 +ive: 0.52 -ive: 0.25 diff: 0.27\n",
            "i0 5117 Increment: -12 >> New Balance: 2540\n",
            ">>> Actual: -13 +ive: 0.59 -ive: 0.26 diff: 0.33\n",
            "i0 5118 Increment: -13 >> New Balance: 2527\n",
            ">>> Actual: -7 +ive: 0.76 -ive: 0.24 diff: 0.52\n",
            "i0 5119 Increment: -7 >> New Balance: 2520\n",
            "i0 5120 Increment: 4 >> New Balance: 2524\n",
            "i0 5121 Increment: 8 >> New Balance: 2532\n",
            ">>> Actual: -1 +ive: 0.51 -ive: 0.23 diff: 0.28\n",
            "i0 5122 Increment: -1 >> New Balance: 2531\n",
            ">>> Actual: -1 +ive: 0.63 -ive: 0.26 diff: 0.37\n",
            "i0 5124 Increment: -1 >> New Balance: 2530\n",
            "i0 5125 Increment: 1 >> New Balance: 2531\n",
            ">>> Actual: 0 +ive: 0.64 -ive: 0.16 diff: 0.48\n",
            "i0 5131 Increment: 0 >> New Balance: 2531\n",
            "i0 5132 Increment: 2 >> New Balance: 2533\n",
            ">>> Actual: 0 +ive: 0.57 -ive: 0.22 diff: 0.35\n",
            "i0 5134 Increment: 0 >> New Balance: 2533\n",
            ">>> Actual: -8 +ive: 0.51 -ive: 0.25 diff: 0.26\n",
            "i0 5136 Increment: -8 >> New Balance: 2525\n",
            ">>> Actual: -4 +ive: 0.59 -ive: 0.23 diff: 0.36\n",
            "i0 5137 Increment: -4 >> New Balance: 2521\n",
            ">>> Actual: -1 +ive: 0.51 -ive: 0.26 diff: 0.25\n",
            "i0 5138 Increment: -1 >> New Balance: 2520\n",
            ">>> Actual: -2 +ive: 0.59 -ive: 0.26 diff: 0.33\n",
            "i0 5139 Increment: -2 >> New Balance: 2518\n",
            "i0 5140 Increment: 1 >> New Balance: 2519\n",
            ">>> Actual: 0 +ive: 0.56 -ive: 0.2 diff: 0.36\n",
            "i0 5141 Increment: 0 >> New Balance: 2519\n",
            "i0 5149 Increment: 2 >> New Balance: 2521\n",
            ">>> Actual: -7 +ive: 0.53 -ive: 0.26 diff: 0.27\n",
            "i0 5153 Increment: -7 >> New Balance: 2514\n",
            ">>> Actual: -4 +ive: 0.53 -ive: 0.29 diff: 0.24\n",
            "i0 5155 Increment: -4 >> New Balance: 2510\n",
            "i0 5157 Increment: 5 >> New Balance: 2515\n",
            "i0 5159 Increment: 1 >> New Balance: 2516\n",
            ">>> Actual: -6 +ive: 0.53 -ive: 0.26 diff: 0.27\n",
            "i0 5161 Increment: -6 >> New Balance: 2510\n",
            ">>> Actual: 0 +ive: 0.56 -ive: 0.16 diff: 0.4\n",
            "i0 5162 Increment: 0 >> New Balance: 2510\n",
            ">>> Actual: -9 +ive: 0.6 -ive: 0.23 diff: 0.37\n",
            "i0 5165 Increment: -9 >> New Balance: 2501\n",
            ">>> Actual: -6 +ive: 0.54 -ive: 0.24 diff: 0.3\n",
            "i0 5166 Increment: -6 >> New Balance: 2495\n",
            "i0 5169 Increment: 18 >> New Balance: 2513\n",
            ">>> Actual: -3 +ive: 0.64 -ive: 0.28 diff: 0.36\n",
            "i0 5170 Increment: -3 >> New Balance: 2510\n",
            "i0 5176 Increment: 11 >> New Balance: 2521\n",
            "i0 5178 Increment: 8 >> New Balance: 2529\n",
            "i0 5183 Increment: 4 >> New Balance: 2533\n",
            "i0 5184 Increment: 11 >> New Balance: 2544\n",
            "i0 5185 Increment: 4 >> New Balance: 2548\n",
            "i0 5186 Increment: 4 >> New Balance: 2552\n",
            "i0 5187 Increment: 9 >> New Balance: 2561\n",
            "i0 5188 Increment: 17 >> New Balance: 2578\n",
            "i0 5189 Increment: 19 >> New Balance: 2597\n",
            "i0 5190 Increment: 30 >> New Balance: 2627\n",
            "i0 5192 Increment: 2 >> New Balance: 2629\n",
            "i0 5193 Increment: 9 >> New Balance: 2638\n",
            "i0 5196 Increment: 21 >> New Balance: 2659\n",
            "i0 5197 Increment: 11 >> New Balance: 2670\n",
            "i0 5199 Increment: 5 >> New Balance: 2675\n",
            ">>> Actual: -4 +ive: 0.53 -ive: 0.29 diff: 0.24\n",
            "i0 5211 Increment: -4 >> New Balance: 2671\n",
            "i0 5217 Increment: 1 >> New Balance: 2672\n",
            "i0 5222 Increment: 19 >> New Balance: 2691\n",
            "i0 5224 Increment: 3 >> New Balance: 2694\n",
            "i0 5225 Increment: 4 >> New Balance: 2698\n",
            "i0 5226 Increment: 3 >> New Balance: 2701\n",
            ">>> Actual: 0 +ive: 0.63 -ive: 0.22 diff: 0.41\n",
            "i0 5227 Increment: 0 >> New Balance: 2701\n",
            ">>> Actual: -1 +ive: 0.59 -ive: 0.2 diff: 0.39\n",
            "i0 5229 Increment: -1 >> New Balance: 2700\n",
            "i0 5235 Increment: 2 >> New Balance: 2702\n",
            "i0 5236 Increment: 3 >> New Balance: 2705\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.29 diff: 0.26\n",
            "i0 5237 Increment: 0 >> New Balance: 2705\n",
            ">>> Actual: -9 +ive: 0.61 -ive: 0.27 diff: 0.34\n",
            "i0 5240 Increment: -9 >> New Balance: 2696\n",
            ">>> Actual: -11 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 5244 Increment: -11 >> New Balance: 2685\n",
            "i0 5246 Increment: 3 >> New Balance: 2688\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.14 diff: 0.38\n",
            "i0 5247 Increment: 0 >> New Balance: 2688\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.26 diff: 0.25\n",
            "i0 5249 Increment: 0 >> New Balance: 2688\n",
            ">>> Actual: -1 +ive: 0.63 -ive: 0.18 diff: 0.45\n",
            "i0 5252 Increment: -1 >> New Balance: 2687\n",
            "i0 5259 Increment: 1 >> New Balance: 2688\n",
            ">>> Actual: -8 +ive: 0.56 -ive: 0.29 diff: 0.27\n",
            "i0 5270 Increment: -8 >> New Balance: 2680\n",
            ">>> Actual: -2 +ive: 0.55 -ive: 0.25 diff: 0.3\n",
            "i0 5274 Increment: -2 >> New Balance: 2678\n",
            ">>> Actual: -4 +ive: 0.56 -ive: 0.29 diff: 0.27\n",
            "i0 5275 Increment: -4 >> New Balance: 2674\n",
            ">>> Actual: -3 +ive: 0.55 -ive: 0.29 diff: 0.26\n",
            "i0 5276 Increment: -3 >> New Balance: 2671\n",
            "i0 5280 Increment: 3 >> New Balance: 2674\n",
            "i0 5281 Increment: 9 >> New Balance: 2683\n",
            "i0 5287 Increment: 1 >> New Balance: 2684\n",
            ">>> Actual: 0 +ive: 0.67 -ive: 0.19 diff: 0.48\n",
            "i0 5288 Increment: 0 >> New Balance: 2684\n",
            ">>> Actual: -8 +ive: 0.59 -ive: 0.27 diff: 0.32\n",
            "i0 5292 Increment: -8 >> New Balance: 2676\n",
            ">>> Actual: -2 +ive: 0.54 -ive: 0.25 diff: 0.29\n",
            "i0 5294 Increment: -2 >> New Balance: 2674\n",
            ">>> Actual: -3 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 5295 Increment: -3 >> New Balance: 2671\n",
            "i0 5301 Increment: 5 >> New Balance: 2676\n",
            ">>> Actual: -3 +ive: 0.56 -ive: 0.26 diff: 0.3\n",
            "i0 5311 Increment: -3 >> New Balance: 2673\n",
            ">>> Actual: -6 +ive: 0.53 -ive: 0.29 diff: 0.24\n",
            "i0 5318 Increment: -6 >> New Balance: 2667\n",
            "i0 5324 Increment: 1 >> New Balance: 2668\n",
            "i0 5325 Increment: 4 >> New Balance: 2672\n",
            "i0 5329 Increment: 2 >> New Balance: 2674\n",
            "i0 5330 Increment: 3 >> New Balance: 2677\n",
            "i0 5331 Increment: 4 >> New Balance: 2681\n",
            "i0 5337 Increment: 2 >> New Balance: 2683\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 5340 Increment: 0 >> New Balance: 2683\n",
            "i0 5344 Increment: 1 >> New Balance: 2684\n",
            "i0 5345 Increment: 5 >> New Balance: 2689\n",
            "i0 5346 Increment: 4 >> New Balance: 2693\n",
            "i0 5347 Increment: 3 >> New Balance: 2696\n",
            "i0 5348 Increment: 5 >> New Balance: 2701\n",
            "i0 5349 Increment: 7 >> New Balance: 2708\n",
            "i0 5351 Increment: 9 >> New Balance: 2717\n",
            "i0 5355 Increment: 1 >> New Balance: 2718\n",
            "i0 5360 Increment: 31 >> New Balance: 2749\n",
            "i0 5364 Increment: 41 >> New Balance: 2790\n",
            "i0 5365 Increment: 9 >> New Balance: 2799\n",
            "i0 5366 Increment: 13 >> New Balance: 2812\n",
            "i0 5367 Increment: 7 >> New Balance: 2819\n",
            "i0 5368 Increment: 2 >> New Balance: 2821\n",
            "i0 5369 Increment: 6 >> New Balance: 2827\n",
            "i0 5370 Increment: 2 >> New Balance: 2829\n",
            "i0 5371 Increment: 2 >> New Balance: 2831\n",
            ">>> Actual: -4 +ive: 0.58 -ive: 0.22 diff: 0.36\n",
            "i0 5377 Increment: -4 >> New Balance: 2827\n",
            "i0 5378 Increment: 7 >> New Balance: 2834\n",
            "i0 5379 Increment: 10 >> New Balance: 2844\n",
            "i0 5380 Increment: 12 >> New Balance: 2856\n",
            "i0 5381 Increment: 9 >> New Balance: 2865\n",
            "i0 5386 Increment: 3 >> New Balance: 2868\n",
            "i0 5391 Increment: 6 >> New Balance: 2874\n",
            "i0 5393 Increment: 1 >> New Balance: 2875\n",
            "i0 5396 Increment: 4 >> New Balance: 2879\n",
            "i0 5399 Increment: 2 >> New Balance: 2881\n",
            "i0 5400 Increment: 11 >> New Balance: 2892\n",
            "i0 5401 Increment: 13 >> New Balance: 2905\n",
            "i0 5402 Increment: 11 >> New Balance: 2916\n",
            "i0 5403 Increment: 11 >> New Balance: 2927\n",
            "i0 5404 Increment: 7 >> New Balance: 2934\n",
            "i0 5405 Increment: 4 >> New Balance: 2938\n",
            "i0 5406 Increment: 8 >> New Balance: 2946\n",
            "i0 5407 Increment: 3 >> New Balance: 2949\n",
            ">>> Actual: -4 +ive: 0.51 -ive: 0.25 diff: 0.26\n",
            "i0 5414 Increment: -4 >> New Balance: 2945\n",
            ">>> Actual: -7 +ive: 0.58 -ive: 0.28 diff: 0.3\n",
            "i0 5415 Increment: -7 >> New Balance: 2938\n",
            "i0 5416 Increment: 7 >> New Balance: 2945\n",
            ">>> Actual: 0 +ive: 0.57 -ive: 0.12 diff: 0.45\n",
            "i0 5424 Increment: 0 >> New Balance: 2945\n",
            ">>> Actual: -4 +ive: 0.61 -ive: 0.22 diff: 0.39\n",
            "i0 5430 Increment: -4 >> New Balance: 2941\n",
            ">>> Actual: -5 +ive: 0.55 -ive: 0.18 diff: 0.37\n",
            "i0 5432 Increment: -5 >> New Balance: 2936\n",
            ">>> Actual: -2 +ive: 0.52 -ive: 0.26 diff: 0.26\n",
            "i0 5435 Increment: -2 >> New Balance: 2934\n",
            "i0 5440 Increment: 2 >> New Balance: 2936\n",
            "i0 5446 Increment: 1 >> New Balance: 2937\n",
            "i0 5447 Increment: 4 >> New Balance: 2941\n",
            "i0 5448 Increment: 1 >> New Balance: 2942\n",
            "i0 5451 Increment: 4 >> New Balance: 2946\n",
            "i0 5452 Increment: 5 >> New Balance: 2951\n",
            "i0 5454 Increment: 6 >> New Balance: 2957\n",
            "i0 5459 Increment: 15 >> New Balance: 2972\n",
            "i0 5462 Increment: 11 >> New Balance: 2983\n",
            "i0 5464 Increment: 2 >> New Balance: 2985\n",
            "i0 5466 Increment: 1 >> New Balance: 2986\n",
            "i0 5476 Increment: 4 >> New Balance: 2990\n",
            "i0 5491 Increment: 18 >> New Balance: 3008\n",
            "i0 5495 Increment: 1 >> New Balance: 3009\n",
            "i0 5497 Increment: 4 >> New Balance: 3013\n",
            "i0 5499 Increment: 9 >> New Balance: 3022\n",
            "i0 5500 Increment: 12 >> New Balance: 3034\n",
            "i0 5505 Increment: 5 >> New Balance: 3039\n",
            "i0 5506 Increment: 2 >> New Balance: 3041\n",
            "i0 5514 Increment: 2 >> New Balance: 3043\n",
            "i0 5515 Increment: 5 >> New Balance: 3048\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.26 diff: 0.28\n",
            "i0 5518 Increment: 0 >> New Balance: 3048\n",
            ">>> Actual: -5 +ive: 0.56 -ive: 0.25 diff: 0.31\n",
            "i0 5523 Increment: -5 >> New Balance: 3043\n",
            ">>> Actual: -4 +ive: 0.54 -ive: 0.25 diff: 0.29\n",
            "i0 5531 Increment: -4 >> New Balance: 3039\n",
            "i0 5536 Increment: 3 >> New Balance: 3042\n",
            "i0 5539 Increment: 4 >> New Balance: 3046\n",
            "i0 5540 Increment: 4 >> New Balance: 3050\n",
            "i0 5542 Increment: 1 >> New Balance: 3051\n",
            ">>> Actual: -5 +ive: 0.64 -ive: 0.23 diff: 0.41\n",
            "i0 5543 Increment: -5 >> New Balance: 3046\n",
            "i0 5549 Increment: 1 >> New Balance: 3047\n",
            ">>> Actual: -3 +ive: 0.6 -ive: 0.15 diff: 0.45\n",
            "i0 5551 Increment: -3 >> New Balance: 3044\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.22 diff: 0.32\n",
            "i0 5554 Increment: 0 >> New Balance: 3044\n",
            "i0 5555 Increment: 1 >> New Balance: 3045\n",
            ">>> Actual: -5 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 5557 Increment: -5 >> New Balance: 3040\n",
            ">>> Actual: -6 +ive: 0.54 -ive: 0.27 diff: 0.27\n",
            "i0 5559 Increment: -6 >> New Balance: 3034\n",
            "i0 5576 Increment: 3 >> New Balance: 3037\n",
            "i0 5578 Increment: 3 >> New Balance: 3040\n",
            "i0 5579 Increment: 1 >> New Balance: 3041\n",
            "i0 5580 Increment: 4 >> New Balance: 3045\n",
            "i0 5581 Increment: 1 >> New Balance: 3046\n",
            "i0 5582 Increment: 1 >> New Balance: 3047\n",
            "i0 5587 Increment: 1 >> New Balance: 3048\n",
            "i0 5588 Increment: 4 >> New Balance: 3052\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.2 diff: 0.33\n",
            "i0 5589 Increment: 0 >> New Balance: 3052\n",
            "i0 5590 Increment: 4 >> New Balance: 3056\n",
            "i0 5592 Increment: 3 >> New Balance: 3059\n",
            "i0 5593 Increment: 2 >> New Balance: 3061\n",
            "i0 5602 Increment: 2 >> New Balance: 3063\n",
            "i0 5607 Increment: 7 >> New Balance: 3070\n",
            "i0 5609 Increment: 3 >> New Balance: 3073\n",
            "i0 5612 Increment: 9 >> New Balance: 3082\n",
            ">>> Actual: -3 +ive: 0.52 -ive: 0.28 diff: 0.24\n",
            "i0 5617 Increment: -3 >> New Balance: 3079\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.26 diff: 0.29\n",
            "i0 5619 Increment: 0 >> New Balance: 3079\n",
            ">>> Actual: -1 +ive: 0.53 -ive: 0.18 diff: 0.35\n",
            "i0 5620 Increment: -1 >> New Balance: 3078\n",
            ">>> Actual: 0 +ive: 0.64 -ive: 0.25 diff: 0.39\n",
            "i0 5622 Increment: 0 >> New Balance: 3078\n",
            "i0 5628 Increment: 1 >> New Balance: 3079\n",
            "i0 5638 Increment: 2 >> New Balance: 3081\n",
            "i0 5640 Increment: 1 >> New Balance: 3082\n",
            "i0 5642 Increment: 2 >> New Balance: 3084\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.28 diff: 0.24\n",
            "i0 5648 Increment: 0 >> New Balance: 3084\n",
            "i0 5654 Increment: 3 >> New Balance: 3087\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 5658 Increment: 0 >> New Balance: 3087\n",
            ">>> Actual: -1 +ive: 0.51 -ive: 0.23 diff: 0.28\n",
            "i0 5663 Increment: -1 >> New Balance: 3086\n",
            "i0 5674 Increment: 3 >> New Balance: 3089\n",
            "i0 5679 Increment: 3 >> New Balance: 3092\n",
            ">>> Actual: -7 +ive: 0.71 -ive: 0.27 diff: 0.44\n",
            "i0 5680 Increment: -7 >> New Balance: 3085\n",
            ">>> Actual: -7 +ive: 0.72 -ive: 0.21 diff: 0.51\n",
            "i0 5681 Increment: -7 >> New Balance: 3078\n",
            ">>> Actual: -7 +ive: 0.55 -ive: 0.26 diff: 0.29\n",
            "i0 5682 Increment: -7 >> New Balance: 3071\n",
            ">>> Actual: -1 +ive: 0.58 -ive: 0.24 diff: 0.34\n",
            "i0 5684 Increment: -1 >> New Balance: 3070\n",
            "i0 5685 Increment: 2 >> New Balance: 3072\n",
            ">>> Actual: -1 +ive: 0.54 -ive: 0.29 diff: 0.25\n",
            "i0 5688 Increment: -1 >> New Balance: 3071\n",
            ">>> Actual: -1 +ive: 0.61 -ive: 0.19 diff: 0.42\n",
            "i0 5693 Increment: -1 >> New Balance: 3070\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.24 diff: 0.28\n",
            "i0 5695 Increment: 0 >> New Balance: 3070\n",
            "i0 5699 Increment: 2 >> New Balance: 3072\n",
            "i0 5700 Increment: 2 >> New Balance: 3074\n",
            "i0 5701 Increment: 2 >> New Balance: 3076\n",
            "i0 5703 Increment: 1 >> New Balance: 3077\n",
            ">>> Actual: -2 +ive: 0.52 -ive: 0.2 diff: 0.32\n",
            "i0 5704 Increment: -2 >> New Balance: 3075\n",
            ">>> Actual: -3 +ive: 0.54 -ive: 0.21 diff: 0.33\n",
            "i0 5705 Increment: -3 >> New Balance: 3072\n",
            "i0 5708 Increment: 1 >> New Balance: 3073\n",
            "i0 5709 Increment: 3 >> New Balance: 3076\n",
            "i0 5713 Increment: 6 >> New Balance: 3082\n",
            "i0 5714 Increment: 2 >> New Balance: 3084\n",
            "i0 5715 Increment: 3 >> New Balance: 3087\n",
            "i0 5717 Increment: 7 >> New Balance: 3094\n",
            "i0 5720 Increment: 1 >> New Balance: 3095\n",
            ">>> Actual: -3 +ive: 0.53 -ive: 0.27 diff: 0.26\n",
            "i0 5726 Increment: -3 >> New Balance: 3092\n",
            ">>> Actual: -4 +ive: 0.52 -ive: 0.23 diff: 0.29\n",
            "i0 5728 Increment: -4 >> New Balance: 3088\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 5731 Increment: 0 >> New Balance: 3088\n",
            "i0 5755 Increment: 2 >> New Balance: 3090\n",
            "i0 5757 Increment: 6 >> New Balance: 3096\n",
            "i0 5759 Increment: 2 >> New Balance: 3098\n",
            ">>> Actual: 0 +ive: 0.58 -ive: 0.26 diff: 0.32\n",
            "i0 5761 Increment: 0 >> New Balance: 3098\n",
            ">>> Actual: -2 +ive: 0.53 -ive: 0.29 diff: 0.24\n",
            "i0 5768 Increment: -2 >> New Balance: 3096\n",
            ">>> Actual: -4 +ive: 0.54 -ive: 0.28 diff: 0.26\n",
            "i0 5769 Increment: -4 >> New Balance: 3092\n",
            "i0 5774 Increment: 8 >> New Balance: 3100\n",
            "i0 5776 Increment: 6 >> New Balance: 3106\n",
            "i0 5777 Increment: 6 >> New Balance: 3112\n",
            ">>> Actual: -1 +ive: 0.59 -ive: 0.23 diff: 0.36\n",
            "i0 5782 Increment: -1 >> New Balance: 3111\n",
            ">>> Actual: -2 +ive: 0.54 -ive: 0.25 diff: 0.29\n",
            "i0 5783 Increment: -2 >> New Balance: 3109\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.24 diff: 0.28\n",
            "i0 5788 Increment: 0 >> New Balance: 3109\n",
            "i0 5789 Increment: 2 >> New Balance: 3111\n",
            ">>> Actual: 0 +ive: 0.52 -ive: 0.26 diff: 0.26\n",
            "i0 5791 Increment: 0 >> New Balance: 3111\n",
            ">>> Actual: -1 +ive: 0.54 -ive: 0.26 diff: 0.28\n",
            "i0 5792 Increment: -1 >> New Balance: 3110\n",
            "i0 5813 Increment: 3 >> New Balance: 3113\n",
            "i0 5815 Increment: 2 >> New Balance: 3115\n",
            "i0 5818 Increment: 2 >> New Balance: 3117\n",
            "i0 5826 Increment: 3 >> New Balance: 3120\n",
            "i0 5828 Increment: 2 >> New Balance: 3122\n",
            "i0 5830 Increment: 1 >> New Balance: 3123\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.25 diff: 0.28\n",
            "i0 5831 Increment: 0 >> New Balance: 3123\n",
            ">>> Actual: -2 +ive: 0.56 -ive: 0.28 diff: 0.28\n",
            "i0 5832 Increment: -2 >> New Balance: 3121\n",
            ">>> Actual: 0 +ive: 0.57 -ive: 0.25 diff: 0.32\n",
            "i0 5834 Increment: 0 >> New Balance: 3121\n",
            "i0 5836 Increment: 2 >> New Balance: 3123\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.28 diff: 0.26\n",
            "i0 5837 Increment: 0 >> New Balance: 3123\n",
            "i0 5838 Increment: 3 >> New Balance: 3126\n",
            "i0 5839 Increment: 8 >> New Balance: 3134\n",
            "i0 5843 Increment: 3 >> New Balance: 3137\n",
            "i0 5844 Increment: 5 >> New Balance: 3142\n",
            ">>> Actual: -2 +ive: 0.56 -ive: 0.28 diff: 0.28\n",
            "i0 5846 Increment: -2 >> New Balance: 3140\n",
            "i0 5852 Increment: 3 >> New Balance: 3143\n",
            "i0 5855 Increment: 8 >> New Balance: 3151\n",
            "i0 5861 Increment: 4 >> New Balance: 3155\n",
            ">>> Actual: 0 +ive: 0.89 -ive: 0.28 diff: 0.61\n",
            "i0 5863 Increment: 0 >> New Balance: 3155\n",
            ">>> Actual: -2 +ive: 0.59 -ive: 0.24 diff: 0.35\n",
            "i0 5876 Increment: -2 >> New Balance: 3153\n",
            ">>> Actual: -4 +ive: 0.57 -ive: 0.26 diff: 0.31\n",
            "i0 5885 Increment: -4 >> New Balance: 3149\n",
            ">>> Actual: -4 +ive: 0.57 -ive: 0.27 diff: 0.3\n",
            "i0 5886 Increment: -4 >> New Balance: 3145\n",
            "i0 5888 Increment: 4 >> New Balance: 3149\n",
            "i0 5889 Increment: 9 >> New Balance: 3158\n",
            "i0 5890 Increment: 7 >> New Balance: 3165\n",
            "i0 5891 Increment: 3 >> New Balance: 3168\n",
            "i0 5895 Increment: 1 >> New Balance: 3169\n",
            "i0 5897 Increment: 6 >> New Balance: 3175\n",
            "i0 5898 Increment: 5 >> New Balance: 3180\n",
            ">>> Actual: 0 +ive: 0.56 -ive: 0.27 diff: 0.29\n",
            "i0 5904 Increment: 0 >> New Balance: 3180\n",
            ">>> Actual: -8 +ive: 0.58 -ive: 0.27 diff: 0.31\n",
            "i0 5906 Increment: -8 >> New Balance: 3172\n",
            ">>> Actual: -4 +ive: 0.51 -ive: 0.28 diff: 0.23\n",
            "i0 5907 Increment: -4 >> New Balance: 3168\n",
            ">>> Actual: -9 +ive: 0.56 -ive: 0.25 diff: 0.31\n",
            "i0 5908 Increment: -9 >> New Balance: 3159\n",
            "i0 5913 Increment: 5 >> New Balance: 3164\n",
            "i0 5920 Increment: 6 >> New Balance: 3170\n",
            "i0 5921 Increment: 1 >> New Balance: 3171\n",
            "i0 5922 Increment: 2 >> New Balance: 3173\n",
            "i0 5924 Increment: 4 >> New Balance: 3177\n",
            "i0 5925 Increment: 3 >> New Balance: 3180\n",
            "i0 5928 Increment: 1 >> New Balance: 3181\n",
            "i0 5929 Increment: 6 >> New Balance: 3187\n",
            "i0 5930 Increment: 6 >> New Balance: 3193\n",
            "i0 5931 Increment: 2 >> New Balance: 3195\n",
            "i0 5934 Increment: 2 >> New Balance: 3197\n",
            "i0 5935 Increment: 3 >> New Balance: 3200\n",
            "i0 5936 Increment: 2 >> New Balance: 3202\n",
            "i0 5939 Increment: 3 >> New Balance: 3205\n",
            ">>> Actual: 0 +ive: 0.69 -ive: 0.23 diff: 0.46\n",
            "i0 5940 Increment: 0 >> New Balance: 3205\n",
            ">>> Actual: 0 +ive: 0.55 -ive: 0.29 diff: 0.26\n",
            "i0 5951 Increment: 0 >> New Balance: 3205\n",
            ">>> Actual: 0 +ive: 0.53 -ive: 0.28 diff: 0.25\n",
            "i0 5954 Increment: 0 >> New Balance: 3205\n",
            "i0 5955 Increment: 1 >> New Balance: 3206\n",
            ">>> Actual: 0 +ive: 0.54 -ive: 0.29 diff: 0.25\n",
            "i0 5956 Increment: 0 >> New Balance: 3206\n",
            ">>> Actual: 0 +ive: 0.51 -ive: 0.29 diff: 0.22\n",
            "i0 5965 Increment: 0 >> New Balance: 3206\n",
            ">>> Actual: -1 +ive: 0.52 -ive: 0.27 diff: 0.25\n",
            "i0 5974 Increment: -1 >> New Balance: 3205\n",
            ">>> Actual: -2 +ive: 0.52 -ive: 0.16 diff: 0.36\n",
            "i0 5984 Increment: -2 >> New Balance: 3203\n",
            ">>> Actual: 0 +ive: 0.57 -ive: 0.26 diff: 0.31\n",
            "i0 5987 Increment: 0 >> New Balance: 3203\n",
            "i0 5990 Increment: 2 >> New Balance: 3205\n",
            "i0 5991 Increment: 21 >> New Balance: 3226\n",
            "i0 5992 Increment: 3 >> New Balance: 3229\n",
            "i0 5994 Increment: 13 >> New Balance: 3242\n",
            "start_i 6000 n_test 6000 n_top_preds 20 pos_threshold 0.5 neg_threshold 0.3 diff_threshold 0\n",
            "number of sells: 2044 good: 442 bad 153\n",
            "Final Balance: 3242\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#now testing to see the output of the rnn on actual data\n",
        "import torch, random\n",
        "\n",
        "dir_name=\"apple_models-history30\"\n",
        "dir_name=\"apple_models2\"\n",
        "#dir_name=\"apple_models-history10\"\n",
        "model_dir=os.path.join(cwd,dir_name) \n",
        "if not os.path.exists(model_dir): os.makedirs(model_dir)\n",
        "e0=49\n",
        "PATH=os.path.join(model_dir, \"model-%s.model\"%e0)\n",
        "\n",
        "# rnn = torch.load(PATH)\n",
        "# model.eval()\n",
        "checkpoint = torch.load(PATH)\n",
        "rnn.load_state_dict(checkpoint['model_state_dict'])\n",
        "rnn.eval()\n",
        "\n",
        "#rnn.load_state_dict()\n",
        "\n",
        "torch.manual_seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "start_i=6000\n",
        "n_test=6000\n",
        "pos_threshold=0.5\n",
        "neg_threshold=0.3\n",
        "diff_threshold=0\n",
        "n_top_preds=20\n",
        "\n",
        "balance=0\n",
        "n_sells=0\n",
        "good_sells=0  #gained more than 5%\n",
        "bad_sells=0  #lost more than 5%\n",
        "for i0,tr0 in enumerate(all_testing[start_i:start_i+n_test]):\n",
        "  input_list,output_list=tr0\n",
        "  input_oh=list2one_hot(input_list,mv_labels)\n",
        "  output_oh=list2one_hot(output_list,mv_labels)\n",
        "  input_tensor,output_tensor=torch.tensor(input_oh) , torch.tensor(output_oh).ravel()\n",
        "  rnn.hidden = rnn.init_hidden()\n",
        "  rnn.zero_grad()\n",
        "  rnn_output = rnn(input_tensor).ravel().tolist()\n",
        "  predictions=out2labels(rnn_output,mv_labels)\n",
        "  #print(\"Actual:\",output_list)\n",
        "  #print(len(predictions))\n",
        "  valid_preds=[]\n",
        "  selling_pts=[]\n",
        "  for ot,pd in zip(output_list,predictions):\n",
        "    if ot==\"\": continue\n",
        "    #if pd[0][0]==\"0\": continue\n",
        "    pred_positive,pred_negative=0,0\n",
        "    for p_ in pd[:n_top_preds]:\n",
        "      mv_str,mv_pred_val=p_\n",
        "      if mv_str==\"\" or mv_str==\"0\": continue\n",
        "      mv_int=int(mv_str)\n",
        "      if mv_int>0: pred_positive+=mv_pred_val\n",
        "      if mv_int<0: pred_negative+=mv_pred_val\n",
        "    pred_positive=round(pred_positive,2)\n",
        "    pred_negative=round(pred_negative,2)\n",
        "    diff_pos_neg=pred_positive-pred_negative\n",
        "    diff_pos_neg=round(diff_pos_neg,2)\n",
        "      \n",
        "    #if ot!=0: continue\n",
        "    #valid_preds.append((ot,pd))\n",
        "    tmp_pred=[(v[0],round(v[1],2)) for v in pd]\n",
        "    #test=[int(v[0]) for v in tmp_pred if v[0]!=\"\" and int(v[0])>0]\n",
        "    #print(\"Correct:\",ot, \"predicted:\", tmp_pred[:5], \", +ive:\", round(pred_positive,2), \", -ive:\", round(pred_negative,2))\n",
        "    if pred_positive>pos_threshold and pred_negative<neg_threshold and diff_pos_neg>diff_threshold: \n",
        "      #print(\"SELLING POINT - Correct:\",ot, \"predicted:\", tmp_pred[:5], \", +ive:\", round(pred_positive,2), \", -ive:\", round(pred_negative,2))\n",
        "      \n",
        "      selling_pts.append((int(ot), pred_positive,pred_negative,diff_pos_neg))\n",
        "\n",
        "    #print(test, tmp_pred)\n",
        "    # if len(test)>5 and ot!=0:\n",
        "    #   print(\"Correct:\",ot, \"predicted:\", tmp_pred)\n",
        "  #if len(valid_preds)==0: continue\n",
        "  #print(i0)\n",
        "  # print(\"input_list\",input_list)\n",
        "  # print(\"output_list\",output_list)\n",
        "  if selling_pts:\n",
        "    #print(i0)\n",
        "    selling_pts.sort(key=lambda x:-x[-1])\n",
        "    increment=selling_pts[0][0]\n",
        "    balance=balance+increment\n",
        "    n_sells+=1\n",
        "    if increment<=0:\n",
        "      for a,b,c,d in selling_pts[:1]:\n",
        "        print(\">>> Actual:\",a, \"+ive:\",b, \"-ive:\",c,\"diff:\",d)\n",
        "    if increment>=5:good_sells+=1\n",
        "    if increment<-5:bad_sells+=1\n",
        "    \n",
        "    print(\"i0\",i0, \"Increment:\",increment, \">> New Balance:\",balance)\n",
        "    #print(\"---------\")\n",
        "\n",
        "\n",
        "print(\"start_i\",start_i, \"n_test\",n_test, \"n_top_preds\",n_top_preds, \"pos_threshold\",pos_threshold, \"neg_threshold\",neg_threshold,\"diff_threshold\",diff_threshold)\n",
        "print(\"number of sells:\",n_sells, \"good:\",good_sells,\"bad\",bad_sells)\n",
        "print(\"Final Balance:\",balance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWIm7h4aDrUm",
        "outputId": "12fdfc73-8032-406d-edfc-639d922e750b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 2)\n",
            "torch.Size([1, 10])\n",
            "tensor([[0.8303, 0.1261, 0.9075, 0.8199, 0.9201, 0.1166, 0.1644, 0.7379, 0.0333,\n",
            "         0.9942]])\n",
            "torch_output: tensor([[ 0.0701, -0.2320, -0.1152,  0.1141,  0.1107, -0.1932,  0.0740,  0.1925,\n",
            "         -0.0370, -0.0561]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "#Initialize an PyTorch LSTM for comparison to our Numpy LSTM\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers=1):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_dim=hidden_dim\n",
        "        #LSTM Layer\n",
        "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)\n",
        "        #Final, fully-connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        batch_size = 1\n",
        "        # get LSTM outputs\n",
        "        lstm_output, (h,c) = self.lstm(x, hidden)\n",
        "        # shape output to be (batch_size*seq_length, hidden_dim)\n",
        "        lstm_output = lstm_output.view(-1, self.hidden_dim)  \n",
        "        \n",
        "        # get final output \n",
        "        model_output = self.fc(lstm_output)\n",
        "        \n",
        "        return model_output, (h,c)\n",
        "      \n",
        "torch.manual_seed(5)\n",
        "#rPyTorch expects an extra dimension for batch size:\n",
        "\n",
        "data = np.array(\n",
        "           [[1,1],\n",
        "            [2,2],\n",
        "            [3,3]])\n",
        "print(data.shape)\n",
        "data_test=torch.rand(1, 10)\n",
        "print(data_test.shape)\n",
        "print(data_test)\n",
        "input_size  = 10 # size of one 'event', or sample, in our batch of data\n",
        "n_hidden = hidden_dim  = 16 # 3 cells in the LSTM layer\n",
        "output_size = 10 # desired model output\n",
        "num_layers=2\n",
        "\n",
        "\n",
        "torch_lstm = LSTM(input_size = input_size, \n",
        "                 hidden_dim = hidden_dim,\n",
        "                 output_size = output_size,\n",
        "                  n_layers=num_layers\n",
        "                 )\n",
        "state = torch_lstm.state_dict()\n",
        "torch_batch = torch.Tensor(data_test).unsqueeze(0) \n",
        "torch_output, (torch_hidden, torch_cell) = torch_lstm(torch_batch, None)\n",
        "print(\"torch_output:\", torch_output)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-hewj39W5-n",
        "outputId": "96dcf573-9505-492e-b308-c04478666dab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-100 0.0\n",
            "-90 0.0\n",
            "-80 0.0\n",
            "-70 0.0\n",
            "-60 0.0\n",
            "-50 0.0\n",
            "-40 0.0\n",
            "-30 0.0\n",
            "-20 0.0\n",
            "-19 0.0\n",
            "-18 0.0\n",
            "-17 0.0\n",
            "-16 0.0\n",
            "-15 0.0\n",
            "-14 0.0\n",
            "-13 0.0\n",
            "-12 0.0\n",
            "-11 0.0\n",
            "-10 0.0\n",
            "-9 0.0\n",
            "-8 0.0\n",
            "-7 0.0\n",
            "-6 0.0\n",
            "-5 0.0\n",
            "-4 0.0\n",
            "-3 0.0\n",
            "-2 0.0\n",
            "-1 0.0\n",
            "0 0.0\n",
            "1 0.0\n",
            "2 0.0\n",
            "3 0.0\n",
            "4 0.0\n",
            "5 0.0\n",
            "6 0.0\n",
            "7 0.0\n",
            "8 0.0\n",
            "9 0.0\n",
            "10 0.0\n",
            "11 0.0\n",
            "12 0.0\n",
            "13 0.0\n",
            "14 0.0\n",
            "15 0.0\n",
            "16 0.0\n",
            "17 0.0\n",
            "18 0.0\n",
            "19 0.0\n",
            "20 0.0\n",
            "30 0.0\n",
            "40 0.0\n",
            "50 1.0\n",
            "60 0.0\n",
            "70 0.0\n",
            "80 0.0\n",
            "90 0.0\n",
            "100 0.0\n",
            " 0.0\n"
          ]
        }
      ],
      "source": [
        "test_out_array=get_array(50,labels)\n",
        "for a0,lb0 in zip(labels,test_out_array):\n",
        "  print(a0,lb0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3nZPZ46_c4Y",
        "outputId": "76089a2b-c472-4524-f010-15c34c9ae05d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  inflating: stock_market_data/nasdaq/json/DLHC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DLTR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DMFG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DMLP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DMND.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DMRC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DORM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DOVR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DOX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DPRX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DRIV.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DRNA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DRRX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DRWI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DSCI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DSCO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DSGX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DSKY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DSWL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DTLK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DTSI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DVAX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DWA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DWCH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DWSN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DXCM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DXLG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DXM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DXPE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DXYN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DYAX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DYNT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/DYSL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EAC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EBAY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EBIO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EBIX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EBMT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EBTC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ECOL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ECPG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ECYT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EDAP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EDF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EDGW.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EDI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EDSFF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EDUC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EEFT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EFLVF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EFOI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EFSC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EGAN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EGBN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EGHT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EGLE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EGRX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EGT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EHTH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ELNK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ELON.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ELOS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ELRC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ELTK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EMCF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EMF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EMITF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EMKR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EML.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EMMS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ENBP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ENDP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ENOC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ENPH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ENSG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ENTA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ENTG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ENTR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ENVI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ENZN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ENZY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EOPN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EPAM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EPAX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EPAY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EPRS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EPZM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EQIX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ERIE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ERII.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EROC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ERS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ESBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ESCA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ESCR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ESEA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ESGR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ESIO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ESLT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ESMC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ESPR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ESRX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ESSA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ESSX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ETOLF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ETRM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EVAR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EVBS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EVEP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EVLV.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EVOK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EVOL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EWBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EXA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EXAC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EXAS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EXEL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EXLP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EXLS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EXPD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EXPE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EXPO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EXTR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EYES.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EZCH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/EZPW.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FALC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FAM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FANG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FARM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FARO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FAST.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FATE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FAV.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FBIZ.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FBMS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FBP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FBRC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FCAP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FCBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FCCO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FCCY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FCEL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FCLF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FCMGF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FCNCA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FCS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FCT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FCTY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FCVA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FCZA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FDUS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FEI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FEIC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FEIM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FELE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FES.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FFA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FFBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FFHL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FFIC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FFIN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FFIV.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FFKT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FFNM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FFNW.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FFWM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FGEN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FIBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FIF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FINL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FISI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FISV.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FITB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FIVE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FIVN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FIZZ.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FLDM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FLIC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FLL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FLXS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FMBI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FMER.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FMI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FMNB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FMY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FNBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FNFG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FNHC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FNLC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FNRG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FOLD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FONR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FORD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FORM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FORR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FORTY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FOSL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FOXF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FRBA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FRBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FREE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FRGI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FRME.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FRP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FRPH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FRPT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FRSH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FSBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FSBW.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FSC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FSD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FSFF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FSFG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FSFR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FSGI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FSLR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FSTR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FTEK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FTNT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FUEL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FULL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FULT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FUNC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FUND.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FWM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FWP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FWRD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FXCB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/FXEN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GABC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GAIA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GAIN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GALE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GALT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GAME.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GASS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GBCI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GBDC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GBIM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GBLI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GBLX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GBNK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GBSN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GCBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GCRIF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GDEF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GENC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GENE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GEOS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GERN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GEVA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GEVO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GFED.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GGACU.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GGAL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GIFI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GIGM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GILD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GILT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GKNT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GLAD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GLBD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GLBS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GLBZ.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GLDC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GLDD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GLMD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GLNG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GLNIF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GLPI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GLRI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GLYC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GMAN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GMCR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GNBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GNCA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GNCMA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GNCNF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GNOW.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GNSG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GNSZ.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GNTX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GNVC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GOGO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GOLD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GOOD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GPOR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GPRE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GPRO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GPS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GRBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GRFS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GRMN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GROW.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GRPN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GRSFF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GSBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GSIG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GSIT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GSOL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GTIM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GTLS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GTWN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GUID.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GULTU.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GURE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/GWGH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HAFC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HAIN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HALL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HALO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HART.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HAS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HAWK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HAYN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HBAN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HBCP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HBHC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HBIO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HBMD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HBNC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HBNK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HBOS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HBP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HCBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HCFB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HCKT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HCOM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HCSG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HDNG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HDP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HDSN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HEAR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HEES.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HELE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HEOP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HERO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HES.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HFBL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HFFC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HFWA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HGSH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HIBB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HIFS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HIHO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HILL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HIMX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HKTV.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HLIT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HLSS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HMHC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HMIN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HMNF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HMNY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HMPR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HMST.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HMTV.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HNH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HNNA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HNRDF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HNRG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HNSN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HOFT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HOLI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HOLX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HOTR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HOV.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HPCQ.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HPTX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HQCL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HQY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HRGP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HRTX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HRZN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HSIC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HSII.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HSKA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HSNI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HSON.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HSTM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HTBI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HTBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HTBX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HTCH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HTHT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HTLD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HTLF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HTWR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HUBG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HURC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HURN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HWBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HWKN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/HZNB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IAC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IART.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IBCA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IBCP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IBKR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IBOC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IBTX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ICCC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ICEL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ICFI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ICLD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ICPT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ICUI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IDCC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IDRA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IDXX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IEP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IFON.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IGLD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IGLU.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IGOI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IGTE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IHD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/III.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IIIN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IIN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IKAN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IKGH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ILMN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IMGN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IMIAY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IMKTA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IMMR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IMMY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IMOS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IMRS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/INBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/INCR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/INCY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/INDB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/INFA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/INFI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/INFN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/INGN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ININ.json  \n",
            "  inflating: stock_market_data/nasdaq/json/INO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/INOD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/INSA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/INTC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/INTG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/INTU.json  \n",
            "  inflating: stock_market_data/nasdaq/json/INTX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/INVE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/INVT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IOSP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IPAR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IPAS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IPCC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IPCM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IPDN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IPGP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IPWR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IPXL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IQNT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IRBT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IRDM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IRG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IRIX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IRMD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IROQ.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IRWD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ISBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ISIG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ISIL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ISIS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ISLE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ISPTF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ISRG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ISSC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ISSI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ISTR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ITI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ITIC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ITRI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ITRN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ITSXF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IUSPF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IUTCF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IUTSF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IVAC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/IXYS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JACK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JAKK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JBHT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JBLU.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JBSS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JCS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JIVE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JJSF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JKHY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JMBA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JOBS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JOUT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JPM-PC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JRJC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JRVR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JSD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JST.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JTPY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JUNO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JVA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JXSB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/JYNT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KALU.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KANG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KBAL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KBIOQ.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KCLI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KELYA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KEQU.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KERX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KEYW.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KFFB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KFRC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KFX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KGJI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KINS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KIRK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KITE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KLIC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KLXI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KMDA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KNDI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KONE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KOPN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KOSS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KPTI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KRNY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KTCC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KTEC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KTOS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KTWO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KUTV.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KVHI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KYTH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/KZ.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LABC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LACO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LAKE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LAMR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LANC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LAND.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LARK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LAWS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LAYN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LBAI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LBIX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LBRDA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LBTYA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LCUT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LDRH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LECO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LEDS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LFUS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LFVN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LGCY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LGIH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LGND.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LILA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LIME.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LINC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LINE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LION.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LIOX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LIQD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LJPC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LKFN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LKQ.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LLNW.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LLTC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LMAT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LMDCF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LMIA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LMNR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LMOS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LMRK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LNBB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LNCO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LNDC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LOAN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LOCM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LOCO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LOGI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LOJN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LONG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LOOK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LOPE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LPCN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LPHIQ.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LPLA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LPNT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LPSB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LPSN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LPTH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LPTN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LQDT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LRCX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LSBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LSCC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LSTR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LTBR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LTRE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LTRPA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LTRX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LULU.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LUNA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LVWD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LWAY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LXRX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/LYTS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MACK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MANH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MANT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MAR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MARA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MARPS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MASI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MAT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MATR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MATW.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MAYS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MBCN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MBII.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MBRG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MBUU.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MBVT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MBWM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MCBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MCBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MCCK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MCFUF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MCGC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MCHP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MCHX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MCOA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MCOX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MCRI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MCUR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MDAS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MDLZ.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MDM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MDRX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MDVN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MDWD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MDXG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MEIL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MEIP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MELI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MEMP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MENT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MEOH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MERC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MERU.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MET.json  \n",
            "  inflating: stock_market_data/nasdaq/json/METR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MFRM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MGCD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MGEE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MGI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MGIC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MGLN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MGN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MGNX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MGPI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MGRC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MGYR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MHGC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MHLD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MICT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MIDD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MIFI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MIND.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MITK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MITL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MKSI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MKTO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MKTX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MLAB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MLNK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MLVF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MMLP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MMS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MMSI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MMU.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MMYT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MNDO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MNKD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MNOV.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MNRK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MNRO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MNST.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MNTX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MOBL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MOCO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MOFG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MOG-A.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MOLG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MOMO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MORN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MOSY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MPAA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MPB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MPEL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MPET.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MPWR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MRCC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MRCY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MRKT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MRLN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MRNS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MRTN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MRTX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MRVC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MRVL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MSCC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MSEX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MSFG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MSFT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MSLI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MSTR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MTBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MTEX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MTLS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MTRX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MTSN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MU.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MVIS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MWIV.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MYGN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MYRG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/MZOR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NAII.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NAME.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NATH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NATI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NATL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NATR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NAUH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NBBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NBIX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NBN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NBS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NBTB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NCIT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NCLH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NCLIP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NCMI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NCTY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NDLS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NDRM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NDSN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NECB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NEO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NEOG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NEON.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NEOT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NEPT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NERV.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NEWS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NEWT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NFEC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NFLX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NHTB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NICE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NICK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NILE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NKSH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NKTR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NLST.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NMIH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NMRX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NNBR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NOXL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NPBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NPSP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NRCIB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NRIM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NRX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NSEC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NSIT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NSPH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NSSC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NSTG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NSYS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NTAP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NTCT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NTES.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NTGR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NTIC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NTK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NTLS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NTRS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NTWK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NUAN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NURO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NUTR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NUVA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NVAX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NVCN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NVDA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NVDQ.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NVEC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NVFY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NVGN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NVMI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NVSL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NWBI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NWBO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NWFL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NWPX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NWSA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NXPI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NYMT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/NYMX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OBAS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OBCI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OCC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OCFC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OCLR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OCRX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OCUL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ODFL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ODP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OFED.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OFIX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OFLX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OFS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OGXI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OIIM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OIS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OKE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OKSB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OLED.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OMAB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OMCL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OMER.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OMEX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OMF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OMRNY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ON.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ONB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ONCY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ONEQ.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ONFC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ONTX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ONTY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ONVI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OPHC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OPOF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OPTT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OPXA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OREX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ORIG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ORLY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ORMP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ORRF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OSBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OSHC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OSIS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OSTK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OSUR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OTEX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OTIC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OTTR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OUTR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OVAS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OVBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OVLY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OVTI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OXBR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/OXLC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PAAS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PACB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PACW.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PAHC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PANL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PAOTF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PARN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PATI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PATK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PAYX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PBCP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PBCT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PBHC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PBIB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PBIP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PBMD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PBPB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PBSK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PCAR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PCBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PCCC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PCH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PCLN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PCO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PCOM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PCRX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PCTY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PCYC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PCYG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PCYO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PDCE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PDCO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PDFS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PEBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PEBO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PEGA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PENN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PENX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PEOP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PERF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PERI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PERY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PETM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PETS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PFBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PFBX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PFIE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PFIN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PFIS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PFLT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PFMT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PFSW.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PHI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PHMD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PINC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PKBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PKT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PLAB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PLAY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PLBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PLCE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PLCM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PLKI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PLMT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PLNR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PLPC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PLPL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PLPM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PLUG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PLUS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PLXS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PMD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PME.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PMFG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PNBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PNFP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PNNT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PNRA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PNRG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PODD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/POLMF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/POOL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/POWI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/POWL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PPBI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PPC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PPG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PPHM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PPSI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PRAA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PRAY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PREC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PRFT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PRGN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PRGS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PRIM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PRKR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PRLS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PRMW.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PROV.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PRPH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PRQR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PRSS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PRTA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PRTK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PRTS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PRXI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PRXL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PSBQ.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PSDV.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PSEC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PSEM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PSIX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PSMT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PSO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PSTB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PSTI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PSTR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PSUN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PTC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PTCT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PTNR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PTRY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PTSI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PULB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PVTB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PWOD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PWRD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PWX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PXLW.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PYS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/PZZA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/QBAK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/QCCO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/QCOM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/QCRH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/QDEL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/QIFTF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/QKLS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/QLIK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/QLTY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/QLYS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/QNST.json  \n",
            "  inflating: stock_market_data/nasdaq/json/QRHC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/QRVO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/QSII.json  \n",
            "  inflating: stock_market_data/nasdaq/json/QTNT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/QTWW.json  \n",
            "  inflating: stock_market_data/nasdaq/json/QUIK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/QUMU.json  \n",
            "  inflating: stock_market_data/nasdaq/json/QUNR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/QURE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RADA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RAIL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RAND.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RARE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RAVE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RBCAA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RBCF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RBCN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RBPAA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RCKY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RCMT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RCON.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RCPI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RCPT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RDCM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RDEN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RDHL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RDI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RDNT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RDUS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RDWR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/REDF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/REFR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/REGI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/REGN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/REIS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RELL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RELV.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RENT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/REPH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RESN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/REXI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/REXX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RFIL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RGCO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RGDX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RGEN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RGLD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RGLS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RGS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RHDGF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RIBT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RICK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RIGL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RITT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RIVR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RJET.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RLJE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RLOC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RLOG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RLYP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RMBS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RMCF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RMGN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RMTI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RNST.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RNWK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ROCK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ROIA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ROIC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ROKA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ROLL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ROSG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ROST.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ROYL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RPRX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RPTP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RRD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RRGB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RSYS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RTK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RUSHA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RUTH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RVBD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RVNC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RVSB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RWLK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RWMI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RXDX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RXII.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RYAAY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/RYI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/S.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SAAS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SABR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SAFM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SAFT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SAGE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SAIA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SAJA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SAL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SALE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SAMG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SANM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SANW.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SASR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SATS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SAVE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SBAC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SBAY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SBCF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SBCP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SBFG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SBGI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SBLK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SBNY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SBRA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SBSA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SBSI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SBUX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SCAI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SCHL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SCHN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SCLN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SCOK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SCOR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SCSC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SCSS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SCTY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SCVL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SCYT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SCYX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SDAD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SEAC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SEED.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SEIC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SEMI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SENEB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SEV.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SFBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SFBS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SFM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SFNC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SFST.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SFXE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SGBI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SGBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SGC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SGEN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SGI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SGMA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SGMS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SGNL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SGNT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SGRP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SHBI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SHEN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SHERF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SHIP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SHLD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SHLM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SHOO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SHOR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SHPG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SIBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SIBE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SIEB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SIEN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SIFI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SIFY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SIGAQ.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SIGI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SILC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SIMG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SIMO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SIRI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SIRO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SIVB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SIXD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SKPI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SKUL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SKYAY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SKYS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SKYW.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SLAB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SLGN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SLM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SLP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SLRC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SLTC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SLVM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SLXP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SMBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SMCI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SMED.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SMIT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SMLR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SMMF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SMRT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SMSI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SMTC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SNAK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SNBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SNC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SNCR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SNFCA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SNMX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SNPS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SNSGF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SNTA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SOCB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SODA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SOFO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SOHO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SOHU.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SONC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SONS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SPCB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SPDC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SPHS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SPIL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SPLK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SPLS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SPNC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SPNS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SPOK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SPPI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SPRO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SPSC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SPTN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SPWH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SPWR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SPXX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SQI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SQNM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SRCE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SRCL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SRDX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SREV.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SRNE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SRPT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SSB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SSBI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SSH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SSNC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SSRG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SSYS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/STAA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/STBA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/STBZ.json  \n",
            "  inflating: stock_market_data/nasdaq/json/STEM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/STFC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/STKL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/STLD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/STLY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/STNR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/STRA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/STRL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/STRM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/STRN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/STRS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/STRZA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/STX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/STXS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SUBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SUMR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SUNS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SUPN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SURG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SUSQ.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SUTR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SVA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SVVC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SWIR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SWKS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SWSH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SYBT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SYMX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SYNA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SYNL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SYNT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SYPR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SYUT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/SZMK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TACT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TAIT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TASR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TAST.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TATT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TAXI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TAYD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TBBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TBNK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TBPH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TCB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TCBI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TCBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TCCO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TCFC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TCPC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TCX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TECU.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TEDU.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TEI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TENX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TESO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TESS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TFM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TGA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TGEN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TGLS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TGTX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/THFF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/THLD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/THRX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TICC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TIGR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TILE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TITN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TKAI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TLMR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TLOG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TNDM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TNGO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TNP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TNXP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TOPS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TORM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TOUR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TOWN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TPIL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TRAK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TREE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TRGT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TRIB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TRIP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TRIV.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TRMK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TRNS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TROW.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TRS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TRST.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TRUE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TRVN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TRYF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TSBK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TSC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TSCO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TSEM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TSRE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TSRI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TSSI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TSYS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TTEC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TTEK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TTGT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TTHI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TTMI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TTOO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TUBE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TWER.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TWIN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TWOU.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TXN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TXRH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TYL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/TZOO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UACL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UBCP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UBFO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UBOH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UBSI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UCBA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UCBI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UCP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UCTT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UDF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UEIC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UEPS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UFCS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UFPI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UFPT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UHS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UIHC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ULBI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ULTR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UMBF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UMPQ.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UNAM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UNB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UNFI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UNIS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UNTD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UNTY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UPLD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/URBN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/URRE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/USAK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/USAP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/USEG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/USLM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/USMD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/USTR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UTEK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UTHR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UTIW.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UTMD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UTSI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/UVSP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/V.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VALU.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VASC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VBFC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VBIV.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VBLT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VBTX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VCEL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VCYT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VDSI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VECO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VIAS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VICR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VIDE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VIEWF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VIVO.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VLGEA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VLNSF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VLY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VNDA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VNET.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VNOM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VNR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VOD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VOLC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VOXX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VRA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VRHD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VRNG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VRNS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VRNT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VRSK.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VRSN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VRTB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VRTS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VRTX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VSAR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VSAT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VSCP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VSEC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VSTM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VTAE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VTNR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VTR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VWR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/VYFC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WABC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WAFD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WASH.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WATT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WAVX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WAYN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WBA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WBB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WBKC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WBMD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WDC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WEB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WEN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WERN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WETF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WEYS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WFBI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WFM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WGBS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WHF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WHLM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WHLR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WIBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WINA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WIRE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WIX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WLB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WLDN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WLFC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WLKR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WMAR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WNDLF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WOOF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WPCS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WPPGY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WRES.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WRLD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WSBC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WSBF.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WSCI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WSFS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WSTC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WSTG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WSTL.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WTBA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WTFC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WVFC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WVVI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WWD.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WWSG.json  \n",
            "  inflating: stock_market_data/nasdaq/json/WYNN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/XBKS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/XCRA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/XENE.json  \n",
            "  inflating: stock_market_data/nasdaq/json/XENT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/XLNX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/XNCR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/XNET.json  \n",
            "  inflating: stock_market_data/nasdaq/json/XNPT.json  \n",
            "  inflating: stock_market_data/nasdaq/json/XOMA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/XOOM.json  \n",
            "  inflating: stock_market_data/nasdaq/json/XPLR.json  \n",
            "  inflating: stock_market_data/nasdaq/json/XTLB.json  \n",
            "  inflating: stock_market_data/nasdaq/json/XXIA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/YNDX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/YORW.json  \n",
            "  inflating: stock_market_data/nasdaq/json/YOSN.json  \n",
            "  inflating: stock_market_data/nasdaq/json/YY.json  \n",
            "  inflating: stock_market_data/nasdaq/json/Z.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ZAZA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ZBRA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ZEUS.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ZGNX.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ZINC.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ZION.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ZIOP.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ZIXI.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ZLTQ.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ZNGA.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ZOES.json  \n",
            "  inflating: stock_market_data/nasdaq/json/ZUMZ.json  \n",
            "  inflating: stock_market_data/nyse/csv/AAC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AAP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AAT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ABC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ABG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ABM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ABR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ABT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ACC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ACG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ACGL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ACH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ACP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ACRE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ADC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ADPT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ADS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AEL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AEM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AEO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AEP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AER.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AFB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AFG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AFSI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AFT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AGD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AGI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AGM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AGO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AGRO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AHH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AHL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AHT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AIF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AIG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AINV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AIT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AIV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AJG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AKO-A.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AKR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ALEX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ALK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ALL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ALLE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ALLY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ALSN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AMC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AME.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AMG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AMH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AMIVF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AMP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AMT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AMTD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ANET.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ANF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ANR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AOD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/APAM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/APB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/APD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/APL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ARAH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ARC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ARCC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ARCO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ARDC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ARE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ARHVF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ARI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ARL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ARR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ARW.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ASA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ASB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ASC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ASGN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ASPN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ASR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ASX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ATEN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ATI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ATO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ATW.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AU.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AUTR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AVB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AVD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AVK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AVY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AWF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AWH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AWK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AWR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AXL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AXP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AXTA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/AZN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BAH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BAK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BALT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BAM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BAP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BBL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BBVA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BCC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BCS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BCX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BDCZ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BDJ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BDN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BDX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BEN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BEP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BERY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BFAM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BFK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BFZ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BGB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BGC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BGR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BGT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BGX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BHE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BHK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BHLB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BHP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BIF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BIP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BJZ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BKD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BKN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BKT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BLH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BLK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BLW.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BLX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BME.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BMO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BMS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BNCM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BNJ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BNY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BOH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BOOT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BPK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BPT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BRFS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BRK-A.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BRO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BRP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BRX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BSAC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BSL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BST.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BSX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BTF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BTO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BTSGY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BTU.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BTZ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BUI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BURL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BWG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BWMG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BWP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BXC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BXMT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BXMX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BXP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BYM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/BZH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/C-PK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CAF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CAH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CBA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CBD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CBI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CBL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CBU.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CCI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CCK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CCM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CCS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CCU.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CCZ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CDR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CEA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CEE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CEM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CEN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CEO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CEQP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CFG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CFR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CGA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CHCO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CHD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CHE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CHH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CHMI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CHNR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CHS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CHT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CIB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CIF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CII.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CIM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CIO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CIR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CIVI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CLB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CLH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CLR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CLW.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CMC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CMCSA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CMG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CMP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CMS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CNHI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CNI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CNO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CNP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CNQ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CNS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CNX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CODI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/COF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/COL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/COP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/COR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CORR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CPB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CPE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CPF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CPG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CPK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CPT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CRC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CRD-B.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CRK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CRL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CRS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CRT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CSH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CSL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CSLT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CSTM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CSV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CTR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CTT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CUBI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CUDA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CUK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CUPUF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CUZ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CVE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CWT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CXE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CXH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CYD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CYH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/CYS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DAL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DAR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DBL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DCI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DCO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DCT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DDF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DDS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DDT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DECK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DEI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DEL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DEX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DFS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DGX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DHF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DHG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DHI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DHT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DIAX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DKS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DLB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DLNG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DLR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DMB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DMO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DNB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DNP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DOMR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DOOR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DPG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DPSGY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DPZ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DRH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DRI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DRLCQ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DSL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DSM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DST.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DSU.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DSX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DTE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DTK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DVD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DVN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/DY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EARN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EAT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EBS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ED.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EDD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EDF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EDI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EEA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EFR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EFT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EGF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EGL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EGO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EGP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EHI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EIG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EIX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ELP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ELS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ELY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EME.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EMF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EMN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EMO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EMR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ENVA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EOD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EOG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EOS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EPAM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EPD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EPR-PC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EPR-PE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EPR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EQS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ESI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ESNT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ESRT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ESS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ETN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ETP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ETX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EVC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EVER.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EVF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EVN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EVR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EVT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EW.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EXC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EXP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/EXR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/F.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FBC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FBHS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FBP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FBR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FCB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FCF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FCN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FCT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FDP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FDS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FEI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FEO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FET.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FFA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FFC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FGB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FHN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FIF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FIS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FIX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FLC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FLO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FLT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FMN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FMS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FMX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FMY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FNF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FOR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FPF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FPL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FPRUF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FRA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FRO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FRT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FSD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FSM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FSS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FTK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FUL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/FUN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/G.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GAB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GAIN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GAM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GBX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GCH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GCV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GDO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GDV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GEL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GER.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GGZ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GHC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GHY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GIM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GIS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GJS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GLF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GLOB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GLW.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GMED.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GNE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GNRC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GNT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GNW.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GOF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GPC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GPI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GPK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GPN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GPT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GRR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GRX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GS-PJ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GSK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GSL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GTN-A.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GUT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GVA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GWB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GWRE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GWW.csv  \n",
            "  inflating: stock_market_data/nyse/csv/GXP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HAL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HASI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HDB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HEP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HEQ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HFC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HIE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HIG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HII.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HIL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HIO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HIVE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HIW.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HIX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HLF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HLT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HLX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HMC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HMN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HMY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HNP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HON.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HOT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HOV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HPF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HPP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HPS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HQH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HQL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HRL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HRTG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HRZN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HSBC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HST.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HSY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HTA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HTD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HTH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HTZ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HVT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HYB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HYI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/HYT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IBA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IBM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IBN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IBP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ICB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ICD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ICE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ICL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IDE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IFF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IGA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IGD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IGI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IGR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IGT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IHC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IHD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IIF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IIM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/INGR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/INN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/INT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IPG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IPI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IQI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IRL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IRM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IRS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ISD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ITW.csv  \n",
            "  inflating: stock_market_data/nyse/csv/IVR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JAZZ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JBT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JCS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JEQ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JFR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JGH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JHI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JHS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JLL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JNJ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JNPR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JOB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JOF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JPC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JPI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JPM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JQC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JRI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JRO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JSD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/JW-A.csv  \n",
            "  inflating: stock_market_data/nyse/csv/K.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KAR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KED.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KEP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KEYS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KFS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KFY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KIO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KMF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KMG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KMPR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KMX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KND.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KNX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KODK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KOF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KOS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KRC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KRG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KRO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KSM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KST.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KSU.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KTF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KWR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KYE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/KYN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LAD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LADR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LBBB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LDOS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LDP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LEE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LEG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LEN-B.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LEO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LEU.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LFC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LGI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LHO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LII.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LLY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LMT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LNC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LNT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LOW.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LPG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LPI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LQ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LTC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LUV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LVS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LXP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LXU.csv  \n",
            "  inflating: stock_market_data/nyse/csv/LYV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MAIN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MAN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MAV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MCA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MCN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MCR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MCY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MDC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MDU.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MEG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MEI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MFA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MFC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MFG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MFL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MFM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MFV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MGA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MGF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MGM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MGU.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MHD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MHF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MHI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MHK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MHLD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MHN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MHNC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MIG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MIN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MITT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MIY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MKC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MLI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MLM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MLP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MLR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MMC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MMD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MMI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MMP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MMT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MMU.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MNP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MNR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MOD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MOH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MOV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MPA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MPC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MPRWP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MPV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MPW.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MPX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MQT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MQY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MRIN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MS-PF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MSA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MSB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MSD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MSFG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MSI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MSM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MTDR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MTG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MTN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MTR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MTRN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MTX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MUA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MUC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MUE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MUI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MUJ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MUSA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MUX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MVT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MXCHF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MXE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MYC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MYD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MYE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MYI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MYJ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MYN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/MZF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NAT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NBB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NBD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NBHC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NBR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NCA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NCV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NCZ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NDP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NEE-PP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NEE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NEM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NEU.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NEV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NFG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NFJ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NFX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NGS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NGVC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NHI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NID.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NIE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NIM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NIO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NIQ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NJR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NLY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NMFC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NMI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NMS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NNY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NOA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NOAH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NOC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NORNQ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NOV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NPK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NPO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NPTN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NRP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NRT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NRZ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NSC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NSL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NSM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NSS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NTP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NTZ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NUS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NUV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NVO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NWN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NXC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NXN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NXRT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NYCB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/NYRT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/OAS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/OB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/OCN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/OEC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/OFC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/OHI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/OIA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/OII.csv  \n",
            "  inflating: stock_market_data/nyse/csv/OIS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/OLP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/OMC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/OMI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ONE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ORAN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ORC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ORI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/OXM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/OXY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/P.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PAA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PAG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PAI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PAM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PANW.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PAR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PAY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PAYC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PBA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PBH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PBI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PBR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PBT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PBYI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PCF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PCN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PCQ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PDI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PDM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PDS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PDT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PEB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PEG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PEI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PFD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PFG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PFN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PFO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PFS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PFSI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PGEM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PGH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PGRE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PGZ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PHG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PHX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PII.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PIM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PKG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PKI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PLOW.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PMF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PMM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PMO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PMT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PMX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PNC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PNF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PNK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PNNT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PNW.csv  \n",
            "  inflating: stock_market_data/nyse/csv/POR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/POST.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PPG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PPT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PRGO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PRLB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PRO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PRU.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PSA-PQ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PSA-PR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PSB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PSEC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PSF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PSX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PTR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PTY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PVG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PWR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PXD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PYN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PYS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PZC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PZE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/PZN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/QSR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/QTWO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/R.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RBA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RCI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RCL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RCS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RDY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/REG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RESI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/REX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/REXR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RFI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RFIL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RFP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RGA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RGC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RGR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RGT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RHI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RHP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RJF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RLGY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RMAX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RNP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RNR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ROC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ROK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RPM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RQI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RRC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RRTS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RSG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RSPP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RVT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RWT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RYAM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/RYI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SAH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SAM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SAN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SAP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SAR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SBR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SBS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SCCO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SCD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SCI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SEAS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SEM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SFE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SFL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SGF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SGU.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SHG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SHI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SID.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SIG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SIGI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SIX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SJI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SJR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SJT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SKM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SKT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SKX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SLB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SLCA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SLF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SMG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SMI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SMP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SNI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SNOW.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SNP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SNV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SOCGM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SON.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SOR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SPB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SPE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SPG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SPH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SPLP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SPR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SPXX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SQM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SRC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SRE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SSD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SSTK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ST.csv  \n",
            "  inflating: stock_market_data/nyse/csv/STAG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/STC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/STL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/STM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/STNG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/STOR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/STRI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/STT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/STWD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/STZ-B.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SU.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SUI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SUP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SWK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SWN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SWZ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SXC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SXI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SXT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/SYF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/T.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TAC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TAP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TARO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TCI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TCPTF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TDF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TDG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TDS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TDY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TEI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TEO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TEUFF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TEVA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TGH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TGI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TGP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TGS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/THG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/THLEF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/THO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/THQ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/THR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/THS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TKC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TLK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TMHC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TMO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TMST.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TNC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TNH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TNK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TNP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TOL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TPC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TPL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TPPPF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TPVG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TPX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TPZ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TRC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TREC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TRI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TRMR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TRN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TRNO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TRQ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TRV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TSE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TSI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TSLX.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TSM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TSQ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TTM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TTP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TUP.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TVE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TVPT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TW.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TWI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TWO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/TYG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/UAL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/UBA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/UHS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/UHT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/UL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/UMC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/UMH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/UNH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/UNM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/UPS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/URI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/USM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/USNA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/USPH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/UTF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/UTI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/V.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VAC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VBF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VCRA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VCV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VEEV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VET.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VGI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VGM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VGR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VIV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VKQ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VLT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VLY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VMC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VMI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VMO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VNCE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VOYA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VPG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VPV.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VSH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VTN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VULC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VVR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/VZ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WAB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WAL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WBK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WBS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WCC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WCN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WD.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WES.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WFC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WGL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WGO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WHG.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WHZT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WIA.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WIT.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WLK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WLL.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WMB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WMC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WMK.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WMS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WNC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WNS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WOR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WPC.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WPZ.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WRB.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WRE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WSR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WST.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WTI.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WTM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WTS.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WTW.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WWE.csv  \n",
            "  inflating: stock_market_data/nyse/csv/WWW.csv  \n",
            "  inflating: stock_market_data/nyse/csv/X.csv  \n",
            "  inflating: stock_market_data/nyse/csv/XHR.csv  \n",
            "  inflating: stock_market_data/nyse/csv/XIN.csv  \n",
            "  inflating: stock_market_data/nyse/csv/XPO.csv  \n",
            "  inflating: stock_market_data/nyse/csv/YPF.csv  \n",
            "  inflating: stock_market_data/nyse/csv/YUM.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ZDPY.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ZION.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ZNH.csv  \n",
            "  inflating: stock_market_data/nyse/csv/ZOES.csv  \n",
            "  inflating: stock_market_data/nyse/json/AAC.json  \n",
            "  inflating: stock_market_data/nyse/json/AAP.json  \n",
            "  inflating: stock_market_data/nyse/json/AAT.json  \n",
            "  inflating: stock_market_data/nyse/json/AAV.json  \n",
            "  inflating: stock_market_data/nyse/json/AB.json  \n",
            "  inflating: stock_market_data/nyse/json/ABC.json  \n",
            "  inflating: stock_market_data/nyse/json/ABG.json  \n",
            "  inflating: stock_market_data/nyse/json/ABM.json  \n",
            "  inflating: stock_market_data/nyse/json/ABR.json  \n",
            "  inflating: stock_market_data/nyse/json/ABT.json  \n",
            "  inflating: stock_market_data/nyse/json/ACC.json  \n",
            "  inflating: stock_market_data/nyse/json/ACG.json  \n",
            "  inflating: stock_market_data/nyse/json/ACGL.json  \n",
            "  inflating: stock_market_data/nyse/json/ACH.json  \n",
            "  inflating: stock_market_data/nyse/json/ACP.json  \n",
            "  inflating: stock_market_data/nyse/json/ACRE.json  \n",
            "  inflating: stock_market_data/nyse/json/ADC.json  \n",
            "  inflating: stock_market_data/nyse/json/ADPT.json  \n",
            "  inflating: stock_market_data/nyse/json/ADS.json  \n",
            "  inflating: stock_market_data/nyse/json/AEL.json  \n",
            "  inflating: stock_market_data/nyse/json/AEM.json  \n",
            "  inflating: stock_market_data/nyse/json/AEO.json  \n",
            "  inflating: stock_market_data/nyse/json/AEP.json  \n",
            "  inflating: stock_market_data/nyse/json/AER.json  \n",
            "  inflating: stock_market_data/nyse/json/AES-PC.json  \n",
            "  inflating: stock_market_data/nyse/json/AF.json  \n",
            "  inflating: stock_market_data/nyse/json/AFB.json  \n",
            "  inflating: stock_market_data/nyse/json/AFG.json  \n",
            "  inflating: stock_market_data/nyse/json/AFSI.json  \n",
            "  inflating: stock_market_data/nyse/json/AFT.json  \n",
            "  inflating: stock_market_data/nyse/json/AG.json  \n",
            "  inflating: stock_market_data/nyse/json/AGD.json  \n",
            "  inflating: stock_market_data/nyse/json/AGI.json  \n",
            "  inflating: stock_market_data/nyse/json/AGM.json  \n",
            "  inflating: stock_market_data/nyse/json/AGO.json  \n",
            "  inflating: stock_market_data/nyse/json/AGRO.json  \n",
            "  inflating: stock_market_data/nyse/json/AHH.json  \n",
            "  inflating: stock_market_data/nyse/json/AHL.json  \n",
            "  inflating: stock_market_data/nyse/json/AHP.json  \n",
            "  inflating: stock_market_data/nyse/json/AHS.json  \n",
            "  inflating: stock_market_data/nyse/json/AHT.json  \n",
            "  inflating: stock_market_data/nyse/json/AI.json  \n",
            "  inflating: stock_market_data/nyse/json/AIF.json  \n",
            "  inflating: stock_market_data/nyse/json/AIG.json  \n",
            "  inflating: stock_market_data/nyse/json/AINV.json  \n",
            "  inflating: stock_market_data/nyse/json/AIT.json  \n",
            "  inflating: stock_market_data/nyse/json/AIV.json  \n",
            "  inflating: stock_market_data/nyse/json/AJG.json  \n",
            "  inflating: stock_market_data/nyse/json/AKO-A.json  \n",
            "  inflating: stock_market_data/nyse/json/AKR.json  \n",
            "  inflating: stock_market_data/nyse/json/ALEX.json  \n",
            "  inflating: stock_market_data/nyse/json/ALJ.json  \n",
            "  inflating: stock_market_data/nyse/json/ALK.json  \n",
            "  inflating: stock_market_data/nyse/json/ALL.json  \n",
            "  inflating: stock_market_data/nyse/json/ALLE.json  \n",
            "  inflating: stock_market_data/nyse/json/ALLY.json  \n",
            "  inflating: stock_market_data/nyse/json/ALSN.json  \n",
            "  inflating: stock_market_data/nyse/json/AMC.json  \n",
            "  inflating: stock_market_data/nyse/json/AME.json  \n",
            "  inflating: stock_market_data/nyse/json/AMG.json  \n",
            "  inflating: stock_market_data/nyse/json/AMH.json  \n",
            "  inflating: stock_market_data/nyse/json/AMIVF.json  \n",
            "  inflating: stock_market_data/nyse/json/AMP.json  \n",
            "  inflating: stock_market_data/nyse/json/AMT.json  \n",
            "  inflating: stock_market_data/nyse/json/AMTD.json  \n",
            "  inflating: stock_market_data/nyse/json/AMTG.json  \n",
            "  inflating: stock_market_data/nyse/json/ANET.json  \n",
            "  inflating: stock_market_data/nyse/json/ANF.json  \n",
            "  inflating: stock_market_data/nyse/json/ANR.json  \n",
            "  inflating: stock_market_data/nyse/json/ANW.json  \n",
            "  inflating: stock_market_data/nyse/json/AOD.json  \n",
            "  inflating: stock_market_data/nyse/json/AOI.json  \n",
            "  inflating: stock_market_data/nyse/json/APAM.json  \n",
            "  inflating: stock_market_data/nyse/json/APB.json  \n",
            "  inflating: stock_market_data/nyse/json/APD.json  \n",
            "  inflating: stock_market_data/nyse/json/APL.json  \n",
            "  inflating: stock_market_data/nyse/json/AR.json  \n",
            "  inflating: stock_market_data/nyse/json/ARAH.json  \n",
            "  inflating: stock_market_data/nyse/json/ARC.json  \n",
            "  inflating: stock_market_data/nyse/json/ARCC.json  \n",
            "  inflating: stock_market_data/nyse/json/ARCO.json  \n",
            "  inflating: stock_market_data/nyse/json/ARDC.json  \n",
            "  inflating: stock_market_data/nyse/json/ARE.json  \n",
            "  inflating: stock_market_data/nyse/json/ARHVF.json  \n",
            "  inflating: stock_market_data/nyse/json/ARI.json  \n",
            "  inflating: stock_market_data/nyse/json/ARL.json  \n",
            "  inflating: stock_market_data/nyse/json/ARR.json  \n",
            "  inflating: stock_market_data/nyse/json/ARW.json  \n",
            "  inflating: stock_market_data/nyse/json/ASA.json  \n",
            "  inflating: stock_market_data/nyse/json/ASB.json  \n",
            "  inflating: stock_market_data/nyse/json/ASC.json  \n",
            "  inflating: stock_market_data/nyse/json/ASGN.json  \n",
            "  inflating: stock_market_data/nyse/json/ASPN.json  \n",
            "  inflating: stock_market_data/nyse/json/ASR.json  \n",
            "  inflating: stock_market_data/nyse/json/ASX.json  \n",
            "  inflating: stock_market_data/nyse/json/ATEN.json  \n",
            "  inflating: stock_market_data/nyse/json/ATI.json  \n",
            "  inflating: stock_market_data/nyse/json/ATO.json  \n",
            "  inflating: stock_market_data/nyse/json/ATW.json  \n",
            "  inflating: stock_market_data/nyse/json/AU.json  \n",
            "  inflating: stock_market_data/nyse/json/AUQ.json  \n",
            "  inflating: stock_market_data/nyse/json/AUTR.json  \n",
            "  inflating: stock_market_data/nyse/json/AVB.json  \n",
            "  inflating: stock_market_data/nyse/json/AVD.json  \n",
            "  inflating: stock_market_data/nyse/json/AVG.json  \n",
            "  inflating: stock_market_data/nyse/json/AVK.json  \n",
            "  inflating: stock_market_data/nyse/json/AVY.json  \n",
            "  inflating: stock_market_data/nyse/json/AWF.json  \n",
            "  inflating: stock_market_data/nyse/json/AWH.json  \n",
            "  inflating: stock_market_data/nyse/json/AWK.json  \n",
            "  inflating: stock_market_data/nyse/json/AWR.json  \n",
            "  inflating: stock_market_data/nyse/json/AXL.json  \n",
            "  inflating: stock_market_data/nyse/json/AXP.json  \n",
            "  inflating: stock_market_data/nyse/json/AXTA.json  \n",
            "  inflating: stock_market_data/nyse/json/AYN.json  \n",
            "  inflating: stock_market_data/nyse/json/AZN.json  \n",
            "  inflating: stock_market_data/nyse/json/BAH.json  \n",
            "  inflating: stock_market_data/nyse/json/BAK.json  \n",
            "  inflating: stock_market_data/nyse/json/BALT.json  \n",
            "  inflating: stock_market_data/nyse/json/BAM.json  \n",
            "  inflating: stock_market_data/nyse/json/BAP.json  \n",
            "  inflating: stock_market_data/nyse/json/BBG.json  \n",
            "  inflating: stock_market_data/nyse/json/BBL.json  \n",
            "  inflating: stock_market_data/nyse/json/BBVA.json  \n",
            "  inflating: stock_market_data/nyse/json/BCC.json  \n",
            "  inflating: stock_market_data/nyse/json/BCS.json  \n",
            "  inflating: stock_market_data/nyse/json/BCX.json  \n",
            "  inflating: stock_market_data/nyse/json/BDCZ.json  \n",
            "  inflating: stock_market_data/nyse/json/BDJ.json  \n",
            "  inflating: stock_market_data/nyse/json/BDN.json  \n",
            "  inflating: stock_market_data/nyse/json/BDX.json  \n",
            "  inflating: stock_market_data/nyse/json/BEN.json  \n",
            "  inflating: stock_market_data/nyse/json/BEP.json  \n",
            "  inflating: stock_market_data/nyse/json/BERY.json  \n",
            "  inflating: stock_market_data/nyse/json/BFAM.json  \n",
            "  inflating: stock_market_data/nyse/json/BFK.json  \n",
            "  inflating: stock_market_data/nyse/json/BFZ.json  \n",
            "  inflating: stock_market_data/nyse/json/BG.json  \n",
            "  inflating: stock_market_data/nyse/json/BGB.json  \n",
            "  inflating: stock_market_data/nyse/json/BGC.json  \n",
            "  inflating: stock_market_data/nyse/json/BGR.json  \n",
            "  inflating: stock_market_data/nyse/json/BGT.json  \n",
            "  inflating: stock_market_data/nyse/json/BGX.json  \n",
            "  inflating: stock_market_data/nyse/json/BH.json  \n",
            "  inflating: stock_market_data/nyse/json/BHE.json  \n",
            "  inflating: stock_market_data/nyse/json/BHI.json  \n",
            "  inflating: stock_market_data/nyse/json/BHK.json  \n",
            "  inflating: stock_market_data/nyse/json/BHL.json  \n",
            "  inflating: stock_market_data/nyse/json/BHLB.json  \n",
            "  inflating: stock_market_data/nyse/json/BHP.json  \n",
            "  inflating: stock_market_data/nyse/json/BIE.json  \n",
            "  inflating: stock_market_data/nyse/json/BIF.json  \n",
            "  inflating: stock_market_data/nyse/json/BIN.json  \n",
            "  inflating: stock_market_data/nyse/json/BIP.json  \n",
            "  inflating: stock_market_data/nyse/json/BJZ.json  \n",
            "  inflating: stock_market_data/nyse/json/BK.json  \n",
            "  inflating: stock_market_data/nyse/json/BKD.json  \n",
            "  inflating: stock_market_data/nyse/json/BKN.json  \n",
            "  inflating: stock_market_data/nyse/json/BKT.json  \n",
            "  inflating: stock_market_data/nyse/json/BLH.json  \n",
            "  inflating: stock_market_data/nyse/json/BLK.json  \n",
            "  inflating: stock_market_data/nyse/json/BLT.json  \n",
            "  inflating: stock_market_data/nyse/json/BLW.json  \n",
            "  inflating: stock_market_data/nyse/json/BLX.json  \n",
            "  inflating: stock_market_data/nyse/json/BME.json  \n",
            "  inflating: stock_market_data/nyse/json/BMO.json  \n",
            "  inflating: stock_market_data/nyse/json/BMS.json  \n",
            "  inflating: stock_market_data/nyse/json/BNCM.json  \n",
            "  inflating: stock_market_data/nyse/json/BNJ.json  \n",
            "  inflating: stock_market_data/nyse/json/BNK.json  \n",
            "  inflating: stock_market_data/nyse/json/BNKJF.json  \n",
            "  inflating: stock_market_data/nyse/json/BNY.json  \n",
            "  inflating: stock_market_data/nyse/json/BOH.json  \n",
            "  inflating: stock_market_data/nyse/json/BOI.json  \n",
            "  inflating: stock_market_data/nyse/json/BOOT.json  \n",
            "  inflating: stock_market_data/nyse/json/BOXC.json  \n",
            "  inflating: stock_market_data/nyse/json/BPK.json  \n",
            "  inflating: stock_market_data/nyse/json/BPT.json  \n",
            "  inflating: stock_market_data/nyse/json/BR.json  \n",
            "  inflating: stock_market_data/nyse/json/BRFS.json  \n",
            "  inflating: stock_market_data/nyse/json/BRK-A.json  \n",
            "  inflating: stock_market_data/nyse/json/BRO.json  \n",
            "  inflating: stock_market_data/nyse/json/BRP.json  \n",
            "  inflating: stock_market_data/nyse/json/BRX.json  \n",
            "  inflating: stock_market_data/nyse/json/BSAC.json  \n",
            "  inflating: stock_market_data/nyse/json/BSI.json  \n",
            "  inflating: stock_market_data/nyse/json/BSL.json  \n",
            "  inflating: stock_market_data/nyse/json/BST.json  \n",
            "  inflating: stock_market_data/nyse/json/BSX.json  \n",
            "  inflating: stock_market_data/nyse/json/BTF.json  \n",
            "  inflating: stock_market_data/nyse/json/BTO.json  \n",
            "  inflating: stock_market_data/nyse/json/BTSGY.json  \n",
            "  inflating: stock_market_data/nyse/json/BTU.json  \n",
            "  inflating: stock_market_data/nyse/json/BTZ.json  \n",
            "  inflating: stock_market_data/nyse/json/BUI.json  \n",
            "  inflating: stock_market_data/nyse/json/BURL.json  \n",
            "  inflating: stock_market_data/nyse/json/BWG.json  \n",
            "  inflating: stock_market_data/nyse/json/BWMG.json  \n",
            "  inflating: stock_market_data/nyse/json/BWP.json  \n",
            "  inflating: stock_market_data/nyse/json/BXC.json  \n",
            "  inflating: stock_market_data/nyse/json/BXE.json  \n",
            "  inflating: stock_market_data/nyse/json/BXMT.json  \n",
            "  inflating: stock_market_data/nyse/json/BXMX.json  \n",
            "  inflating: stock_market_data/nyse/json/BXP.json  \n",
            "  inflating: stock_market_data/nyse/json/BYM.json  \n",
            "  inflating: stock_market_data/nyse/json/BZH.json  \n",
            "  inflating: stock_market_data/nyse/json/C-PK.json  \n",
            "  inflating: stock_market_data/nyse/json/CAF.json  \n",
            "  inflating: stock_market_data/nyse/json/CAH.json  \n",
            "  inflating: stock_market_data/nyse/json/CAM.json  \n",
            "  inflating: stock_market_data/nyse/json/CBA.json  \n",
            "  inflating: stock_market_data/nyse/json/CBD.json  \n",
            "  inflating: stock_market_data/nyse/json/CBI.json  \n",
            "  inflating: stock_market_data/nyse/json/CBL.json  \n",
            "  inflating: stock_market_data/nyse/json/CBU.json  \n",
            "  inflating: stock_market_data/nyse/json/CCI.json  \n",
            "  inflating: stock_market_data/nyse/json/CCK.json  \n",
            "  inflating: stock_market_data/nyse/json/CCM.json  \n",
            "  inflating: stock_market_data/nyse/json/CCS.json  \n",
            "  inflating: stock_market_data/nyse/json/CCU.json  \n",
            "  inflating: stock_market_data/nyse/json/CCZ.json  \n",
            "  inflating: stock_market_data/nyse/json/CDR.json  \n",
            "  inflating: stock_market_data/nyse/json/CEA.json  \n",
            "  inflating: stock_market_data/nyse/json/CEE.json  \n",
            "  inflating: stock_market_data/nyse/json/CEM.json  \n",
            "  inflating: stock_market_data/nyse/json/CEN.json  \n",
            "  inflating: stock_market_data/nyse/json/CEO.json  \n",
            "  inflating: stock_market_data/nyse/json/CEQP.json  \n",
            "  inflating: stock_market_data/nyse/json/CF.json  \n",
            "  inflating: stock_market_data/nyse/json/CFC-PA.json  \n",
            "  inflating: stock_market_data/nyse/json/CFG.json  \n",
            "  inflating: stock_market_data/nyse/json/CFR.json  \n",
            "  inflating: stock_market_data/nyse/json/CGA.json  \n",
            "  inflating: stock_market_data/nyse/json/CGG.json  \n",
            "  inflating: stock_market_data/nyse/json/CGI.json  \n",
            "  inflating: stock_market_data/nyse/json/CHCO.json  \n",
            "  inflating: stock_market_data/nyse/json/CHD.json  \n",
            "  inflating: stock_market_data/nyse/json/CHE.json  \n",
            "  inflating: stock_market_data/nyse/json/CHH.json  \n",
            "  inflating: stock_market_data/nyse/json/CHMI.json  \n",
            "  inflating: stock_market_data/nyse/json/CHNR.json  \n",
            "  inflating: stock_market_data/nyse/json/CHS.json  \n",
            "  inflating: stock_market_data/nyse/json/CHT.json  \n",
            "  inflating: stock_market_data/nyse/json/CIB.json  \n",
            "  inflating: stock_market_data/nyse/json/CIE.json  \n",
            "  inflating: stock_market_data/nyse/json/CIF.json  \n",
            "  inflating: stock_market_data/nyse/json/CII.json  \n",
            "  inflating: stock_market_data/nyse/json/CIM.json  \n",
            "  inflating: stock_market_data/nyse/json/CIO.json  \n",
            "  inflating: stock_market_data/nyse/json/CIR.json  \n",
            "  inflating: stock_market_data/nyse/json/CIVI.json  \n",
            "  inflating: stock_market_data/nyse/json/CKP.json  \n",
            "  inflating: stock_market_data/nyse/json/CLB.json  \n",
            "  inflating: stock_market_data/nyse/json/CLH.json  \n",
            "  inflating: stock_market_data/nyse/json/CLR.json  \n",
            "  inflating: stock_market_data/nyse/json/CLW.json  \n",
            "  inflating: stock_market_data/nyse/json/CM.json  \n",
            "  inflating: stock_market_data/nyse/json/CMC.json  \n",
            "  inflating: stock_market_data/nyse/json/CMCSA.json  \n",
            "  inflating: stock_market_data/nyse/json/CMG.json  \n",
            "  inflating: stock_market_data/nyse/json/CMN.json  \n",
            "  inflating: stock_market_data/nyse/json/CMP.json  \n",
            "  inflating: stock_market_data/nyse/json/CMS.json  \n",
            "  inflating: stock_market_data/nyse/json/CNGW.json  \n",
            "  inflating: stock_market_data/nyse/json/CNHI.json  \n",
            "  inflating: stock_market_data/nyse/json/CNI.json  \n",
            "  inflating: stock_market_data/nyse/json/CNO.json  \n",
            "  inflating: stock_market_data/nyse/json/CNP.json  \n",
            "  inflating: stock_market_data/nyse/json/CNQ.json  \n",
            "  inflating: stock_market_data/nyse/json/CNS.json  \n",
            "  inflating: stock_market_data/nyse/json/CNX.json  \n",
            "  inflating: stock_market_data/nyse/json/CO.json  \n",
            "  inflating: stock_market_data/nyse/json/CODI.json  \n",
            "  inflating: stock_market_data/nyse/json/COF.json  \n",
            "  inflating: stock_market_data/nyse/json/COL.json  \n",
            "  inflating: stock_market_data/nyse/json/COP.json  \n",
            "  inflating: stock_market_data/nyse/json/COR.json  \n",
            "  inflating: stock_market_data/nyse/json/CORR.json  \n",
            "  inflating: stock_market_data/nyse/json/CP.json  \n",
            "  inflating: stock_market_data/nyse/json/CPB.json  \n",
            "  inflating: stock_market_data/nyse/json/CPE.json  \n",
            "  inflating: stock_market_data/nyse/json/CPF.json  \n",
            "  inflating: stock_market_data/nyse/json/CPG.json  \n",
            "  inflating: stock_market_data/nyse/json/CPK.json  \n",
            "  inflating: stock_market_data/nyse/json/CPT.json  \n",
            "  inflating: stock_market_data/nyse/json/CRC.json  \n",
            "  inflating: stock_market_data/nyse/json/CRD-B.json  \n",
            "  inflating: stock_market_data/nyse/json/CRK.json  \n",
            "  inflating: stock_market_data/nyse/json/CRL.json  \n",
            "  inflating: stock_market_data/nyse/json/CRS.json  \n",
            "  inflating: stock_market_data/nyse/json/CRT.json  \n",
            "  inflating: stock_market_data/nyse/json/CS.json  \n",
            "  inflating: stock_market_data/nyse/json/CSC.json  \n",
            "  inflating: stock_market_data/nyse/json/CSH.json  \n",
            "  inflating: stock_market_data/nyse/json/CSI.json  \n",
            "  inflating: stock_market_data/nyse/json/CSL.json  \n",
            "  inflating: stock_market_data/nyse/json/CSLT.json  \n",
            "  inflating: stock_market_data/nyse/json/CSTM.json  \n",
            "  inflating: stock_market_data/nyse/json/CSV.json  \n",
            "  inflating: stock_market_data/nyse/json/CTR.json  \n",
            "  inflating: stock_market_data/nyse/json/CTT.json  \n",
            "  inflating: stock_market_data/nyse/json/CUBI.json  \n",
            "  inflating: stock_market_data/nyse/json/CUDA.json  \n",
            "  inflating: stock_market_data/nyse/json/CUK.json  \n",
            "  inflating: stock_market_data/nyse/json/CUPUF.json  \n",
            "  inflating: stock_market_data/nyse/json/CUZ.json  \n",
            "  inflating: stock_market_data/nyse/json/CVB.json  \n",
            "  inflating: stock_market_data/nyse/json/CVC.json  \n",
            "  inflating: stock_market_data/nyse/json/CVE.json  \n",
            "  inflating: stock_market_data/nyse/json/CVO.json  \n",
            "  inflating: stock_market_data/nyse/json/CWEI.json  \n",
            "  inflating: stock_market_data/nyse/json/CWT.json  \n",
            "  inflating: stock_market_data/nyse/json/CXE.json  \n",
            "  inflating: stock_market_data/nyse/json/CXH.json  \n",
            "  inflating: stock_market_data/nyse/json/CYD.json  \n",
            "  inflating: stock_market_data/nyse/json/CYH.json  \n",
            "  inflating: stock_market_data/nyse/json/CYS.json  \n",
            "  inflating: stock_market_data/nyse/json/DAL.json  \n",
            "  inflating: stock_market_data/nyse/json/DAR.json  \n",
            "  inflating: stock_market_data/nyse/json/DBL.json  \n",
            "  inflating: stock_market_data/nyse/json/DCA.json  \n",
            "  inflating: stock_market_data/nyse/json/DCI.json  \n",
            "  inflating: stock_market_data/nyse/json/DCO.json  \n",
            "  inflating: stock_market_data/nyse/json/DCT.json  \n",
            "  inflating: stock_market_data/nyse/json/DD.json  \n",
            "  inflating: stock_market_data/nyse/json/DDC.json  \n",
            "  inflating: stock_market_data/nyse/json/DDF.json  \n",
            "  inflating: stock_market_data/nyse/json/DDS.json  \n",
            "  inflating: stock_market_data/nyse/json/DDT.json  \n",
            "  inflating: stock_market_data/nyse/json/DE.json  \n",
            "  inflating: stock_market_data/nyse/json/DECK.json  \n",
            "  inflating: stock_market_data/nyse/json/DEG.json  \n",
            "  inflating: stock_market_data/nyse/json/DEI.json  \n",
            "  inflating: stock_market_data/nyse/json/DEL.json  \n",
            "  inflating: stock_market_data/nyse/json/DEX.json  \n",
            "  inflating: stock_market_data/nyse/json/DFS.json  \n",
            "  inflating: stock_market_data/nyse/json/DG.json  \n",
            "  inflating: stock_market_data/nyse/json/DGI.json  \n",
            "  inflating: stock_market_data/nyse/json/DGX.json  \n",
            "  inflating: stock_market_data/nyse/json/DHF.json  \n",
            "  inflating: stock_market_data/nyse/json/DHG.json  \n",
            "  inflating: stock_market_data/nyse/json/DHI.json  \n",
            "  inflating: stock_market_data/nyse/json/DHT.json  \n",
            "  inflating: stock_market_data/nyse/json/DIAX.json  \n",
            "  inflating: stock_market_data/nyse/json/DK.json  \n",
            "  inflating: stock_market_data/nyse/json/DKS.json  \n",
            "  inflating: stock_market_data/nyse/json/DLB.json  \n",
            "  inflating: stock_market_data/nyse/json/DLNG.json  \n",
            "  inflating: stock_market_data/nyse/json/DLR.json  \n",
            "  inflating: stock_market_data/nyse/json/DMB.json  \n",
            "  inflating: stock_market_data/nyse/json/DMO.json  \n",
            "  inflating: stock_market_data/nyse/json/DNB.json  \n",
            "  inflating: stock_market_data/nyse/json/DNP.json  \n",
            "  inflating: stock_market_data/nyse/json/DNY.json  \n",
            "  inflating: stock_market_data/nyse/json/DOMR.json  \n",
            "  inflating: stock_market_data/nyse/json/DOOR.json  \n",
            "  inflating: stock_market_data/nyse/json/DPG.json  \n",
            "  inflating: stock_market_data/nyse/json/DPSGY.json  \n",
            "  inflating: stock_market_data/nyse/json/DPZ.json  \n",
            "  inflating: stock_market_data/nyse/json/DRA.json  \n",
            "  inflating: stock_market_data/nyse/json/DRH.json  \n",
            "  inflating: stock_market_data/nyse/json/DRI.json  \n",
            "  inflating: stock_market_data/nyse/json/DRII.json  \n",
            "  inflating: stock_market_data/nyse/json/DRLCQ.json  \n",
            "  inflating: stock_market_data/nyse/json/DSL.json  \n",
            "  inflating: stock_market_data/nyse/json/DSM.json  \n",
            "  inflating: stock_market_data/nyse/json/DST.json  \n",
            "  inflating: stock_market_data/nyse/json/DSU.json  \n",
            "  inflating: stock_market_data/nyse/json/DSX.json  \n",
            "  inflating: stock_market_data/nyse/json/DTE.json  \n",
            "  inflating: stock_market_data/nyse/json/DTK.json  \n",
            "  inflating: stock_market_data/nyse/json/DV.json  \n",
            "  inflating: stock_market_data/nyse/json/DVD.json  \n",
            "  inflating: stock_market_data/nyse/json/DVN.json  \n",
            "  inflating: stock_market_data/nyse/json/DX.json  \n",
            "  inflating: stock_market_data/nyse/json/DY.json  \n",
            "  inflating: stock_market_data/nyse/json/EARN.json  \n",
            "  inflating: stock_market_data/nyse/json/EAT.json  \n",
            "  inflating: stock_market_data/nyse/json/EBS.json  \n",
            "  inflating: stock_market_data/nyse/json/ED.json  \n",
            "  inflating: stock_market_data/nyse/json/EDD.json  \n",
            "  inflating: stock_market_data/nyse/json/EDE.json  \n",
            "  inflating: stock_market_data/nyse/json/EDF.json  \n",
            "  inflating: stock_market_data/nyse/json/EDI.json  \n",
            "  inflating: stock_market_data/nyse/json/EEA.json  \n",
            "  inflating: stock_market_data/nyse/json/EFM.json  \n",
            "  inflating: stock_market_data/nyse/json/EFR.json  \n",
            "  inflating: stock_market_data/nyse/json/EFT.json  \n",
            "  inflating: stock_market_data/nyse/json/EGF.json  \n",
            "  inflating: stock_market_data/nyse/json/EGL.json  \n",
            "  inflating: stock_market_data/nyse/json/EGO.json  \n",
            "  inflating: stock_market_data/nyse/json/EGP.json  \n",
            "  inflating: stock_market_data/nyse/json/EHI.json  \n",
            "  inflating: stock_market_data/nyse/json/EIG.json  \n",
            "  inflating: stock_market_data/nyse/json/EIX.json  \n",
            "  inflating: stock_market_data/nyse/json/EL.json  \n",
            "  inflating: stock_market_data/nyse/json/ELP.json  \n",
            "  inflating: stock_market_data/nyse/json/ELS.json  \n",
            "  inflating: stock_market_data/nyse/json/ELY.json  \n",
            "  inflating: stock_market_data/nyse/json/EME.json  \n",
            "  inflating: stock_market_data/nyse/json/EMF.json  \n",
            "  inflating: stock_market_data/nyse/json/EMN.json  \n",
            "  inflating: stock_market_data/nyse/json/EMO.json  \n",
            "  inflating: stock_market_data/nyse/json/EMR.json  \n",
            "  inflating: stock_market_data/nyse/json/ENH.json  \n",
            "  inflating: stock_market_data/nyse/json/ENL.json  \n",
            "  inflating: stock_market_data/nyse/json/ENVA.json  \n",
            "  inflating: stock_market_data/nyse/json/EOC.json  \n",
            "  inflating: stock_market_data/nyse/json/EOD.json  \n",
            "  inflating: stock_market_data/nyse/json/EOG.json  \n",
            "  inflating: stock_market_data/nyse/json/EOS.json  \n",
            "  inflating: stock_market_data/nyse/json/EPAM.json  \n",
            "  inflating: stock_market_data/nyse/json/EPD.json  \n",
            "  inflating: stock_market_data/nyse/json/EPR-PC.json  \n",
            "  inflating: stock_market_data/nyse/json/EPR-PE.json  \n",
            "  inflating: stock_market_data/nyse/json/EPR.json  \n",
            "  inflating: stock_market_data/nyse/json/EQS.json  \n",
            "  inflating: stock_market_data/nyse/json/ESD.json  \n",
            "  inflating: stock_market_data/nyse/json/ESI.json  \n",
            "  inflating: stock_market_data/nyse/json/ESNT.json  \n",
            "  inflating: stock_market_data/nyse/json/ESRT.json  \n",
            "  inflating: stock_market_data/nyse/json/ESS.json  \n",
            "  inflating: stock_market_data/nyse/json/ETN.json  \n",
            "  inflating: stock_market_data/nyse/json/ETP.json  \n",
            "  inflating: stock_market_data/nyse/json/ETX.json  \n",
            "  inflating: stock_market_data/nyse/json/EVC.json  \n",
            "  inflating: stock_market_data/nyse/json/EVDY.json  \n",
            "  inflating: stock_market_data/nyse/json/EVER.json  \n",
            "  inflating: stock_market_data/nyse/json/EVF.json  \n",
            "  inflating: stock_market_data/nyse/json/EVN.json  \n",
            "  inflating: stock_market_data/nyse/json/EVR.json  \n",
            "  inflating: stock_market_data/nyse/json/EVT.json  \n",
            "  inflating: stock_market_data/nyse/json/EW.json  \n",
            "  inflating: stock_market_data/nyse/json/EXAM.json  \n",
            "  inflating: stock_market_data/nyse/json/EXC.json  \n",
            "  inflating: stock_market_data/nyse/json/EXL.json  \n",
            "  inflating: stock_market_data/nyse/json/EXP.json  \n",
            "  inflating: stock_market_data/nyse/json/EXR.json  \n",
            "  inflating: stock_market_data/nyse/json/F.json  \n",
            "  inflating: stock_market_data/nyse/json/FAC.json  \n",
            "  inflating: stock_market_data/nyse/json/FAV.json  \n",
            "  inflating: stock_market_data/nyse/json/FBC.json  \n",
            "  inflating: stock_market_data/nyse/json/FBHS.json  \n",
            "  inflating: stock_market_data/nyse/json/FBP.json  \n",
            "  inflating: stock_market_data/nyse/json/FBR.json  \n",
            "  inflating: stock_market_data/nyse/json/FCB.json  \n",
            "  inflating: stock_market_data/nyse/json/FCF.json  \n",
            "  inflating: stock_market_data/nyse/json/FCH.json  \n",
            "  inflating: stock_market_data/nyse/json/FCN.json  \n",
            "  inflating: stock_market_data/nyse/json/FCT.json  \n",
            "  inflating: stock_market_data/nyse/json/FDI.json  \n",
            "  inflating: stock_market_data/nyse/json/FDO.json  \n",
            "  inflating: stock_market_data/nyse/json/FDP.json  \n",
            "  inflating: stock_market_data/nyse/json/FDS.json  \n",
            "  inflating: stock_market_data/nyse/json/FEI.json  \n",
            "  inflating: stock_market_data/nyse/json/FEO.json  \n",
            "  inflating: stock_market_data/nyse/json/FET.json  \n",
            "  inflating: stock_market_data/nyse/json/FF.json  \n",
            "  inflating: stock_market_data/nyse/json/FFA.json  \n",
            "  inflating: stock_market_data/nyse/json/FFC.json  \n",
            "  inflating: stock_market_data/nyse/json/FGB.json  \n",
            "  inflating: stock_market_data/nyse/json/FGL.json  \n",
            "  inflating: stock_market_data/nyse/json/FHN.json  \n",
            "  inflating: stock_market_data/nyse/json/FIF.json  \n",
            "  inflating: stock_market_data/nyse/json/FIG.json  \n",
            "  inflating: stock_market_data/nyse/json/FIS.json  \n",
            "  inflating: stock_market_data/nyse/json/FIX.json  \n",
            "  inflating: stock_market_data/nyse/json/FL.json  \n",
            "  inflating: stock_market_data/nyse/json/FLC.json  \n",
            "  inflating: stock_market_data/nyse/json/FLO.json  \n",
            "  inflating: stock_market_data/nyse/json/FLT.json  \n",
            "  inflating: stock_market_data/nyse/json/FLTX.json  \n",
            "  inflating: stock_market_data/nyse/json/FMD.json  \n",
            "  inflating: stock_market_data/nyse/json/FMN.json  \n",
            "  inflating: stock_market_data/nyse/json/FMS.json  \n",
            "  inflating: stock_market_data/nyse/json/FMX.json  \n",
            "  inflating: stock_market_data/nyse/json/FMY.json  \n",
            "  inflating: stock_market_data/nyse/json/FNF.json  \n",
            "  inflating: stock_market_data/nyse/json/FNFG.json  \n",
            "  inflating: stock_market_data/nyse/json/FOR.json  \n",
            "  inflating: stock_market_data/nyse/json/FPF.json  \n",
            "  inflating: stock_market_data/nyse/json/FPL.json  \n",
            "  inflating: stock_market_data/nyse/json/FPRUF.json  \n",
            "  inflating: stock_market_data/nyse/json/FPT.json  \n",
            "  inflating: stock_market_data/nyse/json/FR.json  \n",
            "  inflating: stock_market_data/nyse/json/FRA.json  \n",
            "  inflating: stock_market_data/nyse/json/FRC-PA.json  \n",
            "  inflating: stock_market_data/nyse/json/FRO.json  \n",
            "  inflating: stock_market_data/nyse/json/FRT.json  \n",
            "  inflating: stock_market_data/nyse/json/FSC.json  \n",
            "  inflating: stock_market_data/nyse/json/FSD.json  \n",
            "  inflating: stock_market_data/nyse/json/FSIC.json  \n",
            "  inflating: stock_market_data/nyse/json/FSM.json  \n",
            "  inflating: stock_market_data/nyse/json/FSS.json  \n",
            "  inflating: stock_market_data/nyse/json/FT.json  \n",
            "  inflating: stock_market_data/nyse/json/FTK.json  \n",
            "  inflating: stock_market_data/nyse/json/FUL.json  \n",
            "  inflating: stock_market_data/nyse/json/FUN.json  \n",
            "  inflating: stock_market_data/nyse/json/FUR.json  \n",
            "  inflating: stock_market_data/nyse/json/FVEN.json  \n",
            "  inflating: stock_market_data/nyse/json/G.json  \n",
            "  inflating: stock_market_data/nyse/json/GAB.json  \n",
            "  inflating: stock_market_data/nyse/json/GAHCE.json  \n",
            "  inflating: stock_market_data/nyse/json/GAIN.json  \n",
            "  inflating: stock_market_data/nyse/json/GAM.json  \n",
            "  inflating: stock_market_data/nyse/json/GBX.json  \n",
            "  inflating: stock_market_data/nyse/json/GCH.json  \n",
            "  inflating: stock_market_data/nyse/json/GCV.json  \n",
            "  inflating: stock_market_data/nyse/json/GD.json  \n",
            "  inflating: stock_market_data/nyse/json/GDF.json  \n",
            "  inflating: stock_market_data/nyse/json/GDO.json  \n",
            "  inflating: stock_market_data/nyse/json/GDV.json  \n",
            "  inflating: stock_market_data/nyse/json/GE.json  \n",
            "  inflating: stock_market_data/nyse/json/GEL.json  \n",
            "  inflating: stock_market_data/nyse/json/GEQ.json  \n",
            "  inflating: stock_market_data/nyse/json/GER.json  \n",
            "  inflating: stock_market_data/nyse/json/GF.json  \n",
            "  inflating: stock_market_data/nyse/json/GGE.json  \n",
            "  inflating: stock_market_data/nyse/json/GGZ.json  \n",
            "  inflating: stock_market_data/nyse/json/GHC.json  \n",
            "  inflating: stock_market_data/nyse/json/GHI.json  \n",
            "  inflating: stock_market_data/nyse/json/GHY.json  \n",
            "  inflating: stock_market_data/nyse/json/GIM.json  \n",
            "  inflating: stock_market_data/nyse/json/GIS.json  \n",
            "  inflating: stock_market_data/nyse/json/GJS.json  \n",
            "  inflating: stock_market_data/nyse/json/GLF.json  \n",
            "  inflating: stock_market_data/nyse/json/GLOB.json  \n",
            "  inflating: stock_market_data/nyse/json/GLPW.json  \n",
            "  inflating: stock_market_data/nyse/json/GLW.json  \n",
            "  inflating: stock_market_data/nyse/json/GM.json  \n",
            "  inflating: stock_market_data/nyse/json/GMED.json  \n",
            "  inflating: stock_market_data/nyse/json/GNE.json  \n",
            "  inflating: stock_market_data/nyse/json/GNI.json  \n",
            "  inflating: stock_market_data/nyse/json/GNRC.json  \n",
            "  inflating: stock_market_data/nyse/json/GNT.json  \n",
            "  inflating: stock_market_data/nyse/json/GNW.json  \n",
            "  inflating: stock_market_data/nyse/json/GOF.json  \n",
            "  inflating: stock_market_data/nyse/json/GOV.json  \n",
            "  inflating: stock_market_data/nyse/json/GPC.json  \n",
            "  inflating: stock_market_data/nyse/json/GPI.json  \n",
            "  inflating: stock_market_data/nyse/json/GPK.json  \n",
            "  inflating: stock_market_data/nyse/json/GPN.json  \n",
            "  inflating: stock_market_data/nyse/json/GPT.json  \n",
            "  inflating: stock_market_data/nyse/json/GRR.json  \n",
            "  inflating: stock_market_data/nyse/json/GRX.json  \n",
            "  inflating: stock_market_data/nyse/json/GS-PJ.json  \n",
            "  inflating: stock_market_data/nyse/json/GSI.json  \n",
            "  inflating: stock_market_data/nyse/json/GSK.json  \n",
            "  inflating: stock_market_data/nyse/json/GSL.json  \n",
            "  inflating: stock_market_data/nyse/json/GTN-A.json  \n",
            "  inflating: stock_market_data/nyse/json/GUT.json  \n",
            "  inflating: stock_market_data/nyse/json/GVA.json  \n",
            "  inflating: stock_market_data/nyse/json/GWB.json  \n",
            "  inflating: stock_market_data/nyse/json/GWRE.json  \n",
            "  inflating: stock_market_data/nyse/json/GWW.json  \n",
            "  inflating: stock_market_data/nyse/json/GXP.json  \n",
            "  inflating: stock_market_data/nyse/json/HAL.json  \n",
            "  inflating: stock_market_data/nyse/json/HAR.json  \n",
            "  inflating: stock_market_data/nyse/json/HASI.json  \n",
            "  inflating: stock_market_data/nyse/json/HCRE.json  \n",
            "  inflating: stock_market_data/nyse/json/HDB.json  \n",
            "  inflating: stock_market_data/nyse/json/HE.json  \n",
            "  inflating: stock_market_data/nyse/json/HELIF.json  \n",
            "  inflating: stock_market_data/nyse/json/HEP.json  \n",
            "  inflating: stock_market_data/nyse/json/HEQ.json  \n",
            "  inflating: stock_market_data/nyse/json/HFC.json  \n",
            "  inflating: stock_market_data/nyse/json/HGT.json  \n",
            "  inflating: stock_market_data/nyse/json/HHY.json  \n",
            "  inflating: stock_market_data/nyse/json/HIE.json  \n",
            "  inflating: stock_market_data/nyse/json/HIG.json  \n",
            "  inflating: stock_market_data/nyse/json/HII.json  \n",
            "  inflating: stock_market_data/nyse/json/HIL.json  \n",
            "  inflating: stock_market_data/nyse/json/HIO.json  \n",
            "  inflating: stock_market_data/nyse/json/HIVE.json  \n",
            "  inflating: stock_market_data/nyse/json/HIW.json  \n",
            "  inflating: stock_market_data/nyse/json/HIX.json  \n",
            "  inflating: stock_market_data/nyse/json/HL.json  \n",
            "  inflating: stock_market_data/nyse/json/HLF.json  \n",
            "  inflating: stock_market_data/nyse/json/HLT.json  \n",
            "  inflating: stock_market_data/nyse/json/HLX.json  \n",
            "  inflating: stock_market_data/nyse/json/HMC.json  \n",
            "  inflating: stock_market_data/nyse/json/HMN.json  \n",
            "  inflating: stock_market_data/nyse/json/HMY.json  \n",
            "  inflating: stock_market_data/nyse/json/HNP.json  \n",
            "  inflating: stock_market_data/nyse/json/HNR.json  \n",
            "  inflating: stock_market_data/nyse/json/HON.json  \n",
            "  inflating: stock_market_data/nyse/json/HOT.json  \n",
            "  inflating: stock_market_data/nyse/json/HOV.json  \n",
            "  inflating: stock_market_data/nyse/json/HP.json  \n",
            "  inflating: stock_market_data/nyse/json/HPF.json  \n",
            "  inflating: stock_market_data/nyse/json/HPP.json  \n",
            "  inflating: stock_market_data/nyse/json/HPS.json  \n",
            "  inflating: stock_market_data/nyse/json/HPY.json  \n",
            "  inflating: stock_market_data/nyse/json/HQH.json  \n",
            "  inflating: stock_market_data/nyse/json/HQL.json  \n",
            "  inflating: stock_market_data/nyse/json/HR.json  \n",
            "  inflating: stock_market_data/nyse/json/HRL.json  \n",
            "  inflating: stock_market_data/nyse/json/HRTG.json  \n",
            "  inflating: stock_market_data/nyse/json/HRZN.json  \n",
            "  inflating: stock_market_data/nyse/json/HSBC.json  \n",
            "  inflating: stock_market_data/nyse/json/HST.json  \n",
            "  inflating: stock_market_data/nyse/json/HSY.json  \n",
            "  inflating: stock_market_data/nyse/json/HTA.json  \n",
            "  inflating: stock_market_data/nyse/json/HTD.json  \n",
            "  inflating: stock_market_data/nyse/json/HTH.json  \n",
            "  inflating: stock_market_data/nyse/json/HTR.json  \n",
            "  inflating: stock_market_data/nyse/json/HTZ.json  \n",
            "  inflating: stock_market_data/nyse/json/HVB.json  \n",
            "  inflating: stock_market_data/nyse/json/HVT.json  \n",
            "  inflating: stock_market_data/nyse/json/HYB.json  \n",
            "  inflating: stock_market_data/nyse/json/HYF.json  \n",
            "  inflating: stock_market_data/nyse/json/HYH.json  \n",
            "  inflating: stock_market_data/nyse/json/HYI.json  \n",
            "  inflating: stock_market_data/nyse/json/HYT.json  \n",
            "  inflating: stock_market_data/nyse/json/IAPLF.json  \n",
            "  inflating: stock_market_data/nyse/json/IBA.json  \n",
            "  inflating: stock_market_data/nyse/json/IBM.json  \n",
            "  inflating: stock_market_data/nyse/json/IBN.json  \n",
            "  inflating: stock_market_data/nyse/json/IBP.json  \n",
            "  inflating: stock_market_data/nyse/json/ICB.json  \n",
            "  inflating: stock_market_data/nyse/json/ICD.json  \n",
            "  inflating: stock_market_data/nyse/json/ICE.json  \n",
            "  inflating: stock_market_data/nyse/json/ICL.json  \n",
            "  inflating: stock_market_data/nyse/json/IDE.json  \n",
            "  inflating: stock_market_data/nyse/json/IFF.json  \n",
            "  inflating: stock_market_data/nyse/json/IGA.json  \n",
            "  inflating: stock_market_data/nyse/json/IGD.json  \n",
            "  inflating: stock_market_data/nyse/json/IGI.json  \n",
            "  inflating: stock_market_data/nyse/json/IGR.json  \n",
            "  inflating: stock_market_data/nyse/json/IGT.json  \n",
            "  inflating: stock_market_data/nyse/json/IHC.json  \n",
            "  inflating: stock_market_data/nyse/json/IHD.json  \n",
            "  inflating: stock_market_data/nyse/json/IIF.json  \n",
            "  inflating: stock_market_data/nyse/json/IIM.json  \n",
            "  inflating: stock_market_data/nyse/json/IL.json  \n",
            "  inflating: stock_market_data/nyse/json/IM.json  \n",
            "  inflating: stock_market_data/nyse/json/IMS.json  \n",
            "  inflating: stock_market_data/nyse/json/INGR.json  \n",
            "  inflating: stock_market_data/nyse/json/INN.json  \n",
            "  inflating: stock_market_data/nyse/json/INT.json  \n",
            "  inflating: stock_market_data/nyse/json/IO.json  \n",
            "  inflating: stock_market_data/nyse/json/IOC.json  \n",
            "  inflating: stock_market_data/nyse/json/IP.json  \n",
            "  inflating: stock_market_data/nyse/json/IPG.json  \n",
            "  inflating: stock_market_data/nyse/json/IPI.json  \n",
            "  inflating: stock_market_data/nyse/json/IQI.json  \n",
            "  inflating: stock_market_data/nyse/json/IR.json  \n",
            "  inflating: stock_market_data/nyse/json/IREBY.json  \n",
            "  inflating: stock_market_data/nyse/json/IRF.json  \n",
            "  inflating: stock_market_data/nyse/json/IRL.json  \n",
            "  inflating: stock_market_data/nyse/json/IRM.json  \n",
            "  inflating: stock_market_data/nyse/json/IRS.json  \n",
            "  inflating: stock_market_data/nyse/json/ISD.json  \n",
            "  inflating: stock_market_data/nyse/json/ISHC.json  \n",
            "  inflating: stock_market_data/nyse/json/ITW.json  \n",
            "  inflating: stock_market_data/nyse/json/IVR.json  \n",
            "  inflating: stock_market_data/nyse/json/JAZZ.json  \n",
            "  inflating: stock_market_data/nyse/json/JBT.json  \n",
            "  inflating: stock_market_data/nyse/json/JCS.json  \n",
            "  inflating: stock_market_data/nyse/json/JE.json  \n",
            "  inflating: stock_market_data/nyse/json/JEQ.json  \n",
            "  inflating: stock_market_data/nyse/json/JFC.json  \n",
            "  inflating: stock_market_data/nyse/json/JFR.json  \n",
            "  inflating: stock_market_data/nyse/json/JGH.json  \n",
            "  inflating: stock_market_data/nyse/json/JGV.json  \n",
            "  inflating: stock_market_data/nyse/json/JHI.json  \n",
            "  inflating: stock_market_data/nyse/json/JHP.json  \n",
            "  inflating: stock_market_data/nyse/json/JHS.json  \n",
            "  inflating: stock_market_data/nyse/json/JLL.json  \n",
            "  inflating: stock_market_data/nyse/json/JNJ.json  \n",
            "  inflating: stock_market_data/nyse/json/JNPR.json  \n",
            "  inflating: stock_market_data/nyse/json/JNS.json  \n",
            "  inflating: stock_market_data/nyse/json/JOB.json  \n",
            "  inflating: stock_market_data/nyse/json/JOF.json  \n",
            "  inflating: stock_market_data/nyse/json/JOY.json  \n",
            "  inflating: stock_market_data/nyse/json/JPC.json  \n",
            "  inflating: stock_market_data/nyse/json/JPI.json  \n",
            "  inflating: stock_market_data/nyse/json/JPM.json  \n",
            "  inflating: stock_market_data/nyse/json/JPW.json  \n",
            "  inflating: stock_market_data/nyse/json/JQC.json  \n",
            "  inflating: stock_market_data/nyse/json/JRI.json  \n",
            "  inflating: stock_market_data/nyse/json/JRN.json  \n",
            "  inflating: stock_market_data/nyse/json/JRO.json  \n",
            "  inflating: stock_market_data/nyse/json/JSD.json  \n",
            "  inflating: stock_market_data/nyse/json/JW-A.json  \n",
            "  inflating: stock_market_data/nyse/json/K.json  \n",
            "  inflating: stock_market_data/nyse/json/KAR.json  \n",
            "  inflating: stock_market_data/nyse/json/KATE.json  \n",
            "  inflating: stock_market_data/nyse/json/KB.json  \n",
            "  inflating: stock_market_data/nyse/json/KCG.json  \n",
            "  inflating: stock_market_data/nyse/json/KED.json  \n",
            "  inflating: stock_market_data/nyse/json/KEF.json  \n",
            "  inflating: stock_market_data/nyse/json/KEP.json  \n",
            "  inflating: stock_market_data/nyse/json/KEYS.json  \n",
            "  inflating: stock_market_data/nyse/json/KFS.json  \n",
            "  inflating: stock_market_data/nyse/json/KFY.json  \n",
            "  inflating: stock_market_data/nyse/json/KHI.json  \n",
            "  inflating: stock_market_data/nyse/json/KIO.json  \n",
            "  inflating: stock_market_data/nyse/json/KKD.json  \n",
            "  inflating: stock_market_data/nyse/json/KMF.json  \n",
            "  inflating: stock_market_data/nyse/json/KMG.json  \n",
            "  inflating: stock_market_data/nyse/json/KMPR.json  \n",
            "  inflating: stock_market_data/nyse/json/KMX.json  \n",
            "  inflating: stock_market_data/nyse/json/KND.json  \n",
            "  inflating: stock_market_data/nyse/json/KNX.json  \n",
            "  inflating: stock_market_data/nyse/json/KODK.json  \n",
            "  inflating: stock_market_data/nyse/json/KOF.json  \n",
            "  inflating: stock_market_data/nyse/json/KORS.json  \n",
            "  inflating: stock_market_data/nyse/json/KOS.json  \n",
            "  inflating: stock_market_data/nyse/json/KRC.json  \n",
            "  inflating: stock_market_data/nyse/json/KRG.json  \n",
            "  inflating: stock_market_data/nyse/json/KRO.json  \n",
            "  inflating: stock_market_data/nyse/json/KS.json  \n",
            "  inflating: stock_market_data/nyse/json/KSM.json  \n",
            "  inflating: stock_market_data/nyse/json/KST.json  \n",
            "  inflating: stock_market_data/nyse/json/KSU.json  \n",
            "  inflating: stock_market_data/nyse/json/KTF.json  \n",
            "  inflating: stock_market_data/nyse/json/KWR.json  \n",
            "  inflating: stock_market_data/nyse/json/KYE.json  \n",
            "  inflating: stock_market_data/nyse/json/KYN.json  \n",
            "  inflating: stock_market_data/nyse/json/LAD.json  \n",
            "  inflating: stock_market_data/nyse/json/LADR.json  \n",
            "  inflating: stock_market_data/nyse/json/LBBB.json  \n",
            "  inflating: stock_market_data/nyse/json/LBF.json  \n",
            "  inflating: stock_market_data/nyse/json/LC.json  \n",
            "  inflating: stock_market_data/nyse/json/LDOS.json  \n",
            "  inflating: stock_market_data/nyse/json/LDP.json  \n",
            "  inflating: stock_market_data/nyse/json/LEE.json  \n",
            "  inflating: stock_market_data/nyse/json/LEG.json  \n",
            "  inflating: stock_market_data/nyse/json/LEN-B.json  \n",
            "  inflating: stock_market_data/nyse/json/LEO.json  \n",
            "  inflating: stock_market_data/nyse/json/LEU.json  \n",
            "  inflating: stock_market_data/nyse/json/LF.json  \n",
            "  inflating: stock_market_data/nyse/json/LFC.json  \n",
            "  inflating: stock_market_data/nyse/json/LFL.json  \n",
            "  inflating: stock_market_data/nyse/json/LGF.json  \n",
            "  inflating: stock_market_data/nyse/json/LGI.json  \n",
            "  inflating: stock_market_data/nyse/json/LH.json  \n",
            "  inflating: stock_market_data/nyse/json/LHO.json  \n",
            "  inflating: stock_market_data/nyse/json/LII.json  \n",
            "  inflating: stock_market_data/nyse/json/LL.json  \n",
            "  inflating: stock_market_data/nyse/json/LLY.json  \n",
            "  inflating: stock_market_data/nyse/json/LMT.json  \n",
            "  inflating: stock_market_data/nyse/json/LNC.json  \n",
            "  inflating: stock_market_data/nyse/json/LNT.json  \n",
            "  inflating: stock_market_data/nyse/json/LOW.json  \n",
            "  inflating: stock_market_data/nyse/json/LPG.json  \n",
            "  inflating: stock_market_data/nyse/json/LPI.json  \n",
            "  inflating: stock_market_data/nyse/json/LQ.json  \n",
            "  inflating: stock_market_data/nyse/json/LTC.json  \n",
            "  inflating: stock_market_data/nyse/json/LUK.json  \n",
            "  inflating: stock_market_data/nyse/json/LUV.json  \n",
            "  inflating: stock_market_data/nyse/json/LUX.json  \n",
            "  inflating: stock_market_data/nyse/json/LVLT.json  \n",
            "  inflating: stock_market_data/nyse/json/LVS.json  \n",
            "  inflating: stock_market_data/nyse/json/LXK.json  \n",
            "  inflating: stock_market_data/nyse/json/LXP.json  \n",
            "  inflating: stock_market_data/nyse/json/LXU.json  \n",
            "  inflating: stock_market_data/nyse/json/LYV.json  \n",
            "  inflating: stock_market_data/nyse/json/MA.json  \n",
            "  inflating: stock_market_data/nyse/json/MAIN.json  \n",
            "  inflating: stock_market_data/nyse/json/MAN.json  \n",
            "  inflating: stock_market_data/nyse/json/MAV.json  \n",
            "  inflating: stock_market_data/nyse/json/MBLY.json  \n",
            "  inflating: stock_market_data/nyse/json/MCA.json  \n",
            "  inflating: stock_market_data/nyse/json/MCN.json  \n",
            "  inflating: stock_market_data/nyse/json/MCR.json  \n",
            "  inflating: stock_market_data/nyse/json/MCY.json  \n",
            "  inflating: stock_market_data/nyse/json/MDC.json  \n",
            "  inflating: stock_market_data/nyse/json/MDU.json  \n",
            "  inflating: stock_market_data/nyse/json/MEG.json  \n",
            "  inflating: stock_market_data/nyse/json/MEI.json  \n",
            "  inflating: stock_market_data/nyse/json/MFA.json  \n",
            "  inflating: stock_market_data/nyse/json/MFC.json  \n",
            "  inflating: stock_market_data/nyse/json/MFG.json  \n",
            "  inflating: stock_market_data/nyse/json/MFL.json  \n",
            "  inflating: stock_market_data/nyse/json/MFM.json  \n",
            "  inflating: stock_market_data/nyse/json/MFV.json  \n",
            "  inflating: stock_market_data/nyse/json/MG.json  \n",
            "  inflating: stock_market_data/nyse/json/MGA.json  \n",
            "  inflating: stock_market_data/nyse/json/MGF.json  \n",
            "  inflating: stock_market_data/nyse/json/MGM.json  \n",
            "  inflating: stock_market_data/nyse/json/MGU.json  \n",
            "  inflating: stock_market_data/nyse/json/MHD.json  \n",
            "  inflating: stock_market_data/nyse/json/MHF.json  \n",
            "  inflating: stock_market_data/nyse/json/MHFI.json  \n",
            "  inflating: stock_market_data/nyse/json/MHG.json  \n",
            "  inflating: stock_market_data/nyse/json/MHI.json  \n",
            "  inflating: stock_market_data/nyse/json/MHK.json  \n",
            "  inflating: stock_market_data/nyse/json/MHLD.json  \n",
            "  inflating: stock_market_data/nyse/json/MHN.json  \n",
            "  inflating: stock_market_data/nyse/json/MHNC.json  \n",
            "  inflating: stock_market_data/nyse/json/MHY.json  \n",
            "  inflating: stock_market_data/nyse/json/MIG.json  \n",
            "  inflating: stock_market_data/nyse/json/MILLQ.json  \n",
            "  inflating: stock_market_data/nyse/json/MIN.json  \n",
            "  inflating: stock_market_data/nyse/json/MITT.json  \n",
            "  inflating: stock_market_data/nyse/json/MIY.json  \n",
            "  inflating: stock_market_data/nyse/json/MJI.json  \n",
            "  inflating: stock_market_data/nyse/json/MJN.json  \n",
            "  inflating: stock_market_data/nyse/json/MKC.json  \n",
            "  inflating: stock_market_data/nyse/json/MLI.json  \n",
            "  inflating: stock_market_data/nyse/json/MLM.json  \n",
            "  inflating: stock_market_data/nyse/json/MLP.json  \n",
            "  inflating: stock_market_data/nyse/json/MLR.json  \n",
            "  inflating: stock_market_data/nyse/json/MMC.json  \n",
            "  inflating: stock_market_data/nyse/json/MMD.json  \n",
            "  inflating: stock_market_data/nyse/json/MMI.json  \n",
            "  inflating: stock_market_data/nyse/json/MMP.json  \n",
            "  inflating: stock_market_data/nyse/json/MMT.json  \n",
            "  inflating: stock_market_data/nyse/json/MMU.json  \n",
            "  inflating: stock_market_data/nyse/json/MN.json  \n",
            "  inflating: stock_market_data/nyse/json/MNP.json  \n",
            "  inflating: stock_market_data/nyse/json/MNR.json  \n",
            "  inflating: stock_market_data/nyse/json/MO.json  \n",
            "  inflating: stock_market_data/nyse/json/MOD.json  \n",
            "  inflating: stock_market_data/nyse/json/MOH.json  \n",
            "  inflating: stock_market_data/nyse/json/MORE.json  \n",
            "  inflating: stock_market_data/nyse/json/MOV.json  \n",
            "  inflating: stock_market_data/nyse/json/MPA.json  \n",
            "  inflating: stock_market_data/nyse/json/MPC.json  \n",
            "  inflating: stock_market_data/nyse/json/MPG.json  \n",
            "  inflating: stock_market_data/nyse/json/MPRWP.json  \n",
            "  inflating: stock_market_data/nyse/json/MPV.json  \n",
            "  inflating: stock_market_data/nyse/json/MPW.json  \n",
            "  inflating: stock_market_data/nyse/json/MPX.json  \n",
            "  inflating: stock_market_data/nyse/json/MQT.json  \n",
            "  inflating: stock_market_data/nyse/json/MQY.json  \n",
            "  inflating: stock_market_data/nyse/json/MRH.json  \n",
            "  inflating: stock_market_data/nyse/json/MRIN.json  \n",
            "  inflating: stock_market_data/nyse/json/MS-PF.json  \n",
            "  inflating: stock_market_data/nyse/json/MSA.json  \n",
            "  inflating: stock_market_data/nyse/json/MSB.json  \n",
            "  inflating: stock_market_data/nyse/json/MSD.json  \n",
            "  inflating: stock_market_data/nyse/json/MSFG.json  \n",
            "  inflating: stock_market_data/nyse/json/MSI.json  \n",
            "  inflating: stock_market_data/nyse/json/MSK.json  \n",
            "  inflating: stock_market_data/nyse/json/MSM.json  \n",
            "  inflating: stock_market_data/nyse/json/MTDR.json  \n",
            "  inflating: stock_market_data/nyse/json/MTG.json  \n",
            "  inflating: stock_market_data/nyse/json/MTN.json  \n",
            "  inflating: stock_market_data/nyse/json/MTR.json  \n",
            "  inflating: stock_market_data/nyse/json/MTRN.json  \n",
            "  inflating: stock_market_data/nyse/json/MTU.json  \n",
            "  inflating: stock_market_data/nyse/json/MTX.json  \n",
            "  inflating: stock_market_data/nyse/json/MUA.json  \n",
            "  inflating: stock_market_data/nyse/json/MUC.json  \n",
            "  inflating: stock_market_data/nyse/json/MUE.json  \n",
            "  inflating: stock_market_data/nyse/json/MUI.json  \n",
            "  inflating: stock_market_data/nyse/json/MUJ.json  \n",
            "  inflating: stock_market_data/nyse/json/MUSA.json  \n",
            "  inflating: stock_market_data/nyse/json/MUX.json  \n",
            "  inflating: stock_market_data/nyse/json/MVNR.json  \n",
            "  inflating: stock_market_data/nyse/json/MVT.json  \n",
            "  inflating: stock_market_data/nyse/json/MWO.json  \n",
            "  inflating: stock_market_data/nyse/json/MWR.json  \n",
            "  inflating: stock_market_data/nyse/json/MWW.json  \n",
            "  inflating: stock_market_data/nyse/json/MXCHF.json  \n",
            "  inflating: stock_market_data/nyse/json/MXE.json  \n",
            "  inflating: stock_market_data/nyse/json/MYC.json  \n",
            "  inflating: stock_market_data/nyse/json/MYCC.json  \n",
            "  inflating: stock_market_data/nyse/json/MYD.json  \n",
            "  inflating: stock_market_data/nyse/json/MYE.json  \n",
            "  inflating: stock_market_data/nyse/json/MYI.json  \n",
            "  inflating: stock_market_data/nyse/json/MYJ.json  \n",
            "  inflating: stock_market_data/nyse/json/MYN.json  \n",
            "  inflating: stock_market_data/nyse/json/MZF.json  \n",
            "  inflating: stock_market_data/nyse/json/NADL.json  \n",
            "  inflating: stock_market_data/nyse/json/NAT.json  \n",
            "  inflating: stock_market_data/nyse/json/NBB.json  \n",
            "  inflating: stock_market_data/nyse/json/NBD.json  \n",
            "  inflating: stock_market_data/nyse/json/NBHC.json  \n",
            "  inflating: stock_market_data/nyse/json/NBR.json  \n",
            "  inflating: stock_market_data/nyse/json/NC.json  \n",
            "  inflating: stock_market_data/nyse/json/NCA.json  \n",
            "  inflating: stock_market_data/nyse/json/NCFT.json  \n",
            "  inflating: stock_market_data/nyse/json/NCV.json  \n",
            "  inflating: stock_market_data/nyse/json/NCZ.json  \n",
            "  inflating: stock_market_data/nyse/json/NDP.json  \n",
            "  inflating: stock_market_data/nyse/json/NE.json  \n",
            "  inflating: stock_market_data/nyse/json/NEE-PP.json  \n",
            "  inflating: stock_market_data/nyse/json/NEE.json  \n",
            "  inflating: stock_market_data/nyse/json/NEM.json  \n",
            "  inflating: stock_market_data/nyse/json/NESC.json  \n",
            "  inflating: stock_market_data/nyse/json/NEU.json  \n",
            "  inflating: stock_market_data/nyse/json/NEV.json  \n",
            "  inflating: stock_market_data/nyse/json/NEWS.json  \n",
            "  inflating: stock_market_data/nyse/json/NFG.json  \n",
            "  inflating: stock_market_data/nyse/json/NFJ.json  \n",
            "  inflating: stock_market_data/nyse/json/NFX.json  \n",
            "  inflating: stock_market_data/nyse/json/NGS.json  \n",
            "  inflating: stock_market_data/nyse/json/NGVC.json  \n",
            "  inflating: stock_market_data/nyse/json/NHI.json  \n",
            "  inflating: stock_market_data/nyse/json/NID.json  \n",
            "  inflating: stock_market_data/nyse/json/NIE.json  \n",
            "  inflating: stock_market_data/nyse/json/NIM.json  \n",
            "  inflating: stock_market_data/nyse/json/NIO.json  \n",
            "  inflating: stock_market_data/nyse/json/NIQ.json  \n",
            "  inflating: stock_market_data/nyse/json/NJR.json  \n",
            "  inflating: stock_market_data/nyse/json/NL.json  \n",
            "  inflating: stock_market_data/nyse/json/NLY.json  \n",
            "  inflating: stock_market_data/nyse/json/NM.json  \n",
            "  inflating: stock_market_data/nyse/json/NMA.json  \n",
            "  inflating: stock_market_data/nyse/json/NMBL.json  \n",
            "  inflating: stock_market_data/nyse/json/NMFC.json  \n",
            "  inflating: stock_market_data/nyse/json/NMI.json  \n",
            "  inflating: stock_market_data/nyse/json/NMO.json  \n",
            "  inflating: stock_market_data/nyse/json/NMS.json  \n",
            "  inflating: stock_market_data/nyse/json/NNP.json  \n",
            "  inflating: stock_market_data/nyse/json/NNY.json  \n",
            "  inflating: stock_market_data/nyse/json/NOA.json  \n",
            "  inflating: stock_market_data/nyse/json/NOAH.json  \n",
            "  inflating: stock_market_data/nyse/json/NOC.json  \n",
            "  inflating: stock_market_data/nyse/json/NORD.json  \n",
            "  inflating: stock_market_data/nyse/json/NORNQ.json  \n",
            "  inflating: stock_market_data/nyse/json/NOV.json  \n",
            "  inflating: stock_market_data/nyse/json/NP.json  \n",
            "  inflating: stock_market_data/nyse/json/NPD.json  \n",
            "  inflating: stock_market_data/nyse/json/NPF.json  \n",
            "  inflating: stock_market_data/nyse/json/NPI.json  \n",
            "  inflating: stock_market_data/nyse/json/NPK.json  \n",
            "  inflating: stock_market_data/nyse/json/NPO.json  \n",
            "  inflating: stock_market_data/nyse/json/NPP.json  \n",
            "  inflating: stock_market_data/nyse/json/NPT.json  \n",
            "  inflating: stock_market_data/nyse/json/NPTN.json  \n",
            "  inflating: stock_market_data/nyse/json/NQI.json  \n",
            "  inflating: stock_market_data/nyse/json/NQM.json  \n",
            "  inflating: stock_market_data/nyse/json/NQS.json  \n",
            "  inflating: stock_market_data/nyse/json/NQU.json  \n",
            "  inflating: stock_market_data/nyse/json/NR.json  \n",
            "  inflating: stock_market_data/nyse/json/NRF.json  \n",
            "  inflating: stock_market_data/nyse/json/NRP.json  \n",
            "  inflating: stock_market_data/nyse/json/NRT.json  \n",
            "  inflating: stock_market_data/nyse/json/NRZ.json  \n",
            "  inflating: stock_market_data/nyse/json/NS.json  \n",
            "  inflating: stock_market_data/nyse/json/NSAM.json  \n",
            "  inflating: stock_market_data/nyse/json/NSC.json  \n",
            "  inflating: stock_market_data/nyse/json/NSL.json  \n",
            "  inflating: stock_market_data/nyse/json/NSM.json  \n",
            "  inflating: stock_market_data/nyse/json/NSS.json  \n",
            "  inflating: stock_market_data/nyse/json/NTL.json  \n",
            "  inflating: stock_market_data/nyse/json/NTP.json  \n",
            "  inflating: stock_market_data/nyse/json/NTT.json  \n",
            "  inflating: stock_market_data/nyse/json/NTZ.json  \n",
            "  inflating: stock_market_data/nyse/json/NUS.json  \n",
            "  inflating: stock_market_data/nyse/json/NUV.json  \n",
            "  inflating: stock_market_data/nyse/json/NVO.json  \n",
            "  inflating: stock_market_data/nyse/json/NWN.json  \n",
            "  inflating: stock_market_data/nyse/json/NX.json  \n",
            "  inflating: stock_market_data/nyse/json/NXC.json  \n",
            "  inflating: stock_market_data/nyse/json/NXK.json  \n",
            "  inflating: stock_market_data/nyse/json/NXN.json  \n",
            "  inflating: stock_market_data/nyse/json/NXRT.json  \n",
            "  inflating: stock_market_data/nyse/json/NXZ.json  \n",
            "  inflating: stock_market_data/nyse/json/NYCB.json  \n",
            "  inflating: stock_market_data/nyse/json/NYRT.json  \n",
            "  inflating: stock_market_data/nyse/json/NZH.json  \n",
            "  inflating: stock_market_data/nyse/json/OAKS.json  \n",
            "  inflating: stock_market_data/nyse/json/OAS.json  \n",
            "  inflating: stock_market_data/nyse/json/OB.json  \n",
            "  inflating: stock_market_data/nyse/json/OCN.json  \n",
            "  inflating: stock_market_data/nyse/json/OEC.json  \n",
            "  inflating: stock_market_data/nyse/json/OFC.json  \n",
            "  inflating: stock_market_data/nyse/json/OHI.json  \n",
            "  inflating: stock_market_data/nyse/json/OIA.json  \n",
            "  inflating: stock_market_data/nyse/json/OII.json  \n",
            "  inflating: stock_market_data/nyse/json/OIS.json  \n",
            "  inflating: stock_market_data/nyse/json/OKS.json  \n",
            "  inflating: stock_market_data/nyse/json/OLP.json  \n",
            "  inflating: stock_market_data/nyse/json/OMAM.json  \n",
            "  inflating: stock_market_data/nyse/json/OMC.json  \n",
            "  inflating: stock_market_data/nyse/json/OMI.json  \n",
            "  inflating: stock_market_data/nyse/json/ONE.json  \n",
            "  inflating: stock_market_data/nyse/json/ORAN.json  \n",
            "  inflating: stock_market_data/nyse/json/ORC.json  \n",
            "  inflating: stock_market_data/nyse/json/ORI.json  \n",
            "  inflating: stock_market_data/nyse/json/OXM.json  \n",
            "  inflating: stock_market_data/nyse/json/OXY.json  \n",
            "  inflating: stock_market_data/nyse/json/P.json  \n",
            "  inflating: stock_market_data/nyse/json/PAA.json  \n",
            "  inflating: stock_market_data/nyse/json/PAG.json  \n",
            "  inflating: stock_market_data/nyse/json/PAH.json  \n",
            "  inflating: stock_market_data/nyse/json/PAI.json  \n",
            "  inflating: stock_market_data/nyse/json/PAM.json  \n",
            "  inflating: stock_market_data/nyse/json/PANW.json  \n",
            "  inflating: stock_market_data/nyse/json/PAR.json  \n",
            "  inflating: stock_market_data/nyse/json/PAY.json  \n",
            "  inflating: stock_market_data/nyse/json/PAYC.json  \n",
            "  inflating: stock_market_data/nyse/json/PB.json  \n",
            "  inflating: stock_market_data/nyse/json/PBA.json  \n",
            "  inflating: stock_market_data/nyse/json/PBH.json  \n",
            "  inflating: stock_market_data/nyse/json/PBI.json  \n",
            "  inflating: stock_market_data/nyse/json/PBR.json  \n",
            "  inflating: stock_market_data/nyse/json/PBT.json  \n",
            "  inflating: stock_market_data/nyse/json/PBYI.json  \n",
            "  inflating: stock_market_data/nyse/json/PCF.json  \n",
            "  inflating: stock_market_data/nyse/json/PCG-PA.json  \n",
            "  inflating: stock_market_data/nyse/json/PCL.json  \n",
            "  inflating: stock_market_data/nyse/json/PCN.json  \n",
            "  inflating: stock_market_data/nyse/json/PCQ.json  \n",
            "  inflating: stock_market_data/nyse/json/PDI.json  \n",
            "  inflating: stock_market_data/nyse/json/PDM.json  \n",
            "  inflating: stock_market_data/nyse/json/PDS.json  \n",
            "  inflating: stock_market_data/nyse/json/PDT.json  \n",
            "  inflating: stock_market_data/nyse/json/PEB.json  \n",
            "  inflating: stock_market_data/nyse/json/PEG.json  \n",
            "  inflating: stock_market_data/nyse/json/PEI.json  \n",
            "  inflating: stock_market_data/nyse/json/PFD.json  \n",
            "  inflating: stock_market_data/nyse/json/PFG.json  \n",
            "  inflating: stock_market_data/nyse/json/PFN.json  \n",
            "  inflating: stock_market_data/nyse/json/PFO.json  \n",
            "  inflating: stock_market_data/nyse/json/PFS.json  \n",
            "  inflating: stock_market_data/nyse/json/PFSI.json  \n",
            "  inflating: stock_market_data/nyse/json/PG.json  \n",
            "  inflating: stock_market_data/nyse/json/PGEM.json  \n",
            "  inflating: stock_market_data/nyse/json/PGH.json  \n",
            "  inflating: stock_market_data/nyse/json/PGNPQ.json  \n",
            "  inflating: stock_market_data/nyse/json/PGRE.json  \n",
            "  inflating: stock_market_data/nyse/json/PGZ.json  \n",
            "  inflating: stock_market_data/nyse/json/PHG.json  \n",
            "  inflating: stock_market_data/nyse/json/PHX.json  \n",
            "  inflating: stock_market_data/nyse/json/PII.json  \n",
            "  inflating: stock_market_data/nyse/json/PIM.json  \n",
            "  inflating: stock_market_data/nyse/json/PJS.json  \n",
            "  inflating: stock_market_data/nyse/json/PKG.json  \n",
            "  inflating: stock_market_data/nyse/json/PKI.json  \n",
            "  inflating: stock_market_data/nyse/json/PLOW.json  \n",
            "  inflating: stock_market_data/nyse/json/PM.json  \n",
            "  inflating: stock_market_data/nyse/json/PMF.json  \n",
            "  inflating: stock_market_data/nyse/json/PMM.json  \n",
            "  inflating: stock_market_data/nyse/json/PMO.json  \n",
            "  inflating: stock_market_data/nyse/json/PMT.json  \n",
            "  inflating: stock_market_data/nyse/json/PMX.json  \n",
            "  inflating: stock_market_data/nyse/json/PNC.json  \n",
            "  inflating: stock_market_data/nyse/json/PNF.json  \n",
            "  inflating: stock_market_data/nyse/json/PNK.json  \n",
            "  inflating: stock_market_data/nyse/json/PNNT.json  \n",
            "  inflating: stock_market_data/nyse/json/PNW.json  \n",
            "  inflating: stock_market_data/nyse/json/PNX.json  \n",
            "  inflating: stock_market_data/nyse/json/PNY.json  \n",
            "  inflating: stock_market_data/nyse/json/POR.json  \n",
            "  inflating: stock_market_data/nyse/json/POST.json  \n",
            "  inflating: stock_market_data/nyse/json/POT.json  \n",
            "  inflating: stock_market_data/nyse/json/POWR.json  \n",
            "  inflating: stock_market_data/nyse/json/PPG.json  \n",
            "  inflating: stock_market_data/nyse/json/PPS.json  \n",
            "  inflating: stock_market_data/nyse/json/PPT.json  \n",
            "  inflating: stock_market_data/nyse/json/PQ.json  \n",
            "  inflating: stock_market_data/nyse/json/PRGO.json  \n",
            "  inflating: stock_market_data/nyse/json/PRLB.json  \n",
            "  inflating: stock_market_data/nyse/json/PRO.json  \n",
            "  inflating: stock_market_data/nyse/json/PRU.json  \n",
            "  inflating: stock_market_data/nyse/json/PSA-PQ.json  \n",
            "  inflating: stock_market_data/nyse/json/PSA-PR.json  \n",
            "  inflating: stock_market_data/nyse/json/PSB.json  \n",
            "  inflating: stock_market_data/nyse/json/PSEC.json  \n",
            "  inflating: stock_market_data/nyse/json/PSF.json  \n",
            "  inflating: stock_market_data/nyse/json/PSG.json  \n",
            "  inflating: stock_market_data/nyse/json/PSX.json  \n",
            "  inflating: stock_market_data/nyse/json/PT.json  \n",
            "  inflating: stock_market_data/nyse/json/PTP.json  \n",
            "  inflating: stock_market_data/nyse/json/PTR.json  \n",
            "  inflating: stock_market_data/nyse/json/PTY.json  \n",
            "  inflating: stock_market_data/nyse/json/PVAH.json  \n",
            "  inflating: stock_market_data/nyse/json/PVG.json  \n",
            "  inflating: stock_market_data/nyse/json/PWR.json  \n",
            "  inflating: stock_market_data/nyse/json/PXD.json  \n",
            "  inflating: stock_market_data/nyse/json/PYN.json  \n",
            "  inflating: stock_market_data/nyse/json/PYS.json  \n",
            "  inflating: stock_market_data/nyse/json/PZC.json  \n",
            "  inflating: stock_market_data/nyse/json/PZE.json  \n",
            "  inflating: stock_market_data/nyse/json/PZN.json  \n",
            "  inflating: stock_market_data/nyse/json/QSR.json  \n",
            "  inflating: stock_market_data/nyse/json/QTWO.json  \n",
            "  inflating: stock_market_data/nyse/json/R.json  \n",
            "  inflating: stock_market_data/nyse/json/RAI.json  \n",
            "  inflating: stock_market_data/nyse/json/RALY.json  \n",
            "  inflating: stock_market_data/nyse/json/RAX.json  \n",
            "  inflating: stock_market_data/nyse/json/RBA.json  \n",
            "  inflating: stock_market_data/nyse/json/RBS-PE.json  \n",
            "  inflating: stock_market_data/nyse/json/RBS-PG.json  \n",
            "  inflating: stock_market_data/nyse/json/RBS-PI.json  \n",
            "  inflating: stock_market_data/nyse/json/RCI.json  \n",
            "  inflating: stock_market_data/nyse/json/RCL.json  \n",
            "  inflating: stock_market_data/nyse/json/RCS.json  \n",
            "  inflating: stock_market_data/nyse/json/RDY.json  \n",
            "  inflating: stock_market_data/nyse/json/RE.json  \n",
            "  inflating: stock_market_data/nyse/json/REG.json  \n",
            "  inflating: stock_market_data/nyse/json/RESI.json  \n",
            "  inflating: stock_market_data/nyse/json/REX.json  \n",
            "  inflating: stock_market_data/nyse/json/REXR.json  \n",
            "  inflating: stock_market_data/nyse/json/RF.json  \n",
            "  inflating: stock_market_data/nyse/json/RFI.json  \n",
            "  inflating: stock_market_data/nyse/json/RFIL.json  \n",
            "  inflating: stock_market_data/nyse/json/RFP.json  \n",
            "  inflating: stock_market_data/nyse/json/RGA.json  \n",
            "  inflating: stock_market_data/nyse/json/RGC.json  \n",
            "  inflating: stock_market_data/nyse/json/RGR.json  \n",
            "  inflating: stock_market_data/nyse/json/RGT.json  \n",
            "  inflating: stock_market_data/nyse/json/RHI.json  \n",
            "  inflating: stock_market_data/nyse/json/RHP.json  \n",
            "  inflating: stock_market_data/nyse/json/RIOM.json  \n",
            "  inflating: stock_market_data/nyse/json/RIT.json  \n",
            "  inflating: stock_market_data/nyse/json/RJF.json  \n",
            "  inflating: stock_market_data/nyse/json/RKUS.json  \n",
            "  inflating: stock_market_data/nyse/json/RL.json  \n",
            "  inflating: stock_market_data/nyse/json/RLGY.json  \n",
            "  inflating: stock_market_data/nyse/json/RM.json  \n",
            "  inflating: stock_market_data/nyse/json/RMAX.json  \n",
            "  inflating: stock_market_data/nyse/json/RNE.json  \n",
            "  inflating: stock_market_data/nyse/json/RNP.json  \n",
            "  inflating: stock_market_data/nyse/json/RNR.json  \n",
            "  inflating: stock_market_data/nyse/json/ROC.json  \n",
            "  inflating: stock_market_data/nyse/json/ROK.json  \n",
            "  inflating: stock_market_data/nyse/json/RPM.json  \n",
            "  inflating: stock_market_data/nyse/json/RQI.json  \n",
            "  inflating: stock_market_data/nyse/json/RRC.json  \n",
            "  inflating: stock_market_data/nyse/json/RRTS.json  \n",
            "  inflating: stock_market_data/nyse/json/RS.json  \n",
            "  inflating: stock_market_data/nyse/json/RSE.json  \n",
            "  inflating: stock_market_data/nyse/json/RSG.json  \n",
            "  inflating: stock_market_data/nyse/json/RSO.json  \n",
            "  inflating: stock_market_data/nyse/json/RSPP.json  \n",
            "  inflating: stock_market_data/nyse/json/RT.json  \n",
            "  inflating: stock_market_data/nyse/json/RTI.json  \n",
            "  inflating: stock_market_data/nyse/json/RVM.json  \n",
            "  inflating: stock_market_data/nyse/json/RVT.json  \n",
            "  inflating: stock_market_data/nyse/json/RWT.json  \n",
            "  inflating: stock_market_data/nyse/json/RY.json  \n",
            "  inflating: stock_market_data/nyse/json/RYAM.json  \n",
            "  inflating: stock_market_data/nyse/json/RYI.json  \n",
            "  inflating: stock_market_data/nyse/json/SAH.json  \n",
            "  inflating: stock_market_data/nyse/json/SAM.json  \n",
            "  inflating: stock_market_data/nyse/json/SAN.json  \n",
            "  inflating: stock_market_data/nyse/json/SAP.json  \n",
            "  inflating: stock_market_data/nyse/json/SAR.json  \n",
            "  inflating: stock_market_data/nyse/json/SBR.json  \n",
            "  inflating: stock_market_data/nyse/json/SBS.json  \n",
            "  inflating: stock_market_data/nyse/json/SBW.json  \n",
            "  inflating: stock_market_data/nyse/json/SBY.json  \n",
            "  inflating: stock_market_data/nyse/json/SC.json  \n",
            "  inflating: stock_market_data/nyse/json/SCCO.json  \n",
            "  inflating: stock_market_data/nyse/json/SCD.json  \n",
            "  inflating: stock_market_data/nyse/json/SCI.json  \n",
            "  inflating: stock_market_data/nyse/json/SDOC.json  \n",
            "  inflating: stock_market_data/nyse/json/SE.json  \n",
            "  inflating: stock_market_data/nyse/json/SEAS.json  \n",
            "  inflating: stock_market_data/nyse/json/SEM.json  \n",
            "  inflating: stock_market_data/nyse/json/SF.json  \n",
            "  inflating: stock_market_data/nyse/json/SFE.json  \n",
            "  inflating: stock_market_data/nyse/json/SFL.json  \n",
            "  inflating: stock_market_data/nyse/json/SGF.json  \n",
            "  inflating: stock_market_data/nyse/json/SGL.json  \n",
            "  inflating: stock_market_data/nyse/json/SGM.json  \n",
            "  inflating: stock_market_data/nyse/json/SGU.json  \n",
            "  inflating: stock_market_data/nyse/json/SGY.json  \n",
            "  inflating: stock_market_data/nyse/json/SHG.json  \n",
            "  inflating: stock_market_data/nyse/json/SHI.json  \n",
            "  inflating: stock_market_data/nyse/json/SID.json  \n",
            "  inflating: stock_market_data/nyse/json/SIG.json  \n",
            "  inflating: stock_market_data/nyse/json/SIGI.json  \n",
            "  inflating: stock_market_data/nyse/json/SIX.json  \n",
            "  inflating: stock_market_data/nyse/json/SJI.json  \n",
            "  inflating: stock_market_data/nyse/json/SJR.json  \n",
            "  inflating: stock_market_data/nyse/json/SJT.json  \n",
            "  inflating: stock_market_data/nyse/json/SKM.json  \n",
            "  inflating: stock_market_data/nyse/json/SKT.json  \n",
            "  inflating: stock_market_data/nyse/json/SKX.json  \n",
            "  inflating: stock_market_data/nyse/json/SLB.json  \n",
            "  inflating: stock_market_data/nyse/json/SLCA.json  \n",
            "  inflating: stock_market_data/nyse/json/SLF.json  \n",
            "  inflating: stock_market_data/nyse/json/SLW.json  \n",
            "  inflating: stock_market_data/nyse/json/SM.json  \n",
            "  inflating: stock_market_data/nyse/json/SMG.json  \n",
            "  inflating: stock_market_data/nyse/json/SMI.json  \n",
            "  inflating: stock_market_data/nyse/json/SMP.json  \n",
            "  inflating: stock_market_data/nyse/json/SNI.json  \n",
            "  inflating: stock_market_data/nyse/json/SNOW.json  \n",
            "  inflating: stock_market_data/nyse/json/SNP.json  \n",
            "  inflating: stock_market_data/nyse/json/SNV.json  \n",
            "  inflating: stock_market_data/nyse/json/SOCGM.json  \n",
            "  inflating: stock_market_data/nyse/json/SON.json  \n",
            "  inflating: stock_market_data/nyse/json/SOR.json  \n",
            "  inflating: stock_market_data/nyse/json/SPB.json  \n",
            "  inflating: stock_market_data/nyse/json/SPE.json  \n",
            "  inflating: stock_market_data/nyse/json/SPG.json  \n",
            "  inflating: stock_market_data/nyse/json/SPH.json  \n",
            "  inflating: stock_market_data/nyse/json/SPLP.json  \n",
            "  inflating: stock_market_data/nyse/json/SPR.json  \n",
            "  inflating: stock_market_data/nyse/json/SPXX.json  \n",
            "  inflating: stock_market_data/nyse/json/SQM.json  \n",
            "  inflating: stock_market_data/nyse/json/SRC.json  \n",
            "  inflating: stock_market_data/nyse/json/SRCF.json  \n",
            "  inflating: stock_market_data/nyse/json/SRE.json  \n",
            "  inflating: stock_market_data/nyse/json/SSD.json  \n",
            "  inflating: stock_market_data/nyse/json/SSE.json  \n",
            "  inflating: stock_market_data/nyse/json/SSNI.json  \n",
            "  inflating: stock_market_data/nyse/json/SSS.json  \n",
            "  inflating: stock_market_data/nyse/json/SSTK.json  \n",
            "  inflating: stock_market_data/nyse/json/ST.json  \n",
            "  inflating: stock_market_data/nyse/json/STAG.json  \n",
            "  inflating: stock_market_data/nyse/json/STC.json  \n",
            "  inflating: stock_market_data/nyse/json/STJ.json  \n",
            "  inflating: stock_market_data/nyse/json/STL.json  \n",
            "  inflating: stock_market_data/nyse/json/STM.json  \n",
            "  inflating: stock_market_data/nyse/json/STNG.json  \n",
            "  inflating: stock_market_data/nyse/json/STO.json  \n",
            "  inflating: stock_market_data/nyse/json/STOR.json  \n",
            "  inflating: stock_market_data/nyse/json/STRI.json  \n",
            "  inflating: stock_market_data/nyse/json/STT.json  \n",
            "  inflating: stock_market_data/nyse/json/STV.json  \n",
            "  inflating: stock_market_data/nyse/json/STWD.json  \n",
            "  inflating: stock_market_data/nyse/json/STZ-B.json  \n",
            "  inflating: stock_market_data/nyse/json/SU.json  \n",
            "  inflating: stock_market_data/nyse/json/SUI.json  \n",
            "  inflating: stock_market_data/nyse/json/SUP.json  \n",
            "  inflating: stock_market_data/nyse/json/SWC.json  \n",
            "  inflating: stock_market_data/nyse/json/SWFT.json  \n",
            "  inflating: stock_market_data/nyse/json/SWK.json  \n",
            "  inflating: stock_market_data/nyse/json/SWN.json  \n",
            "  inflating: stock_market_data/nyse/json/SWZ.json  \n",
            "  inflating: stock_market_data/nyse/json/SXC.json  \n",
            "  inflating: stock_market_data/nyse/json/SXI.json  \n",
            "  inflating: stock_market_data/nyse/json/SXT.json  \n",
            "  inflating: stock_market_data/nyse/json/SYF.json  \n",
            "  inflating: stock_market_data/nyse/json/SYT.json  \n",
            "  inflating: stock_market_data/nyse/json/T.json  \n",
            "  inflating: stock_market_data/nyse/json/TA.json  \n",
            "  inflating: stock_market_data/nyse/json/TAC.json  \n",
            "  inflating: stock_market_data/nyse/json/TAP.json  \n",
            "  inflating: stock_market_data/nyse/json/TARO.json  \n",
            "  inflating: stock_market_data/nyse/json/TCAP.json  \n",
            "  inflating: stock_market_data/nyse/json/TCB.json  \n",
            "  inflating: stock_market_data/nyse/json/TCI.json  \n",
            "  inflating: stock_market_data/nyse/json/TCK.json  \n",
            "  inflating: stock_market_data/nyse/json/TCPI.json  \n",
            "  inflating: stock_market_data/nyse/json/TCPTF.json  \n",
            "  inflating: stock_market_data/nyse/json/TDF.json  \n",
            "  inflating: stock_market_data/nyse/json/TDG.json  \n",
            "  inflating: stock_market_data/nyse/json/TDS.json  \n",
            "  inflating: stock_market_data/nyse/json/TDY.json  \n",
            "  inflating: stock_market_data/nyse/json/TEG.json  \n",
            "  inflating: stock_market_data/nyse/json/TEI.json  \n",
            "  inflating: stock_market_data/nyse/json/TEO.json  \n",
            "  inflating: stock_market_data/nyse/json/TEUFF.json  \n",
            "  inflating: stock_market_data/nyse/json/TEVA.json  \n",
            "  inflating: stock_market_data/nyse/json/TGH.json  \n",
            "  inflating: stock_market_data/nyse/json/TGI.json  \n",
            "  inflating: stock_market_data/nyse/json/TGP.json  \n",
            "  inflating: stock_market_data/nyse/json/TGS.json  \n",
            "  inflating: stock_market_data/nyse/json/THG.json  \n",
            "  inflating: stock_market_data/nyse/json/THLEF.json  \n",
            "  inflating: stock_market_data/nyse/json/THO.json  \n",
            "  inflating: stock_market_data/nyse/json/THQ.json  \n",
            "  inflating: stock_market_data/nyse/json/THR.json  \n",
            "  inflating: stock_market_data/nyse/json/THS.json  \n",
            "  inflating: stock_market_data/nyse/json/TKC.json  \n",
            "  inflating: stock_market_data/nyse/json/TKF.json  \n",
            "  inflating: stock_market_data/nyse/json/TLK.json  \n",
            "  inflating: stock_market_data/nyse/json/TLM.json  \n",
            "  inflating: stock_market_data/nyse/json/TMH.json  \n",
            "  inflating: stock_market_data/nyse/json/TMHC.json  \n",
            "  inflating: stock_market_data/nyse/json/TMO.json  \n",
            "  inflating: stock_market_data/nyse/json/TMST.json  \n",
            "  inflating: stock_market_data/nyse/json/TNC.json  \n",
            "  inflating: stock_market_data/nyse/json/TNH.json  \n",
            "  inflating: stock_market_data/nyse/json/TNK.json  \n",
            "  inflating: stock_market_data/nyse/json/TNP.json  \n",
            "  inflating: stock_market_data/nyse/json/TOL.json  \n",
            "  inflating: stock_market_data/nyse/json/TPC.json  \n",
            "  inflating: stock_market_data/nyse/json/TPL.json  \n",
            "  inflating: stock_market_data/nyse/json/TPPPF.json  \n",
            "  inflating: stock_market_data/nyse/json/TPUB.json  \n",
            "  inflating: stock_market_data/nyse/json/TPVG.json  \n",
            "  inflating: stock_market_data/nyse/json/TPX.json  \n",
            "  inflating: stock_market_data/nyse/json/TPZ.json  \n",
            "  inflating: stock_market_data/nyse/json/TR.json  \n",
            "  inflating: stock_market_data/nyse/json/TRC.json  \n",
            "  inflating: stock_market_data/nyse/json/TREC.json  \n",
            "  inflating: stock_market_data/nyse/json/TRI.json  \n",
            "  inflating: stock_market_data/nyse/json/TRMR.json  \n",
            "  inflating: stock_market_data/nyse/json/TRN.json  \n",
            "  inflating: stock_market_data/nyse/json/TRNO.json  \n",
            "  inflating: stock_market_data/nyse/json/TRQ.json  \n",
            "  inflating: stock_market_data/nyse/json/TRR.json  \n",
            "  inflating: stock_market_data/nyse/json/TRV.json  \n",
            "  inflating: stock_market_data/nyse/json/TRW.json  \n",
            "  inflating: stock_market_data/nyse/json/TSE.json  \n",
            "  inflating: stock_market_data/nyse/json/TSI.json  \n",
            "  inflating: stock_market_data/nyse/json/TSLX.json  \n",
            "  inflating: stock_market_data/nyse/json/TSM.json  \n",
            "  inflating: stock_market_data/nyse/json/TSQ.json  \n",
            "  inflating: stock_market_data/nyse/json/TTM.json  \n",
            "  inflating: stock_market_data/nyse/json/TTP.json  \n",
            "  inflating: stock_market_data/nyse/json/TUMI.json  \n",
            "  inflating: stock_market_data/nyse/json/TUP.json  \n",
            "  inflating: stock_market_data/nyse/json/TV.json  \n",
            "  inflating: stock_market_data/nyse/json/TVE.json  \n",
            "  inflating: stock_market_data/nyse/json/TVPT.json  \n",
            "  inflating: stock_market_data/nyse/json/TW.json  \n",
            "  inflating: stock_market_data/nyse/json/TWC.json  \n",
            "  inflating: stock_market_data/nyse/json/TWI.json  \n",
            "  inflating: stock_market_data/nyse/json/TWO.json  \n",
            "  inflating: stock_market_data/nyse/json/TY.json  \n",
            "  inflating: stock_market_data/nyse/json/TYC.json  \n",
            "  inflating: stock_market_data/nyse/json/TYG.json  \n",
            "  inflating: stock_market_data/nyse/json/UAL.json  \n",
            "  inflating: stock_market_data/nyse/json/UBA.json  \n",
            "  inflating: stock_market_data/nyse/json/UBS-PD.json  \n",
            "  inflating: stock_market_data/nyse/json/UHS.json  \n",
            "  inflating: stock_market_data/nyse/json/UHT.json  \n",
            "  inflating: stock_market_data/nyse/json/UL.json  \n",
            "  inflating: stock_market_data/nyse/json/UMC.json  \n",
            "  inflating: stock_market_data/nyse/json/UMH.json  \n",
            "  inflating: stock_market_data/nyse/json/UNH.json  \n",
            "  inflating: stock_market_data/nyse/json/UNM.json  \n",
            "  inflating: stock_market_data/nyse/json/UPS.json  \n",
            "  inflating: stock_market_data/nyse/json/URI.json  \n",
            "  inflating: stock_market_data/nyse/json/USM.json  \n",
            "  inflating: stock_market_data/nyse/json/USNA.json  \n",
            "  inflating: stock_market_data/nyse/json/USPH.json  \n",
            "  inflating: stock_market_data/nyse/json/UTF.json  \n",
            "  inflating: stock_market_data/nyse/json/UTI.json  \n",
            "  inflating: stock_market_data/nyse/json/V.json  \n",
            "  inflating: stock_market_data/nyse/json/VAC.json  \n",
            "  inflating: stock_market_data/nyse/json/VBF.json  \n",
            "  inflating: stock_market_data/nyse/json/VCO.json  \n",
            "  inflating: stock_market_data/nyse/json/VCRA.json  \n",
            "  inflating: stock_market_data/nyse/json/VCV.json  \n",
            "  inflating: stock_market_data/nyse/json/VEEV.json  \n",
            "  inflating: stock_market_data/nyse/json/VET.json  \n",
            "  inflating: stock_market_data/nyse/json/VG.json  \n",
            "  inflating: stock_market_data/nyse/json/VGI.json  \n",
            "  inflating: stock_market_data/nyse/json/VGM.json  \n",
            "  inflating: stock_market_data/nyse/json/VGR.json  \n",
            "  inflating: stock_market_data/nyse/json/VIV.json  \n",
            "  inflating: stock_market_data/nyse/json/VKQ.json  \n",
            "  inflating: stock_market_data/nyse/json/VLT.json  \n",
            "  inflating: stock_market_data/nyse/json/VLY.json  \n",
            "  inflating: stock_market_data/nyse/json/VMC.json  \n",
            "  inflating: stock_market_data/nyse/json/VMEM.json  \n",
            "  inflating: stock_market_data/nyse/json/VMI.json  \n",
            "  inflating: stock_market_data/nyse/json/VMO.json  \n",
            "  inflating: stock_market_data/nyse/json/VNCE.json  \n",
            "  inflating: stock_market_data/nyse/json/VOYA.json  \n",
            "  inflating: stock_market_data/nyse/json/VPG.json  \n",
            "  inflating: stock_market_data/nyse/json/VPV.json  \n",
            "  inflating: stock_market_data/nyse/json/VR.json  \n",
            "  inflating: stock_market_data/nyse/json/VRX.json  \n",
            "  inflating: stock_market_data/nyse/json/VSH.json  \n",
            "  inflating: stock_market_data/nyse/json/VTN.json  \n",
            "  inflating: stock_market_data/nyse/json/VTSS.json  \n",
            "  inflating: stock_market_data/nyse/json/VULC.json  \n",
            "  inflating: stock_market_data/nyse/json/VVR.json  \n",
            "  inflating: stock_market_data/nyse/json/VZ.json  \n",
            "  inflating: stock_market_data/nyse/json/WAB.json  \n",
            "  inflating: stock_market_data/nyse/json/WAC.json  \n",
            "  inflating: stock_market_data/nyse/json/WAL.json  \n",
            "  inflating: stock_market_data/nyse/json/WBK.json  \n",
            "  inflating: stock_market_data/nyse/json/WBS.json  \n",
            "  inflating: stock_market_data/nyse/json/WCC.json  \n",
            "  inflating: stock_market_data/nyse/json/WCIC.json  \n",
            "  inflating: stock_market_data/nyse/json/WCN.json  \n",
            "  inflating: stock_market_data/nyse/json/WD.json  \n",
            "  inflating: stock_market_data/nyse/json/WES.json  \n",
            "  inflating: stock_market_data/nyse/json/WFC.json  \n",
            "  inflating: stock_market_data/nyse/json/WG.json  \n",
            "  inflating: stock_market_data/nyse/json/WGL.json  \n",
            "  inflating: stock_market_data/nyse/json/WGO.json  \n",
            "  inflating: stock_market_data/nyse/json/WHG.json  \n",
            "  inflating: stock_market_data/nyse/json/WHZT.json  \n",
            "  inflating: stock_market_data/nyse/json/WIA.json  \n",
            "  inflating: stock_market_data/nyse/json/WIT.json  \n",
            "  inflating: stock_market_data/nyse/json/WLK.json  \n",
            "  inflating: stock_market_data/nyse/json/WLL.json  \n",
            "  inflating: stock_market_data/nyse/json/WM.json  \n",
            "  inflating: stock_market_data/nyse/json/WMB.json  \n",
            "  inflating: stock_market_data/nyse/json/WMC.json  \n",
            "  inflating: stock_market_data/nyse/json/WMK.json  \n",
            "  inflating: stock_market_data/nyse/json/WMS.json  \n",
            "  inflating: stock_market_data/nyse/json/WNC.json  \n",
            "  inflating: stock_market_data/nyse/json/WNS.json  \n",
            "  inflating: stock_market_data/nyse/json/WOR.json  \n",
            "  inflating: stock_market_data/nyse/json/WPC.json  \n",
            "  inflating: stock_market_data/nyse/json/WPZ.json  \n",
            "  inflating: stock_market_data/nyse/json/WR.json  \n",
            "  inflating: stock_market_data/nyse/json/WRB.json  \n",
            "  inflating: stock_market_data/nyse/json/WRE.json  \n",
            "  inflating: stock_market_data/nyse/json/WSR.json  \n",
            "  inflating: stock_market_data/nyse/json/WST.json  \n",
            "  inflating: stock_market_data/nyse/json/WTI.json  \n",
            "  inflating: stock_market_data/nyse/json/WTM.json  \n",
            "  inflating: stock_market_data/nyse/json/WTS.json  \n",
            "  inflating: stock_market_data/nyse/json/WTW.json  \n",
            "  inflating: stock_market_data/nyse/json/WWE.json  \n",
            "  inflating: stock_market_data/nyse/json/WWW.json  \n",
            "  inflating: stock_market_data/nyse/json/WYN.json  \n",
            "  inflating: stock_market_data/nyse/json/X.json  \n",
            "  inflating: stock_market_data/nyse/json/XHR.json  \n",
            "  inflating: stock_market_data/nyse/json/XIN.json  \n",
            "  inflating: stock_market_data/nyse/json/XPO.json  \n",
            "  inflating: stock_market_data/nyse/json/YDKN.json  \n",
            "  inflating: stock_market_data/nyse/json/YGE.json  \n",
            "  inflating: stock_market_data/nyse/json/YPF.json  \n",
            "  inflating: stock_market_data/nyse/json/YUM.json  \n",
            "  inflating: stock_market_data/nyse/json/YZC.json  \n",
            "  inflating: stock_market_data/nyse/json/ZAHLY.json  \n",
            "  inflating: stock_market_data/nyse/json/ZDPY.json  \n",
            "  inflating: stock_market_data/nyse/json/ZFC.json  \n",
            "  inflating: stock_market_data/nyse/json/ZION.json  \n",
            "  inflating: stock_market_data/nyse/json/ZNH.json  \n",
            "  inflating: stock_market_data/nyse/json/ZOES.json  \n",
            "  inflating: stock_market_data/sp500/csv/A.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AAL.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AAP.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AAPL.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ABBV.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ABC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ABMD.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ABT.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ACN.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ADI.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ADM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ADP.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ADSK.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AEE.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AEP.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AIZ.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AJG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AKAM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ALB.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ALGN.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ALK.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ALLE.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ALTR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AMAT.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AMD.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AME.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AMGN.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AMP.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AMT.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AMZN.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ANET.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ANTM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AON.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AOS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/APA.csv  \n",
            "  inflating: stock_market_data/sp500/csv/APD.csv  \n",
            "  inflating: stock_market_data/sp500/csv/APH.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ARE.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ATVI.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AVB.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AVY.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AWK.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AXP.csv  \n",
            "  inflating: stock_market_data/sp500/csv/AZO.csv  \n",
            "  inflating: stock_market_data/sp500/csv/BA.csv  \n",
            "  inflating: stock_market_data/sp500/csv/BAC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/BAX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/BBY.csv  \n",
            "  inflating: stock_market_data/sp500/csv/BDX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/BEN.csv  \n",
            "  inflating: stock_market_data/sp500/csv/BF-A.csv  \n",
            "  inflating: stock_market_data/sp500/csv/BHI.csv  \n",
            "  inflating: stock_market_data/sp500/csv/BIIB.csv  \n",
            "  inflating: stock_market_data/sp500/csv/BIO.csv  \n",
            "  inflating: stock_market_data/sp500/csv/BK.csv  \n",
            "  inflating: stock_market_data/sp500/csv/BLK.csv  \n",
            "  inflating: stock_market_data/sp500/csv/BMRA.csv  \n",
            "  inflating: stock_market_data/sp500/csv/BMY.csv  \n",
            "  inflating: stock_market_data/sp500/csv/BR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/BRK-A.csv  \n",
            "  inflating: stock_market_data/sp500/csv/BSHI.csv  \n",
            "  inflating: stock_market_data/sp500/csv/BSX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/BWA.csv  \n",
            "  inflating: stock_market_data/sp500/csv/BXP.csv  \n",
            "  inflating: stock_market_data/sp500/csv/C.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CAG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CAH.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CAT.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CB.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CCI.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CDE.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CDNS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CF.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CFG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CHD.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CHRW.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CHTR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CINF.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CL.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CLX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CME.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CMG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CMI.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CNC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CNP.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CNWT.csv  \n",
            "  inflating: stock_market_data/sp500/csv/COO.csv  \n",
            "  inflating: stock_market_data/sp500/csv/COP.csv  \n",
            "  inflating: stock_market_data/sp500/csv/COST.csv  \n",
            "  inflating: stock_market_data/sp500/csv/COTY.csv  \n",
            "  inflating: stock_market_data/sp500/csv/COWN.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CPB.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CPICQ.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CPRT.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CRM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CSCO.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CTAS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CTQ.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CTSH.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CTXS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/CUK.csv  \n",
            "  inflating: stock_market_data/sp500/csv/D.csv  \n",
            "  inflating: stock_market_data/sp500/csv/DAL.csv  \n",
            "  inflating: stock_market_data/sp500/csv/DE.csv  \n",
            "  inflating: stock_market_data/sp500/csv/DFS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/DG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/DGX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/DHI.csv  \n",
            "  inflating: stock_market_data/sp500/csv/DIS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/DLTR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/DOV.csv  \n",
            "  inflating: stock_market_data/sp500/csv/DPZ.csv  \n",
            "  inflating: stock_market_data/sp500/csv/DRE.csv  \n",
            "  inflating: stock_market_data/sp500/csv/DRI.csv  \n",
            "  inflating: stock_market_data/sp500/csv/DTE.csv  \n",
            "  inflating: stock_market_data/sp500/csv/DVA.csv  \n",
            "  inflating: stock_market_data/sp500/csv/DXCM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/EA.csv  \n",
            "  inflating: stock_market_data/sp500/csv/EBAY.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ECL.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ED.csv  \n",
            "  inflating: stock_market_data/sp500/csv/EFX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/EIX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/EL.csv  \n",
            "  inflating: stock_market_data/sp500/csv/EMN.csv  \n",
            "  inflating: stock_market_data/sp500/csv/EMR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ENS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/EOG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/EQIX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/EQR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ES.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ESS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/EW.csv  \n",
            "  inflating: stock_market_data/sp500/csv/EXR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/F.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FANG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FAST.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FB.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FBHS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FCGN.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FCX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FDX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FE.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FFIV.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FIS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FISV.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FITB.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FLS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FLT.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FMBM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FMC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FN.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FPLPF.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FRC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FRMC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FRT.csv  \n",
            "  inflating: stock_market_data/sp500/csv/FTI.csv  \n",
            "  inflating: stock_market_data/sp500/csv/GD.csv  \n",
            "  inflating: stock_market_data/sp500/csv/GE.csv  \n",
            "  inflating: stock_market_data/sp500/csv/GGG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/GILD.csv  \n",
            "  inflating: stock_market_data/sp500/csv/GIS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/GM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/GOOG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/GPC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/GPN.csv  \n",
            "  inflating: stock_market_data/sp500/csv/GRMN.csv  \n",
            "  inflating: stock_market_data/sp500/csv/GS-PJ.csv  \n",
            "  inflating: stock_market_data/sp500/csv/GWW.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HAL.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HAS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HBAN.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HBI.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HCA.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HD.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HES.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HFC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HII.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HLT.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HOLX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HON.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HPE.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HPQ.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HRB.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HRL.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HSIC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HST.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HSY.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HTLF.csv  \n",
            "  inflating: stock_market_data/sp500/csv/HUM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/IBM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ICE.csv  \n",
            "  inflating: stock_market_data/sp500/csv/IDXX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/IEX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/IFF.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ILMN.csv  \n",
            "  inflating: stock_market_data/sp500/csv/INTH.csv  \n",
            "  inflating: stock_market_data/sp500/csv/INTU.csv  \n",
            "  inflating: stock_market_data/sp500/csv/IP.csv  \n",
            "  inflating: stock_market_data/sp500/csv/IPGP.csv  \n",
            "  inflating: stock_market_data/sp500/csv/IR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/IRM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ISRG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/IT.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ITW.csv  \n",
            "  inflating: stock_market_data/sp500/csv/IVZ.csv  \n",
            "  inflating: stock_market_data/sp500/csv/JBHT.csv  \n",
            "  inflating: stock_market_data/sp500/csv/JCI.csv  \n",
            "  inflating: stock_market_data/sp500/csv/JKHY.csv  \n",
            "  inflating: stock_market_data/sp500/csv/JNJ.csv  \n",
            "  inflating: stock_market_data/sp500/csv/JNPR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/JPM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/K.csv  \n",
            "  inflating: stock_market_data/sp500/csv/KACPF.csv  \n",
            "  inflating: stock_market_data/sp500/csv/KEY.csv  \n",
            "  inflating: stock_market_data/sp500/csv/KEYS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/KGNR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/KHC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/KIM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/KMB.csv  \n",
            "  inflating: stock_market_data/sp500/csv/KMX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/KO.csv  \n",
            "  inflating: stock_market_data/sp500/csv/KR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/KRA.csv  \n",
            "  inflating: stock_market_data/sp500/csv/KSS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/KSU.csv  \n",
            "  inflating: stock_market_data/sp500/csv/LBTYA.csv  \n",
            "  inflating: stock_market_data/sp500/csv/LDOS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/LEG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/LH.csv  \n",
            "  inflating: stock_market_data/sp500/csv/LKQ.csv  \n",
            "  inflating: stock_market_data/sp500/csv/LMT.csv  \n",
            "  inflating: stock_market_data/sp500/csv/LNC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/LNT.csv  \n",
            "  inflating: stock_market_data/sp500/csv/LOW.csv  \n",
            "  inflating: stock_market_data/sp500/csv/LRCX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/LUV.csv  \n",
            "  inflating: stock_market_data/sp500/csv/LVS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/LYB.csv  \n",
            "  inflating: stock_market_data/sp500/csv/LYV.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MAA.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MAR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MCD.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MCHP.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MCK.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MCO.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MDLZ.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MDT.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MET.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MGM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MHK.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MKTX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MLM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MMC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MMM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MNST.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MO.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MOS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MPC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MRCR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MRK.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MRO.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MS-PF.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MSCI.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MSFT.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MSI.csv  \n",
            "  inflating: stock_market_data/sp500/csv/MU.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NCLH.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NCTKF.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NDAQ.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NEE.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NEOG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NFLX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NI.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NLSN.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NMHLY.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NOC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NOK.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NOV.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NOW.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NOXL.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NRG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NSC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NTAP.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NTRA.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NTRR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NTRS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NVR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NVRO.csv  \n",
            "  inflating: stock_market_data/sp500/csv/NWL.csv  \n",
            "  inflating: stock_market_data/sp500/csv/O.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ODFL.csv  \n",
            "  inflating: stock_market_data/sp500/csv/OKE.csv  \n",
            "  inflating: stock_market_data/sp500/csv/OMC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ORLY.csv  \n",
            "  inflating: stock_market_data/sp500/csv/OXY.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PAYX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PBCT.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PCAR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PEG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PEP.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PFE.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PH.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PHM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PKG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PKI.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PLD.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PNR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PNW.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PNWRF.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PPG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PRU.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PSX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PVH.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PWR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/PXD.csv  \n",
            "  inflating: stock_market_data/sp500/csv/QRVO.csv  \n",
            "  inflating: stock_market_data/sp500/csv/RCL.csv  \n",
            "  inflating: stock_market_data/sp500/csv/RE.csv  \n",
            "  inflating: stock_market_data/sp500/csv/REG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/REGN.csv  \n",
            "  inflating: stock_market_data/sp500/csv/RF.csv  \n",
            "  inflating: stock_market_data/sp500/csv/RHI.csv  \n",
            "  inflating: stock_market_data/sp500/csv/RIBT.csv  \n",
            "  inflating: stock_market_data/sp500/csv/RJF.csv  \n",
            "  inflating: stock_market_data/sp500/csv/RL.csv  \n",
            "  inflating: stock_market_data/sp500/csv/RLI.csv  \n",
            "  inflating: stock_market_data/sp500/csv/RMD.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ROK.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ROL.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ROP.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ROST.csv  \n",
            "  inflating: stock_market_data/sp500/csv/RSG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/RSNHF.csv  \n",
            "  inflating: stock_market_data/sp500/csv/RXMD.csv  \n",
            "  inflating: stock_market_data/sp500/csv/SBUX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/SCHW.csv  \n",
            "  inflating: stock_market_data/sp500/csv/SEE.csv  \n",
            "  inflating: stock_market_data/sp500/csv/SEGXF.csv  \n",
            "  inflating: stock_market_data/sp500/csv/SHW.csv  \n",
            "  inflating: stock_market_data/sp500/csv/SIVB.csv  \n",
            "  inflating: stock_market_data/sp500/csv/SLB.csv  \n",
            "  inflating: stock_market_data/sp500/csv/SLG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/SNPS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/SO.csv  \n",
            "  inflating: stock_market_data/sp500/csv/SONC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/SPG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/SRE.csv  \n",
            "  inflating: stock_market_data/sp500/csv/SRG.csv  \n",
            "  inflating: stock_market_data/sp500/csv/STT.csv  \n",
            "  inflating: stock_market_data/sp500/csv/STX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/STZ-B.csv  \n",
            "  inflating: stock_market_data/sp500/csv/SWK.csv  \n",
            "  inflating: stock_market_data/sp500/csv/SWKS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/SYF.csv  \n",
            "  inflating: stock_market_data/sp500/csv/SYK.csv  \n",
            "  inflating: stock_market_data/sp500/csv/T.csv  \n",
            "  inflating: stock_market_data/sp500/csv/TAP.csv  \n",
            "  inflating: stock_market_data/sp500/csv/TCYSF.csv  \n",
            "  inflating: stock_market_data/sp500/csv/TEL.csv  \n",
            "  inflating: stock_market_data/sp500/csv/TJX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/TMO.csv  \n",
            "  inflating: stock_market_data/sp500/csv/TMUS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/TRAUF.csv  \n",
            "  inflating: stock_market_data/sp500/csv/TROW.csv  \n",
            "  inflating: stock_market_data/sp500/csv/TRV.csv  \n",
            "  inflating: stock_market_data/sp500/csv/TSCO.csv  \n",
            "  inflating: stock_market_data/sp500/csv/TSN.csv  \n",
            "  inflating: stock_market_data/sp500/csv/TTWO.csv  \n",
            "  inflating: stock_market_data/sp500/csv/TW.csv  \n",
            "  inflating: stock_market_data/sp500/csv/TWTR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/TXN.csv  \n",
            "  inflating: stock_market_data/sp500/csv/TXT.csv  \n",
            "  inflating: stock_market_data/sp500/csv/TYL.csv  \n",
            "  inflating: stock_market_data/sp500/csv/UA.csv  \n",
            "  inflating: stock_market_data/sp500/csv/UAL.csv  \n",
            "  inflating: stock_market_data/sp500/csv/UDR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/UEEC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/UHS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ULTA.csv  \n",
            "  inflating: stock_market_data/sp500/csv/UNM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/UNP.csv  \n",
            "  inflating: stock_market_data/sp500/csv/UPS.csv  \n",
            "  inflating: stock_market_data/sp500/csv/URI.csv  \n",
            "  inflating: stock_market_data/sp500/csv/USB.csv  \n",
            "  inflating: stock_market_data/sp500/csv/V.csv  \n",
            "  inflating: stock_market_data/sp500/csv/VFC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/VMC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/VRSK.csv  \n",
            "  inflating: stock_market_data/sp500/csv/VRSN.csv  \n",
            "  inflating: stock_market_data/sp500/csv/VTR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/VZ.csv  \n",
            "  inflating: stock_market_data/sp500/csv/WAT.csv  \n",
            "  inflating: stock_market_data/sp500/csv/WBA.csv  \n",
            "  inflating: stock_market_data/sp500/csv/WDC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/WEC.csv  \n",
            "  inflating: stock_market_data/sp500/csv/WHR.csv  \n",
            "  inflating: stock_market_data/sp500/csv/WM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/WMB.csv  \n",
            "  inflating: stock_market_data/sp500/csv/WRB.csv  \n",
            "  inflating: stock_market_data/sp500/csv/WRK.csv  \n",
            "  inflating: stock_market_data/sp500/csv/WSPOF.csv  \n",
            "  inflating: stock_market_data/sp500/csv/WST.csv  \n",
            "  inflating: stock_market_data/sp500/csv/WU.csv  \n",
            "  inflating: stock_market_data/sp500/csv/WY.csv  \n",
            "  inflating: stock_market_data/sp500/csv/WYNN.csv  \n",
            "  inflating: stock_market_data/sp500/csv/XEL.csv  \n",
            "  inflating: stock_market_data/sp500/csv/XLEFF.csv  \n",
            "  inflating: stock_market_data/sp500/csv/XLNX.csv  \n",
            "  inflating: stock_market_data/sp500/csv/XOM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/XYL.csv  \n",
            "  inflating: stock_market_data/sp500/csv/YUM.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ZBH.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ZION.csv  \n",
            "  inflating: stock_market_data/sp500/csv/ZTS.csv  \n",
            "  inflating: stock_market_data/sp500/json/A.json  \n",
            "  inflating: stock_market_data/sp500/json/AAL.json  \n",
            "  inflating: stock_market_data/sp500/json/AAP.json  \n",
            "  inflating: stock_market_data/sp500/json/AAPL.json  \n",
            "  inflating: stock_market_data/sp500/json/ABBV.json  \n",
            "  inflating: stock_market_data/sp500/json/ABC.json  \n",
            "  inflating: stock_market_data/sp500/json/ABMD.json  \n",
            "  inflating: stock_market_data/sp500/json/ABT.json  \n",
            "  inflating: stock_market_data/sp500/json/ACN.json  \n",
            "  inflating: stock_market_data/sp500/json/ADI.json  \n",
            "  inflating: stock_market_data/sp500/json/ADM.json  \n",
            "  inflating: stock_market_data/sp500/json/ADP.json  \n",
            "  inflating: stock_market_data/sp500/json/ADSK.json  \n",
            "  inflating: stock_market_data/sp500/json/AEE.json  \n",
            "  inflating: stock_market_data/sp500/json/AEP.json  \n",
            "  inflating: stock_market_data/sp500/json/AES-PC.json  \n",
            "  inflating: stock_market_data/sp500/json/AIZ.json  \n",
            "  inflating: stock_market_data/sp500/json/AJG.json  \n",
            "  inflating: stock_market_data/sp500/json/AKAM.json  \n",
            "  inflating: stock_market_data/sp500/json/ALB.json  \n",
            "  inflating: stock_market_data/sp500/json/ALGN.json  \n",
            "  inflating: stock_market_data/sp500/json/ALK.json  \n",
            "  inflating: stock_market_data/sp500/json/ALLE.json  \n",
            "  inflating: stock_market_data/sp500/json/ALTR.json  \n",
            "  inflating: stock_market_data/sp500/json/AMAT.json  \n",
            "  inflating: stock_market_data/sp500/json/AMD.json  \n",
            "  inflating: stock_market_data/sp500/json/AME.json  \n",
            "  inflating: stock_market_data/sp500/json/AMGN.json  \n",
            "  inflating: stock_market_data/sp500/json/AMP.json  \n",
            "  inflating: stock_market_data/sp500/json/AMT.json  \n",
            "  inflating: stock_market_data/sp500/json/AMZN.json  \n",
            "  inflating: stock_market_data/sp500/json/ANET.json  \n",
            "  inflating: stock_market_data/sp500/json/ANTM.json  \n",
            "  inflating: stock_market_data/sp500/json/AON.json  \n",
            "  inflating: stock_market_data/sp500/json/AOS.json  \n",
            "  inflating: stock_market_data/sp500/json/APA.json  \n",
            "  inflating: stock_market_data/sp500/json/APD.json  \n",
            "  inflating: stock_market_data/sp500/json/APH.json  \n",
            "  inflating: stock_market_data/sp500/json/ARE.json  \n",
            "  inflating: stock_market_data/sp500/json/ATVI.json  \n",
            "  inflating: stock_market_data/sp500/json/AVB.json  \n",
            "  inflating: stock_market_data/sp500/json/AVY.json  \n",
            "  inflating: stock_market_data/sp500/json/AWK.json  \n",
            "  inflating: stock_market_data/sp500/json/AXP.json  \n",
            "  inflating: stock_market_data/sp500/json/AZO.json  \n",
            "  inflating: stock_market_data/sp500/json/BA.json  \n",
            "  inflating: stock_market_data/sp500/json/BAC.json  \n",
            "  inflating: stock_market_data/sp500/json/BAX.json  \n",
            "  inflating: stock_market_data/sp500/json/BBY.json  \n",
            "  inflating: stock_market_data/sp500/json/BDX.json  \n",
            "  inflating: stock_market_data/sp500/json/BEN.json  \n",
            "  inflating: stock_market_data/sp500/json/BF-A.json  \n",
            "  inflating: stock_market_data/sp500/json/BHI.json  \n",
            "  inflating: stock_market_data/sp500/json/BIIB.json  \n",
            "  inflating: stock_market_data/sp500/json/BIO.json  \n",
            "  inflating: stock_market_data/sp500/json/BK.json  \n",
            "  inflating: stock_market_data/sp500/json/BLK.json  \n",
            "  inflating: stock_market_data/sp500/json/BMRA.json  \n",
            "  inflating: stock_market_data/sp500/json/BMY.json  \n",
            "  inflating: stock_market_data/sp500/json/BR.json  \n",
            "  inflating: stock_market_data/sp500/json/BRK-A.json  \n",
            "  inflating: stock_market_data/sp500/json/BSFT.json  \n",
            "  inflating: stock_market_data/sp500/json/BSHI.json  \n",
            "  inflating: stock_market_data/sp500/json/BSX.json  \n",
            "  inflating: stock_market_data/sp500/json/BWA.json  \n",
            "  inflating: stock_market_data/sp500/json/BXP.json  \n",
            "  inflating: stock_market_data/sp500/json/BYLK.json  \n",
            "  inflating: stock_market_data/sp500/json/C.json  \n",
            "  inflating: stock_market_data/sp500/json/CAG.json  \n",
            "  inflating: stock_market_data/sp500/json/CAH.json  \n",
            "  inflating: stock_market_data/sp500/json/CAT.json  \n",
            "  inflating: stock_market_data/sp500/json/CB.json  \n",
            "  inflating: stock_market_data/sp500/json/CBG.json  \n",
            "  inflating: stock_market_data/sp500/json/CCI.json  \n",
            "  inflating: stock_market_data/sp500/json/CDE.json  \n",
            "  inflating: stock_market_data/sp500/json/CDNS.json  \n",
            "  inflating: stock_market_data/sp500/json/CF.json  \n",
            "  inflating: stock_market_data/sp500/json/CFG.json  \n",
            "  inflating: stock_market_data/sp500/json/CHD.json  \n",
            "  inflating: stock_market_data/sp500/json/CHRW.json  \n",
            "  inflating: stock_market_data/sp500/json/CHTR.json  \n",
            "  inflating: stock_market_data/sp500/json/CINF.json  \n",
            "  inflating: stock_market_data/sp500/json/CL.json  \n",
            "  inflating: stock_market_data/sp500/json/CLX.json  \n",
            "  inflating: stock_market_data/sp500/json/CME.json  \n",
            "  inflating: stock_market_data/sp500/json/CMG.json  \n",
            "  inflating: stock_market_data/sp500/json/CMI.json  \n",
            "  inflating: stock_market_data/sp500/json/CNC.json  \n",
            "  inflating: stock_market_data/sp500/json/CNP.json  \n",
            "  inflating: stock_market_data/sp500/json/CNWT.json  \n",
            "  inflating: stock_market_data/sp500/json/COO.json  \n",
            "  inflating: stock_market_data/sp500/json/COP.json  \n",
            "  inflating: stock_market_data/sp500/json/COST.json  \n",
            "  inflating: stock_market_data/sp500/json/COTY.json  \n",
            "  inflating: stock_market_data/sp500/json/COWN.json  \n",
            "  inflating: stock_market_data/sp500/json/CPB.json  \n",
            "  inflating: stock_market_data/sp500/json/CPICQ.json  \n",
            "  inflating: stock_market_data/sp500/json/CPRT.json  \n",
            "  inflating: stock_market_data/sp500/json/CRM.json  \n",
            "  inflating: stock_market_data/sp500/json/CSCO.json  \n",
            "  inflating: stock_market_data/sp500/json/CTAS.json  \n",
            "  inflating: stock_market_data/sp500/json/CTQ.json  \n",
            "  inflating: stock_market_data/sp500/json/CTSH.json  \n",
            "  inflating: stock_market_data/sp500/json/CTXS.json  \n",
            "  inflating: stock_market_data/sp500/json/CUK.json  \n",
            "  inflating: stock_market_data/sp500/json/D.json  \n",
            "  inflating: stock_market_data/sp500/json/DAL.json  \n",
            "  inflating: stock_market_data/sp500/json/DE.json  \n",
            "  inflating: stock_market_data/sp500/json/DFS.json  \n",
            "  inflating: stock_market_data/sp500/json/DG.json  \n",
            "  inflating: stock_market_data/sp500/json/DGX.json  \n",
            "  inflating: stock_market_data/sp500/json/DHI.json  \n",
            "  inflating: stock_market_data/sp500/json/DIS.json  \n",
            "  inflating: stock_market_data/sp500/json/DLTR.json  \n",
            "  inflating: stock_market_data/sp500/json/DOV.json  \n",
            "  inflating: stock_market_data/sp500/json/DPZ.json  \n",
            "  inflating: stock_market_data/sp500/json/DRE.json  \n",
            "  inflating: stock_market_data/sp500/json/DRI.json  \n",
            "  inflating: stock_market_data/sp500/json/DTE.json  \n",
            "  inflating: stock_market_data/sp500/json/DUNR.json  \n",
            "  inflating: stock_market_data/sp500/json/DVA.json  \n",
            "  inflating: stock_market_data/sp500/json/DXCM.json  \n",
            "  inflating: stock_market_data/sp500/json/EA.json  \n",
            "  inflating: stock_market_data/sp500/json/EBAY.json  \n",
            "  inflating: stock_market_data/sp500/json/ECL.json  \n",
            "  inflating: stock_market_data/sp500/json/ED.json  \n",
            "  inflating: stock_market_data/sp500/json/EFX.json  \n",
            "  inflating: stock_market_data/sp500/json/EIX.json  \n",
            "  inflating: stock_market_data/sp500/json/EL.json  \n",
            "  inflating: stock_market_data/sp500/json/EMN.json  \n",
            "  inflating: stock_market_data/sp500/json/EMR.json  \n",
            "  inflating: stock_market_data/sp500/json/ENS.json  \n",
            "  inflating: stock_market_data/sp500/json/EOG.json  \n",
            "  inflating: stock_market_data/sp500/json/EQIX.json  \n",
            "  inflating: stock_market_data/sp500/json/EQR.json  \n",
            "  inflating: stock_market_data/sp500/json/ES.json  \n",
            "  inflating: stock_market_data/sp500/json/ESS.json  \n",
            "  inflating: stock_market_data/sp500/json/ETVVF.json  \n",
            "  inflating: stock_market_data/sp500/json/EW.json  \n",
            "  inflating: stock_market_data/sp500/json/EXR.json  \n",
            "  inflating: stock_market_data/sp500/json/F.json  \n",
            "  inflating: stock_market_data/sp500/json/FANG.json  \n",
            "  inflating: stock_market_data/sp500/json/FAST.json  \n",
            "  inflating: stock_market_data/sp500/json/FB.json  \n",
            "  inflating: stock_market_data/sp500/json/FBHS.json  \n",
            "  inflating: stock_market_data/sp500/json/FCGN.json  \n",
            "  inflating: stock_market_data/sp500/json/FCX.json  \n",
            "  inflating: stock_market_data/sp500/json/FDX.json  \n",
            "  inflating: stock_market_data/sp500/json/FE.json  \n",
            "  inflating: stock_market_data/sp500/json/FFIV.json  \n",
            "  inflating: stock_market_data/sp500/json/FIS.json  \n",
            "  inflating: stock_market_data/sp500/json/FISV.json  \n",
            "  inflating: stock_market_data/sp500/json/FITB.json  \n",
            "  inflating: stock_market_data/sp500/json/FLS.json  \n",
            "  inflating: stock_market_data/sp500/json/FLT.json  \n",
            "  inflating: stock_market_data/sp500/json/FMBM.json  \n",
            "  inflating: stock_market_data/sp500/json/FMC.json  \n",
            "  inflating: stock_market_data/sp500/json/FN.json  \n",
            "  inflating: stock_market_data/sp500/json/FPLPF.json  \n",
            "  inflating: stock_market_data/sp500/json/FRC.json  \n",
            "  inflating: stock_market_data/sp500/json/FRMC.json  \n",
            "  inflating: stock_market_data/sp500/json/FRT.json  \n",
            "  inflating: stock_market_data/sp500/json/FTI.json  \n",
            "  inflating: stock_market_data/sp500/json/GD.json  \n",
            "  inflating: stock_market_data/sp500/json/GE.json  \n",
            "  inflating: stock_market_data/sp500/json/GGG.json  \n",
            "  inflating: stock_market_data/sp500/json/GILD.json  \n",
            "  inflating: stock_market_data/sp500/json/GIS.json  \n",
            "  inflating: stock_market_data/sp500/json/GM.json  \n",
            "  inflating: stock_market_data/sp500/json/GOOG.json  \n",
            "  inflating: stock_market_data/sp500/json/GPC.json  \n",
            "  inflating: stock_market_data/sp500/json/GPN.json  \n",
            "  inflating: stock_market_data/sp500/json/GRMN.json  \n",
            "  inflating: stock_market_data/sp500/json/GS-PJ.json  \n",
            "  inflating: stock_market_data/sp500/json/GWW.json  \n",
            "  inflating: stock_market_data/sp500/json/HAL.json  \n",
            "  inflating: stock_market_data/sp500/json/HAS.json  \n",
            "  inflating: stock_market_data/sp500/json/HBAN.json  \n",
            "  inflating: stock_market_data/sp500/json/HBI.json  \n",
            "  inflating: stock_market_data/sp500/json/HCA.json  \n",
            "  inflating: stock_market_data/sp500/json/HCN.json  \n",
            "  inflating: stock_market_data/sp500/json/HD.json  \n",
            "  inflating: stock_market_data/sp500/json/HES.json  \n",
            "  inflating: stock_market_data/sp500/json/HFC.json  \n",
            "  inflating: stock_market_data/sp500/json/HGHN.json  \n",
            "  inflating: stock_market_data/sp500/json/HII.json  \n",
            "  inflating: stock_market_data/sp500/json/HLT.json  \n",
            "  inflating: stock_market_data/sp500/json/HOLX.json  \n",
            "  inflating: stock_market_data/sp500/json/HON.json  \n",
            "  inflating: stock_market_data/sp500/json/HPE.json  \n",
            "  inflating: stock_market_data/sp500/json/HPQ.json  \n",
            "  inflating: stock_market_data/sp500/json/HRB.json  \n",
            "  inflating: stock_market_data/sp500/json/HRL.json  \n",
            "  inflating: stock_market_data/sp500/json/HSIC.json  \n",
            "  inflating: stock_market_data/sp500/json/HST.json  \n",
            "  inflating: stock_market_data/sp500/json/HSY.json  \n",
            "  inflating: stock_market_data/sp500/json/HTLF.json  \n",
            "  inflating: stock_market_data/sp500/json/HUM.json  \n",
            "  inflating: stock_market_data/sp500/json/IBM.json  \n",
            "  inflating: stock_market_data/sp500/json/ICE.json  \n",
            "  inflating: stock_market_data/sp500/json/IDXX.json  \n",
            "  inflating: stock_market_data/sp500/json/IEX.json  \n",
            "  inflating: stock_market_data/sp500/json/IFF.json  \n",
            "  inflating: stock_market_data/sp500/json/ILMN.json  \n",
            "  inflating: stock_market_data/sp500/json/INTH.json  \n",
            "  inflating: stock_market_data/sp500/json/INTU.json  \n",
            "  inflating: stock_market_data/sp500/json/IP.json  \n",
            "  inflating: stock_market_data/sp500/json/IPGP.json  \n",
            "  inflating: stock_market_data/sp500/json/IR.json  \n",
            "  inflating: stock_market_data/sp500/json/IRM.json  \n",
            "  inflating: stock_market_data/sp500/json/ISRG.json  \n",
            "  inflating: stock_market_data/sp500/json/IT.json  \n",
            "  inflating: stock_market_data/sp500/json/ITW.json  \n",
            "  inflating: stock_market_data/sp500/json/IVZ.json  \n",
            "  inflating: stock_market_data/sp500/json/JBHT.json  \n",
            "  inflating: stock_market_data/sp500/json/JCI.json  \n",
            "  inflating: stock_market_data/sp500/json/JKHY.json  \n",
            "  inflating: stock_market_data/sp500/json/JNJ.json  \n",
            "  inflating: stock_market_data/sp500/json/JNPR.json  \n",
            "  inflating: stock_market_data/sp500/json/JPM.json  \n",
            "  inflating: stock_market_data/sp500/json/K.json  \n",
            "  inflating: stock_market_data/sp500/json/KACPF.json  \n",
            "  inflating: stock_market_data/sp500/json/KEY.json  \n",
            "  inflating: stock_market_data/sp500/json/KEYS.json  \n",
            "  inflating: stock_market_data/sp500/json/KGNR.json  \n",
            "  inflating: stock_market_data/sp500/json/KHC.json  \n",
            "  inflating: stock_market_data/sp500/json/KIM.json  \n",
            "  inflating: stock_market_data/sp500/json/KMB.json  \n",
            "  inflating: stock_market_data/sp500/json/KMX.json  \n",
            "  inflating: stock_market_data/sp500/json/KO.json  \n",
            "  inflating: stock_market_data/sp500/json/KR.json  \n",
            "  inflating: stock_market_data/sp500/json/KRA.json  \n",
            "  inflating: stock_market_data/sp500/json/KSS.json  \n",
            "  inflating: stock_market_data/sp500/json/KSU.json  \n",
            "  inflating: stock_market_data/sp500/json/LBTYA.json  \n",
            "  inflating: stock_market_data/sp500/json/LDOS.json  \n",
            "  inflating: stock_market_data/sp500/json/LEG.json  \n",
            "  inflating: stock_market_data/sp500/json/LH.json  \n",
            "  inflating: stock_market_data/sp500/json/LKQ.json  \n",
            "  inflating: stock_market_data/sp500/json/LMT.json  \n",
            "  inflating: stock_market_data/sp500/json/LNC.json  \n",
            "  inflating: stock_market_data/sp500/json/LNT.json  \n",
            "  inflating: stock_market_data/sp500/json/LOW.json  \n",
            "  inflating: stock_market_data/sp500/json/LRCX.json  \n",
            "  inflating: stock_market_data/sp500/json/LUV.json  \n",
            "  inflating: stock_market_data/sp500/json/LVS.json  \n",
            "  inflating: stock_market_data/sp500/json/LYB.json  \n",
            "  inflating: stock_market_data/sp500/json/LYV.json  \n",
            "  inflating: stock_market_data/sp500/json/MAA.json  \n",
            "  inflating: stock_market_data/sp500/json/MAR.json  \n",
            "  inflating: stock_market_data/sp500/json/MCD.json  \n",
            "  inflating: stock_market_data/sp500/json/MCHP.json  \n",
            "  inflating: stock_market_data/sp500/json/MCK.json  \n",
            "  inflating: stock_market_data/sp500/json/MCO.json  \n",
            "  inflating: stock_market_data/sp500/json/MDLZ.json  \n",
            "  inflating: stock_market_data/sp500/json/MDT.json  \n",
            "  inflating: stock_market_data/sp500/json/MET.json  \n",
            "  inflating: stock_market_data/sp500/json/MGM.json  \n",
            "  inflating: stock_market_data/sp500/json/MHK.json  \n",
            "  inflating: stock_market_data/sp500/json/MKTX.json  \n",
            "  inflating: stock_market_data/sp500/json/MLM.json  \n",
            "  inflating: stock_market_data/sp500/json/MMC.json  \n",
            "  inflating: stock_market_data/sp500/json/MMM.json  \n",
            "  inflating: stock_market_data/sp500/json/MNST.json  \n",
            "  inflating: stock_market_data/sp500/json/MO.json  \n",
            "  inflating: stock_market_data/sp500/json/MOS.json  \n",
            "  inflating: stock_market_data/sp500/json/MPC.json  \n",
            "  inflating: stock_market_data/sp500/json/MRCR.json  \n",
            "  inflating: stock_market_data/sp500/json/MRK.json  \n",
            "  inflating: stock_market_data/sp500/json/MRKT.json  \n",
            "  inflating: stock_market_data/sp500/json/MRO.json  \n",
            "  inflating: stock_market_data/sp500/json/MS-PF.json  \n",
            "  inflating: stock_market_data/sp500/json/MSCI.json  \n",
            "  inflating: stock_market_data/sp500/json/MSFT.json  \n",
            "  inflating: stock_market_data/sp500/json/MSI.json  \n",
            "  inflating: stock_market_data/sp500/json/MU.json  \n",
            "  inflating: stock_market_data/sp500/json/NCLH.json  \n",
            "  inflating: stock_market_data/sp500/json/NCTKF.json  \n",
            "  inflating: stock_market_data/sp500/json/NDAQ.json  \n",
            "  inflating: stock_market_data/sp500/json/NEE.json  \n",
            "  inflating: stock_market_data/sp500/json/NEOG.json  \n",
            "  inflating: stock_market_data/sp500/json/NFLX.json  \n",
            "  inflating: stock_market_data/sp500/json/NI.json  \n",
            "  inflating: stock_market_data/sp500/json/NIHDQ.json  \n",
            "  inflating: stock_market_data/sp500/json/NLSN.json  \n",
            "  inflating: stock_market_data/sp500/json/NMHLY.json  \n",
            "  inflating: stock_market_data/sp500/json/NOC.json  \n",
            "  inflating: stock_market_data/sp500/json/NOK.json  \n",
            "  inflating: stock_market_data/sp500/json/NOV.json  \n",
            "  inflating: stock_market_data/sp500/json/NOW.json  \n",
            "  inflating: stock_market_data/sp500/json/NOXL.json  \n",
            "  inflating: stock_market_data/sp500/json/NRG.json  \n",
            "  inflating: stock_market_data/sp500/json/NSC.json  \n",
            "  inflating: stock_market_data/sp500/json/NTAP.json  \n",
            "  inflating: stock_market_data/sp500/json/NTRA.json  \n",
            "  inflating: stock_market_data/sp500/json/NTRR.json  \n",
            "  inflating: stock_market_data/sp500/json/NTRS.json  \n",
            "  inflating: stock_market_data/sp500/json/NVR.json  \n",
            "  inflating: stock_market_data/sp500/json/NVRO.json  \n",
            "  inflating: stock_market_data/sp500/json/NWL.json  \n",
            "  inflating: stock_market_data/sp500/json/O.json  \n",
            "  inflating: stock_market_data/sp500/json/ODFL.json  \n",
            "  inflating: stock_market_data/sp500/json/OKE.json  \n",
            "  inflating: stock_market_data/sp500/json/OMC.json  \n",
            "  inflating: stock_market_data/sp500/json/ORLY.json  \n",
            "  inflating: stock_market_data/sp500/json/OXY.json  \n",
            "  inflating: stock_market_data/sp500/json/PAYX.json  \n",
            "  inflating: stock_market_data/sp500/json/PBCT.json  \n",
            "  inflating: stock_market_data/sp500/json/PCAR.json  \n",
            "  inflating: stock_market_data/sp500/json/PEG.json  \n",
            "  inflating: stock_market_data/sp500/json/PEP.json  \n",
            "  inflating: stock_market_data/sp500/json/PFE.json  \n",
            "  inflating: stock_market_data/sp500/json/PG.json  \n",
            "  inflating: stock_market_data/sp500/json/PH.json  \n",
            "  inflating: stock_market_data/sp500/json/PHM.json  \n",
            "  inflating: stock_market_data/sp500/json/PKG.json  \n",
            "  inflating: stock_market_data/sp500/json/PKI.json  \n",
            "  inflating: stock_market_data/sp500/json/PLD.json  \n",
            "  inflating: stock_market_data/sp500/json/PM.json  \n",
            "  inflating: stock_market_data/sp500/json/PNR.json  \n",
            "  inflating: stock_market_data/sp500/json/PNW.json  \n",
            "  inflating: stock_market_data/sp500/json/PNWRF.json  \n",
            "  inflating: stock_market_data/sp500/json/PPG.json  \n",
            "  inflating: stock_market_data/sp500/json/PRU.json  \n",
            "  inflating: stock_market_data/sp500/json/PSX.json  \n",
            "  inflating: stock_market_data/sp500/json/PVH.json  \n",
            "  inflating: stock_market_data/sp500/json/PWR.json  \n",
            "  inflating: stock_market_data/sp500/json/PXD.json  \n",
            "  inflating: stock_market_data/sp500/json/QRVO.json  \n",
            "  inflating: stock_market_data/sp500/json/RCL.json  \n",
            "  inflating: stock_market_data/sp500/json/RE.json  \n",
            "  inflating: stock_market_data/sp500/json/REG.json  \n",
            "  inflating: stock_market_data/sp500/json/REGN.json  \n",
            "  inflating: stock_market_data/sp500/json/RF.json  \n",
            "  inflating: stock_market_data/sp500/json/RHI.json  \n",
            "  inflating: stock_market_data/sp500/json/RIBT.json  \n",
            "  inflating: stock_market_data/sp500/json/RJF.json  \n",
            "  inflating: stock_market_data/sp500/json/RL.json  \n",
            "  inflating: stock_market_data/sp500/json/RLI.json  \n",
            "  inflating: stock_market_data/sp500/json/RMD.json  \n",
            "  inflating: stock_market_data/sp500/json/ROK.json  \n",
            "  inflating: stock_market_data/sp500/json/ROL.json  \n",
            "  inflating: stock_market_data/sp500/json/ROP.json  \n",
            "  inflating: stock_market_data/sp500/json/ROST.json  \n",
            "  inflating: stock_market_data/sp500/json/RSG.json  \n",
            "  inflating: stock_market_data/sp500/json/RSNHF.json  \n",
            "  inflating: stock_market_data/sp500/json/RXMD.json  \n",
            "  inflating: stock_market_data/sp500/json/SBUX.json  \n",
            "  inflating: stock_market_data/sp500/json/SCHW.json  \n",
            "  inflating: stock_market_data/sp500/json/SEE.json  \n",
            "  inflating: stock_market_data/sp500/json/SEGXF.json  \n",
            "  inflating: stock_market_data/sp500/json/SHW.json  \n",
            "  inflating: stock_market_data/sp500/json/SIVB.json  \n",
            "  inflating: stock_market_data/sp500/json/SLB.json  \n",
            "  inflating: stock_market_data/sp500/json/SLG.json  \n",
            "  inflating: stock_market_data/sp500/json/SNPS.json  \n",
            "  inflating: stock_market_data/sp500/json/SO.json  \n",
            "  inflating: stock_market_data/sp500/json/SONC.json  \n",
            "  inflating: stock_market_data/sp500/json/SPG.json  \n",
            "  inflating: stock_market_data/sp500/json/SRE.json  \n",
            "  inflating: stock_market_data/sp500/json/SRG.json  \n",
            "  inflating: stock_market_data/sp500/json/STT.json  \n",
            "  inflating: stock_market_data/sp500/json/STX.json  \n",
            "  inflating: stock_market_data/sp500/json/STZ-B.json  \n",
            "  inflating: stock_market_data/sp500/json/SWK.json  \n",
            "  inflating: stock_market_data/sp500/json/SWKS.json  \n",
            "  inflating: stock_market_data/sp500/json/SYF.json  \n",
            "  inflating: stock_market_data/sp500/json/SYK.json  \n",
            "  inflating: stock_market_data/sp500/json/T.json  \n",
            "  inflating: stock_market_data/sp500/json/TAP.json  \n",
            "  inflating: stock_market_data/sp500/json/TCYSF.json  \n",
            "  inflating: stock_market_data/sp500/json/TEL.json  \n",
            "  inflating: stock_market_data/sp500/json/TIME.json  \n",
            "  inflating: stock_market_data/sp500/json/TJX.json  \n",
            "  inflating: stock_market_data/sp500/json/TMO.json  \n",
            "  inflating: stock_market_data/sp500/json/TMUS.json  \n",
            "  inflating: stock_market_data/sp500/json/TRAUF.json  \n",
            "  inflating: stock_market_data/sp500/json/TROW.json  \n",
            "  inflating: stock_market_data/sp500/json/TRV.json  \n",
            "  inflating: stock_market_data/sp500/json/TSCO.json  \n",
            "  inflating: stock_market_data/sp500/json/TSN.json  \n",
            "  inflating: stock_market_data/sp500/json/TTWO.json  \n",
            "  inflating: stock_market_data/sp500/json/TW.json  \n",
            "  inflating: stock_market_data/sp500/json/TWTR.json  \n",
            "  inflating: stock_market_data/sp500/json/TXN.json  \n",
            "  inflating: stock_market_data/sp500/json/TXT.json  \n",
            "  inflating: stock_market_data/sp500/json/TYL.json  \n",
            "  inflating: stock_market_data/sp500/json/UA.json  \n",
            "  inflating: stock_market_data/sp500/json/UAL.json  \n",
            "  inflating: stock_market_data/sp500/json/UDR.json  \n",
            "  inflating: stock_market_data/sp500/json/UEEC.json  \n",
            "  inflating: stock_market_data/sp500/json/UHS.json  \n",
            "  inflating: stock_market_data/sp500/json/ULTA.json  \n",
            "  inflating: stock_market_data/sp500/json/UNM.json  \n",
            "  inflating: stock_market_data/sp500/json/UNP.json  \n",
            "  inflating: stock_market_data/sp500/json/UPS.json  \n",
            "  inflating: stock_market_data/sp500/json/URI.json  \n",
            "  inflating: stock_market_data/sp500/json/USB.json  \n",
            "  inflating: stock_market_data/sp500/json/UTIW.json  \n",
            "  inflating: stock_market_data/sp500/json/V.json  \n",
            "  inflating: stock_market_data/sp500/json/VFC.json  \n",
            "  inflating: stock_market_data/sp500/json/VMC.json  \n",
            "  inflating: stock_market_data/sp500/json/VRSK.json  \n",
            "  inflating: stock_market_data/sp500/json/VRSN.json  \n",
            "  inflating: stock_market_data/sp500/json/VTAE.json  \n",
            "  inflating: stock_market_data/sp500/json/VTR.json  \n",
            "  inflating: stock_market_data/sp500/json/VZ.json  \n",
            "  inflating: stock_market_data/sp500/json/WAT.json  \n",
            "  inflating: stock_market_data/sp500/json/WBA.json  \n",
            "  inflating: stock_market_data/sp500/json/WDC.json  \n",
            "  inflating: stock_market_data/sp500/json/WEC.json  \n",
            "  inflating: stock_market_data/sp500/json/WHR.json  \n",
            "  inflating: stock_market_data/sp500/json/WM.json  \n",
            "  inflating: stock_market_data/sp500/json/WMB.json  \n",
            "  inflating: stock_market_data/sp500/json/WRB.json  \n",
            "  inflating: stock_market_data/sp500/json/WRK.json  \n",
            "  inflating: stock_market_data/sp500/json/WSPOF.json  \n",
            "  inflating: stock_market_data/sp500/json/WST.json  \n",
            "  inflating: stock_market_data/sp500/json/WU.json  \n",
            "  inflating: stock_market_data/sp500/json/WY.json  \n",
            "  inflating: stock_market_data/sp500/json/WYNN.json  \n",
            "  inflating: stock_market_data/sp500/json/XEL.json  \n",
            "  inflating: stock_market_data/sp500/json/XIDEQ.json  \n",
            "  inflating: stock_market_data/sp500/json/XLEFF.json  \n",
            "  inflating: stock_market_data/sp500/json/XLNX.json  \n",
            "  inflating: stock_market_data/sp500/json/XOM.json  \n",
            "  inflating: stock_market_data/sp500/json/XYL.json  \n",
            "  inflating: stock_market_data/sp500/json/YUM.json  \n",
            "  inflating: stock_market_data/sp500/json/ZBH.json  \n",
            "  inflating: stock_market_data/sp500/json/ZION.json  \n",
            "  inflating: stock_market_data/sp500/json/ZTS.json  \n"
          ]
        }
      ],
      "source": [
        "ككككككككككككككككككك00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000-ى-ك----------------!unzip archive.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRUuGoqf_1JE",
        "outputId": "eeb02371-d03b-45ef-83fa-e0278797072a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AAL.csv    BSHI.csv   ED.csv\t HON.csv    MAA.csv    PEP.csv\t  TCYSF.csv\n",
            "AAP.csv    BSX.csv    EFX.csv\t HPE.csv    MAR.csv    PFE.csv\t  TEL.csv\n",
            "AAPL.csv   BWA.csv    EIX.csv\t HPQ.csv    MCD.csv    PG.csv\t  TJX.csv\n",
            "ABBV.csv   BXP.csv    EL.csv\t HRB.csv    MCHP.csv   PH.csv\t  TMO.csv\n",
            "ABC.csv    CAG.csv    EMN.csv\t HRL.csv    MCK.csv    PHM.csv\t  TMUS.csv\n",
            "ABMD.csv   CAH.csv    EMR.csv\t HSIC.csv   MCO.csv    PKG.csv\t  TRAUF.csv\n",
            "ABT.csv    CAT.csv    ENS.csv\t HST.csv    MDLZ.csv   PKI.csv\t  TROW.csv\n",
            "ACN.csv    CB.csv     EOG.csv\t HSY.csv    MDT.csv    PLD.csv\t  TRV.csv\n",
            "A.csv\t   CCI.csv    EQIX.csv\t HTLF.csv   MET.csv    PM.csv\t  TSCO.csv\n",
            "ADI.csv    C.csv      EQR.csv\t HUM.csv    MGM.csv    PNR.csv\t  TSN.csv\n",
            "ADM.csv    CDE.csv    ES.csv\t IBM.csv    MHK.csv    PNW.csv\t  TTWO.csv\n",
            "ADP.csv    CDNS.csv   ESS.csv\t ICE.csv    MKTX.csv   PNWRF.csv  TW.csv\n",
            "ADSK.csv   CF.csv     EW.csv\t IDXX.csv   MLM.csv    PPG.csv\t  TWTR.csv\n",
            "AEE.csv    CFG.csv    EXR.csv\t IEX.csv    MMC.csv    PRU.csv\t  TXN.csv\n",
            "AEP.csv    CHD.csv    FANG.csv\t IFF.csv    MMM.csv    PSX.csv\t  TXT.csv\n",
            "AIZ.csv    CHRW.csv   FAST.csv\t ILMN.csv   MNST.csv   PVH.csv\t  TYL.csv\n",
            "AJG.csv    CHTR.csv   FB.csv\t INTH.csv   MO.csv     PWR.csv\t  UA.csv\n",
            "AKAM.csv   CINF.csv   FBHS.csv\t INTU.csv   MOS.csv    PXD.csv\t  UAL.csv\n",
            "ALB.csv    CL.csv     FCGN.csv\t IP.csv     MPC.csv    QRVO.csv   UDR.csv\n",
            "ALGN.csv   CLX.csv    F.csv\t IPGP.csv   MRCR.csv   RCL.csv\t  UEEC.csv\n",
            "ALK.csv    CME.csv    FCX.csv\t IR.csv     MRK.csv    RE.csv\t  UHS.csv\n",
            "ALLE.csv   CMG.csv    FDX.csv\t IRM.csv    MRO.csv    REG.csv\t  ULTA.csv\n",
            "ALTR.csv   CMI.csv    FE.csv\t ISRG.csv   MSCI.csv   REGN.csv   UNM.csv\n",
            "AMAT.csv   CNC.csv    FFIV.csv\t IT.csv     MSFT.csv   RF.csv\t  UNP.csv\n",
            "AMD.csv    CNP.csv    FIS.csv\t ITW.csv    MSI.csv    RHI.csv\t  UPS.csv\n",
            "AME.csv    CNWT.csv   FISV.csv\t IVZ.csv    MS-PF.csv  RIBT.csv   URI.csv\n",
            "AMGN.csv   COO.csv    FITB.csv\t JBHT.csv   MU.csv     RJF.csv\t  USB.csv\n",
            "AMP.csv    COP.csv    FLS.csv\t JCI.csv    NCLH.csv   RL.csv\t  V.csv\n",
            "AMT.csv    COST.csv   FLT.csv\t JKHY.csv   NCTKF.csv  RLI.csv\t  VFC.csv\n",
            "AMZN.csv   COTY.csv   FMBM.csv\t JNJ.csv    NDAQ.csv   RMD.csv\t  VMC.csv\n",
            "ANET.csv   COWN.csv   FMC.csv\t JNPR.csv   NEE.csv    ROK.csv\t  VRSK.csv\n",
            "ANTM.csv   CPB.csv    FN.csv\t JPM.csv    NEOG.csv   ROL.csv\t  VRSN.csv\n",
            "AON.csv    CPICQ.csv  FPLPF.csv  KACPF.csv  NFLX.csv   ROP.csv\t  VTR.csv\n",
            "AOS.csv    CPRT.csv   FRC.csv\t K.csv\t    NI.csv     ROST.csv   VZ.csv\n",
            "APA.csv    CRM.csv    FRMC.csv\t KEY.csv    NLSN.csv   RSG.csv\t  WAT.csv\n",
            "APD.csv    CSCO.csv   FRT.csv\t KEYS.csv   NMHLY.csv  RSNHF.csv  WBA.csv\n",
            "APH.csv    CTAS.csv   FTI.csv\t KGNR.csv   NOC.csv    RXMD.csv   WDC.csv\n",
            "ARE.csv    CTQ.csv    GD.csv\t KHC.csv    NOK.csv    SBUX.csv   WEC.csv\n",
            "ATVI.csv   CTSH.csv   GE.csv\t KIM.csv    NOV.csv    SCHW.csv   WHR.csv\n",
            "AVB.csv    CTXS.csv   GGG.csv\t KMB.csv    NOW.csv    SEE.csv\t  WMB.csv\n",
            "AVY.csv    CUK.csv    GILD.csv\t KMX.csv    NOXL.csv   SEGXF.csv  WM.csv\n",
            "AWK.csv    DAL.csv    GIS.csv\t KO.csv     NRG.csv    SHW.csv\t  WRB.csv\n",
            "AXP.csv    D.csv      GM.csv\t KRA.csv    NSC.csv    SIVB.csv   WRK.csv\n",
            "AZO.csv    DE.csv     GOOG.csv\t KR.csv     NTAP.csv   SLB.csv\t  WSPOF.csv\n",
            "BAC.csv    DFS.csv    GPC.csv\t KSS.csv    NTRA.csv   SLG.csv\t  WST.csv\n",
            "BA.csv\t   DG.csv     GPN.csv\t KSU.csv    NTRR.csv   SNPS.csv   WU.csv\n",
            "BAX.csv    DGX.csv    GRMN.csv\t LBTYA.csv  NTRS.csv   SO.csv\t  WY.csv\n",
            "BBY.csv    DHI.csv    GS-PJ.csv  LDOS.csv   NVR.csv    SONC.csv   WYNN.csv\n",
            "BDX.csv    DIS.csv    GWW.csv\t LEG.csv    NVRO.csv   SPG.csv\t  XEL.csv\n",
            "BEN.csv    DLTR.csv   HAL.csv\t LH.csv     NWL.csv    SRE.csv\t  XLEFF.csv\n",
            "BF-A.csv   DOV.csv    HAS.csv\t LKQ.csv    O.csv      SRG.csv\t  XLNX.csv\n",
            "BHI.csv    DPZ.csv    HBAN.csv\t LMT.csv    ODFL.csv   STT.csv\t  XOM.csv\n",
            "BIIB.csv   DRE.csv    HBI.csv\t LNC.csv    OKE.csv    STX.csv\t  XYL.csv\n",
            "BIO.csv    DRI.csv    HCA.csv\t LNT.csv    OMC.csv    STZ-B.csv  YUM.csv\n",
            "BK.csv\t   DTE.csv    HD.csv\t LOW.csv    ORLY.csv   SWK.csv\t  ZBH.csv\n",
            "BLK.csv    DVA.csv    HES.csv\t LRCX.csv   OXY.csv    SWKS.csv   ZION.csv\n",
            "BMRA.csv   DXCM.csv   HFC.csv\t LUV.csv    PAYX.csv   SYF.csv\t  ZTS.csv\n",
            "BMY.csv    EA.csv     HII.csv\t LVS.csv    PBCT.csv   SYK.csv\n",
            "BR.csv\t   EBAY.csv   HLT.csv\t LYB.csv    PCAR.csv   TAP.csv\n",
            "BRK-A.csv  ECL.csv    HOLX.csv\t LYV.csv    PEG.csv    T.csv\n"
          ]
        }
      ],
      "source": [
        "!ls stock_market_data/sp500/csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "DNWJCKigHdxS",
        "outputId": "ef4cc579-f33d-44f8-ab75-c50aad70130c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'RNN(\\n  (lstm): LSTM(58, 64, num_layers=2)\\n  (hidden2out): Linear(in_features=64, out_features=580, bias=True)\\n)'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(rnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kba-UuXhYhG9",
        "outputId": "46ec6330-d211-4f34-e167-2c27e2f3ff2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0644, -0.0552, -0.0242,  ...,  0.0999, -0.0063, -0.0894],\n",
            "        [ 0.0761,  0.0388, -0.0808,  ..., -0.0830,  0.0151,  0.0886],\n",
            "        [ 0.0906,  0.0777, -0.0905,  ...,  0.0534,  0.0225,  0.0292],\n",
            "        ...,\n",
            "        [-0.0333, -0.0124,  0.1182,  ..., -0.0908,  0.0785, -0.1251],\n",
            "        [-0.0031, -0.0939, -0.0930,  ..., -0.0372,  0.0625, -0.0756],\n",
            "        [-0.0902,  0.0928,  0.1212,  ...,  0.0390,  0.1190, -0.0812]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0083,  0.0977, -0.0681,  ...,  0.0967,  0.0294, -0.0102],\n",
            "        [ 0.0350,  0.0996, -0.0384,  ...,  0.0100, -0.0388,  0.0587],\n",
            "        [-0.0036,  0.0485,  0.0890,  ...,  0.1266, -0.1005,  0.0468],\n",
            "        ...,\n",
            "        [ 0.0957,  0.0142, -0.0808,  ...,  0.0643, -0.1215, -0.0306],\n",
            "        [ 0.0534,  0.0724,  0.0012,  ..., -0.1178,  0.1175,  0.1068],\n",
            "        [ 0.0940, -0.0759, -0.0637,  ...,  0.0349, -0.0960, -0.0182]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 1.7880e-02,  5.4735e-02,  4.0185e-02,  6.7817e-02,  8.1851e-02,\n",
            "         6.3040e-02,  3.5289e-02,  7.2376e-02,  3.0956e-02,  1.1053e-01,\n",
            "        -5.8386e-02, -9.6293e-02,  5.3341e-02,  7.0609e-02, -9.5649e-02,\n",
            "        -6.3695e-02, -5.5872e-02, -8.3513e-02,  2.5055e-02,  7.7713e-02,\n",
            "         8.9989e-02,  3.7305e-02,  1.2166e-01,  6.0794e-02, -2.4500e-02,\n",
            "        -2.5328e-02,  6.6966e-02,  9.1260e-02,  9.8644e-02,  6.2043e-02,\n",
            "         8.9917e-02,  2.8575e-02, -2.6059e-03, -6.8475e-02,  8.7993e-02,\n",
            "        -9.6553e-02, -3.6356e-02,  1.1078e-01,  5.2206e-03,  1.3617e-01,\n",
            "         1.2258e-01, -5.1348e-02, -3.6721e-04, -9.3186e-02,  2.7861e-02,\n",
            "        -1.0708e-01, -8.6882e-02, -9.5717e-03,  3.1746e-04, -5.5416e-02,\n",
            "        -1.1757e-01, -1.0607e-01,  1.2112e-02,  1.4060e-01,  3.0219e-02,\n",
            "         2.2644e-02,  2.3561e-03,  1.2210e-01,  1.0599e-01,  4.3875e-02,\n",
            "        -1.1467e-02,  2.5124e-02, -7.2047e-02, -8.3102e-02, -4.3075e-02,\n",
            "        -1.0080e-01,  1.1357e-01,  1.7570e-02,  5.9507e-02,  1.0114e-01,\n",
            "         2.3391e-02, -2.6284e-02,  2.8708e-02, -4.7639e-02, -7.6534e-02,\n",
            "         7.7771e-02, -1.1667e-01, -9.5173e-02, -8.5578e-02, -7.3082e-02,\n",
            "        -7.5826e-02,  7.4299e-02,  6.2507e-02, -2.3073e-02,  2.8954e-02,\n",
            "         4.1175e-02,  6.0875e-02, -6.0344e-02,  6.1240e-02, -2.7885e-02,\n",
            "         1.4662e-02, -3.4326e-02, -1.2723e-02,  1.0182e-01,  6.1318e-03,\n",
            "         6.7496e-02,  7.0482e-02,  5.7718e-02,  1.1071e-01,  1.2095e-02,\n",
            "         1.1867e-01,  7.4488e-02,  3.4016e-02, -2.6473e-02, -3.1658e-02,\n",
            "        -3.3705e-02,  1.0551e-01, -1.1223e-01,  1.0533e-01, -1.1173e-01,\n",
            "        -6.1597e-02,  1.0281e-02, -1.1571e-01, -6.5656e-02,  2.2373e-02,\n",
            "        -9.3388e-02,  9.5058e-02,  5.8328e-02,  6.0955e-02,  8.3882e-02,\n",
            "        -3.4816e-02, -5.0526e-02,  7.9625e-02,  8.6182e-02,  1.3310e-01,\n",
            "        -5.9131e-02,  1.2523e-03,  7.6712e-02,  9.7641e-02, -5.2951e-02,\n",
            "        -8.8028e-02,  1.7740e-02,  3.2218e-02,  6.3137e-02, -1.2386e-01,\n",
            "         3.7043e-02, -2.7281e-03, -1.0608e-01, -3.0531e-02, -3.4428e-02,\n",
            "        -2.5245e-02,  1.0108e-01, -2.3221e-02, -5.7784e-02,  1.3003e-01,\n",
            "        -4.9299e-03, -7.3307e-02,  5.8985e-03,  8.5702e-02,  7.3242e-02,\n",
            "        -1.1998e-01, -3.6469e-03,  5.7064e-02, -9.3866e-02, -1.3363e-02,\n",
            "        -1.0631e-01,  2.8205e-02,  7.6661e-03, -5.8978e-02,  1.1290e-01,\n",
            "         6.2910e-02,  1.3222e-01,  1.1874e-01, -9.4540e-02,  1.6027e-02,\n",
            "         1.2877e-01, -1.1184e-01,  3.1518e-02,  6.3499e-02, -9.1913e-03,\n",
            "         4.1909e-02, -5.8744e-02,  8.6943e-02, -5.7598e-02,  1.2954e-01,\n",
            "        -6.4035e-02,  3.0670e-02, -1.1686e-01, -2.4514e-02,  6.6192e-02,\n",
            "         3.5517e-02, -2.4972e-02,  1.0027e-01,  4.1494e-02, -1.4137e-01,\n",
            "         8.0076e-02,  1.0754e-01,  9.7015e-02,  6.8791e-02, -7.0861e-02,\n",
            "         3.5207e-03, -6.4388e-02,  3.5722e-02,  9.8177e-02, -1.9476e-02,\n",
            "        -4.7234e-02, -3.8059e-03,  1.3120e-03,  4.8686e-02,  1.0918e-02,\n",
            "        -6.6599e-02, -4.6379e-02, -3.7291e-02, -1.1800e-01,  1.1063e-01,\n",
            "         4.4406e-02,  1.0690e-01, -8.1141e-02,  8.1987e-02, -4.9459e-02,\n",
            "         4.6916e-02,  2.0187e-02, -1.1077e-01,  7.4275e-02,  1.0698e-01,\n",
            "         5.7726e-02,  1.0885e-01, -2.1974e-02,  6.8485e-02,  3.5282e-02,\n",
            "        -1.1824e-01, -1.0000e-01, -4.0623e-02, -4.6952e-03,  1.0125e-01,\n",
            "         7.5408e-02,  3.4029e-02,  8.8018e-02,  2.9838e-02,  9.8728e-05,\n",
            "        -3.5231e-02, -1.3640e-02,  7.8889e-02, -5.3185e-02, -8.3148e-02,\n",
            "         3.3170e-02,  3.1631e-02, -7.4422e-02, -5.9245e-02, -1.8377e-02,\n",
            "         3.4146e-02,  9.8014e-02,  3.8407e-02,  9.3496e-02, -5.7901e-02,\n",
            "         5.3463e-02, -1.4563e-03,  6.3721e-02,  9.1742e-02,  5.6761e-02,\n",
            "        -4.4614e-02,  1.4381e-01,  7.6497e-02, -5.5611e-02,  9.9291e-02,\n",
            "        -3.4159e-02], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0522,  0.0027, -0.0806, -0.0712, -0.0730, -0.0989,  0.0213,  0.1292,\n",
            "        -0.0917,  0.0157,  0.0218, -0.0988,  0.0482,  0.0151, -0.0848,  0.0055,\n",
            "        -0.0920,  0.0071,  0.0974, -0.1013, -0.0589,  0.0350, -0.0499, -0.0484,\n",
            "         0.1238,  0.0225, -0.0599, -0.0891, -0.1058,  0.1050, -0.0078,  0.0766,\n",
            "        -0.0177, -0.0927, -0.0257, -0.0150,  0.1276, -0.0230, -0.0024,  0.1151,\n",
            "         0.0253, -0.1078,  0.1341, -0.0193, -0.0562,  0.0796, -0.0208, -0.1062,\n",
            "         0.0664,  0.0798,  0.0707,  0.0763,  0.0019, -0.0125,  0.0274,  0.0812,\n",
            "         0.0496,  0.0797, -0.0171,  0.0518,  0.1339,  0.0615,  0.0614,  0.0322,\n",
            "        -0.0594,  0.0361, -0.0938, -0.0600, -0.1125, -0.0530,  0.0049,  0.0107,\n",
            "         0.1290,  0.1375, -0.1030,  0.0340,  0.1037,  0.0020,  0.1085, -0.1110,\n",
            "         0.0435,  0.0562, -0.0419, -0.0935,  0.0555, -0.1293, -0.0308, -0.0572,\n",
            "        -0.0425,  0.0099,  0.0822,  0.0989, -0.0084, -0.0617,  0.0184, -0.0190,\n",
            "         0.1215, -0.0874, -0.0703, -0.0322, -0.0453, -0.0704,  0.0347, -0.0073,\n",
            "         0.1324,  0.0568,  0.0464,  0.1192, -0.0851,  0.0129, -0.0569,  0.0357,\n",
            "         0.0282,  0.0622, -0.0686, -0.0181,  0.0250, -0.0298, -0.0526,  0.0314,\n",
            "         0.0413, -0.0987, -0.1129, -0.0658,  0.0655,  0.0471,  0.1226,  0.0108,\n",
            "         0.0922, -0.1275, -0.0892, -0.0130,  0.0223,  0.0647, -0.0783, -0.1316,\n",
            "        -0.0896, -0.0998, -0.0391,  0.0037, -0.0813,  0.1100,  0.0500,  0.1369,\n",
            "        -0.0364,  0.0115, -0.0053, -0.0376,  0.0561, -0.0906, -0.0357, -0.0513,\n",
            "        -0.1070,  0.1303,  0.0923, -0.0228,  0.0226, -0.0147, -0.0069, -0.0936,\n",
            "         0.1166,  0.0410,  0.0898, -0.0606, -0.1110,  0.0223, -0.1053,  0.1171,\n",
            "        -0.0366,  0.1188,  0.0393, -0.0587,  0.1081,  0.0392, -0.0707,  0.0612,\n",
            "         0.1199, -0.0917,  0.0800,  0.1359, -0.1023, -0.0951, -0.0039,  0.0768,\n",
            "        -0.0703,  0.1144, -0.1192,  0.0853,  0.0500,  0.0657,  0.0497,  0.0020,\n",
            "        -0.0031, -0.0153,  0.0127, -0.0686,  0.0465, -0.0779, -0.0068, -0.0564,\n",
            "        -0.1176, -0.0178,  0.0573, -0.0834, -0.0578,  0.1371,  0.0406,  0.0373,\n",
            "        -0.0230,  0.1040, -0.0796, -0.0027, -0.1080,  0.0007,  0.0670, -0.1181,\n",
            "         0.0239,  0.0572,  0.1273, -0.0300,  0.0147, -0.0760,  0.0647,  0.1086,\n",
            "         0.0759, -0.0441, -0.0310,  0.1266, -0.1011,  0.0184,  0.0102,  0.0937,\n",
            "        -0.0392,  0.1096,  0.0275,  0.0085, -0.0141, -0.1224, -0.0494, -0.0274,\n",
            "         0.0486, -0.0414, -0.0631, -0.0806, -0.1010, -0.0485, -0.0549,  0.0569,\n",
            "         0.0574, -0.0274,  0.0601,  0.0704,  0.1368,  0.0264,  0.0060,  0.1161],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.0042,  0.0641, -0.0703,  ..., -0.0914,  0.0258,  0.0359],\n",
            "        [ 0.0322, -0.0037,  0.0674,  ...,  0.1024, -0.0278,  0.0955],\n",
            "        [-0.0066,  0.0318, -0.1191,  ...,  0.0348, -0.0953, -0.1161],\n",
            "        ...,\n",
            "        [-0.0427, -0.0588,  0.0241,  ...,  0.1038,  0.1101,  0.0025],\n",
            "        [-0.0223, -0.0542, -0.0760,  ...,  0.0851,  0.0603, -0.1041],\n",
            "        [ 0.0016, -0.1015, -0.1228,  ..., -0.0386,  0.0277, -0.0638]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.1098,  0.1104, -0.0850,  ...,  0.0265, -0.0674, -0.0852],\n",
            "        [-0.0998,  0.0629, -0.0289,  ..., -0.0820,  0.0532,  0.0421],\n",
            "        [-0.0573, -0.0465, -0.0396,  ...,  0.1293,  0.0013,  0.0041],\n",
            "        ...,\n",
            "        [-0.0118,  0.0848,  0.0930,  ..., -0.0820,  0.0349,  0.0401],\n",
            "        [-0.0488, -0.0412,  0.0186,  ..., -0.1278, -0.0929,  0.1012],\n",
            "        [ 0.0385, -0.0040, -0.0881,  ..., -0.0365, -0.0868,  0.0618]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-2.4851e-02, -1.0428e-01,  1.3955e-02, -4.1457e-02,  7.1887e-02,\n",
            "        -6.3805e-02,  9.3447e-02, -9.8859e-02,  5.5682e-02, -5.1769e-02,\n",
            "         1.3231e-01, -4.7025e-02,  4.9634e-02,  1.2050e-01,  3.8667e-02,\n",
            "        -2.3896e-02,  6.5725e-02,  9.7909e-02,  8.6547e-02, -8.8288e-02,\n",
            "         1.2227e-01, -3.1839e-02,  6.4997e-02, -2.7111e-02, -5.7829e-02,\n",
            "        -1.1338e-01, -3.8425e-02,  8.2690e-02,  9.8042e-02, -5.0418e-02,\n",
            "        -3.4359e-02, -4.7011e-02,  5.1784e-02,  5.7453e-02,  5.9079e-02,\n",
            "        -3.4955e-02,  7.0630e-02,  5.3393e-02,  8.8390e-02,  3.9069e-03,\n",
            "        -7.1461e-02,  1.8392e-02,  1.0638e-01,  1.9612e-02, -2.4864e-03,\n",
            "        -5.8720e-02, -3.4894e-02,  2.6992e-02,  9.3239e-02,  2.8969e-02,\n",
            "         3.9230e-02,  1.2047e-01, -5.4549e-02,  2.2059e-02,  2.6731e-02,\n",
            "         6.8562e-02, -3.3256e-02, -7.1045e-02, -3.0993e-02, -7.6452e-02,\n",
            "        -9.4133e-02,  4.5281e-02, -2.0294e-02,  8.0504e-02,  1.0312e-02,\n",
            "         2.7065e-02,  8.9813e-02,  6.2302e-02,  9.3050e-02,  1.3149e-01,\n",
            "         7.8706e-02,  1.3232e-01, -3.2893e-02,  1.0410e-01, -5.4183e-02,\n",
            "         5.9439e-02,  6.4293e-02,  3.1073e-02,  6.2806e-02, -2.0057e-02,\n",
            "         4.8571e-02,  4.7791e-02,  3.4092e-02, -5.7937e-02, -3.8548e-02,\n",
            "         1.3643e-01, -1.6065e-02, -3.7014e-02, -8.6583e-02, -2.6493e-02,\n",
            "         6.8891e-02,  8.7401e-04,  7.8505e-02,  6.1549e-02,  1.1196e-02,\n",
            "        -7.6249e-02,  7.7373e-02,  3.9005e-02,  2.6584e-02, -8.3701e-02,\n",
            "         1.2184e-02,  8.5182e-02,  8.4547e-02, -1.0057e-01,  3.3010e-02,\n",
            "        -2.4842e-05, -2.0323e-03,  1.8817e-02,  7.1001e-02,  9.6483e-02,\n",
            "         4.1977e-02,  1.1358e-01,  4.5964e-02,  4.4315e-02,  1.1962e-02,\n",
            "         5.3156e-02,  6.7437e-02, -2.8120e-02,  4.3239e-02, -1.0379e-01,\n",
            "         1.2616e-01,  1.2444e-02, -8.3789e-02,  5.1944e-02,  3.5655e-02,\n",
            "         4.0636e-02,  2.9097e-02, -8.4259e-02,  2.2490e-02,  1.1172e-01,\n",
            "        -2.4460e-02, -3.2353e-02, -3.5312e-02, -1.7428e-02, -2.1462e-02,\n",
            "        -1.1932e-01,  9.8145e-02, -7.7209e-02,  1.1915e-01, -6.6502e-02,\n",
            "        -3.6971e-02, -1.0987e-01, -1.1684e-01,  5.9167e-02,  7.4612e-02,\n",
            "         4.9742e-02, -4.8801e-02, -4.6767e-03, -9.7638e-02,  8.4279e-03,\n",
            "         6.1300e-02, -5.8427e-03,  4.0965e-02,  4.5635e-02, -3.9011e-02,\n",
            "         1.2305e-01,  1.0665e-01, -2.8137e-02,  8.1562e-02, -4.8835e-02,\n",
            "        -6.6067e-02,  7.3029e-02,  2.0903e-02, -3.6364e-02,  1.6131e-02,\n",
            "        -3.0903e-02, -5.2660e-02,  1.8944e-02, -6.5640e-02,  2.8592e-02,\n",
            "        -1.0264e-01,  1.0223e-01,  9.6294e-03, -7.1257e-02, -5.4581e-02,\n",
            "         7.2674e-02,  2.5061e-02,  1.0918e-01, -8.6270e-02,  9.4499e-02,\n",
            "         5.5807e-02,  1.9876e-02, -1.6078e-02, -7.3456e-02, -2.5848e-02,\n",
            "         2.4806e-02,  7.5622e-02,  5.3610e-02, -2.6117e-02,  7.4251e-02,\n",
            "         8.6766e-02, -7.9884e-02,  7.8330e-03, -8.8976e-02, -4.1981e-02,\n",
            "         9.3204e-03, -1.1720e-02,  7.5143e-02, -1.0543e-01, -7.2190e-02,\n",
            "         8.9670e-02,  7.7221e-02,  6.0464e-02,  1.7858e-02, -8.7124e-02,\n",
            "         6.3768e-03, -2.0865e-02, -3.0664e-02, -1.0218e-03,  1.3053e-01,\n",
            "         8.7540e-02, -7.6776e-02, -9.8336e-02, -1.0935e-01,  6.8806e-02,\n",
            "         9.2892e-02, -9.6534e-02,  8.4598e-02, -5.4136e-02, -8.7712e-02,\n",
            "         5.8961e-02,  8.5192e-02, -3.6144e-02, -9.2829e-02, -3.3649e-02,\n",
            "         1.2983e-01, -8.3407e-02, -1.0226e-02, -9.3485e-02,  7.4354e-02,\n",
            "        -8.1076e-02,  9.9876e-02,  1.8280e-02, -6.7663e-02,  1.3406e-01,\n",
            "         3.9023e-02,  4.5513e-02,  5.6296e-02,  4.5685e-02, -1.1943e-01,\n",
            "        -6.6781e-02, -3.9861e-02, -3.8064e-02, -9.6671e-02, -7.0650e-02,\n",
            "         1.3386e-01, -7.4018e-02,  1.9722e-03,  1.0488e-01,  5.9570e-02,\n",
            "        -9.6596e-02, -9.9834e-02,  4.5643e-03,  1.2516e-01,  1.2525e-01,\n",
            "         9.6725e-02], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0439,  0.0222,  0.0540,  0.0343, -0.0634,  0.0431, -0.0047, -0.1040,\n",
            "        -0.0466, -0.0847, -0.0936,  0.0306, -0.0270, -0.0460,  0.0889, -0.0025,\n",
            "         0.0804,  0.0965,  0.0716,  0.0905,  0.0461, -0.0329, -0.0926, -0.0146,\n",
            "        -0.0427, -0.0963,  0.0341, -0.1060,  0.0322, -0.1041, -0.0104, -0.0796,\n",
            "        -0.0700,  0.0086,  0.0397,  0.0898, -0.1138,  0.0453, -0.0064,  0.1366,\n",
            "        -0.0981, -0.0382, -0.0698,  0.0039,  0.1014,  0.0823, -0.1091, -0.0027,\n",
            "         0.0133,  0.0548,  0.0245,  0.0214, -0.0504, -0.0507,  0.0882, -0.0881,\n",
            "         0.1135, -0.1003,  0.0853, -0.0087,  0.0123, -0.0306,  0.1318,  0.1134,\n",
            "         0.0308, -0.0835,  0.0818, -0.0974,  0.0100,  0.0345,  0.0070,  0.1119,\n",
            "        -0.0174, -0.0421,  0.0534,  0.1039, -0.0171, -0.0397,  0.0526,  0.0520,\n",
            "         0.0739, -0.0747,  0.1312,  0.0064,  0.0325,  0.0320, -0.0307,  0.1030,\n",
            "         0.0100, -0.0429,  0.0074, -0.0994,  0.0703,  0.0951, -0.0712, -0.0203,\n",
            "        -0.1041, -0.0920,  0.0743,  0.1272, -0.1089,  0.0747, -0.0281,  0.1322,\n",
            "         0.0534,  0.0754,  0.0630,  0.0279,  0.0532,  0.0154, -0.1020, -0.0093,\n",
            "        -0.0024,  0.0242,  0.0716,  0.0903, -0.1124,  0.0791,  0.0341,  0.0551,\n",
            "        -0.1133,  0.0608,  0.0477,  0.0651,  0.0621, -0.0706, -0.0831, -0.0519,\n",
            "        -0.0169,  0.0005, -0.0351, -0.1208, -0.0904,  0.0375, -0.0825,  0.0917,\n",
            "        -0.0872,  0.0537, -0.0566, -0.0895,  0.0297, -0.0579,  0.0963,  0.0142,\n",
            "         0.1038, -0.0999,  0.0373,  0.0478,  0.0277,  0.1363, -0.0492, -0.1080,\n",
            "         0.0640, -0.0531,  0.0867, -0.1099,  0.0360,  0.0891, -0.1328, -0.1205,\n",
            "        -0.0258, -0.0452, -0.0590,  0.0036,  0.1235, -0.0127, -0.0702,  0.0239,\n",
            "         0.1031,  0.0104, -0.0963,  0.0902,  0.1043,  0.0320,  0.1139, -0.0066,\n",
            "        -0.0479,  0.0730, -0.0379, -0.0942, -0.0699, -0.0933,  0.0561, -0.0302,\n",
            "        -0.0226, -0.0782, -0.0457,  0.0287,  0.1170, -0.0027,  0.0418, -0.1233,\n",
            "        -0.0333,  0.0366, -0.0782, -0.0197,  0.0417,  0.0749, -0.0148, -0.0296,\n",
            "        -0.0661,  0.0895,  0.1307,  0.0879,  0.0367, -0.0668,  0.1208, -0.0472,\n",
            "         0.0904,  0.0022,  0.0257,  0.0445,  0.0459,  0.0537, -0.0073, -0.0672,\n",
            "         0.0366,  0.0917, -0.0282,  0.0904, -0.1078, -0.1069,  0.0756, -0.0980,\n",
            "        -0.0372,  0.0686, -0.0127,  0.0593, -0.0417,  0.0455,  0.0331,  0.0719,\n",
            "         0.0442, -0.1031,  0.0797, -0.0718,  0.0863, -0.0429,  0.0436, -0.0126,\n",
            "         0.0605, -0.0999,  0.1035,  0.0231,  0.1230,  0.0951,  0.0471, -0.1003,\n",
            "        -0.0478, -0.0470,  0.0837,  0.0081, -0.0095, -0.1238, -0.0669, -0.1145],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0780, -0.1086,  0.1198,  ..., -0.0829, -0.0464, -0.0736],\n",
            "        [-0.0838,  0.0300, -0.0853,  ..., -0.0081, -0.0297,  0.0584],\n",
            "        [-0.0943, -0.0279,  0.0633,  ...,  0.0661,  0.1372,  0.0241],\n",
            "        ...,\n",
            "        [-0.1176, -0.0758,  0.0128,  ...,  0.1053, -0.0209, -0.0678],\n",
            "        [-0.0948, -0.1133,  0.0267,  ..., -0.1324,  0.1079, -0.0143],\n",
            "        [-0.0323, -0.1009,  0.0259,  ...,  0.0961,  0.1043, -0.0031]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 9.7346e-02, -6.9488e-02, -9.2938e-03, -5.6175e-02,  1.0851e-04,\n",
            "         3.0683e-02,  9.3365e-02, -5.8100e-02,  4.6851e-02, -8.3722e-02,\n",
            "        -7.0694e-03, -4.7345e-02, -8.6244e-02, -5.1102e-02, -3.5516e-02,\n",
            "        -8.0341e-02, -1.6310e-02,  9.0952e-02,  4.4116e-02, -3.2436e-02,\n",
            "         9.4157e-02,  2.2037e-02, -4.9968e-02,  6.9101e-02, -1.1704e-01,\n",
            "        -4.1652e-02,  5.5058e-02, -2.1750e-02,  8.5666e-02,  8.7681e-02,\n",
            "         3.8049e-02, -7.4907e-02, -4.7544e-02, -7.4886e-02,  9.8061e-02,\n",
            "        -1.5708e-02,  6.9884e-02,  6.7142e-02,  6.4108e-02,  6.8011e-02,\n",
            "        -5.0752e-02,  4.1264e-02, -2.6894e-02, -6.0107e-02, -1.2174e-01,\n",
            "         5.5815e-02, -1.1331e-01, -5.6735e-03,  7.5719e-02,  6.5804e-02,\n",
            "        -5.3782e-02, -1.0489e-01,  8.3015e-02,  8.5521e-02, -7.6864e-02,\n",
            "         1.3018e-02, -9.8328e-02,  6.3578e-02, -1.3468e-02,  6.2866e-02,\n",
            "         2.7995e-02,  1.0892e-02,  6.0882e-02, -1.7396e-02,  9.0297e-02,\n",
            "        -1.0505e-01,  8.6637e-02, -1.1021e-01, -9.8358e-02,  8.9839e-02,\n",
            "        -2.8483e-02, -5.6080e-02, -1.0010e-01,  1.2243e-01, -7.4346e-02,\n",
            "        -3.6682e-02,  6.5073e-02,  2.2293e-02,  1.9118e-02,  9.1738e-03,\n",
            "        -4.6433e-02,  5.2323e-02,  1.2668e-01,  7.9649e-02, -2.1639e-03,\n",
            "         1.0669e-01,  1.3111e-01,  3.4798e-02,  6.5434e-02, -2.2517e-03,\n",
            "        -4.2802e-02, -3.9572e-03, -2.0746e-02,  9.7119e-02,  6.5228e-02,\n",
            "         1.0458e-01, -9.6809e-02, -3.0449e-02,  4.1800e-02, -7.8113e-03,\n",
            "        -8.8048e-02, -9.2599e-02, -1.0420e-01,  1.0512e-01,  8.0649e-02,\n",
            "        -2.4909e-02, -6.0272e-03,  2.6667e-03, -2.0533e-02,  7.3431e-03,\n",
            "         1.0092e-01,  9.6456e-03,  1.3539e-02,  8.5244e-02, -8.5138e-02,\n",
            "         1.2573e-02, -5.3102e-02,  4.8963e-02,  7.8442e-02, -3.4214e-02,\n",
            "        -8.4450e-02, -3.5925e-02, -3.6628e-02, -3.5950e-02, -2.6167e-02,\n",
            "        -7.0822e-03, -3.6059e-02, -9.1779e-02, -1.7538e-02, -9.2682e-02,\n",
            "        -5.5358e-02, -2.1849e-02, -9.2200e-02, -8.1508e-02, -6.7126e-02,\n",
            "         3.6101e-02,  3.7301e-02, -4.0875e-03, -1.9063e-02,  5.6617e-02,\n",
            "         8.9977e-02, -1.6747e-02,  9.0421e-02,  5.2825e-02,  1.1157e-01,\n",
            "        -2.6495e-02, -6.8981e-02,  7.8495e-02, -8.3552e-02, -6.8656e-03,\n",
            "         8.6562e-02, -9.6977e-02, -1.0289e-01, -7.3678e-03,  2.4804e-02,\n",
            "        -1.3695e-03, -1.4082e-02, -5.2492e-02,  1.7902e-02,  2.1704e-02,\n",
            "         8.9594e-02,  3.4037e-02, -5.7708e-02, -8.5564e-02, -1.9074e-02,\n",
            "        -1.1012e-01, -4.9240e-02,  1.8618e-02, -9.9970e-02, -2.5405e-02,\n",
            "        -4.7969e-02,  9.5199e-02,  5.9198e-02,  6.9437e-02, -2.4641e-03,\n",
            "        -8.1181e-02,  3.5790e-02, -2.0335e-02,  8.8879e-02,  1.1947e-03,\n",
            "         9.6477e-02, -9.6352e-02,  8.5851e-02, -6.7059e-02, -8.5786e-02,\n",
            "        -3.6138e-02, -2.6955e-02,  2.7814e-02,  2.9657e-02, -9.8173e-02,\n",
            "        -6.9064e-02,  4.8519e-02, -1.2508e-01,  7.1801e-02, -7.6662e-03,\n",
            "        -1.0773e-01,  1.9013e-02,  2.6047e-02, -6.4500e-02, -1.5969e-02,\n",
            "         2.7512e-02, -8.6216e-02, -6.0820e-02, -7.7570e-03,  9.3452e-04,\n",
            "         1.0379e-01, -5.3777e-03,  7.1368e-02, -6.6103e-02, -7.1251e-02,\n",
            "         4.6555e-02,  5.1551e-02, -7.5349e-02,  3.3507e-02, -8.8349e-02,\n",
            "        -1.9352e-02,  1.0756e-01,  7.9580e-02, -2.5200e-02, -5.2473e-02,\n",
            "         4.1744e-02, -1.0872e-02, -3.0160e-02, -7.1539e-03,  7.5284e-02,\n",
            "        -6.9002e-02, -5.9524e-02, -3.9267e-02, -5.1222e-02, -4.3258e-02,\n",
            "        -4.2770e-02, -9.0925e-02,  2.9093e-02, -8.4672e-02, -1.8987e-02,\n",
            "        -9.8314e-02, -1.0028e-01,  8.0368e-02,  1.0228e-01,  6.9680e-02,\n",
            "        -8.7551e-02,  1.7535e-02, -4.6538e-02,  1.0116e-01, -7.4357e-02,\n",
            "        -7.5400e-02,  9.5559e-02, -4.5395e-02, -9.5924e-02,  3.0496e-02,\n",
            "        -5.7002e-02, -9.0860e-02,  7.5133e-02, -8.7376e-02, -7.6718e-02,\n",
            "        -5.8116e-02, -5.3476e-02,  6.8747e-02, -5.4294e-02, -7.8686e-03,\n",
            "         6.4482e-02, -5.1252e-02, -1.8273e-02,  1.0883e-01, -9.8384e-02,\n",
            "         1.7128e-02, -1.5866e-02,  1.1572e-01,  7.1183e-03, -1.0490e-01,\n",
            "        -8.7479e-02,  8.8897e-02,  6.2655e-02, -6.6053e-02, -3.2041e-02,\n",
            "         5.8080e-02,  7.8796e-02,  6.3081e-02,  1.1423e-01, -7.8819e-02,\n",
            "         5.3278e-02,  7.8153e-02, -6.1564e-02, -1.4527e-02, -5.4682e-02,\n",
            "         1.0843e-01, -7.7834e-02, -7.5386e-02,  3.1312e-02, -7.2620e-02,\n",
            "        -5.9980e-02, -8.9566e-02,  8.6930e-02,  6.1813e-02,  6.6813e-03,\n",
            "         5.1193e-02, -3.3729e-02,  2.8810e-02,  8.4053e-02, -3.5546e-02,\n",
            "         8.2182e-02,  8.5866e-02,  5.7524e-02,  6.4632e-02, -2.2814e-02,\n",
            "         1.1358e-01,  1.1064e-02,  4.3942e-02,  5.0289e-02,  6.1384e-02,\n",
            "        -5.8566e-02, -2.5525e-02,  9.0603e-02,  5.1937e-02,  6.0171e-02,\n",
            "        -2.9409e-02, -1.9129e-03,  9.1908e-03, -5.4092e-03, -1.0837e-01,\n",
            "         9.5309e-02,  9.3523e-02, -3.2674e-02, -5.6801e-03, -1.0463e-01,\n",
            "        -9.8896e-02,  3.6284e-02, -8.9188e-03, -5.7008e-03,  6.7930e-02,\n",
            "         1.2158e-01,  3.0004e-02,  4.2713e-02,  9.8856e-02,  5.3338e-02,\n",
            "        -3.1436e-02, -1.0025e-01,  5.5724e-02,  8.3592e-02, -8.7874e-02,\n",
            "         3.1462e-02,  3.8240e-02, -4.9003e-02,  6.3497e-02,  7.0040e-02,\n",
            "        -2.1546e-02,  4.9136e-02, -8.1764e-02,  2.5971e-02,  4.6867e-03,\n",
            "        -6.7696e-02,  8.8943e-02,  3.2870e-02,  2.9696e-02,  1.0782e-01,\n",
            "        -7.9624e-02, -1.0556e-04, -6.7043e-02, -1.8691e-02, -9.9342e-02,\n",
            "         4.5954e-02,  3.4428e-02,  5.8159e-02,  8.5318e-02, -4.1854e-02,\n",
            "         1.0158e-01, -1.0273e-01, -8.7448e-02,  1.3318e-02, -1.9634e-02,\n",
            "        -6.0770e-02, -6.6416e-02,  7.9641e-02, -4.1088e-02, -2.7891e-02,\n",
            "         8.8510e-02,  7.0220e-02,  5.8805e-02, -2.1233e-02,  9.3979e-02,\n",
            "         3.2032e-04,  1.1666e-02, -8.5738e-02,  2.2255e-02,  4.8229e-02,\n",
            "        -4.6877e-02,  6.1391e-03, -1.5849e-02, -1.8722e-02, -6.8986e-03,\n",
            "         6.0071e-02,  8.4337e-02,  6.8582e-02,  3.9489e-02,  2.5320e-02,\n",
            "         7.1338e-02,  5.8812e-02, -4.7241e-02,  1.1060e-02, -6.1885e-02,\n",
            "        -1.1889e-01,  3.6212e-02, -9.7496e-02,  4.1440e-02,  1.0028e-01,\n",
            "         9.4766e-02,  4.0573e-02,  1.0442e-01,  8.7351e-02, -7.7028e-02,\n",
            "        -2.4117e-02, -2.0158e-02,  2.0507e-02,  4.3675e-02,  4.6547e-02,\n",
            "         8.2468e-03, -4.4949e-02, -1.0914e-02,  4.8796e-02,  3.6073e-02,\n",
            "         7.8421e-02, -4.1392e-02, -5.0319e-02, -2.0767e-03,  4.9311e-02,\n",
            "         7.6802e-02,  8.3034e-03, -1.1009e-01, -8.8002e-02, -5.0386e-02,\n",
            "         1.0964e-01, -8.4337e-02,  1.6594e-02, -7.6217e-02, -4.5910e-02,\n",
            "         8.2476e-02,  7.8835e-02,  4.4548e-03,  8.3881e-02, -6.2238e-02,\n",
            "         7.8743e-02,  7.9957e-02,  2.1452e-02, -9.6615e-03, -9.5410e-02,\n",
            "         4.8121e-02, -8.2821e-02, -3.8887e-02, -5.7422e-02, -3.2235e-03,\n",
            "        -5.0999e-02, -2.9614e-02,  7.5003e-02, -5.8823e-02, -1.1285e-01,\n",
            "        -6.0154e-02,  8.4803e-03, -8.0389e-02, -6.9064e-03, -6.9751e-02,\n",
            "         3.5242e-03, -1.1410e-02, -3.7816e-02, -3.6486e-02, -8.7187e-02,\n",
            "         4.7115e-02, -6.6250e-02,  8.3353e-02, -1.0738e-01,  1.8209e-02,\n",
            "         1.1274e-02,  4.8558e-02, -1.1955e-02,  5.3512e-03, -1.1016e-02,\n",
            "         1.1155e-01, -1.1045e-01, -7.6784e-03, -4.6583e-03,  6.0103e-03,\n",
            "         5.5131e-03, -5.6861e-02, -8.9815e-03, -5.3066e-02,  1.2306e-01,\n",
            "        -2.3932e-02,  1.1239e-01, -1.2687e-02, -1.4087e-02, -5.4400e-02,\n",
            "        -1.1569e-01, -7.5087e-02,  2.4729e-02,  6.1557e-02,  7.8853e-02,\n",
            "        -7.0523e-02,  8.6616e-02, -5.0619e-02,  5.3036e-03,  6.8607e-02,\n",
            "         7.4500e-02,  5.3529e-02,  7.7159e-02, -4.0076e-02,  9.3660e-02,\n",
            "         3.5176e-02, -8.4147e-02, -1.8759e-02,  2.0871e-02, -3.6166e-02,\n",
            "         7.6809e-04, -5.8568e-02,  4.2961e-02, -2.8134e-02,  2.3863e-02,\n",
            "        -9.0123e-02, -7.4248e-02, -3.7267e-02,  8.2949e-02,  1.2729e-02,\n",
            "        -3.3073e-02, -2.8594e-02,  7.9120e-02,  5.6969e-03,  8.7777e-02,\n",
            "         4.7100e-02, -9.2889e-02, -2.7237e-02, -2.3986e-02,  8.4244e-03,\n",
            "        -3.9073e-02,  3.6409e-02,  8.6184e-03, -5.2114e-02, -3.1350e-02,\n",
            "         1.1043e-01,  1.4558e-03,  6.6777e-02, -3.5875e-02,  6.9219e-02,\n",
            "         6.5105e-02,  2.5112e-02, -2.3129e-02,  1.9750e-02,  1.1601e-01,\n",
            "         6.0977e-02,  3.2653e-02,  6.0520e-02,  2.9938e-02, -5.0882e-02,\n",
            "         8.6494e-02, -6.3896e-02, -6.7705e-02,  2.5844e-02, -8.9274e-02,\n",
            "        -4.0278e-02,  7.7148e-02,  8.5355e-02,  7.8150e-02, -1.0877e-01,\n",
            "         7.0199e-03,  7.4308e-02,  3.6456e-03, -5.7434e-02,  1.0178e-01,\n",
            "        -6.0796e-02, -4.4282e-03,  7.7963e-02,  1.0363e-01,  1.6569e-02,\n",
            "         3.8828e-02, -2.8696e-02,  1.3939e-02,  4.1611e-02,  3.6706e-02,\n",
            "        -7.9663e-02, -1.0405e-03,  1.5375e-02,  7.9018e-02,  2.2274e-02],\n",
            "       requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for a in rnn.parameters():\n",
        "  print(a)\n",
        "rnn.n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RNN experiments"
      ],
      "metadata": {
        "id": "pK1-7QQ_vxOu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "2R84sVKcZXUD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce6ac1f7-e445-4de0-8cbc-afa4d741b3b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.1574,  0.1559]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3687, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.1574,  0.1559]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4223, 0.5777]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8620, -0.5487]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.1541,  0.1585]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3659, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.1541,  0.1585]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4225, 0.5775]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8617, -0.5490]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.1509,  0.1612]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3632, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.1509,  0.1612]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4226, 0.5774]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8613, -0.5492]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.1477,  0.1639]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3604, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.1477,  0.1639]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4227, 0.5773]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8610, -0.5495]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.1444,  0.1666]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3577, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.1444,  0.1666]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4229, 0.5771]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8607, -0.5497]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.1412,  0.1693]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3550, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.1412,  0.1693]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4230, 0.5770]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8604, -0.5499]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.1379,  0.1720]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3523, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.1379,  0.1720]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4231, 0.5769]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8601, -0.5502]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.1347,  0.1746]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3497, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.1347,  0.1746]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4233, 0.5767]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8597, -0.5504]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.1315,  0.1773]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3470, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.1315,  0.1773]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4234, 0.5766]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8594, -0.5506]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.1282,  0.1800]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3444, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.1282,  0.1800]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4235, 0.5765]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8591, -0.5508]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.1250,  0.1827]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3418, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.1250,  0.1827]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4237, 0.5763]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8588, -0.5511]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.1218,  0.1854]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3392, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.1218,  0.1854]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4238, 0.5762]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1.0000, grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8585, -0.5513]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.1185,  0.1881]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3366, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.1185,  0.1881]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4239, 0.5761]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8582, -0.5515]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.1153,  0.1909]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3340, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.1153,  0.1909]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4240, 0.5760]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8579, -0.5517]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.1121,  0.1936]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3315, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.1121,  0.1936]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4242, 0.5758]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8576, -0.5519]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.1089,  0.1963]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3289, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.1089,  0.1963]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4243, 0.5757]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8573, -0.5522]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.1057,  0.1990]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3264, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.1057,  0.1990]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4244, 0.5756]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8571, -0.5524]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.1025,  0.2017]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3239, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.1025,  0.2017]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4245, 0.5755]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8568, -0.5526]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0994,  0.2044]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3214, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0994,  0.2044]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4246, 0.5754]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8565, -0.5527]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0962,  0.2072]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3189, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0962,  0.2072]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4247, 0.5753]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1.0000, grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8563, -0.5529]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0930,  0.2099]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3165, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0930,  0.2099]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4248, 0.5752]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1.0000, grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8560, -0.5531]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0899,  0.2126]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3140, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0899,  0.2126]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4249, 0.5751]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8558, -0.5533]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0868,  0.2153]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3116, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0868,  0.2153]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4250, 0.5750]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8556, -0.5535]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0837,  0.2181]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3092, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0837,  0.2181]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4251, 0.5749]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8554, -0.5536]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0806,  0.2208]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3068, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0806,  0.2208]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4252, 0.5748]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8551, -0.5538]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0775,  0.2236]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3044, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0775,  0.2236]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4253, 0.5747]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8550, -0.5539]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0744,  0.2263]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.3021, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0744,  0.2263]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4254, 0.5746]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8548, -0.5540]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0714,  0.2291]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2997, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0714,  0.2291]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4255, 0.5745]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8546, -0.5542]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0683,  0.2318]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2974, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0683,  0.2318]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4255, 0.5745]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8544, -0.5543]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0653,  0.2346]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2951, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0653,  0.2346]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4256, 0.5744]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1.0000, grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8543, -0.5544]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0623,  0.2373]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2928, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0623,  0.2373]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4256, 0.5744]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8542, -0.5545]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0594,  0.2401]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2905, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0594,  0.2401]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4257, 0.5743]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8541, -0.5546]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0564,  0.2429]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2882, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0564,  0.2429]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4257, 0.5743]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8540, -0.5546]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0535,  0.2457]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2859, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0535,  0.2457]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4258, 0.5742]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8539, -0.5547]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0506,  0.2485]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2837, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0506,  0.2485]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4258, 0.5742]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8538, -0.5547]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0478,  0.2512]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2815, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0478,  0.2512]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4258, 0.5742]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8538, -0.5548]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0449,  0.2540]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2792, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0449,  0.2540]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4258, 0.5742]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1.0000, grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8538, -0.5548]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0421,  0.2568]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2770, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0421,  0.2568]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4258, 0.5742]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8538, -0.5548]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0393,  0.2596]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2748, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0393,  0.2596]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4258, 0.5742]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8538, -0.5548]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0366,  0.2625]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2727, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0366,  0.2625]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4258, 0.5742]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8538, -0.5548]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0338,  0.2653]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2705, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0338,  0.2653]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4258, 0.5742]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8539, -0.5547]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0312,  0.2681]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2683, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0312,  0.2681]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4257, 0.5743]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8539, -0.5547]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0285,  0.2709]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2662, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0285,  0.2709]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4257, 0.5743]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8540, -0.5546]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0259,  0.2738]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2640, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0259,  0.2738]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4256, 0.5744]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8542, -0.5545]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0233,  0.2766]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2619, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0233,  0.2766]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4256, 0.5744]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8543, -0.5544]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0207,  0.2795]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2598, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0207,  0.2795]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4255, 0.5745]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8545, -0.5543]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0182,  0.2823]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2577, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0182,  0.2823]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4254, 0.5746]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8547, -0.5541]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0158,  0.2852]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2556, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0158,  0.2852]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4253, 0.5747]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8549, -0.5539]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0133,  0.2881]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2535, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0133,  0.2881]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4252, 0.5748]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8552, -0.5538]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n",
            "tensor([[0.0000, 0.5000, 0.7000]])\n",
            "tensor([[-0.0109,  0.2910]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0.2514, grad_fn=<MseLossBackward0>)\n",
            "checking softmax - dim 0\n",
            "tensor([[-0.0109,  0.2910]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1., 1.]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(2., grad_fn=<SumBackward0>)\n",
            "tensor([[0., 0.]], grad_fn=<LogSoftmaxBackward0>)\n",
            "checking softmax - dim 1\n",
            "tensor([[0.4251, 0.5749]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([[-0.8554, -0.5536]], grad_fn=<LogSoftmaxBackward0>)\n",
            "-----\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "#Initialize an PyTorch LSTM for comparison to our Numpy LSTM\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers=1,batch_size=1):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_dim=hidden_dim\n",
        "        self.batch_size=batch_size\n",
        "        self.input_size=input_size\n",
        "        #LSTM Layer\n",
        "        #self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)\n",
        "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers)\n",
        "        #Final, fully-connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.hidden=self.init_hidden()\n",
        "    #def forward(self, x, hidden):\n",
        "    def forward(self, input_data):\n",
        "        batch_size = 1\n",
        "        # get LSTM outputs\n",
        "        #lstm_output, (h,c) = self.lstm(x, hidden)\n",
        "        for x in input_data:\n",
        "          x=x.view([1,1,self.input_size])\n",
        "          lstm_output, self.hidden = self.lstm(x, self.hidden)\n",
        "          \n",
        "          # shape output to be (batch_size*seq_length, hidden_dim)\n",
        "          lstm_output = lstm_output.view(-1, self.hidden_dim)  \n",
        "          \n",
        "          # get final output \n",
        "          model_output = self.fc(lstm_output)\n",
        "          #model_output=torch.sigmoid(model_output)\n",
        "        \n",
        "        return model_output, self.hidden\n",
        "        #return model_output, (h,c)\n",
        "\n",
        "    # def init_hidden(self):\n",
        "    #   return \n",
        "    def init_hidden(self):\n",
        "        return (torch.zeros(1, self.batch_size, self.hidden_dim),\n",
        "                torch.zeros(1, self.batch_size, self.hidden_dim))  \n",
        "              \n",
        "torch.manual_seed(5)\n",
        "input_size=3\n",
        "hidden_dim=8\n",
        "output_size=2\n",
        "\n",
        "torch_lstm = LSTM(input_size = input_size, \n",
        "                 hidden_dim = hidden_dim,\n",
        "                 output_size = output_size,\n",
        "                 )\n",
        "LR=0.001\n",
        "loss_func = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(torch_lstm.parameters(), lr=LR)\n",
        "\n",
        "input_tensor=torch.rand((1, input_size))\n",
        "input_list1=[[0, 0.5, 0.7]]\n",
        "out_list1=[0.,1.]\n",
        "\n",
        "for a in range(50):\n",
        "  torch_lstm.hidden=torch_lstm.init_hidden()\n",
        "  torch_lstm.zero_grad()\n",
        "\n",
        "  input_tensor1=torch.tensor(input_list1)\n",
        "  output_tensor1=torch.tensor(out_list1)\n",
        "  print(input_tensor1)\n",
        "  rnn_output,_=torch_lstm(input_tensor1)\n",
        "  loss = loss_func(output_tensor1.ravel(), rnn_output.ravel()) #calculate the loss, difference between the output and the desired outcome tensors\n",
        "  loss.backward()\n",
        "  optimizer.step() \n",
        "  print(rnn_output)\n",
        "  print(loss)\n",
        "\n",
        "\n",
        "  # data = torch.randn(5)\n",
        "  # data = torch.randn(1,5)\n",
        "  print(\"checking softmax - dim 0\")\n",
        "  data=rnn_output\n",
        "  print(data)\n",
        "  print(F.softmax(data, dim=0))\n",
        "  print(F.softmax(data, dim=0).sum())  # Sums to 1 because it is a distribution!\n",
        "  print(F.log_softmax(data, dim=0))  # theres also log_softmax\n",
        "  print(\"checking softmax - dim 1\")\n",
        "  print(F.softmax(data, dim=1))\n",
        "  print(F.softmax(data, dim=1).sum())  # Sums to 1 because it is a distribution!\n",
        "  print(F.log_softmax(data, dim=1))  # theres also log_softmax\n",
        "\n",
        "  print(\"-----\")\n",
        "\n",
        "# torch_lstm.init_hidden()\n",
        "# torch_lstm.zero_grad()\n",
        "# input_tensor1=torch.tensor(input_list1)\n",
        "# output_tensor1=torch.tensor(out_list1)\n",
        "# rnn_output,_=torch_lstm(input_tensor1)\n",
        "# loss = loss_func(output_tensor1.ravel(), rnn_output.ravel()) #calculate the loss, difference between the output and the desired outcome tensors\n",
        "# loss.backward()\n",
        "# optimizer.step() \n",
        "# print(rnn_output)\n",
        "# print(loss)\n",
        "\n",
        "\n",
        "# torch_lstm.init_hidden()\n",
        "# torch_lstm.zero_grad()\n",
        "# input_tensor1=torch.tensor(input_list1)\n",
        "# output_tensor1=torch.tensor(out_list1)\n",
        "# rnn_output,_=torch_lstm(input_tensor1)\n",
        "# loss = loss_func(output_tensor1.ravel(), rnn_output.ravel()) #calculate the loss, difference between the output and the desired outcome tensors\n",
        "# loss.backward()\n",
        "# optimizer.step() \n",
        "# print(rnn_output)\n",
        "# print(loss)\n",
        "\n",
        "# state = torch_lstm.state_dict()\n",
        "# print(state)\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "device = torch.device('cpu')\n",
        "\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size,num_layers, matching_in_out=False, batch_size=1):\n",
        "    super(RNN, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = num_layers\n",
        "    self.batch_size = batch_size\n",
        "    self.matching_in_out = matching_in_out #length of input vector matches the length of output vector \n",
        "    self.lstm = nn.LSTM(input_size, hidden_size,num_layers)\n",
        "    self.hidden2out = nn.Linear(hidden_size, output_size)\n",
        "    #self.softmax = nn.LogSoftmax(dim=2)\n",
        "    #self.softmax = F.softmax(dim=2)\n",
        "    self.softmax =nn.Softmax(dim=2)\n",
        "    \n",
        "    #self.sigmoid = torch.sigmoid(dim=1)\n",
        "    self.hidden = self.init_hidden()\n",
        "  def forward(self, feature_list):\n",
        "    feature_list=torch.tensor(feature_list)\n",
        "    \n",
        "    feature_list=feature_list.to(device) #### <<<<<<<<<<<<<<<<< \n",
        "    if self.matching_in_out:\n",
        "      lstm_out, _ = self.lstm( feature_list.view(len( feature_list), 1, -1))\n",
        "      output_space = self.hidden2out(lstm_out.view(len( feature_list), -1))\n",
        "      output_scores = torch.sigmoid(output_space) #we'll need to check if we need this sigmoid\n",
        "      return output_scores #output_scores\n",
        "    else:\n",
        "      for i in range(len(feature_list)):\n",
        "        cur_ft_tensor=feature_list[i]#.view([1,1,self.input_size])\n",
        "        cur_ft_tensor=cur_ft_tensor.view([1,1,self.input_size])\n",
        "        lstm_out, self.hidden = self.lstm(cur_ft_tensor, self.hidden)\n",
        "        outs=self.hidden2out(lstm_out)\n",
        "        #outs=torch.sigmoid(outs) #check this\n",
        "        #print(\"outs - before softmax\",outs)\n",
        "        outs = self.softmax(outs).to(device)\n",
        "        #outs = self.sigmoid(outs).to(device)\n",
        "        #self.softmax = nn.LogSoftmax(dim=1)\n",
        "      return outs\n",
        "  def init_hidden(self):\n",
        "    #return torch.rand(self.num_layers, self.batch_size, self.hidden_size)\n",
        "    return (torch.rand(self.num_layers, self.batch_size, self.hidden_size).to(device),\n",
        "            torch.rand(self.num_layers, self.batch_size, self.hidden_size).to(device))\n",
        "    \n",
        "\n",
        "prev_n=20\n",
        "next_n=10\n",
        "print(\"loaded network\") #uncomment the following text to test it\n",
        "n_input=3 #len(mv_labels2)\n",
        "n_output=2 # next_n*len(mv_labels2)\n",
        "n_hidden =8#64\n",
        "n_layers=2\n",
        "LR=0.0000001\n",
        "LR=0.001\n",
        "\n",
        "rnn = RNN(n_input, n_hidden, n_output,n_layers, matching_in_out=False).to(device)\n",
        "loss_func = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)\n",
        "\n",
        "print(rnn)\n",
        "input_list1=[[0, 0.5, 0.7]]\n",
        "out_list1=[0.,1.]\n",
        "out_list1=[1.,0.]\n",
        "\n",
        "for a in range(100):\n",
        "  print(a)\n",
        "  rnn.hidden=rnn.init_hidden()\n",
        "  rnn.zero_grad()\n",
        "  input_tensor1=torch.tensor(input_list1)\n",
        "  output_tensor1=torch.tensor(out_list1)  \n",
        "  #input_tensor=torch.rand((1, n_input)).to(device)\n",
        "  #print(\"input_tensor1\",input_tensor1.shape)\n",
        "  #input_tensor=torch.rand((prev_n, n_input)).to(device)\n",
        "  rnn_output = rnn(input_tensor1)\n",
        "  #print(rnn_output.shape)\n",
        "  \n",
        "  loss = loss_func(output_tensor1, rnn_output) #calculate the loss, difference between the output and the desired outcome tensors\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  print(\"rnn_output\", rnn_output)\n",
        "  print(\"loss\", loss.item())\n",
        "  print(\"--------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwwGzmgeuP28",
        "outputId": "f6441463-d6fe-4000-8cec-62b9bed9070a"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded network\n",
            "RNN(\n",
            "  (lstm): LSTM(3, 8, num_layers=2)\n",
            "  (hidden2out): Linear(in_features=8, out_features=2, bias=True)\n",
            "  (softmax): Softmax(dim=2)\n",
            ")\n",
            "0\n",
            "rnn_output tensor([[[0.4563, 0.5437]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.2955794036388397\n",
            "--------\n",
            "1\n",
            "rnn_output tensor([[[0.4797, 0.5203]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.27076077461242676\n",
            "--------\n",
            "2\n",
            "rnn_output tensor([[[0.4558, 0.5442]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.29617515206336975\n",
            "--------\n",
            "3\n",
            "rnn_output tensor([[[0.4822, 0.5178]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.26815086603164673\n",
            "--------\n",
            "4\n",
            "rnn_output tensor([[[0.4659, 0.5341]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.2852593958377838\n",
            "--------\n",
            "5\n",
            "rnn_output tensor([[[0.4889, 0.5111]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.2611868381500244\n",
            "--------\n",
            "6\n",
            "rnn_output tensor([[[0.4753, 0.5247]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.2753411829471588\n",
            "--------\n",
            "7\n",
            "rnn_output tensor([[[0.5152, 0.4848]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.23507459461688995\n",
            "--------\n",
            "8\n",
            "rnn_output tensor([[[0.5199, 0.4801]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.23050105571746826\n",
            "--------\n",
            "9\n",
            "rnn_output tensor([[[0.4791, 0.5209]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.2713102400302887\n",
            "--------\n",
            "10\n",
            "rnn_output tensor([[[0.4799, 0.5201]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.270508348941803\n",
            "--------\n",
            "11\n",
            "rnn_output tensor([[[0.5052, 0.4948]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.24484264850616455\n",
            "--------\n",
            "12\n",
            "rnn_output tensor([[[0.4950, 0.5050]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.25500690937042236\n",
            "--------\n",
            "13\n",
            "rnn_output tensor([[[0.5119, 0.4881]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.23826302587985992\n",
            "--------\n",
            "14\n",
            "rnn_output tensor([[[0.5301, 0.4699]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.22081375122070312\n",
            "--------\n",
            "15\n",
            "rnn_output tensor([[[0.5013, 0.4987]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.2487419992685318\n",
            "--------\n",
            "16\n",
            "rnn_output tensor([[[0.4936, 0.5064]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.2564086318016052\n",
            "--------\n",
            "17\n",
            "rnn_output tensor([[[0.5062, 0.4938]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.24385163187980652\n",
            "--------\n",
            "18\n",
            "rnn_output tensor([[[0.5106, 0.4894]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.23947927355766296\n",
            "--------\n",
            "19\n",
            "rnn_output tensor([[[0.5111, 0.4889]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.2390511929988861\n",
            "--------\n",
            "20\n",
            "rnn_output tensor([[[0.5256, 0.4744]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.22504860162734985\n",
            "--------\n",
            "21\n",
            "rnn_output tensor([[[0.5320, 0.4680]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.21903589367866516\n",
            "--------\n",
            "22\n",
            "rnn_output tensor([[[0.5448, 0.4552]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.20720040798187256\n",
            "--------\n",
            "23\n",
            "rnn_output tensor([[[0.5225, 0.4775]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.22804808616638184\n",
            "--------\n",
            "24\n",
            "rnn_output tensor([[[0.5341, 0.4659]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.21707716584205627\n",
            "--------\n",
            "25\n",
            "rnn_output tensor([[[0.5448, 0.4552]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.20724360644817352\n",
            "--------\n",
            "26\n",
            "rnn_output tensor([[[0.5035, 0.4965]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.2464642971754074\n",
            "--------\n",
            "27\n",
            "rnn_output tensor([[[0.5472, 0.4528]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.20502230525016785\n",
            "--------\n",
            "28\n",
            "rnn_output tensor([[[0.5170, 0.4830]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.23328836262226105\n",
            "--------\n",
            "29\n",
            "rnn_output tensor([[[0.5632, 0.4368]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.190810889005661\n",
            "--------\n",
            "30\n",
            "rnn_output tensor([[[0.5569, 0.4431]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.1963547021150589\n",
            "--------\n",
            "31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([1, 1, 2])) that is different to the input size (torch.Size([2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rnn_output tensor([[[0.5182, 0.4818]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.23212039470672607\n",
            "--------\n",
            "32\n",
            "rnn_output tensor([[[0.5687, 0.4313]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.18600748479366302\n",
            "--------\n",
            "33\n",
            "rnn_output tensor([[[0.5278, 0.4722]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.2229379564523697\n",
            "--------\n",
            "34\n",
            "rnn_output tensor([[[0.5578, 0.4422]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.19552019238471985\n",
            "--------\n",
            "35\n",
            "rnn_output tensor([[[0.5577, 0.4423]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.19566357135772705\n",
            "--------\n",
            "36\n",
            "rnn_output tensor([[[0.5335, 0.4665]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.2176627218723297\n",
            "--------\n",
            "37\n",
            "rnn_output tensor([[[0.5639, 0.4361]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.1901671141386032\n",
            "--------\n",
            "38\n",
            "rnn_output tensor([[[0.5553, 0.4447]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.19772115349769592\n",
            "--------\n",
            "39\n",
            "rnn_output tensor([[[0.5432, 0.4568]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.2086455076932907\n",
            "--------\n",
            "40\n",
            "rnn_output tensor([[[0.5786, 0.4214]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.17761150002479553\n",
            "--------\n",
            "41\n",
            "rnn_output tensor([[[0.5823, 0.4177]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.1744976043701172\n",
            "--------\n",
            "42\n",
            "rnn_output tensor([[[0.5634, 0.4366]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.19063030183315277\n",
            "--------\n",
            "43\n",
            "rnn_output tensor([[[0.5794, 0.4206]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.1769101619720459\n",
            "--------\n",
            "44\n",
            "rnn_output tensor([[[0.5526, 0.4474]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.20017153024673462\n",
            "--------\n",
            "45\n",
            "rnn_output tensor([[[0.5501, 0.4499]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.2023972123861313\n",
            "--------\n",
            "46\n",
            "rnn_output tensor([[[0.5656, 0.4344]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.18871092796325684\n",
            "--------\n",
            "47\n",
            "rnn_output tensor([[[0.5913, 0.4087]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.16707275807857513\n",
            "--------\n",
            "48\n",
            "rnn_output tensor([[[0.5870, 0.4130]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.17059464752674103\n",
            "--------\n",
            "49\n",
            "rnn_output tensor([[[0.5780, 0.4220]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.17809852957725525\n",
            "--------\n",
            "50\n",
            "rnn_output tensor([[[0.5467, 0.4533]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.20546212792396545\n",
            "--------\n",
            "51\n",
            "rnn_output tensor([[[0.5765, 0.4235]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.17935492098331451\n",
            "--------\n",
            "52\n",
            "rnn_output tensor([[[0.6047, 0.3953]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.15627744793891907\n",
            "--------\n",
            "53\n",
            "rnn_output tensor([[[0.6005, 0.3995]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.15960584580898285\n",
            "--------\n",
            "54\n",
            "rnn_output tensor([[[0.5750, 0.4250]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.1806337833404541\n",
            "--------\n",
            "55\n",
            "rnn_output tensor([[[0.5697, 0.4303]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.1851520836353302\n",
            "--------\n",
            "56\n",
            "rnn_output tensor([[[0.5904, 0.4096]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.16774986684322357\n",
            "--------\n",
            "57\n",
            "rnn_output tensor([[[0.5870, 0.4130]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.17055638134479523\n",
            "--------\n",
            "58\n",
            "rnn_output tensor([[[0.5957, 0.4043]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.16345089673995972\n",
            "--------\n",
            "59\n",
            "rnn_output tensor([[[0.5662, 0.4338]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.18816915154457092\n",
            "--------\n",
            "60\n",
            "rnn_output tensor([[[0.6134, 0.3866]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.14945988357067108\n",
            "--------\n",
            "61\n",
            "rnn_output tensor([[[0.6209, 0.3791]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.143680602312088\n",
            "--------\n",
            "62\n",
            "rnn_output tensor([[[0.5856, 0.4144]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.17171524465084076\n",
            "--------\n",
            "63\n",
            "rnn_output tensor([[[0.6216, 0.3784]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.14316263794898987\n",
            "--------\n",
            "64\n",
            "rnn_output tensor([[[0.6383, 0.3617]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.13082033395767212\n",
            "--------\n",
            "65\n",
            "rnn_output tensor([[[0.6308, 0.3692]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.13629162311553955\n",
            "--------\n",
            "66\n",
            "rnn_output tensor([[[0.6181, 0.3819]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.1458551436662674\n",
            "--------\n",
            "67\n",
            "rnn_output tensor([[[0.5884, 0.4116]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.16945019364356995\n",
            "--------\n",
            "68\n",
            "rnn_output tensor([[[0.5880, 0.4120]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.16970562934875488\n",
            "--------\n",
            "69\n",
            "rnn_output tensor([[[0.6191, 0.3809]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.1450852006673813\n",
            "--------\n",
            "70\n",
            "rnn_output tensor([[[0.6251, 0.3749]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.1405251920223236\n",
            "--------\n",
            "71\n",
            "rnn_output tensor([[[0.6523, 0.3477]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.12087535858154297\n",
            "--------\n",
            "72\n",
            "rnn_output tensor([[[0.6212, 0.3788]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.14352625608444214\n",
            "--------\n",
            "73\n",
            "rnn_output tensor([[[0.6063, 0.3937]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.15501049160957336\n",
            "--------\n",
            "74\n",
            "rnn_output tensor([[[0.6169, 0.3831]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.14673811197280884\n",
            "--------\n",
            "75\n",
            "rnn_output tensor([[[0.6583, 0.3417]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.11675914376974106\n",
            "--------\n",
            "76\n",
            "rnn_output tensor([[[0.6357, 0.3643]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.1327424943447113\n",
            "--------\n",
            "77\n",
            "rnn_output tensor([[[0.6234, 0.3766]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.14185751974582672\n",
            "--------\n",
            "78\n",
            "rnn_output tensor([[[0.6335, 0.3665]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.1342988908290863\n",
            "--------\n",
            "79\n",
            "rnn_output tensor([[[0.6407, 0.3593]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.12909340858459473\n",
            "--------\n",
            "80\n",
            "rnn_output tensor([[[0.6419, 0.3581]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.1282571703195572\n",
            "--------\n",
            "81\n",
            "rnn_output tensor([[[0.6546, 0.3454]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.11932531744241714\n",
            "--------\n",
            "82\n",
            "rnn_output tensor([[[0.6742, 0.3258]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.10617569088935852\n",
            "--------\n",
            "83\n",
            "rnn_output tensor([[[0.6661, 0.3339]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.11150434613227844\n",
            "--------\n",
            "84\n",
            "rnn_output tensor([[[0.6704, 0.3296]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.1086123138666153\n",
            "--------\n",
            "85\n",
            "rnn_output tensor([[[0.6782, 0.3218]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.10352856665849686\n",
            "--------\n",
            "86\n",
            "rnn_output tensor([[[0.6778, 0.3222]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.10379332304000854\n",
            "--------\n",
            "87\n",
            "rnn_output tensor([[[0.6862, 0.3138]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.09848377853631973\n",
            "--------\n",
            "88\n",
            "rnn_output tensor([[[0.6145, 0.3855]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.14857473969459534\n",
            "--------\n",
            "89\n",
            "rnn_output tensor([[[0.6837, 0.3163]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.1000182256102562\n",
            "--------\n",
            "90\n",
            "rnn_output tensor([[[0.6921, 0.3079]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.09480050951242447\n",
            "--------\n",
            "91\n",
            "rnn_output tensor([[[0.6863, 0.3137]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.0984313115477562\n",
            "--------\n",
            "92\n",
            "rnn_output tensor([[[0.6835, 0.3165]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.10018213838338852\n",
            "--------\n",
            "93\n",
            "rnn_output tensor([[[0.7034, 0.2966]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.08795894682407379\n",
            "--------\n",
            "94\n",
            "rnn_output tensor([[[0.6593, 0.3407]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.11610378324985504\n",
            "--------\n",
            "95\n",
            "rnn_output tensor([[[0.6994, 0.3006]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.09034846723079681\n",
            "--------\n",
            "96\n",
            "rnn_output tensor([[[0.7214, 0.2786]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.07761538773775101\n",
            "--------\n",
            "97\n",
            "rnn_output tensor([[[0.6546, 0.3454]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.1193217933177948\n",
            "--------\n",
            "98\n",
            "rnn_output tensor([[[0.7104, 0.2896]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.08384821563959122\n",
            "--------\n",
            "99\n",
            "rnn_output tensor([[[0.6909, 0.3091]]], grad_fn=<SoftmaxBackward0>)\n",
            "loss 0.09557302296161652\n",
            "--------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Experiment with stock data"
      ],
      "metadata": {
        "id": "EPkA7m3-H2Kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir='stock_market_data/sp500/csv'\n",
        "test_files=[\"AAPL\",\"GOOG\",\"FB\",\"AMZN\",\"EA\",\"IBM\",\"MSFT\",\"GM\",\"UPS\",\"PG\"]\n",
        "cur_path=os.path.join(root_dir,\"AAPL.csv\")\n",
        "train0,test0=get_norm_close(cur_path,prev_n0=20,next_n0=10,train_ratio=0.75)\n",
        "cur_train_item=train0[10]\n",
        "#print()\n",
        "input0,output0=cur_train_item\n",
        "input_oh0=list2one_hot2(input0,mv_labels2)\n",
        "output_oh0=list2one_hot2(output0,mv_labels2)\n",
        "# for in0,in_oh0 in zip(input0,input_oh0):\n",
        "#   print(in0, in_oh0)\n",
        "\n",
        "n_input=len(mv_labels2)\n",
        "n_output=10*len(mv_labels2)\n",
        "n_hidden =8#64\n",
        "n_layers=2\n",
        "LR=0.0000001\n",
        "LR=0.01\n",
        "\n",
        "rnn = RNN(n_input, n_hidden, n_output,n_layers, matching_in_out=False).to(device)\n",
        "loss_func = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)\n",
        "\n",
        "print(rnn)\n",
        "# input_list1=[[0, 0.5, 0.7]]\n",
        "# out_list1=[0.,1.]\n",
        "# out_list1=[1.,0.]\n",
        "\n",
        "for a in range(50):\n",
        "  print(a)\n",
        "  rnn.hidden=rnn.init_hidden()\n",
        "  rnn.zero_grad()\n",
        "  # input_tensor1=torch.tensor(input_list1)\n",
        "  # output_tensor1=torch.tensor(out_list1)  \n",
        "  input_tensor1=torch.tensor(input_oh0)\n",
        "  output_tensor1=torch.tensor(output_oh0)  \n",
        "\n",
        "  #input_tensor=torch.rand((1, n_input)).to(device)\n",
        "  #print(\"input_tensor1\",input_tensor1.shape)\n",
        "  #input_tensor=torch.rand((prev_n, n_input)).to(device)\n",
        "  rnn_output = rnn(input_tensor1)\n",
        "  rnn_output=rnn_output.view(output_tensor1.shape)\n",
        "  #print(rnn_output.shape)\n",
        "  \n",
        "  loss = loss_func(output_tensor1.ravel(), rnn_output.ravel()) #calculate the loss, difference between the output and the desired outcome tensors\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  print(\"actual:\",output_tensor1)\n",
        "  print(\"rnn_output\", rnn_output)\n",
        "  print(\"loss\", loss.item())\n",
        "  print(\"--------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYUCprfR56F0",
        "outputId": "04da82e0-6f15-47f4-f19e-71b47d637640"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN(\n",
            "  (lstm): LSTM(7, 8, num_layers=2)\n",
            "  (hidden2out): Linear(in_features=8, out_features=70, bias=True)\n",
            "  (softmax): Softmax(dim=2)\n",
            ")\n",
            "0\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0163, 0.0162, 0.0168, 0.0157, 0.0162, 0.0136, 0.0097],\n",
            "        [0.0117, 0.0107, 0.0175, 0.0137, 0.0192, 0.0139, 0.0102],\n",
            "        [0.0098, 0.0174, 0.0202, 0.0096, 0.0126, 0.0115, 0.0209],\n",
            "        [0.0114, 0.0191, 0.0166, 0.0219, 0.0135, 0.0182, 0.0166],\n",
            "        [0.0149, 0.0152, 0.0215, 0.0109, 0.0118, 0.0168, 0.0185],\n",
            "        [0.0158, 0.0099, 0.0114, 0.0163, 0.0119, 0.0111, 0.0120],\n",
            "        [0.0104, 0.0123, 0.0103, 0.0192, 0.0175, 0.0140, 0.0147],\n",
            "        [0.0104, 0.0111, 0.0159, 0.0170, 0.0128, 0.0149, 0.0129],\n",
            "        [0.0131, 0.0096, 0.0110, 0.0160, 0.0098, 0.0128, 0.0111],\n",
            "        [0.0225, 0.0116, 0.0123, 0.0201, 0.0155, 0.0114, 0.0110]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.13919372856616974\n",
            "--------\n",
            "1\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0161, 0.0166, 0.0175, 0.0155, 0.0162, 0.0132, 0.0101],\n",
            "        [0.0112, 0.0112, 0.0175, 0.0138, 0.0193, 0.0140, 0.0105],\n",
            "        [0.0104, 0.0171, 0.0196, 0.0097, 0.0125, 0.0113, 0.0202],\n",
            "        [0.0123, 0.0186, 0.0164, 0.0216, 0.0133, 0.0185, 0.0169],\n",
            "        [0.0158, 0.0149, 0.0211, 0.0108, 0.0120, 0.0165, 0.0177],\n",
            "        [0.0167, 0.0099, 0.0116, 0.0156, 0.0114, 0.0114, 0.0118],\n",
            "        [0.0110, 0.0124, 0.0103, 0.0189, 0.0177, 0.0142, 0.0147],\n",
            "        [0.0108, 0.0108, 0.0162, 0.0170, 0.0129, 0.0145, 0.0128],\n",
            "        [0.0138, 0.0097, 0.0109, 0.0162, 0.0096, 0.0125, 0.0111],\n",
            "        [0.0232, 0.0120, 0.0117, 0.0193, 0.0149, 0.0112, 0.0113]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.13899430632591248\n",
            "--------\n",
            "2\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0158, 0.0168, 0.0181, 0.0154, 0.0164, 0.0128, 0.0103],\n",
            "        [0.0107, 0.0116, 0.0176, 0.0139, 0.0196, 0.0144, 0.0108],\n",
            "        [0.0110, 0.0166, 0.0192, 0.0097, 0.0125, 0.0112, 0.0193],\n",
            "        [0.0132, 0.0182, 0.0164, 0.0212, 0.0131, 0.0188, 0.0171],\n",
            "        [0.0167, 0.0146, 0.0206, 0.0108, 0.0122, 0.0159, 0.0172],\n",
            "        [0.0177, 0.0098, 0.0115, 0.0151, 0.0109, 0.0117, 0.0115],\n",
            "        [0.0116, 0.0124, 0.0103, 0.0185, 0.0179, 0.0144, 0.0145],\n",
            "        [0.0110, 0.0105, 0.0166, 0.0171, 0.0130, 0.0143, 0.0126],\n",
            "        [0.0147, 0.0097, 0.0108, 0.0165, 0.0093, 0.0121, 0.0108],\n",
            "        [0.0243, 0.0122, 0.0113, 0.0187, 0.0142, 0.0110, 0.0116]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.13878750801086426\n",
            "--------\n",
            "3\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0155, 0.0171, 0.0188, 0.0154, 0.0165, 0.0123, 0.0104],\n",
            "        [0.0103, 0.0120, 0.0176, 0.0139, 0.0198, 0.0147, 0.0110],\n",
            "        [0.0116, 0.0163, 0.0189, 0.0096, 0.0126, 0.0110, 0.0184],\n",
            "        [0.0142, 0.0177, 0.0166, 0.0209, 0.0129, 0.0190, 0.0171],\n",
            "        [0.0176, 0.0142, 0.0202, 0.0107, 0.0123, 0.0153, 0.0167],\n",
            "        [0.0188, 0.0096, 0.0115, 0.0148, 0.0104, 0.0118, 0.0113],\n",
            "        [0.0123, 0.0122, 0.0101, 0.0180, 0.0183, 0.0147, 0.0142],\n",
            "        [0.0113, 0.0102, 0.0170, 0.0173, 0.0131, 0.0141, 0.0123],\n",
            "        [0.0157, 0.0097, 0.0105, 0.0170, 0.0090, 0.0118, 0.0105],\n",
            "        [0.0255, 0.0123, 0.0110, 0.0183, 0.0135, 0.0108, 0.0118]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.13855978846549988\n",
            "--------\n",
            "4\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0151, 0.0174, 0.0198, 0.0153, 0.0166, 0.0119, 0.0103],\n",
            "        [0.0099, 0.0125, 0.0176, 0.0139, 0.0200, 0.0150, 0.0110],\n",
            "        [0.0122, 0.0159, 0.0186, 0.0094, 0.0126, 0.0109, 0.0174],\n",
            "        [0.0154, 0.0171, 0.0168, 0.0207, 0.0129, 0.0192, 0.0170],\n",
            "        [0.0186, 0.0139, 0.0198, 0.0106, 0.0124, 0.0145, 0.0163],\n",
            "        [0.0201, 0.0094, 0.0114, 0.0146, 0.0099, 0.0119, 0.0110],\n",
            "        [0.0130, 0.0121, 0.0100, 0.0173, 0.0188, 0.0149, 0.0139],\n",
            "        [0.0117, 0.0100, 0.0175, 0.0176, 0.0130, 0.0139, 0.0121],\n",
            "        [0.0170, 0.0096, 0.0103, 0.0174, 0.0087, 0.0114, 0.0100],\n",
            "        [0.0270, 0.0123, 0.0107, 0.0179, 0.0128, 0.0105, 0.0120]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.138297438621521\n",
            "--------\n",
            "5\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0147, 0.0178, 0.0211, 0.0152, 0.0167, 0.0114, 0.0101],\n",
            "        [0.0095, 0.0131, 0.0176, 0.0138, 0.0201, 0.0152, 0.0111],\n",
            "        [0.0130, 0.0154, 0.0183, 0.0090, 0.0127, 0.0107, 0.0164],\n",
            "        [0.0168, 0.0163, 0.0171, 0.0205, 0.0128, 0.0194, 0.0169],\n",
            "        [0.0197, 0.0136, 0.0195, 0.0104, 0.0124, 0.0137, 0.0159],\n",
            "        [0.0216, 0.0092, 0.0113, 0.0144, 0.0094, 0.0120, 0.0107],\n",
            "        [0.0139, 0.0119, 0.0097, 0.0166, 0.0194, 0.0151, 0.0134],\n",
            "        [0.0121, 0.0097, 0.0180, 0.0179, 0.0129, 0.0136, 0.0118],\n",
            "        [0.0185, 0.0094, 0.0099, 0.0179, 0.0083, 0.0110, 0.0094],\n",
            "        [0.0286, 0.0122, 0.0104, 0.0176, 0.0120, 0.0102, 0.0121]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.13798658549785614\n",
            "--------\n",
            "6\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0143, 0.0181, 0.0226, 0.0152, 0.0168, 0.0109, 0.0099],\n",
            "        [0.0091, 0.0138, 0.0176, 0.0136, 0.0202, 0.0155, 0.0110],\n",
            "        [0.0138, 0.0150, 0.0179, 0.0086, 0.0128, 0.0105, 0.0153],\n",
            "        [0.0185, 0.0155, 0.0174, 0.0204, 0.0127, 0.0195, 0.0166],\n",
            "        [0.0209, 0.0133, 0.0191, 0.0102, 0.0123, 0.0128, 0.0155],\n",
            "        [0.0234, 0.0089, 0.0111, 0.0142, 0.0089, 0.0120, 0.0104],\n",
            "        [0.0150, 0.0116, 0.0094, 0.0159, 0.0200, 0.0153, 0.0129],\n",
            "        [0.0126, 0.0093, 0.0186, 0.0182, 0.0127, 0.0134, 0.0115],\n",
            "        [0.0203, 0.0093, 0.0095, 0.0184, 0.0079, 0.0105, 0.0087],\n",
            "        [0.0306, 0.0120, 0.0102, 0.0172, 0.0112, 0.0099, 0.0122]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.1376124918460846\n",
            "--------\n",
            "7\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0139, 0.0183, 0.0245, 0.0151, 0.0167, 0.0104, 0.0095],\n",
            "        [0.0086, 0.0146, 0.0176, 0.0132, 0.0202, 0.0156, 0.0108],\n",
            "        [0.0148, 0.0144, 0.0175, 0.0082, 0.0128, 0.0103, 0.0142],\n",
            "        [0.0205, 0.0145, 0.0178, 0.0202, 0.0126, 0.0196, 0.0162],\n",
            "        [0.0223, 0.0129, 0.0187, 0.0100, 0.0120, 0.0119, 0.0151],\n",
            "        [0.0256, 0.0086, 0.0109, 0.0139, 0.0084, 0.0119, 0.0100],\n",
            "        [0.0163, 0.0113, 0.0091, 0.0151, 0.0206, 0.0153, 0.0122],\n",
            "        [0.0132, 0.0090, 0.0192, 0.0186, 0.0124, 0.0132, 0.0111],\n",
            "        [0.0225, 0.0091, 0.0091, 0.0188, 0.0074, 0.0101, 0.0080],\n",
            "        [0.0330, 0.0117, 0.0099, 0.0168, 0.0104, 0.0096, 0.0123]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.13716192543506622\n",
            "--------\n",
            "8\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0135, 0.0184, 0.0269, 0.0150, 0.0165, 0.0098, 0.0090],\n",
            "        [0.0082, 0.0157, 0.0175, 0.0127, 0.0200, 0.0156, 0.0105],\n",
            "        [0.0159, 0.0139, 0.0171, 0.0077, 0.0128, 0.0101, 0.0131],\n",
            "        [0.0229, 0.0136, 0.0181, 0.0199, 0.0125, 0.0195, 0.0157],\n",
            "        [0.0240, 0.0125, 0.0183, 0.0097, 0.0117, 0.0111, 0.0147],\n",
            "        [0.0282, 0.0082, 0.0107, 0.0136, 0.0079, 0.0116, 0.0096],\n",
            "        [0.0178, 0.0109, 0.0087, 0.0143, 0.0212, 0.0152, 0.0116],\n",
            "        [0.0140, 0.0086, 0.0197, 0.0188, 0.0120, 0.0129, 0.0107],\n",
            "        [0.0250, 0.0088, 0.0087, 0.0191, 0.0069, 0.0096, 0.0073],\n",
            "        [0.0360, 0.0114, 0.0097, 0.0164, 0.0096, 0.0092, 0.0122]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.13662798702716827\n",
            "--------\n",
            "9\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0130, 0.0183, 0.0298, 0.0148, 0.0162, 0.0093, 0.0085],\n",
            "        [0.0078, 0.0168, 0.0173, 0.0121, 0.0197, 0.0155, 0.0101],\n",
            "        [0.0171, 0.0133, 0.0165, 0.0072, 0.0127, 0.0098, 0.0122],\n",
            "        [0.0255, 0.0126, 0.0183, 0.0195, 0.0123, 0.0192, 0.0150],\n",
            "        [0.0258, 0.0121, 0.0179, 0.0093, 0.0113, 0.0102, 0.0143],\n",
            "        [0.0312, 0.0078, 0.0105, 0.0133, 0.0074, 0.0112, 0.0092],\n",
            "        [0.0195, 0.0105, 0.0083, 0.0135, 0.0216, 0.0150, 0.0109],\n",
            "        [0.0150, 0.0083, 0.0200, 0.0190, 0.0115, 0.0126, 0.0103],\n",
            "        [0.0279, 0.0084, 0.0083, 0.0193, 0.0064, 0.0092, 0.0066],\n",
            "        [0.0397, 0.0110, 0.0094, 0.0160, 0.0089, 0.0088, 0.0121]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.13601157069206238\n",
            "--------\n",
            "10\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0123, 0.0180, 0.0332, 0.0146, 0.0158, 0.0087, 0.0079],\n",
            "        [0.0073, 0.0181, 0.0168, 0.0116, 0.0194, 0.0154, 0.0097],\n",
            "        [0.0184, 0.0128, 0.0159, 0.0067, 0.0125, 0.0095, 0.0114],\n",
            "        [0.0284, 0.0117, 0.0182, 0.0190, 0.0121, 0.0187, 0.0142],\n",
            "        [0.0277, 0.0117, 0.0175, 0.0089, 0.0109, 0.0095, 0.0139],\n",
            "        [0.0344, 0.0073, 0.0102, 0.0130, 0.0070, 0.0107, 0.0088],\n",
            "        [0.0213, 0.0102, 0.0079, 0.0127, 0.0218, 0.0147, 0.0103],\n",
            "        [0.0162, 0.0080, 0.0200, 0.0190, 0.0110, 0.0123, 0.0098],\n",
            "        [0.0309, 0.0080, 0.0078, 0.0195, 0.0060, 0.0088, 0.0061],\n",
            "        [0.0443, 0.0105, 0.0090, 0.0156, 0.0083, 0.0084, 0.0117]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.13531650602817535\n",
            "--------\n",
            "11\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0115, 0.0175, 0.0372, 0.0143, 0.0153, 0.0082, 0.0074],\n",
            "        [0.0068, 0.0194, 0.0162, 0.0110, 0.0189, 0.0151, 0.0093],\n",
            "        [0.0199, 0.0124, 0.0151, 0.0062, 0.0122, 0.0091, 0.0108],\n",
            "        [0.0316, 0.0109, 0.0180, 0.0184, 0.0117, 0.0180, 0.0133],\n",
            "        [0.0298, 0.0112, 0.0170, 0.0085, 0.0104, 0.0087, 0.0135],\n",
            "        [0.0381, 0.0068, 0.0099, 0.0127, 0.0066, 0.0100, 0.0085],\n",
            "        [0.0233, 0.0098, 0.0075, 0.0120, 0.0218, 0.0142, 0.0096],\n",
            "        [0.0176, 0.0077, 0.0199, 0.0188, 0.0105, 0.0119, 0.0094],\n",
            "        [0.0342, 0.0076, 0.0074, 0.0195, 0.0056, 0.0084, 0.0055],\n",
            "        [0.0497, 0.0099, 0.0086, 0.0153, 0.0077, 0.0079, 0.0113]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.13453824818134308\n",
            "--------\n",
            "12\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0106, 0.0169, 0.0419, 0.0139, 0.0147, 0.0077, 0.0067],\n",
            "        [0.0064, 0.0208, 0.0154, 0.0104, 0.0183, 0.0148, 0.0088],\n",
            "        [0.0214, 0.0118, 0.0143, 0.0057, 0.0118, 0.0087, 0.0101],\n",
            "        [0.0351, 0.0101, 0.0176, 0.0176, 0.0113, 0.0172, 0.0124],\n",
            "        [0.0320, 0.0107, 0.0164, 0.0081, 0.0099, 0.0080, 0.0131],\n",
            "        [0.0422, 0.0062, 0.0096, 0.0124, 0.0061, 0.0094, 0.0081],\n",
            "        [0.0255, 0.0093, 0.0070, 0.0112, 0.0215, 0.0137, 0.0089],\n",
            "        [0.0193, 0.0074, 0.0194, 0.0185, 0.0100, 0.0114, 0.0090],\n",
            "        [0.0378, 0.0070, 0.0069, 0.0194, 0.0052, 0.0080, 0.0050],\n",
            "        [0.0562, 0.0093, 0.0082, 0.0149, 0.0071, 0.0074, 0.0107]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.13366647064685822\n",
            "--------\n",
            "13\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0098, 0.0161, 0.0473, 0.0134, 0.0140, 0.0071, 0.0061],\n",
            "        [0.0059, 0.0224, 0.0145, 0.0098, 0.0176, 0.0143, 0.0083],\n",
            "        [0.0231, 0.0112, 0.0134, 0.0052, 0.0112, 0.0082, 0.0095],\n",
            "        [0.0390, 0.0093, 0.0170, 0.0167, 0.0108, 0.0163, 0.0114],\n",
            "        [0.0344, 0.0102, 0.0158, 0.0077, 0.0093, 0.0073, 0.0126],\n",
            "        [0.0469, 0.0057, 0.0092, 0.0119, 0.0057, 0.0086, 0.0077],\n",
            "        [0.0278, 0.0088, 0.0065, 0.0105, 0.0211, 0.0130, 0.0082],\n",
            "        [0.0211, 0.0070, 0.0188, 0.0180, 0.0094, 0.0109, 0.0085],\n",
            "        [0.0417, 0.0065, 0.0064, 0.0191, 0.0048, 0.0075, 0.0046],\n",
            "        [0.0636, 0.0087, 0.0077, 0.0144, 0.0065, 0.0069, 0.0101]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.13269071280956268\n",
            "--------\n",
            "14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0088, 0.0153, 0.0534, 0.0128, 0.0132, 0.0065, 0.0055],\n",
            "        [0.0054, 0.0242, 0.0134, 0.0091, 0.0167, 0.0137, 0.0077],\n",
            "        [0.0249, 0.0105, 0.0125, 0.0047, 0.0106, 0.0077, 0.0088],\n",
            "        [0.0435, 0.0085, 0.0163, 0.0157, 0.0103, 0.0153, 0.0104],\n",
            "        [0.0370, 0.0096, 0.0150, 0.0072, 0.0086, 0.0066, 0.0119],\n",
            "        [0.0521, 0.0051, 0.0086, 0.0114, 0.0052, 0.0079, 0.0073],\n",
            "        [0.0304, 0.0083, 0.0060, 0.0097, 0.0203, 0.0122, 0.0075],\n",
            "        [0.0230, 0.0066, 0.0180, 0.0173, 0.0087, 0.0103, 0.0080],\n",
            "        [0.0460, 0.0059, 0.0059, 0.0185, 0.0044, 0.0070, 0.0041],\n",
            "        [0.0720, 0.0079, 0.0072, 0.0139, 0.0060, 0.0064, 0.0094]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.1316051483154297\n",
            "--------\n",
            "15\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0079, 0.0142, 0.0603, 0.0121, 0.0123, 0.0059, 0.0049],\n",
            "        [0.0049, 0.0261, 0.0123, 0.0083, 0.0157, 0.0130, 0.0071],\n",
            "        [0.0269, 0.0096, 0.0115, 0.0042, 0.0099, 0.0072, 0.0080],\n",
            "        [0.0485, 0.0076, 0.0154, 0.0146, 0.0096, 0.0142, 0.0093],\n",
            "        [0.0400, 0.0089, 0.0141, 0.0067, 0.0079, 0.0059, 0.0111],\n",
            "        [0.0580, 0.0046, 0.0081, 0.0107, 0.0047, 0.0071, 0.0068],\n",
            "        [0.0331, 0.0076, 0.0055, 0.0089, 0.0194, 0.0114, 0.0067],\n",
            "        [0.0251, 0.0062, 0.0170, 0.0165, 0.0080, 0.0096, 0.0074],\n",
            "        [0.0507, 0.0053, 0.0054, 0.0178, 0.0040, 0.0064, 0.0036],\n",
            "        [0.0814, 0.0072, 0.0067, 0.0131, 0.0054, 0.0058, 0.0087]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.1304149329662323\n",
            "--------\n",
            "16\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0070, 0.0131, 0.0678, 0.0112, 0.0113, 0.0053, 0.0043],\n",
            "        [0.0044, 0.0282, 0.0112, 0.0074, 0.0146, 0.0121, 0.0065],\n",
            "        [0.0289, 0.0088, 0.0104, 0.0037, 0.0092, 0.0065, 0.0072],\n",
            "        [0.0540, 0.0068, 0.0143, 0.0134, 0.0088, 0.0130, 0.0083],\n",
            "        [0.0430, 0.0081, 0.0131, 0.0061, 0.0071, 0.0052, 0.0103],\n",
            "        [0.0643, 0.0040, 0.0074, 0.0100, 0.0041, 0.0063, 0.0062],\n",
            "        [0.0360, 0.0070, 0.0049, 0.0080, 0.0182, 0.0105, 0.0060],\n",
            "        [0.0273, 0.0056, 0.0159, 0.0155, 0.0073, 0.0088, 0.0068],\n",
            "        [0.0558, 0.0047, 0.0048, 0.0168, 0.0035, 0.0059, 0.0032],\n",
            "        [0.0917, 0.0065, 0.0061, 0.0123, 0.0048, 0.0052, 0.0079]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.1291383057832718\n",
            "--------\n",
            "17\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0062, 0.0119, 0.0758, 0.0103, 0.0102, 0.0046, 0.0037],\n",
            "        [0.0038, 0.0303, 0.0100, 0.0066, 0.0133, 0.0112, 0.0058],\n",
            "        [0.0309, 0.0079, 0.0093, 0.0032, 0.0084, 0.0059, 0.0064],\n",
            "        [0.0598, 0.0060, 0.0132, 0.0121, 0.0080, 0.0118, 0.0073],\n",
            "        [0.0462, 0.0073, 0.0119, 0.0055, 0.0063, 0.0045, 0.0093],\n",
            "        [0.0710, 0.0035, 0.0067, 0.0091, 0.0036, 0.0056, 0.0056],\n",
            "        [0.0390, 0.0062, 0.0043, 0.0071, 0.0169, 0.0094, 0.0052],\n",
            "        [0.0296, 0.0051, 0.0146, 0.0144, 0.0065, 0.0080, 0.0061],\n",
            "        [0.0612, 0.0041, 0.0043, 0.0157, 0.0031, 0.0053, 0.0028],\n",
            "        [0.1028, 0.0057, 0.0055, 0.0113, 0.0042, 0.0047, 0.0071]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.12780536711215973\n",
            "--------\n",
            "18\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0053, 0.0106, 0.0840, 0.0093, 0.0091, 0.0040, 0.0031],\n",
            "        [0.0033, 0.0323, 0.0089, 0.0058, 0.0119, 0.0101, 0.0051],\n",
            "        [0.0328, 0.0070, 0.0082, 0.0027, 0.0075, 0.0052, 0.0056],\n",
            "        [0.0657, 0.0051, 0.0120, 0.0107, 0.0072, 0.0105, 0.0063],\n",
            "        [0.0492, 0.0064, 0.0107, 0.0049, 0.0056, 0.0039, 0.0083],\n",
            "        [0.0779, 0.0030, 0.0060, 0.0082, 0.0032, 0.0048, 0.0050],\n",
            "        [0.0420, 0.0055, 0.0038, 0.0063, 0.0154, 0.0084, 0.0045],\n",
            "        [0.0318, 0.0045, 0.0132, 0.0131, 0.0057, 0.0071, 0.0054],\n",
            "        [0.0667, 0.0036, 0.0038, 0.0144, 0.0027, 0.0047, 0.0024],\n",
            "        [0.1145, 0.0050, 0.0049, 0.0102, 0.0036, 0.0041, 0.0063]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.126453697681427\n",
            "--------\n",
            "19\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0046, 0.0093, 0.0922, 0.0083, 0.0080, 0.0035, 0.0026],\n",
            "        [0.0029, 0.0342, 0.0077, 0.0050, 0.0106, 0.0090, 0.0045],\n",
            "        [0.0346, 0.0061, 0.0071, 0.0023, 0.0066, 0.0046, 0.0048],\n",
            "        [0.0714, 0.0044, 0.0107, 0.0094, 0.0063, 0.0092, 0.0054],\n",
            "        [0.0521, 0.0056, 0.0095, 0.0043, 0.0048, 0.0033, 0.0073],\n",
            "        [0.0848, 0.0025, 0.0053, 0.0073, 0.0027, 0.0041, 0.0043],\n",
            "        [0.0449, 0.0048, 0.0032, 0.0054, 0.0138, 0.0074, 0.0038],\n",
            "        [0.0339, 0.0039, 0.0118, 0.0117, 0.0049, 0.0063, 0.0047],\n",
            "        [0.0723, 0.0031, 0.0033, 0.0129, 0.0023, 0.0041, 0.0020],\n",
            "        [0.1266, 0.0043, 0.0043, 0.0091, 0.0031, 0.0035, 0.0055]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.12512575089931488\n",
            "--------\n",
            "20\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0039, 0.0080, 0.1001, 0.0073, 0.0070, 0.0029, 0.0022],\n",
            "        [0.0024, 0.0359, 0.0066, 0.0042, 0.0092, 0.0079, 0.0038],\n",
            "        [0.0361, 0.0053, 0.0061, 0.0019, 0.0057, 0.0039, 0.0041],\n",
            "        [0.0769, 0.0037, 0.0095, 0.0081, 0.0055, 0.0080, 0.0046],\n",
            "        [0.0545, 0.0048, 0.0083, 0.0037, 0.0041, 0.0028, 0.0064],\n",
            "        [0.0915, 0.0021, 0.0046, 0.0064, 0.0023, 0.0035, 0.0037],\n",
            "        [0.0476, 0.0041, 0.0027, 0.0046, 0.0122, 0.0063, 0.0032],\n",
            "        [0.0359, 0.0034, 0.0103, 0.0102, 0.0042, 0.0055, 0.0040],\n",
            "        [0.0777, 0.0026, 0.0028, 0.0115, 0.0019, 0.0035, 0.0016],\n",
            "        [0.1388, 0.0036, 0.0037, 0.0080, 0.0026, 0.0030, 0.0047]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.12386783957481384\n",
            "--------\n",
            "21\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0033, 0.0068, 0.1074, 0.0063, 0.0060, 0.0025, 0.0018],\n",
            "        [0.0020, 0.0372, 0.0057, 0.0036, 0.0079, 0.0068, 0.0032],\n",
            "        [0.0374, 0.0045, 0.0052, 0.0016, 0.0049, 0.0034, 0.0035],\n",
            "        [0.0816, 0.0031, 0.0083, 0.0068, 0.0047, 0.0069, 0.0038],\n",
            "        [0.0565, 0.0041, 0.0072, 0.0032, 0.0035, 0.0023, 0.0055],\n",
            "        [0.0980, 0.0018, 0.0039, 0.0055, 0.0019, 0.0029, 0.0032],\n",
            "        [0.0499, 0.0035, 0.0023, 0.0039, 0.0107, 0.0054, 0.0027],\n",
            "        [0.0376, 0.0029, 0.0089, 0.0089, 0.0035, 0.0047, 0.0034],\n",
            "        [0.0829, 0.0022, 0.0024, 0.0100, 0.0016, 0.0030, 0.0013],\n",
            "        [0.1508, 0.0031, 0.0032, 0.0070, 0.0021, 0.0025, 0.0040]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.12271695584058762\n",
            "--------\n",
            "22\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0028, 0.0057, 0.1138, 0.0055, 0.0051, 0.0020, 0.0015],\n",
            "        [0.0017, 0.0384, 0.0048, 0.0030, 0.0068, 0.0057, 0.0027],\n",
            "        [0.0383, 0.0039, 0.0043, 0.0013, 0.0041, 0.0028, 0.0030],\n",
            "        [0.0856, 0.0026, 0.0071, 0.0057, 0.0041, 0.0058, 0.0032],\n",
            "        [0.0579, 0.0035, 0.0062, 0.0027, 0.0029, 0.0019, 0.0047],\n",
            "        [0.1040, 0.0014, 0.0034, 0.0048, 0.0016, 0.0024, 0.0027],\n",
            "        [0.0518, 0.0029, 0.0019, 0.0033, 0.0092, 0.0045, 0.0022],\n",
            "        [0.0392, 0.0025, 0.0076, 0.0076, 0.0029, 0.0041, 0.0028],\n",
            "        [0.0876, 0.0018, 0.0020, 0.0086, 0.0014, 0.0026, 0.0011],\n",
            "        [0.1624, 0.0026, 0.0027, 0.0060, 0.0018, 0.0021, 0.0034]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.12169492244720459\n",
            "--------\n",
            "23\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0023, 0.0048, 0.1193, 0.0047, 0.0043, 0.0017, 0.0012],\n",
            "        [0.0014, 0.0392, 0.0041, 0.0025, 0.0058, 0.0048, 0.0023],\n",
            "        [0.0389, 0.0033, 0.0036, 0.0011, 0.0035, 0.0024, 0.0025],\n",
            "        [0.0888, 0.0022, 0.0061, 0.0048, 0.0034, 0.0049, 0.0026],\n",
            "        [0.0588, 0.0029, 0.0053, 0.0022, 0.0024, 0.0016, 0.0039],\n",
            "        [0.1097, 0.0012, 0.0029, 0.0040, 0.0014, 0.0019, 0.0022],\n",
            "        [0.0534, 0.0024, 0.0016, 0.0028, 0.0078, 0.0037, 0.0018],\n",
            "        [0.0404, 0.0021, 0.0064, 0.0064, 0.0024, 0.0035, 0.0023],\n",
            "        [0.0919, 0.0015, 0.0017, 0.0073, 0.0011, 0.0022, 0.0009],\n",
            "        [0.1735, 0.0021, 0.0023, 0.0052, 0.0015, 0.0018, 0.0028]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.12080792337656021\n",
            "--------\n",
            "24\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0020, 0.0039, 0.1240, 0.0040, 0.0036, 0.0014, 0.0010],\n",
            "        [0.0012, 0.0399, 0.0034, 0.0020, 0.0048, 0.0040, 0.0019],\n",
            "        [0.0392, 0.0028, 0.0030, 0.0009, 0.0029, 0.0020, 0.0021],\n",
            "        [0.0912, 0.0018, 0.0052, 0.0040, 0.0029, 0.0041, 0.0022],\n",
            "        [0.0592, 0.0025, 0.0045, 0.0019, 0.0020, 0.0013, 0.0033],\n",
            "        [0.1151, 0.0010, 0.0024, 0.0034, 0.0012, 0.0016, 0.0019],\n",
            "        [0.0546, 0.0020, 0.0013, 0.0023, 0.0066, 0.0031, 0.0015],\n",
            "        [0.0414, 0.0017, 0.0054, 0.0053, 0.0020, 0.0030, 0.0019],\n",
            "        [0.0957, 0.0013, 0.0014, 0.0062, 0.0009, 0.0019, 0.0007],\n",
            "        [0.1838, 0.0018, 0.0020, 0.0044, 0.0012, 0.0015, 0.0023]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.12005113810300827\n",
            "--------\n",
            "25\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0017, 0.0032, 0.1278, 0.0034, 0.0030, 0.0012, 0.0008],\n",
            "        [0.0010, 0.0404, 0.0029, 0.0016, 0.0041, 0.0033, 0.0015],\n",
            "        [0.0392, 0.0023, 0.0025, 0.0007, 0.0024, 0.0017, 0.0018],\n",
            "        [0.0930, 0.0015, 0.0045, 0.0033, 0.0024, 0.0034, 0.0018],\n",
            "        [0.0592, 0.0021, 0.0038, 0.0016, 0.0017, 0.0011, 0.0028],\n",
            "        [0.1202, 0.0008, 0.0021, 0.0029, 0.0010, 0.0013, 0.0016],\n",
            "        [0.0554, 0.0017, 0.0011, 0.0019, 0.0056, 0.0025, 0.0012],\n",
            "        [0.0422, 0.0014, 0.0045, 0.0044, 0.0016, 0.0025, 0.0016],\n",
            "        [0.0991, 0.0011, 0.0012, 0.0051, 0.0008, 0.0016, 0.0006],\n",
            "        [0.1932, 0.0015, 0.0017, 0.0038, 0.0010, 0.0012, 0.0019]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.11941416561603546\n",
            "--------\n",
            "26\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0014, 0.0026, 0.1311, 0.0029, 0.0025, 0.0010, 0.0006],\n",
            "        [0.0008, 0.0408, 0.0024, 0.0013, 0.0034, 0.0027, 0.0013],\n",
            "        [0.0391, 0.0020, 0.0021, 0.0006, 0.0020, 0.0014, 0.0015],\n",
            "        [0.0942, 0.0012, 0.0038, 0.0027, 0.0021, 0.0029, 0.0015],\n",
            "        [0.0591, 0.0017, 0.0032, 0.0013, 0.0014, 0.0009, 0.0023],\n",
            "        [0.1248, 0.0006, 0.0017, 0.0024, 0.0008, 0.0010, 0.0013],\n",
            "        [0.0560, 0.0014, 0.0009, 0.0016, 0.0047, 0.0021, 0.0010],\n",
            "        [0.0429, 0.0012, 0.0038, 0.0037, 0.0013, 0.0022, 0.0013],\n",
            "        [0.1021, 0.0009, 0.0010, 0.0043, 0.0007, 0.0014, 0.0005],\n",
            "        [0.2013, 0.0012, 0.0014, 0.0032, 0.0008, 0.0010, 0.0016]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.11888390779495239\n",
            "--------\n",
            "27\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0012, 0.0021, 0.1339, 0.0025, 0.0021, 0.0008, 0.0005],\n",
            "        [0.0007, 0.0412, 0.0020, 0.0011, 0.0028, 0.0022, 0.0010],\n",
            "        [0.0389, 0.0017, 0.0018, 0.0005, 0.0017, 0.0012, 0.0013],\n",
            "        [0.0950, 0.0010, 0.0032, 0.0022, 0.0017, 0.0024, 0.0012],\n",
            "        [0.0588, 0.0015, 0.0027, 0.0011, 0.0011, 0.0008, 0.0019],\n",
            "        [0.1289, 0.0005, 0.0015, 0.0021, 0.0007, 0.0008, 0.0011],\n",
            "        [0.0565, 0.0011, 0.0007, 0.0014, 0.0039, 0.0017, 0.0008],\n",
            "        [0.0435, 0.0010, 0.0031, 0.0030, 0.0011, 0.0018, 0.0011],\n",
            "        [0.1046, 0.0008, 0.0009, 0.0036, 0.0005, 0.0012, 0.0004],\n",
            "        [0.2079, 0.0010, 0.0012, 0.0028, 0.0007, 0.0009, 0.0013]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.11844610422849655\n",
            "--------\n",
            "28\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0010, 0.0018, 0.1365, 0.0021, 0.0018, 0.0007, 0.0004],\n",
            "        [0.0006, 0.0416, 0.0017, 0.0009, 0.0024, 0.0019, 0.0009],\n",
            "        [0.0387, 0.0014, 0.0015, 0.0004, 0.0014, 0.0010, 0.0011],\n",
            "        [0.0957, 0.0009, 0.0027, 0.0018, 0.0015, 0.0020, 0.0010],\n",
            "        [0.0587, 0.0012, 0.0023, 0.0009, 0.0009, 0.0006, 0.0016],\n",
            "        [0.1323, 0.0004, 0.0012, 0.0017, 0.0006, 0.0007, 0.0009],\n",
            "        [0.0570, 0.0009, 0.0006, 0.0012, 0.0033, 0.0014, 0.0007],\n",
            "        [0.0442, 0.0008, 0.0026, 0.0025, 0.0009, 0.0016, 0.0009],\n",
            "        [0.1067, 0.0006, 0.0008, 0.0030, 0.0005, 0.0010, 0.0003],\n",
            "        [0.2125, 0.0008, 0.0010, 0.0024, 0.0006, 0.0007, 0.0011]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.11808541417121887\n",
            "--------\n",
            "29\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0009, 0.0015, 0.1392, 0.0018, 0.0015, 0.0006, 0.0003],\n",
            "        [0.0005, 0.0423, 0.0014, 0.0007, 0.0020, 0.0015, 0.0007],\n",
            "        [0.0386, 0.0012, 0.0013, 0.0003, 0.0012, 0.0008, 0.0009],\n",
            "        [0.0962, 0.0007, 0.0023, 0.0015, 0.0012, 0.0017, 0.0008],\n",
            "        [0.0587, 0.0010, 0.0020, 0.0008, 0.0008, 0.0005, 0.0014],\n",
            "        [0.1352, 0.0004, 0.0010, 0.0015, 0.0005, 0.0006, 0.0008],\n",
            "        [0.0575, 0.0008, 0.0005, 0.0010, 0.0028, 0.0011, 0.0006],\n",
            "        [0.0450, 0.0007, 0.0022, 0.0021, 0.0007, 0.0013, 0.0007],\n",
            "        [0.1084, 0.0005, 0.0006, 0.0025, 0.0004, 0.0009, 0.0003],\n",
            "        [0.2150, 0.0007, 0.0009, 0.0020, 0.0005, 0.0006, 0.0009]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.11778635531663895\n",
            "--------\n",
            "30\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[0.0008, 0.0012, 0.1420, 0.0015, 0.0013, 0.0005, 0.0003],\n",
            "        [0.0004, 0.0431, 0.0012, 0.0006, 0.0017, 0.0013, 0.0006],\n",
            "        [0.0386, 0.0010, 0.0011, 0.0003, 0.0010, 0.0007, 0.0008],\n",
            "        [0.0968, 0.0006, 0.0020, 0.0013, 0.0011, 0.0014, 0.0007],\n",
            "        [0.0589, 0.0009, 0.0017, 0.0007, 0.0007, 0.0005, 0.0012],\n",
            "        [0.1375, 0.0003, 0.0009, 0.0013, 0.0005, 0.0005, 0.0006],\n",
            "        [0.0581, 0.0007, 0.0004, 0.0008, 0.0023, 0.0009, 0.0005],\n",
            "        [0.0459, 0.0006, 0.0018, 0.0018, 0.0006, 0.0012, 0.0006],\n",
            "        [0.1098, 0.0005, 0.0005, 0.0021, 0.0003, 0.0008, 0.0002],\n",
            "        [0.2153, 0.0006, 0.0008, 0.0017, 0.0004, 0.0005, 0.0008]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "loss 0.11753518134355545\n",
            "--------\n",
            "31\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[6.5182e-04, 1.0010e-03, 1.4508e-01, 1.3243e-03, 1.0680e-03, 4.0448e-04,\n",
            "         2.3716e-04],\n",
            "        [3.5037e-04, 4.4086e-02, 1.0265e-03, 5.0863e-04, 1.4037e-03, 1.0777e-03,\n",
            "         4.9688e-04],\n",
            "        [3.8614e-02, 8.7005e-04, 9.1487e-04, 2.3759e-04, 8.3691e-04, 6.1307e-04,\n",
            "         6.6872e-04],\n",
            "        [9.7291e-02, 5.3459e-04, 1.6937e-03, 1.1188e-03, 9.0103e-04, 1.1984e-03,\n",
            "         5.8992e-04],\n",
            "        [5.9410e-02, 7.4961e-04, 1.4698e-03, 5.6914e-04, 5.4480e-04, 4.0419e-04,\n",
            "         1.0135e-03],\n",
            "        [1.3930e-01, 2.5030e-04, 7.3819e-04, 1.0832e-03, 3.8788e-04, 3.9037e-04,\n",
            "         5.4688e-04],\n",
            "        [5.8836e-02, 5.5066e-04, 3.5241e-04, 7.1443e-04, 1.9459e-03, 7.8636e-04,\n",
            "         3.9840e-04],\n",
            "        [4.7006e-02, 5.1464e-04, 1.5414e-03, 1.4985e-03, 5.1587e-04, 9.9086e-04,\n",
            "         5.0796e-04],\n",
            "        [1.1087e-01, 3.8645e-04, 4.7136e-04, 1.7222e-03, 2.7261e-04, 6.5651e-04,\n",
            "         1.8556e-04],\n",
            "        [2.1351e-01, 4.8496e-04, 6.6809e-04, 1.5033e-03, 3.5954e-04, 4.4883e-04,\n",
            "         6.4453e-04]], grad_fn=<ViewBackward0>)\n",
            "loss 0.11732104420661926\n",
            "--------\n",
            "32\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[5.6561e-04, 8.3447e-04, 1.4844e-01, 1.1390e-03, 9.0202e-04, 3.4632e-04,\n",
            "         1.9744e-04],\n",
            "        [3.0441e-04, 4.5377e-02, 8.7718e-04, 4.2406e-04, 1.1800e-03, 9.0728e-04,\n",
            "         4.1556e-04],\n",
            "        [3.8744e-02, 7.4642e-04, 7.8910e-04, 2.0154e-04, 7.1817e-04, 5.3138e-04,\n",
            "         5.7852e-04],\n",
            "        [9.7858e-02, 4.5905e-04, 1.4548e-03, 9.6406e-04, 7.7569e-04, 1.0141e-03,\n",
            "         4.9644e-04],\n",
            "        [6.0136e-02, 6.4455e-04, 1.2745e-03, 4.8642e-04, 4.5473e-04, 3.5219e-04,\n",
            "         8.7803e-04],\n",
            "        [1.4058e-01, 2.1340e-04, 6.2421e-04, 9.3374e-04, 3.3566e-04, 3.2456e-04,\n",
            "         4.6831e-04],\n",
            "        [5.9707e-02, 4.6879e-04, 2.9794e-04, 6.1612e-04, 1.6409e-03, 6.5858e-04,\n",
            "         3.4081e-04],\n",
            "        [4.8358e-02, 4.4219e-04, 1.2998e-03, 1.2748e-03, 4.3494e-04, 8.5606e-04,\n",
            "         4.3108e-04],\n",
            "        [1.1171e-01, 3.2788e-04, 4.0638e-04, 1.4465e-03, 2.3218e-04, 5.7344e-04,\n",
            "         1.5861e-04],\n",
            "        [2.0983e-01, 4.0774e-04, 5.8520e-04, 1.3012e-03, 3.1109e-04, 3.8870e-04,\n",
            "         5.4448e-04]], grad_fn=<ViewBackward0>)\n",
            "loss 0.11713588237762451\n",
            "--------\n",
            "33\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[4.9286e-04, 6.9772e-04, 1.5203e-01, 9.8236e-04, 7.6301e-04, 2.9823e-04,\n",
            "         1.6498e-04],\n",
            "        [2.6662e-04, 4.6961e-02, 7.5251e-04, 3.5474e-04, 9.9292e-04, 7.6720e-04,\n",
            "         3.4848e-04],\n",
            "        [3.8975e-02, 6.4273e-04, 6.8503e-04, 1.7194e-04, 6.2050e-04, 4.6395e-04,\n",
            "         5.0300e-04],\n",
            "        [9.8479e-02, 3.9631e-04, 1.2538e-03, 8.3793e-04, 6.7119e-04, 8.6031e-04,\n",
            "         4.1902e-04],\n",
            "        [6.1135e-02, 5.5726e-04, 1.1107e-03, 4.1734e-04, 3.8009e-04, 3.0941e-04,\n",
            "         7.6637e-04],\n",
            "        [1.4131e-01, 1.8331e-04, 5.2827e-04, 8.0892e-04, 2.9158e-04, 2.7068e-04,\n",
            "         4.0334e-04],\n",
            "        [6.0746e-02, 4.0160e-04, 2.5312e-04, 5.3405e-04, 1.3860e-03, 5.5401e-04,\n",
            "         2.9388e-04],\n",
            "        [4.9976e-02, 3.8226e-04, 1.0990e-03, 1.0906e-03, 3.6877e-04, 7.4231e-04,\n",
            "         3.6824e-04],\n",
            "        [1.1230e-01, 2.7870e-04, 3.5150e-04, 1.2180e-03, 1.9859e-04, 5.0352e-04,\n",
            "         1.3674e-04],\n",
            "        [2.0444e-01, 3.4365e-04, 5.1577e-04, 1.1305e-03, 2.7124e-04, 3.3907e-04,\n",
            "         4.6181e-04]], grad_fn=<ViewBackward0>)\n",
            "loss 0.11697390675544739\n",
            "--------\n",
            "34\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[4.3119e-04, 5.8540e-04, 1.5569e-01, 8.4962e-04, 6.4664e-04, 2.5826e-04,\n",
            "         1.3843e-04],\n",
            "        [2.3528e-04, 4.8854e-02, 6.4810e-04, 2.9788e-04, 8.3676e-04, 6.5173e-04,\n",
            "         2.9313e-04],\n",
            "        [3.9320e-02, 5.5552e-04, 5.9836e-04, 1.4754e-04, 5.3963e-04, 4.0785e-04,\n",
            "         4.3946e-04],\n",
            "        [9.9180e-02, 3.4398e-04, 1.0841e-03, 7.3424e-04, 5.8361e-04, 7.3180e-04,\n",
            "         3.5486e-04],\n",
            "        [6.2416e-02, 4.8436e-04, 9.7264e-04, 3.5948e-04, 3.1835e-04, 2.7394e-04,\n",
            "         6.7360e-04],\n",
            "        [1.4146e-01, 1.5862e-04, 4.4766e-04, 7.0412e-04, 2.5425e-04, 2.2656e-04,\n",
            "         3.4935e-04],\n",
            "        [6.1974e-02, 3.4618e-04, 2.1614e-04, 4.6520e-04, 1.1731e-03, 4.6825e-04,\n",
            "         2.5539e-04],\n",
            "        [5.1879e-02, 3.3240e-04, 9.3197e-04, 9.3799e-04, 3.1446e-04, 6.4597e-04,\n",
            "         3.1658e-04],\n",
            "        [1.1266e-01, 2.3741e-04, 3.0503e-04, 1.0283e-03, 1.7060e-04, 4.4429e-04,\n",
            "         1.1886e-04],\n",
            "        [1.9758e-01, 2.9047e-04, 4.5716e-04, 9.8567e-04, 2.3823e-04, 2.9781e-04,\n",
            "         3.9333e-04]], grad_fn=<ViewBackward0>)\n",
            "loss 0.1168309897184372\n",
            "--------\n",
            "35\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[3.7877e-04, 4.9343e-04, 1.5910e-01, 7.3711e-04, 5.4970e-04, 2.2493e-04,\n",
            "         1.1679e-04],\n",
            "        [2.0904e-04, 5.1054e-02, 5.6059e-04, 2.5140e-04, 7.0716e-04, 5.5649e-04,\n",
            "         2.4764e-04],\n",
            "        [3.9794e-02, 4.8212e-04, 5.2571e-04, 1.2737e-04, 4.7219e-04, 3.6073e-04,\n",
            "         3.8581e-04],\n",
            "        [1.0001e-01, 3.0018e-04, 9.4058e-04, 6.4811e-04, 5.0989e-04, 6.2474e-04,\n",
            "         3.0185e-04],\n",
            "        [6.3973e-02, 4.2320e-04, 8.5550e-04, 3.1099e-04, 2.6759e-04, 2.4420e-04,\n",
            "         5.9577e-04],\n",
            "        [1.4108e-01, 1.3825e-04, 3.8031e-04, 6.1573e-04, 2.2259e-04, 1.9058e-04,\n",
            "         3.0427e-04],\n",
            "        [6.3410e-02, 3.0027e-04, 1.8560e-04, 4.0722e-04, 9.9585e-04, 3.9795e-04,\n",
            "         2.2358e-04],\n",
            "        [5.4073e-02, 2.9069e-04, 7.9328e-04, 8.1118e-04, 2.6982e-04, 5.6418e-04,\n",
            "         2.7395e-04],\n",
            "        [1.1290e-01, 2.0289e-04, 2.6566e-04, 8.7147e-04, 1.4728e-04, 3.9378e-04,\n",
            "         1.0413e-04],\n",
            "        [1.8952e-01, 2.4652e-04, 4.0719e-04, 8.6241e-04, 2.1066e-04, 2.6321e-04,\n",
            "         3.3661e-04]], grad_fn=<ViewBackward0>)\n",
            "loss 0.11670424789190292\n",
            "--------\n",
            "36\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[3.3420e-04, 4.1869e-04, 1.6182e-01, 6.4200e-04, 4.6966e-04, 1.9711e-04,\n",
            "         9.9288e-05],\n",
            "        [1.8681e-04, 5.3532e-02, 4.8743e-04, 2.1369e-04, 6.0073e-04, 4.7815e-04,\n",
            "         2.1057e-04],\n",
            "        [4.0420e-02, 4.2047e-04, 4.6448e-04, 1.1074e-04, 4.1559e-04, 3.2078e-04,\n",
            "         3.4042e-04],\n",
            "        [1.0101e-01, 2.6352e-04, 8.1943e-04, 5.7575e-04, 4.4767e-04, 5.3617e-04,\n",
            "         2.5840e-04],\n",
            "        [6.5780e-02, 3.7175e-04, 7.5570e-04, 2.7043e-04, 2.2633e-04, 2.1899e-04,\n",
            "         5.2980e-04],\n",
            "        [1.4027e-01, 1.2137e-04, 3.2462e-04, 5.4096e-04, 1.9576e-04, 1.6148e-04,\n",
            "         2.6656e-04],\n",
            "        [6.5071e-02, 2.6216e-04, 1.6044e-04, 3.5833e-04, 8.4955e-04, 3.4055e-04,\n",
            "         1.9715e-04],\n",
            "        [5.6542e-02, 2.5566e-04, 6.7885e-04, 7.0558e-04, 2.3315e-04, 4.9476e-04,\n",
            "         2.3870e-04],\n",
            "        [1.1313e-01, 1.7431e-04, 2.3240e-04, 7.4259e-04, 1.2791e-04, 3.5041e-04,\n",
            "         9.1933e-05],\n",
            "        [1.8058e-01, 2.1050e-04, 3.6415e-04, 7.5744e-04, 1.8745e-04, 2.3394e-04,\n",
            "         2.8984e-04]], grad_fn=<ViewBackward0>)\n",
            "loss 0.11659156531095505\n",
            "--------\n",
            "37\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[2.9640e-04, 3.5864e-04, 1.6334e-01, 5.6209e-04, 4.0442e-04, 1.7393e-04,\n",
            "         8.5297e-05],\n",
            "        [1.6781e-04, 5.6232e-02, 4.2660e-04, 1.8344e-04, 5.1455e-04, 4.1411e-04,\n",
            "         1.8071e-04],\n",
            "        [4.1219e-02, 3.6895e-04, 4.1269e-04, 9.7073e-05, 3.6787e-04, 2.8660e-04,\n",
            "         3.0205e-04],\n",
            "        [1.0225e-01, 2.3288e-04, 7.1760e-04, 5.1432e-04, 3.9514e-04, 4.6368e-04,\n",
            "         2.2319e-04],\n",
            "        [6.7796e-02, 3.2847e-04, 6.7050e-04, 2.3670e-04, 1.9328e-04, 1.9738e-04,\n",
            "         4.7335e-04],\n",
            "        [1.3918e-01, 1.0737e-04, 2.7920e-04, 4.7769e-04, 1.7313e-04, 1.3824e-04,\n",
            "         2.3501e-04],\n",
            "        [6.6969e-02, 2.3052e-04, 1.3985e-04, 3.1716e-04, 7.3014e-04, 2.9404e-04,\n",
            "         1.7508e-04],\n",
            "        [5.9248e-02, 2.2618e-04, 5.8535e-04, 6.1772e-04, 2.0318e-04, 4.3602e-04,\n",
            "         2.0956e-04],\n",
            "        [1.1352e-01, 1.5094e-04, 2.0448e-04, 6.3777e-04, 1.1193e-04, 3.1302e-04,\n",
            "         8.1779e-05],\n",
            "        [1.7111e-01, 1.8135e-04, 3.2677e-04, 6.6822e-04, 1.6777e-04, 2.0902e-04,\n",
            "         2.5153e-04]], grad_fn=<ViewBackward0>)\n",
            "loss 0.11649133265018463\n",
            "--------\n",
            "38\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[2.6445e-04, 3.1089e-04, 1.6326e-01, 4.9539e-04, 3.5186e-04, 1.5465e-04,\n",
            "         7.4237e-05],\n",
            "        [1.5141e-04, 5.9083e-02, 3.7632e-04, 1.5942e-04, 4.4567e-04, 3.6207e-04,\n",
            "         1.5693e-04],\n",
            "        [4.2206e-02, 3.2615e-04, 3.6880e-04, 8.5894e-05, 3.2755e-04, 2.5719e-04,\n",
            "         2.6966e-04],\n",
            "        [1.0375e-01, 2.0734e-04, 6.3247e-04, 4.6172e-04, 3.5084e-04, 4.0493e-04,\n",
            "         1.9496e-04],\n",
            "        [6.9969e-02, 2.9208e-04, 5.9776e-04, 2.0881e-04, 1.6715e-04, 1.7868e-04,\n",
            "         4.2473e-04],\n",
            "        [1.3793e-01, 9.5735e-05, 2.4264e-04, 4.2422e-04, 1.5412e-04, 1.1990e-04,\n",
            "         2.0864e-04],\n",
            "        [6.9104e-02, 2.0429e-04, 1.2310e-04, 2.8256e-04, 6.3374e-04, 2.5664e-04,\n",
            "         1.5659e-04],\n",
            "        [6.2139e-02, 2.0136e-04, 5.0967e-04, 5.4477e-04, 1.7878e-04, 3.8652e-04,\n",
            "         1.8552e-04],\n",
            "        [1.1417e-01, 1.3205e-04, 1.8118e-04, 5.5336e-04, 9.8845e-05, 2.8071e-04,\n",
            "         7.3298e-05],\n",
            "        [1.6149e-01, 1.5802e-04, 2.9411e-04, 5.9264e-04, 1.5100e-04, 1.8769e-04,\n",
            "         2.2041e-04]], grad_fn=<ViewBackward0>)\n",
            "loss 0.11640217900276184\n",
            "--------\n",
            "39\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[2.3748e-04, 2.7306e-04, 1.6144e-01, 4.3989e-04, 3.0974e-04, 1.3861e-04,\n",
            "         6.5526e-05],\n",
            "        [1.3721e-04, 6.2028e-02, 3.3485e-04, 1.4043e-04, 3.9092e-04, 3.1986e-04,\n",
            "         1.3806e-04],\n",
            "        [4.3381e-02, 2.9065e-04, 3.3152e-04, 7.6754e-05, 2.9340e-04, 2.3180e-04,\n",
            "         2.4232e-04],\n",
            "        [1.0550e-01, 1.8606e-04, 5.6151e-04, 4.1645e-04, 3.1351e-04, 3.5751e-04,\n",
            "         1.7243e-04],\n",
            "        [7.2252e-02, 2.6148e-04, 5.3564e-04, 1.8580e-04, 1.4662e-04, 1.6241e-04,\n",
            "         3.8268e-04],\n",
            "        [1.3657e-01, 8.6049e-05, 2.1338e-04, 3.7904e-04, 1.3818e-04, 1.0549e-04,\n",
            "         1.8659e-04],\n",
            "        [7.1456e-02, 1.8251e-04, 1.0948e-04, 2.5348e-04, 5.5630e-04, 2.2661e-04,\n",
            "         1.4105e-04],\n",
            "        [6.5168e-02, 1.8043e-04, 4.4864e-04, 4.8421e-04, 1.5894e-04, 3.4488e-04,\n",
            "         1.6565e-04],\n",
            "        [1.1512e-01, 1.1686e-04, 1.6180e-04, 4.8565e-04, 8.8141e-05, 2.5276e-04,\n",
            "         6.6183e-05],\n",
            "        [1.5204e-01, 1.3943e-04, 2.6553e-04, 5.2875e-04, 1.3665e-04, 1.6937e-04,\n",
            "         1.9517e-04]], grad_fn=<ViewBackward0>)\n",
            "loss 0.11632292717695236\n",
            "--------\n",
            "40\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[2.1464e-04, 2.4286e-04, 1.5805e-01, 3.9355e-04, 2.7577e-04, 1.2519e-04,\n",
            "         5.8607e-05],\n",
            "        [1.2486e-04, 6.5039e-02, 3.0047e-04, 1.2527e-04, 3.4711e-04, 2.8540e-04,\n",
            "         1.2299e-04],\n",
            "        [4.4731e-02, 2.6107e-04, 2.9974e-04, 6.9228e-05, 2.6437e-04, 2.0982e-04,\n",
            "         2.1914e-04],\n",
            "        [1.0742e-01, 1.6822e-04, 5.0216e-04, 3.7735e-04, 2.8193e-04, 3.1901e-04,\n",
            "         1.5430e-04],\n",
            "        [7.4612e-02, 2.3564e-04, 4.8250e-04, 1.6672e-04, 1.3035e-04, 1.4821e-04,\n",
            "         3.4624e-04],\n",
            "        [1.3505e-01, 7.7931e-05, 1.8980e-04, 3.4075e-04, 1.2477e-04, 9.4061e-05,\n",
            "         1.6806e-04],\n",
            "        [7.3995e-02, 1.6433e-04, 9.8332e-05, 2.2895e-04, 4.9371e-04, 2.0232e-04,\n",
            "         1.2790e-04],\n",
            "        [6.8307e-02, 1.6271e-04, 3.9913e-04, 4.3370e-04, 1.4267e-04, 3.0976e-04,\n",
            "         1.4913e-04],\n",
            "        [1.1626e-01, 1.0457e-04, 1.4560e-04, 4.3100e-04, 7.9331e-05, 2.2855e-04,\n",
            "         6.0175e-05],\n",
            "        [1.4303e-01, 1.2452e-04, 2.4050e-04, 4.7461e-04, 1.2431e-04, 1.5358e-04,\n",
            "         1.7458e-04]], grad_fn=<ViewBackward0>)\n",
            "loss 0.11625255644321442\n",
            "--------\n",
            "41\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[1.9514e-04, 2.1832e-04, 1.5345e-01, 3.5452e-04, 2.4794e-04, 1.1384e-04,\n",
            "         5.3005e-05],\n",
            "        [1.1409e-04, 6.8119e-02, 2.7165e-04, 1.1297e-04, 3.1145e-04, 2.5689e-04,\n",
            "         1.1073e-04],\n",
            "        [4.6236e-02, 2.3616e-04, 2.7248e-04, 6.2946e-05, 2.3954e-04, 1.9075e-04,\n",
            "         1.9935e-04],\n",
            "        [1.0938e-01, 1.5312e-04, 4.5211e-04, 3.4347e-04, 2.5504e-04, 2.8728e-04,\n",
            "         1.3947e-04],\n",
            "        [7.7031e-02, 2.1366e-04, 4.3683e-04, 1.5072e-04, 1.1721e-04, 1.3578e-04,\n",
            "         3.1460e-04],\n",
            "        [1.3330e-01, 7.1058e-05, 1.7051e-04, 3.0811e-04, 1.1337e-04, 8.4827e-05,\n",
            "         1.5236e-04],\n",
            "        [7.6684e-02, 1.4900e-04, 8.9081e-05, 2.0806e-04, 4.4239e-04, 1.8238e-04,\n",
            "         1.1668e-04],\n",
            "        [7.1549e-02, 1.4759e-04, 3.5839e-04, 3.9118e-04, 1.2916e-04, 2.7992e-04,\n",
            "         1.3525e-04],\n",
            "        [1.1746e-01, 9.4456e-05, 1.3193e-04, 3.8622e-04, 7.1984e-05, 2.0755e-04,\n",
            "         5.5053e-05],\n",
            "        [1.3459e-01, 1.1234e-04, 2.1860e-04, 4.2847e-04, 1.1365e-04, 1.3992e-04,\n",
            "         1.5753e-04]], grad_fn=<ViewBackward0>)\n",
            "loss 0.11619028449058533\n",
            "--------\n",
            "42\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[1.7833e-04, 1.9797e-04, 1.4801e-01, 3.2128e-04, 2.2470e-04, 1.0414e-04,\n",
            "         4.8364e-05],\n",
            "        [1.0468e-04, 7.1280e-02, 2.4717e-04, 1.0276e-04, 2.8183e-04, 2.3294e-04,\n",
            "         1.0054e-04],\n",
            "        [4.7876e-02, 2.1495e-04, 2.4893e-04, 5.7624e-05, 2.1817e-04, 1.7415e-04,\n",
            "         1.8229e-04],\n",
            "        [1.1128e-01, 1.4019e-04, 4.0946e-04, 3.1401e-04, 2.3194e-04, 2.6067e-04,\n",
            "         1.2709e-04],\n",
            "        [7.9496e-02, 1.9478e-04, 3.9736e-04, 1.3713e-04, 1.0636e-04, 1.2488e-04,\n",
            "         2.8704e-04],\n",
            "        [1.3123e-01, 6.5172e-05, 1.5441e-04, 2.8005e-04, 1.0358e-04, 7.7192e-05,\n",
            "         1.3891e-04],\n",
            "        [7.9486e-02, 1.3592e-04, 8.1277e-05, 1.9012e-04, 3.9955e-04, 1.6570e-04,\n",
            "         1.0703e-04],\n",
            "        [7.4894e-02, 1.3460e-04, 3.2429e-04, 3.5501e-04, 1.1777e-04, 2.5432e-04,\n",
            "         1.2343e-04],\n",
            "        [1.1854e-01, 8.5983e-05, 1.2025e-04, 3.4887e-04, 6.5761e-05, 1.8925e-04,\n",
            "         5.0646e-05],\n",
            "        [1.2681e-01, 1.0219e-04, 1.9942e-04, 3.8883e-04, 1.0438e-04, 1.2804e-04,\n",
            "         1.4320e-04]], grad_fn=<ViewBackward0>)\n",
            "loss 0.11613539606332779\n",
            "--------\n",
            "43\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[1.6372e-04, 1.8079e-04, 1.4207e-01, 2.9270e-04, 2.0498e-04, 9.5761e-05,\n",
            "         4.4445e-05],\n",
            "        [9.6411e-05, 7.4525e-02, 2.2613e-04, 9.4132e-05, 2.5680e-04, 2.1254e-04,\n",
            "         9.1929e-05],\n",
            "        [4.9638e-02, 1.9667e-04, 2.2845e-04, 5.3054e-05, 1.9963e-04, 1.5964e-04,\n",
            "         1.6747e-04],\n",
            "        [1.1301e-01, 1.2900e-04, 3.7278e-04, 2.8828e-04, 2.1196e-04, 2.3803e-04,\n",
            "         1.1658e-04],\n",
            "        [8.1992e-02, 1.7843e-04, 3.6305e-04, 1.2545e-04, 9.7218e-05, 1.1528e-04,\n",
            "         2.6296e-04],\n",
            "        [1.2883e-01, 6.0081e-05, 1.4077e-04, 2.5577e-04, 9.5099e-05, 7.0758e-05,\n",
            "         1.2729e-04],\n",
            "        [8.2367e-02, 1.2466e-04, 7.4604e-05, 1.7456e-04, 3.6325e-04, 1.5154e-04,\n",
            "         9.8643e-05],\n",
            "        [7.8331e-02, 1.2334e-04, 2.9534e-04, 3.2393e-04, 1.0803e-04, 2.3219e-04,\n",
            "         1.1326e-04],\n",
            "        [1.1937e-01, 7.8767e-05, 1.1017e-04, 3.1726e-04, 6.0421e-05, 1.7324e-04,\n",
            "         4.6818e-05],\n",
            "        [1.1971e-01, 9.3588e-05, 1.8257e-04, 3.5453e-04, 9.6270e-05, 1.1766e-04,\n",
            "         1.3097e-04]], grad_fn=<ViewBackward0>)\n",
            "loss 0.11608733981847763\n",
            "--------\n",
            "44\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[1.5095e-04, 1.6610e-04, 1.3591e-01, 2.6792e-04, 1.8805e-04, 8.8460e-05,\n",
            "         4.1090e-05],\n",
            "        [8.9128e-05, 7.7844e-02, 2.0790e-04, 8.6746e-05, 2.3538e-04, 1.9499e-04,\n",
            "         8.4556e-05],\n",
            "        [5.1512e-02, 1.8081e-04, 2.1053e-04, 4.9091e-05, 1.8347e-04, 1.4690e-04,\n",
            "         1.5451e-04],\n",
            "        [1.1448e-01, 1.1924e-04, 3.4101e-04, 2.6570e-04, 1.9456e-04, 2.1854e-04,\n",
            "         1.0754e-04],\n",
            "        [8.4496e-02, 1.6418e-04, 3.3307e-04, 1.1532e-04, 8.9412e-05, 1.0680e-04,\n",
            "         2.4183e-04],\n",
            "        [1.2613e-01, 5.5641e-05, 1.2906e-04, 2.3461e-04, 8.7691e-05, 6.5257e-05,\n",
            "         1.1718e-04],\n",
            "        [8.5291e-02, 1.1487e-04, 6.8837e-05, 1.6097e-04, 3.3215e-04, 1.3937e-04,\n",
            "         9.1315e-05],\n",
            "        [8.1842e-02, 1.1351e-04, 2.7048e-04, 2.9702e-04, 9.9610e-05, 2.1294e-04,\n",
            "         1.0444e-04],\n",
            "        [1.1988e-01, 7.2549e-05, 1.0140e-04, 2.9019e-04, 5.5793e-05, 1.5919e-04,\n",
            "         4.3469e-05],\n",
            "        [1.1328e-01, 8.6202e-05, 1.6775e-04, 3.2467e-04, 8.9142e-05, 1.0854e-04,\n",
            "         1.2043e-04]], grad_fn=<ViewBackward0>)\n",
            "loss 0.11604559421539307\n",
            "--------\n",
            "45\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[1.3971e-04, 1.5341e-04, 1.2974e-01, 2.4633e-04, 1.7340e-04, 8.2058e-05,\n",
            "         3.8186e-05],\n",
            "        [8.2685e-05, 8.1218e-02, 1.9198e-04, 8.0360e-05, 2.1689e-04, 1.7977e-04,\n",
            "         7.8182e-05],\n",
            "        [5.3493e-02, 1.6694e-04, 1.9478e-04, 4.5628e-05, 1.6931e-04, 1.3568e-04,\n",
            "         1.4311e-04],\n",
            "        [1.1562e-01, 1.1067e-04, 3.1332e-04, 2.4582e-04, 1.7933e-04, 2.0164e-04,\n",
            "         9.9693e-05],\n",
            "        [8.6982e-02, 1.5169e-04, 3.0677e-04, 1.0649e-04, 8.2676e-05, 9.9278e-05,\n",
            "         2.2323e-04],\n",
            "        [1.2320e-01, 5.1744e-05, 1.1893e-04, 2.1610e-04, 8.1186e-05, 6.0507e-05,\n",
            "         1.0833e-04],\n",
            "        [8.8221e-02, 1.0631e-04, 6.3812e-05, 1.4904e-04, 3.0528e-04, 1.2883e-04,\n",
            "         8.4871e-05],\n",
            "        [8.5394e-02, 1.0490e-04, 2.4896e-04, 2.7358e-04, 9.2283e-05, 1.9609e-04,\n",
            "         9.6736e-05],\n",
            "        [1.2001e-01, 6.7145e-05, 9.3717e-05, 2.6682e-04, 5.1750e-05, 1.4681e-04,\n",
            "         4.0521e-05],\n",
            "        [1.0751e-01, 7.9801e-05, 1.5466e-04, 2.9855e-04, 8.2847e-05, 1.0050e-04,\n",
            "         1.1127e-04]], grad_fn=<ViewBackward0>)\n",
            "loss 0.11600969731807709\n",
            "--------\n",
            "46\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[1.2978e-04, 1.4238e-04, 1.2373e-01, 2.2741e-04, 1.6063e-04, 7.6415e-05,\n",
            "         3.5653e-05],\n",
            "        [7.6965e-05, 8.4620e-02, 1.7802e-04, 7.4795e-05, 2.0081e-04, 1.6648e-04,\n",
            "         7.2628e-05],\n",
            "        [5.5578e-02, 1.5477e-04, 1.8087e-04, 4.2581e-05, 1.5684e-04, 1.2576e-04,\n",
            "         1.3304e-04],\n",
            "        [1.1640e-01, 1.0311e-04, 2.8908e-04, 2.2824e-04, 1.6594e-04, 1.8688e-04,\n",
            "         9.2836e-05],\n",
            "        [8.9426e-02, 1.4070e-04, 2.8360e-04, 9.8741e-05, 7.6817e-05, 9.2586e-05,\n",
            "         2.0679e-04],\n",
            "        [1.2010e-01, 4.8304e-05, 1.1010e-04, 1.9982e-04, 7.5446e-05, 5.6369e-05,\n",
            "         1.0054e-04],\n",
            "        [9.1121e-02, 9.8783e-05, 5.9407e-05, 1.3852e-04, 2.8191e-04, 1.1963e-04,\n",
            "         7.9176e-05],\n",
            "        [8.8953e-02, 9.7312e-05, 2.3022e-04, 2.5305e-04, 8.5861e-05, 1.8128e-04,\n",
            "         8.9964e-05],\n",
            "        [1.1973e-01, 6.2417e-05, 8.6958e-05, 2.4650e-04, 4.8198e-05, 1.3586e-04,\n",
            "         3.7911e-05],\n",
            "        [1.0236e-01, 7.4213e-05, 1.4307e-04, 2.7561e-04, 7.7263e-05, 9.3387e-05,\n",
            "         1.0325e-04]], grad_fn=<ViewBackward0>)\n",
            "loss 0.11597912758588791\n",
            "--------\n",
            "47\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[1.2098e-04, 1.3271e-04, 1.1800e-01, 2.1077e-04, 1.4942e-04, 7.1419e-05,\n",
            "         3.3427e-05],\n",
            "        [7.1873e-05, 8.8021e-02, 1.6571e-04, 6.9912e-05, 1.8673e-04, 1.5482e-04,\n",
            "         6.7759e-05],\n",
            "        [5.7765e-02, 1.4402e-04, 1.6855e-04, 3.9888e-05, 1.4582e-04, 1.1697e-04,\n",
            "         1.2412e-04],\n",
            "        [1.1678e-01, 9.6409e-05, 2.6777e-04, 2.1265e-04, 1.5411e-04, 1.7391e-04,\n",
            "         8.6804e-05],\n",
            "        [9.1801e-02, 1.3097e-04, 2.6312e-04, 9.1909e-05, 7.1686e-05, 8.6613e-05,\n",
            "         1.9222e-04],\n",
            "        [1.1692e-01, 4.5254e-05, 1.0236e-04, 1.8546e-04, 7.0361e-05, 5.2741e-05,\n",
            "         9.3657e-05],\n",
            "        [9.3952e-02, 9.2137e-05, 5.5522e-05, 1.2920e-04, 2.6147e-04, 1.1155e-04,\n",
            "         7.4121e-05],\n",
            "        [9.2474e-02, 9.0602e-05, 2.1379e-04, 2.3498e-04, 8.0203e-05, 1.6822e-04,\n",
            "         8.3985e-05],\n",
            "        [1.1905e-01, 5.8255e-05, 8.0984e-05, 2.2872e-04, 4.5060e-05, 1.2616e-04,\n",
            "         3.5592e-05],\n",
            "        [9.7795e-02, 6.9304e-05, 1.3279e-04, 2.5539e-04, 7.2292e-05, 8.7068e-05,\n",
            "         9.6210e-05]], grad_fn=<ViewBackward0>)\n",
            "loss 0.11595334857702255\n",
            "--------\n",
            "48\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[1.1315e-04, 1.2420e-04, 1.1265e-01, 1.9608e-04, 1.3955e-04, 6.6978e-05,\n",
            "         3.1461e-05],\n",
            "        [6.7326e-05, 9.1386e-02, 1.5482e-04, 6.5604e-05, 1.7434e-04, 1.4454e-04,\n",
            "         6.3467e-05],\n",
            "        [6.0057e-02, 1.3451e-04, 1.5759e-04, 3.7495e-05, 1.3605e-04, 1.0915e-04,\n",
            "         1.1618e-04],\n",
            "        [1.1676e-01, 9.0448e-05, 2.4896e-04, 1.9877e-04, 1.4364e-04, 1.6247e-04,\n",
            "         8.1471e-05],\n",
            "        [9.4083e-02, 1.2235e-04, 2.4497e-04, 8.5861e-05, 6.7168e-05, 8.1270e-05,\n",
            "         1.7927e-04],\n",
            "        [1.1375e-01, 4.2539e-05, 9.5545e-05, 1.7274e-04, 6.5841e-05, 4.9540e-05,\n",
            "         8.7553e-05],\n",
            "        [9.6677e-02, 8.6243e-05, 5.2081e-05, 1.2091e-04, 2.4350e-04, 1.0443e-04,\n",
            "         6.9618e-05],\n",
            "        [9.5911e-02, 8.4647e-05, 1.9934e-04, 2.1902e-04, 7.5194e-05, 1.5666e-04,\n",
            "         7.8682e-05],\n",
            "        [1.1801e-01, 5.4574e-05, 7.5685e-05, 2.1310e-04, 4.2276e-05, 1.1754e-04,\n",
            "         3.3522e-05],\n",
            "        [9.3770e-02, 6.4969e-05, 1.2365e-04, 2.3750e-04, 6.7854e-05, 8.1439e-05,\n",
            "         8.9986e-05]], grad_fn=<ViewBackward0>)\n",
            "loss 0.11593183875083923\n",
            "--------\n",
            "49\n",
            "actual: tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0.]])\n",
            "rnn_output tensor([[1.0617e-04, 1.1667e-04, 1.0773e-01, 1.8306e-04, 1.3081e-04, 6.3017e-05,\n",
            "         2.9715e-05],\n",
            "        [6.3258e-05, 9.4674e-02, 1.4513e-04, 6.1786e-05, 1.6339e-04, 1.3544e-04,\n",
            "         5.9666e-05],\n",
            "        [6.2454e-02, 1.2605e-04, 1.4782e-04, 3.5362e-05, 1.2737e-04, 1.0218e-04,\n",
            "         1.0909e-04],\n",
            "        [1.1636e-01, 8.5128e-05, 2.3230e-04, 1.8639e-04, 1.3434e-04, 1.5234e-04,\n",
            "         7.6735e-05],\n",
            "        [9.6252e-02, 1.1467e-04, 2.2884e-04, 8.0489e-05, 6.3169e-05, 7.6478e-05,\n",
            "         1.6773e-04],\n",
            "        [1.1064e-01, 4.0113e-05, 8.9516e-05, 1.6144e-04, 6.1810e-05, 4.6703e-05,\n",
            "         8.2121e-05],\n",
            "        [9.9259e-02, 8.0998e-05, 4.9020e-05, 1.1352e-04, 2.2763e-04, 9.8113e-05,\n",
            "         6.5593e-05],\n",
            "        [9.9212e-02, 7.9346e-05, 1.8655e-04, 2.0488e-04, 7.0742e-05, 1.4639e-04,\n",
            "         7.3964e-05],\n",
            "        [1.1667e-01, 5.1306e-05, 7.0970e-05, 1.9931e-04, 3.9797e-05, 1.0986e-04,\n",
            "         3.1668e-05],\n",
            "        [9.0244e-02, 6.1123e-05, 1.1550e-04, 2.2163e-04, 6.3881e-05, 7.6413e-05,\n",
            "         8.4464e-05]], grad_fn=<ViewBackward0>)\n",
            "loss 0.11591406166553497\n",
            "--------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Completely new"
      ],
      "metadata": {
        "id": "OYHJ_SBfkNNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "io_obj=io_cls()\n",
        "n_labels=io_obj.n_labels\n",
        "#print(cur_diff_obj.n_labels)\n",
        "#cur_one_hot=cur_diff_obj.one_hot([9,17,14,19,15.5,15.8,16.2,17.1],16)\n",
        "\n",
        "n_input=n_labels\n",
        "n_output=10*n_labels\n",
        "n_hidden =64\n",
        "n_layers=2\n",
        "LR=0.0000001\n",
        "LR=0.0001\n",
        "rnn = RNN(n_input, n_hidden, n_output,n_layers, matching_in_out=False).to(device)\n",
        "loss_func = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)\n",
        "print(rnn)\n",
        "\n",
        "model_name=\"exp4-test0\"\n",
        "model_dir=os.path.join(cwd,\"models\", model_name) \n",
        "tmp_model_dir=os.path.join(cwd,\"models\", model_name,\"tmp\") \n",
        "if not os.path.exists(tmp_model_dir): os.makedirs(tmp_model_dir)\n",
        "log_fpath=os.path.join(model_dir,\"log.txt\")\n",
        "log_fopen=open(log_fpath,\"a\")\n",
        "log_fopen.write(str(rnn)+\"\\n\")\n",
        "#log_fopen.write(str(tmp_params)+\"\\n\")\n",
        "log_fopen.close()\n",
        "\n",
        "root_dir='stock_market_data/sp500/csv'\n",
        "test_files=[\"AAPL\",\"GOOG\",\"FB\",\"AMZN\",\"EA\",\"IBM\",\"MSFT\",\"GM\",\"UPS\",\"PG\"]\n",
        "cur_path=os.path.join(root_dir,\"AAPL.csv\")\n",
        "train0,test0=get_norm_close(cur_path,prev_n0=20,next_n0=10,train_ratio=0.75)\n",
        "\n",
        "cur_train_item=train0[10]\n",
        "for epoch0 in range(50):\n",
        "  PATH=os.path.join(model_dir, \"model-%s.model\"%epoch0)\n",
        "  for fname in test_files[:3]:\n",
        "    #print(\"epoch0\",epoch0, \"fname\",fname)\n",
        "    cur_path=os.path.join(root_dir,fname+\".csv\")\n",
        "    train0,test0=get_norm_close(cur_path,prev_n0=20,next_n0=10,train_ratio=0.75)\n",
        "\n",
        "    total_train_loss,total_test_loss=0,0  \n",
        "    total_train_counter,total_test_counter=0,0  \n",
        "    for train_i,cur_train_item in enumerate(train0):\n",
        "      input0,output0=cur_train_item\n",
        "      input_oh0=io_obj.one_hot(input0,input0[-1])\n",
        "      output_oh0=io_obj.one_hot(output0,input0[-1])\n",
        "      \n",
        "      # print(\"input0\",input0)\n",
        "      # print(\"output0\",output0)\n",
        "      # print(\"--------\")\n",
        "\n",
        "      # continue\n",
        "\n",
        "      # input_oh0=list2one_hot2(input0,mv_labels2)\n",
        "      # output_oh0=list2one_hot2(output0,mv_labels2)\n",
        "      rnn.hidden=rnn.init_hidden()\n",
        "      rnn.zero_grad()\n",
        "      input_tensor1=torch.tensor(input_oh0)\n",
        "      output_tensor1=torch.tensor(output_oh0)  \n",
        "      rnn_output = rnn(input_tensor1)\n",
        "      rnn_output=rnn_output.view(output_tensor1.shape)\n",
        "      loss = loss_func(output_tensor1.ravel(), rnn_output.ravel()) #calculate the loss, difference between the output and the desired outcome tensors\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_train_loss+=loss.item()\n",
        "      total_train_counter+=1\n",
        "      rnn_output2=rnn_output.view(output_tensor1.shape)\n",
        "      # for cur_r0 in rnn_output2:\n",
        "      #   tmp_row=[]\n",
        "      #   for r0,lb0 in zip(cur_r0,mv_labels2): tmp_row.append((lb0,round(r0.item(),4)))\n",
        "      #   tmp_row.sort(key=lambda x:-x[-1])\n",
        "      #   print(tmp_row)\n",
        "      # print(\"-------\")\n",
        "\n",
        "    for test_i,cur_test_item in enumerate(test0):\n",
        "      input0,output0=cur_test_item\n",
        "      input_oh0=io_obj.one_hot(input0,input0[-1])\n",
        "      output_oh0=io_obj.one_hot(output0,input0[-1])\n",
        "\n",
        "      # continue\n",
        "      # input_oh0=list2one_hot2(input0,mv_labels2)\n",
        "      # output_oh0=list2one_hot2(output0,mv_labels2)\n",
        "      rnn.hidden=rnn.init_hidden()\n",
        "      rnn.zero_grad()\n",
        "      input_tensor1=torch.tensor(input_oh0)\n",
        "      output_tensor1=torch.tensor(output_oh0)  \n",
        "      rnn_output = rnn(input_tensor1)\n",
        "      rnn_output=rnn_output.view(output_tensor1.shape)\n",
        "      loss = loss_func(output_tensor1.ravel(), rnn_output.ravel()) #calculate the loss, difference between the output and the desired outcome tensors\n",
        "      total_test_loss+=loss.item()\n",
        "      total_test_counter+=1\n",
        "    print(\"epoch:\", epoch0, \"fname\",fname, \"train_loss\",round(total_train_loss/total_train_counter,6), \"total_test_loss\",round(total_test_loss/total_test_counter,6))\n",
        "  torch.save({\n",
        "          'epoch': epoch0,\n",
        "          'n_input': n_input,\n",
        "          'n_hidden': n_hidden,\n",
        "          'n_layers': n_layers,\n",
        "          'n_output': n_output,\n",
        "          'LR': LR,\n",
        "          'model_state_dict': rnn.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict(),\n",
        "          }, PATH)\n",
        "  print(\"model saved\")\n",
        "  print(\"-----------\")\n",
        "      \n",
        "\n",
        "    # print(\"test_i\",test_i)\n",
        "    # print(\"input0\",input0)\n",
        "    # print(\"actual:\",output_tensor1)\n",
        "    # print(\"rnn_output\", rnn_output)\n",
        "    # print(\"loss\", loss.item())\n",
        "    # print(\"--------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZejZeINsIHNb",
        "outputId": "475361f5-a610-44e9-c041-9c4acb4b1de9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN(\n",
            "  (lstm): LSTM(11, 64, num_layers=2)\n",
            "  (hidden2out): Linear(in_features=64, out_features=110, bias=True)\n",
            "  (softmax): Softmax(dim=2)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 fname AAPL train_loss 0.087926 total_test_loss 0.085925\n",
            "epoch: 0 fname GOOG train_loss 0.085693 total_test_loss 0.085639\n",
            "epoch: 0 fname FB train_loss 0.08627 total_test_loss 0.087167\n",
            "model saved\n",
            "-----------\n",
            "epoch: 1 fname AAPL train_loss 0.087824 total_test_loss 0.085778\n",
            "epoch: 1 fname GOOG train_loss 0.085616 total_test_loss 0.085595\n",
            "epoch: 1 fname FB train_loss 0.086169 total_test_loss 0.087045\n",
            "model saved\n",
            "-----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e0=4\n",
        "model_name=\"exp4-test0\"\n",
        "model_dir=os.path.join(cwd,\"models\", model_name) \n",
        "PATH=os.path.join(model_dir, \"model-%s.model\"%e0)\n",
        "checkpoint = torch.load(PATH)\n",
        "rnn = RNN(checkpoint[\"n_input\"], checkpoint[\"n_hidden\"] , checkpoint[\"n_output\"] , checkpoint[\"n_layers\"] , matching_in_out=False).to(device)\n",
        "rnn.load_state_dict(checkpoint['model_state_dict'])\n",
        "rnn.eval()\n",
        "\n",
        "io_obj=io_cls()\n",
        "n_labels=io_obj.n_labels\n",
        "\n",
        "for test_i,cur_test_item in enumerate(test0[:20]):\n",
        "  input0,output0=cur_test_item\n",
        "  input_oh0=io_obj.one_hot(input0,input0[-1])\n",
        "  output_oh0=io_obj.one_hot(output0,input0[-1])\n",
        "  output_diff_labels=io_obj.diff_list\n",
        "\n",
        "  # input_oh0=list2one_hot2(input0,mv_labels2)\n",
        "  # output_oh0=list2one_hot2(output0,mv_labels2)\n",
        "  rnn.hidden=rnn.init_hidden()\n",
        "  rnn.zero_grad()\n",
        "  input_tensor1=torch.tensor(input_oh0)\n",
        "  output_tensor1=torch.tensor(output_oh0)  \n",
        "  rnn_output = rnn(input_tensor1)\n",
        "  rnn_output=rnn_output.view(output_tensor1.shape)\n",
        "  total_test_loss+=loss.item()\n",
        "  print(\"test_i\",test_i)\n",
        "  print(\"input0\",input0)\n",
        "  cur_preds=io_obj.out2labels(rnn_output.ravel())\n",
        "  for act0,pred0 in zip(output_diff_labels,cur_preds):\n",
        "    pred0=[(v[0],round(v[1].item(),4)) for v in pred0]\n",
        "    print(act0, pred0)\n",
        "  # print(\"actual:\",output_tensor1)\n",
        "  # print(\"rnn_output\", rnn_output)\n",
        "  # print(\"loss\", loss.item())\n",
        "  # print(\"--------\")\n",
        "  # predictions=[]\n",
        "  # for cur_r0 in rnn_output:\n",
        "  #   tmp_row=[]\n",
        "  #   for r0,lb0 in zip(cur_r0,mv_labels2): tmp_row.append((lb0,round(r0.item(),4)))\n",
        "  #   tmp_row.sort(key=lambda x:-x[-1])\n",
        "  #   predictions.append(tmp_row)\n",
        "  # for a,b in zip(output0,predictions):\n",
        "  #   print(a,b)\n",
        "  print(\"===========\")\n",
        "\n",
        "  #   #print(r0)\n",
        "  \n",
        "  # rnn_output2 = rnn_output.ravel().tolist()\n",
        "  # predictions0=out2labels(rnn_output2,mv_labels2)\n",
        "  # #print(\"mv_labels\",mv_labels)\n",
        "  # outcome_str_list=[get_str_percent2(v) for v in output0]\n",
        "  # #print(\"output_list\",output_list, )\n",
        "  # #print(\"Epoch:\", e0, \"- item:\", i0)\n",
        "  # print(\"input_list\",input0)\n",
        "  # #print(\"input_oh\",input_oh)\n",
        "  # for act0,pd0 in zip(outcome_str_list,predictions0):\n",
        "  #   print(\"act0\",act0,\"pred:\", pd0)\n",
        "  #print(\"=======\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vB_5piagNPWd",
        "outputId": "35a5964a-ebf8-4dfe-ff4a-cf26c5590fba"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_i 0\n",
            "input0 [953.27001953125, 957.7899780273438, 951.6799926757812, 969.9600219726562, 978.8900146484376, 977.0, 972.5999755859376, 989.25, 987.8300170898438, 989.6799926757812, 992.0, 992.1799926757812, 992.8099975585938, 984.4500122070312, 988.2000122070312, 968.4500122070312, 970.5399780273438, 973.3300170898438, 972.5599975585938, 1019.27001953125]\n",
            "0 [('0', 0.2265), ('-2', 0.0819), ('2', 0.0817), ('4', 0.0003), ('-4', 0.0002), ('6', 0.0), ('-6', 0.0), ('8', 0.0), ('-8', 0.0), ('10', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.12), ('2', 0.059), ('-2', 0.0454), ('4', 0.0011), ('-4', 0.0003), ('6', 0.0), ('-6', 0.0), ('10', 0.0), ('-8', 0.0), ('8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0592), ('2', 0.0308), ('-2', 0.0138), ('4', 0.0064), ('-4', 0.0008), ('-6', 0.0001), ('8', 0.0), ('6', 0.0), ('10', 0.0), ('-8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0273), ('2', 0.0102), ('4', 0.006), ('-2', 0.0056), ('-4', 0.0004), ('10', 0.0002), ('6', 0.0001), ('8', 0.0001), ('-6', 0.0), ('-10', 0.0), ('-8', 0.0)]\n",
            "2 [('0', 0.0171), ('2', 0.0076), ('10', 0.0019), ('-2', 0.0012), ('4', 0.0007), ('-4', 0.0003), ('6', 0.0), ('-10', 0.0), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('0', 0.0136), ('10', 0.0053), ('2', 0.0046), ('-2', 0.0005), ('4', 0.0002), ('-4', 0.0002), ('-10', 0.0001), ('8', 0.0), ('-8', 0.0), ('6', 0.0), ('-6', 0.0)]\n",
            "2 [('10', 0.0211), ('0', 0.0044), ('2', 0.0027), ('-10', 0.0006), ('-2', 0.0003), ('4', 0.0002), ('-4', 0.0002), ('6', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "2 [('10', 0.0338), ('2', 0.0017), ('-2', 0.0008), ('0', 0.0007), ('-10', 0.0003), ('4', 0.0002), ('6', 0.0001), ('-4', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "2 [('10', 0.0413), ('-10', 0.0007), ('0', 0.0007), ('2', 0.0004), ('-4', 0.0003), ('4', 0.0003), ('-2', 0.0002), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('10', 0.0529), ('-10', 0.0028), ('2', 0.0006), ('-2', 0.0003), ('0', 0.0002), ('-4', 0.0002), ('4', 0.0001), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "===========\n",
            "test_i 1\n",
            "input0 [957.7899780273438, 951.6799926757812, 969.9600219726562, 978.8900146484376, 977.0, 972.5999755859376, 989.25, 987.8300170898438, 989.6799926757812, 992.0, 992.1799926757812, 992.8099975585938, 984.4500122070312, 988.2000122070312, 968.4500122070312, 970.5399780273438, 973.3300170898438, 972.5599975585938, 1019.27001953125, 1017.1099853515624]\n",
            "0 [('0', 0.2265), ('-2', 0.0819), ('2', 0.0817), ('4', 0.0003), ('-4', 0.0002), ('6', 0.0), ('-6', 0.0), ('8', 0.0), ('-8', 0.0), ('10', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.12), ('2', 0.059), ('-2', 0.0454), ('4', 0.0011), ('-4', 0.0003), ('6', 0.0), ('-6', 0.0), ('10', 0.0), ('-8', 0.0), ('8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0592), ('2', 0.0308), ('-2', 0.0138), ('4', 0.0064), ('-4', 0.0008), ('-6', 0.0001), ('8', 0.0), ('6', 0.0), ('10', 0.0), ('-8', 0.0), ('-10', 0.0)]\n",
            "2 [('0', 0.0273), ('2', 0.0102), ('4', 0.006), ('-2', 0.0056), ('-4', 0.0004), ('10', 0.0002), ('6', 0.0001), ('8', 0.0001), ('-6', 0.0), ('-10', 0.0), ('-8', 0.0)]\n",
            "0 [('0', 0.0171), ('2', 0.0076), ('10', 0.0019), ('-2', 0.0012), ('4', 0.0007), ('-4', 0.0003), ('6', 0.0), ('-10', 0.0), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "2 [('0', 0.0136), ('10', 0.0053), ('2', 0.0046), ('-2', 0.0005), ('4', 0.0002), ('-4', 0.0002), ('-10', 0.0001), ('8', 0.0), ('-8', 0.0), ('6', 0.0), ('-6', 0.0)]\n",
            "2 [('10', 0.0211), ('0', 0.0044), ('2', 0.0027), ('-10', 0.0006), ('-2', 0.0003), ('4', 0.0002), ('-4', 0.0002), ('6', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "2 [('10', 0.0338), ('2', 0.0017), ('-2', 0.0008), ('0', 0.0007), ('-10', 0.0003), ('4', 0.0002), ('6', 0.0001), ('-4', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "2 [('10', 0.0413), ('-10', 0.0007), ('0', 0.0007), ('2', 0.0004), ('-4', 0.0003), ('4', 0.0003), ('-2', 0.0002), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('10', 0.0529), ('-10', 0.0028), ('2', 0.0006), ('-2', 0.0003), ('0', 0.0002), ('-4', 0.0002), ('4', 0.0001), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "===========\n",
            "test_i 2\n",
            "input0 [951.6799926757812, 969.9600219726562, 978.8900146484376, 977.0, 972.5999755859376, 989.25, 987.8300170898438, 989.6799926757812, 992.0, 992.1799926757812, 992.8099975585938, 984.4500122070312, 988.2000122070312, 968.4500122070312, 970.5399780273438, 973.3300170898438, 972.5599975585938, 1019.27001953125, 1017.1099853515624, 1016.6400146484376]\n",
            "0 [('0', 0.2265), ('-2', 0.0819), ('2', 0.0817), ('4', 0.0003), ('-4', 0.0002), ('6', 0.0), ('-6', 0.0), ('8', 0.0), ('-8', 0.0), ('10', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.12), ('2', 0.059), ('-2', 0.0454), ('4', 0.0011), ('-4', 0.0003), ('6', 0.0), ('-6', 0.0), ('10', 0.0), ('-8', 0.0), ('8', 0.0), ('-10', 0.0)]\n",
            "2 [('0', 0.0592), ('2', 0.0308), ('-2', 0.0138), ('4', 0.0064), ('-4', 0.0008), ('-6', 0.0001), ('8', 0.0), ('6', 0.0), ('10', 0.0), ('-8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0273), ('2', 0.0102), ('4', 0.006), ('-2', 0.0056), ('-4', 0.0004), ('10', 0.0002), ('6', 0.0001), ('8', 0.0001), ('-6', 0.0), ('-10', 0.0), ('-8', 0.0)]\n",
            "2 [('0', 0.0171), ('2', 0.0076), ('10', 0.0019), ('-2', 0.0012), ('4', 0.0007), ('-4', 0.0003), ('6', 0.0), ('-10', 0.0), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "2 [('0', 0.0136), ('10', 0.0053), ('2', 0.0046), ('-2', 0.0005), ('4', 0.0002), ('-4', 0.0002), ('-10', 0.0001), ('8', 0.0), ('-8', 0.0), ('6', 0.0), ('-6', 0.0)]\n",
            "2 [('10', 0.0211), ('0', 0.0044), ('2', 0.0027), ('-10', 0.0006), ('-2', 0.0003), ('4', 0.0002), ('-4', 0.0002), ('6', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "2 [('10', 0.0338), ('2', 0.0017), ('-2', 0.0008), ('0', 0.0007), ('-10', 0.0003), ('4', 0.0002), ('6', 0.0001), ('-4', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "0 [('10', 0.0413), ('-10', 0.0007), ('0', 0.0007), ('2', 0.0004), ('-4', 0.0003), ('4', 0.0003), ('-2', 0.0002), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('10', 0.0529), ('-10', 0.0028), ('2', 0.0006), ('-2', 0.0003), ('0', 0.0002), ('-4', 0.0002), ('4', 0.0001), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "===========\n",
            "test_i 3\n",
            "input0 [969.9600219726562, 978.8900146484376, 977.0, 972.5999755859376, 989.25, 987.8300170898438, 989.6799926757812, 992.0, 992.1799926757812, 992.8099975585938, 984.4500122070312, 988.2000122070312, 968.4500122070312, 970.5399780273438, 973.3300170898438, 972.5599975585938, 1019.27001953125, 1017.1099853515624, 1016.6400146484376, 1025.5]\n",
            "0 [('0', 0.2265), ('-2', 0.0819), ('2', 0.0817), ('4', 0.0003), ('-4', 0.0002), ('6', 0.0), ('-6', 0.0), ('8', 0.0), ('-8', 0.0), ('10', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.12), ('2', 0.059), ('-2', 0.0454), ('4', 0.0011), ('-4', 0.0003), ('6', 0.0), ('-6', 0.0), ('10', 0.0), ('-8', 0.0), ('8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0592), ('2', 0.0308), ('-2', 0.0138), ('4', 0.0064), ('-4', 0.0008), ('-6', 0.0001), ('8', 0.0), ('6', 0.0), ('10', 0.0), ('-8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0273), ('2', 0.0102), ('4', 0.006), ('-2', 0.0056), ('-4', 0.0004), ('10', 0.0002), ('6', 0.0001), ('8', 0.0001), ('-6', 0.0), ('-10', 0.0), ('-8', 0.0)]\n",
            "2 [('0', 0.0171), ('2', 0.0076), ('10', 0.0019), ('-2', 0.0012), ('4', 0.0007), ('-4', 0.0003), ('6', 0.0), ('-10', 0.0), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('0', 0.0136), ('10', 0.0053), ('2', 0.0046), ('-2', 0.0005), ('4', 0.0002), ('-4', 0.0002), ('-10', 0.0001), ('8', 0.0), ('-8', 0.0), ('6', 0.0), ('-6', 0.0)]\n",
            "0 [('10', 0.0211), ('0', 0.0044), ('2', 0.0027), ('-10', 0.0006), ('-2', 0.0003), ('4', 0.0002), ('-4', 0.0002), ('6', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "0 [('10', 0.0338), ('2', 0.0017), ('-2', 0.0008), ('0', 0.0007), ('-10', 0.0003), ('4', 0.0002), ('6', 0.0001), ('-4', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "0 [('10', 0.0413), ('-10', 0.0007), ('0', 0.0007), ('2', 0.0004), ('-4', 0.0003), ('4', 0.0003), ('-2', 0.0002), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('10', 0.0529), ('-10', 0.0028), ('2', 0.0006), ('-2', 0.0003), ('0', 0.0002), ('-4', 0.0002), ('4', 0.0001), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "===========\n",
            "test_i 4\n",
            "input0 [978.8900146484376, 977.0, 972.5999755859376, 989.25, 987.8300170898438, 989.6799926757812, 992.0, 992.1799926757812, 992.8099975585938, 984.4500122070312, 988.2000122070312, 968.4500122070312, 970.5399780273438, 973.3300170898438, 972.5599975585938, 1019.27001953125, 1017.1099853515624, 1016.6400146484376, 1025.5, 1025.5799560546875]\n",
            "0 [('0', 0.2265), ('-2', 0.0819), ('2', 0.0817), ('4', 0.0003), ('-4', 0.0002), ('6', 0.0), ('-6', 0.0), ('8', 0.0), ('-8', 0.0), ('10', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.12), ('2', 0.059), ('-2', 0.0454), ('4', 0.0011), ('-4', 0.0003), ('6', 0.0), ('-6', 0.0), ('10', 0.0), ('-8', 0.0), ('8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0592), ('2', 0.0308), ('-2', 0.0138), ('4', 0.0064), ('-4', 0.0008), ('-6', 0.0001), ('8', 0.0), ('6', 0.0), ('10', 0.0), ('-8', 0.0), ('-10', 0.0)]\n",
            "2 [('0', 0.0273), ('2', 0.0102), ('4', 0.006), ('-2', 0.0056), ('-4', 0.0004), ('10', 0.0002), ('6', 0.0001), ('8', 0.0001), ('-6', 0.0), ('-10', 0.0), ('-8', 0.0)]\n",
            "0 [('0', 0.0171), ('2', 0.0076), ('10', 0.0019), ('-2', 0.0012), ('4', 0.0007), ('-4', 0.0003), ('6', 0.0), ('-10', 0.0), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('0', 0.0136), ('10', 0.0053), ('2', 0.0046), ('-2', 0.0005), ('4', 0.0002), ('-4', 0.0002), ('-10', 0.0001), ('8', 0.0), ('-8', 0.0), ('6', 0.0), ('-6', 0.0)]\n",
            "0 [('10', 0.0211), ('0', 0.0044), ('2', 0.0027), ('-10', 0.0006), ('-2', 0.0003), ('4', 0.0002), ('-4', 0.0002), ('6', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "0 [('10', 0.0338), ('2', 0.0017), ('-2', 0.0008), ('0', 0.0007), ('-10', 0.0003), ('4', 0.0002), ('6', 0.0001), ('-4', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "0 [('10', 0.0413), ('-10', 0.0007), ('0', 0.0007), ('2', 0.0004), ('-4', 0.0003), ('4', 0.0003), ('-2', 0.0002), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('10', 0.0529), ('-10', 0.0028), ('2', 0.0006), ('-2', 0.0003), ('0', 0.0002), ('-4', 0.0002), ('4', 0.0001), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "===========\n",
            "test_i 5\n",
            "input0 [977.0, 972.5999755859376, 989.25, 987.8300170898438, 989.6799926757812, 992.0, 992.1799926757812, 992.8099975585938, 984.4500122070312, 988.2000122070312, 968.4500122070312, 970.5399780273438, 973.3300170898438, 972.5599975585938, 1019.27001953125, 1017.1099853515624, 1016.6400146484376, 1025.5, 1025.5799560546875, 1032.47998046875]\n",
            "0 [('0', 0.2265), ('-2', 0.0819), ('2', 0.0817), ('4', 0.0003), ('-4', 0.0002), ('6', 0.0), ('-6', 0.0), ('8', 0.0), ('-8', 0.0), ('10', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.12), ('2', 0.059), ('-2', 0.0454), ('4', 0.0011), ('-4', 0.0003), ('6', 0.0), ('-6', 0.0), ('10', 0.0), ('-8', 0.0), ('8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0592), ('2', 0.0308), ('-2', 0.0138), ('4', 0.0064), ('-4', 0.0008), ('-6', 0.0001), ('8', 0.0), ('6', 0.0), ('10', 0.0), ('-8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0273), ('2', 0.0102), ('4', 0.006), ('-2', 0.0056), ('-4', 0.0004), ('10', 0.0002), ('6', 0.0001), ('8', 0.0001), ('-6', 0.0), ('-10', 0.0), ('-8', 0.0)]\n",
            "0 [('0', 0.0171), ('2', 0.0076), ('10', 0.0019), ('-2', 0.0012), ('4', 0.0007), ('-4', 0.0003), ('6', 0.0), ('-10', 0.0), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('0', 0.0136), ('10', 0.0053), ('2', 0.0046), ('-2', 0.0005), ('4', 0.0002), ('-4', 0.0002), ('-10', 0.0001), ('8', 0.0), ('-8', 0.0), ('6', 0.0), ('-6', 0.0)]\n",
            "0 [('10', 0.0211), ('0', 0.0044), ('2', 0.0027), ('-10', 0.0006), ('-2', 0.0003), ('4', 0.0002), ('-4', 0.0002), ('6', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "-2 [('10', 0.0338), ('2', 0.0017), ('-2', 0.0008), ('0', 0.0007), ('-10', 0.0003), ('4', 0.0002), ('6', 0.0001), ('-4', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "0 [('10', 0.0413), ('-10', 0.0007), ('0', 0.0007), ('2', 0.0004), ('-4', 0.0003), ('4', 0.0003), ('-2', 0.0002), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "-2 [('10', 0.0529), ('-10', 0.0028), ('2', 0.0006), ('-2', 0.0003), ('0', 0.0002), ('-4', 0.0002), ('4', 0.0001), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "===========\n",
            "test_i 6\n",
            "input0 [972.5999755859376, 989.25, 987.8300170898438, 989.6799926757812, 992.0, 992.1799926757812, 992.8099975585938, 984.4500122070312, 988.2000122070312, 968.4500122070312, 970.5399780273438, 973.3300170898438, 972.5599975585938, 1019.27001953125, 1017.1099853515624, 1016.6400146484376, 1025.5, 1025.5799560546875, 1032.47998046875, 1025.9000244140625]\n",
            "0 [('0', 0.2265), ('-2', 0.0819), ('2', 0.0817), ('4', 0.0003), ('-4', 0.0002), ('6', 0.0), ('-6', 0.0), ('8', 0.0), ('-8', 0.0), ('10', 0.0), ('-10', 0.0)]\n",
            "2 [('0', 0.12), ('2', 0.059), ('-2', 0.0454), ('4', 0.0011), ('-4', 0.0003), ('6', 0.0), ('-6', 0.0), ('10', 0.0), ('-8', 0.0), ('8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0592), ('2', 0.0308), ('-2', 0.0138), ('4', 0.0064), ('-4', 0.0008), ('-6', 0.0001), ('8', 0.0), ('6', 0.0), ('10', 0.0), ('-8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0273), ('2', 0.0102), ('4', 0.006), ('-2', 0.0056), ('-4', 0.0004), ('10', 0.0002), ('6', 0.0001), ('8', 0.0001), ('-6', 0.0), ('-10', 0.0), ('-8', 0.0)]\n",
            "0 [('0', 0.0171), ('2', 0.0076), ('10', 0.0019), ('-2', 0.0012), ('4', 0.0007), ('-4', 0.0003), ('6', 0.0), ('-10', 0.0), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('0', 0.0136), ('10', 0.0053), ('2', 0.0046), ('-2', 0.0005), ('4', 0.0002), ('-4', 0.0002), ('-10', 0.0001), ('8', 0.0), ('-8', 0.0), ('6', 0.0), ('-6', 0.0)]\n",
            "0 [('10', 0.0211), ('0', 0.0044), ('2', 0.0027), ('-10', 0.0006), ('-2', 0.0003), ('4', 0.0002), ('-4', 0.0002), ('6', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "0 [('10', 0.0338), ('2', 0.0017), ('-2', 0.0008), ('0', 0.0007), ('-10', 0.0003), ('4', 0.0002), ('6', 0.0001), ('-4', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "0 [('10', 0.0413), ('-10', 0.0007), ('0', 0.0007), ('2', 0.0004), ('-4', 0.0003), ('4', 0.0003), ('-2', 0.0002), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('10', 0.0529), ('-10', 0.0028), ('2', 0.0006), ('-2', 0.0003), ('0', 0.0002), ('-4', 0.0002), ('4', 0.0001), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "===========\n",
            "test_i 7\n",
            "input0 [989.25, 987.8300170898438, 989.6799926757812, 992.0, 992.1799926757812, 992.8099975585938, 984.4500122070312, 988.2000122070312, 968.4500122070312, 970.5399780273438, 973.3300170898438, 972.5599975585938, 1019.27001953125, 1017.1099853515624, 1016.6400146484376, 1025.5, 1025.5799560546875, 1032.47998046875, 1025.9000244140625, 1033.3299560546875]\n",
            "0 [('0', 0.2265), ('-2', 0.0819), ('2', 0.0817), ('4', 0.0003), ('-4', 0.0002), ('6', 0.0), ('-6', 0.0), ('8', 0.0), ('-8', 0.0), ('10', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.12), ('2', 0.059), ('-2', 0.0454), ('4', 0.0011), ('-4', 0.0003), ('6', 0.0), ('-6', 0.0), ('10', 0.0), ('-8', 0.0), ('8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0592), ('2', 0.0308), ('-2', 0.0138), ('4', 0.0064), ('-4', 0.0008), ('-6', 0.0001), ('8', 0.0), ('6', 0.0), ('10', 0.0), ('-8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0273), ('2', 0.0102), ('4', 0.006), ('-2', 0.0056), ('-4', 0.0004), ('10', 0.0002), ('6', 0.0001), ('8', 0.0001), ('-6', 0.0), ('-10', 0.0), ('-8', 0.0)]\n",
            "0 [('0', 0.0171), ('2', 0.0076), ('10', 0.0019), ('-2', 0.0012), ('4', 0.0007), ('-4', 0.0003), ('6', 0.0), ('-10', 0.0), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "-2 [('0', 0.0136), ('10', 0.0053), ('2', 0.0046), ('-2', 0.0005), ('4', 0.0002), ('-4', 0.0002), ('-10', 0.0001), ('8', 0.0), ('-8', 0.0), ('6', 0.0), ('-6', 0.0)]\n",
            "0 [('10', 0.0211), ('0', 0.0044), ('2', 0.0027), ('-10', 0.0006), ('-2', 0.0003), ('4', 0.0002), ('-4', 0.0002), ('6', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "-2 [('10', 0.0338), ('2', 0.0017), ('-2', 0.0008), ('0', 0.0007), ('-10', 0.0003), ('4', 0.0002), ('6', 0.0001), ('-4', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "-2 [('10', 0.0413), ('-10', 0.0007), ('0', 0.0007), ('2', 0.0004), ('-4', 0.0003), ('4', 0.0003), ('-2', 0.0002), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('10', 0.0529), ('-10', 0.0028), ('2', 0.0006), ('-2', 0.0003), ('0', 0.0002), ('-4', 0.0002), ('4', 0.0001), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "===========\n",
            "test_i 8\n",
            "input0 [987.8300170898438, 989.6799926757812, 992.0, 992.1799926757812, 992.8099975585938, 984.4500122070312, 988.2000122070312, 968.4500122070312, 970.5399780273438, 973.3300170898438, 972.5599975585938, 1019.27001953125, 1017.1099853515624, 1016.6400146484376, 1025.5, 1025.5799560546875, 1032.47998046875, 1025.9000244140625, 1033.3299560546875, 1039.8499755859375]\n",
            "0 [('0', 0.2265), ('-2', 0.0819), ('2', 0.0817), ('4', 0.0003), ('-4', 0.0002), ('6', 0.0), ('-6', 0.0), ('8', 0.0), ('-8', 0.0), ('10', 0.0), ('-10', 0.0)]\n",
            "-2 [('0', 0.12), ('2', 0.059), ('-2', 0.0454), ('4', 0.0011), ('-4', 0.0003), ('6', 0.0), ('-6', 0.0), ('10', 0.0), ('-8', 0.0), ('8', 0.0), ('-10', 0.0)]\n",
            "-2 [('0', 0.0592), ('2', 0.0308), ('-2', 0.0138), ('4', 0.0064), ('-4', 0.0008), ('-6', 0.0001), ('8', 0.0), ('6', 0.0), ('10', 0.0), ('-8', 0.0), ('-10', 0.0)]\n",
            "-2 [('0', 0.0273), ('2', 0.0102), ('4', 0.006), ('-2', 0.0056), ('-4', 0.0004), ('10', 0.0002), ('6', 0.0001), ('8', 0.0001), ('-6', 0.0), ('-10', 0.0), ('-8', 0.0)]\n",
            "-2 [('0', 0.0171), ('2', 0.0076), ('10', 0.0019), ('-2', 0.0012), ('4', 0.0007), ('-4', 0.0003), ('6', 0.0), ('-10', 0.0), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('0', 0.0136), ('10', 0.0053), ('2', 0.0046), ('-2', 0.0005), ('4', 0.0002), ('-4', 0.0002), ('-10', 0.0001), ('8', 0.0), ('-8', 0.0), ('6', 0.0), ('-6', 0.0)]\n",
            "-2 [('10', 0.0211), ('0', 0.0044), ('2', 0.0027), ('-10', 0.0006), ('-2', 0.0003), ('4', 0.0002), ('-4', 0.0002), ('6', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "-2 [('10', 0.0338), ('2', 0.0017), ('-2', 0.0008), ('0', 0.0007), ('-10', 0.0003), ('4', 0.0002), ('6', 0.0001), ('-4', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "0 [('10', 0.0413), ('-10', 0.0007), ('0', 0.0007), ('2', 0.0004), ('-4', 0.0003), ('4', 0.0003), ('-2', 0.0002), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('10', 0.0529), ('-10', 0.0028), ('2', 0.0006), ('-2', 0.0003), ('0', 0.0002), ('-4', 0.0002), ('4', 0.0001), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "===========\n",
            "test_i 9\n",
            "input0 [989.6799926757812, 992.0, 992.1799926757812, 992.8099975585938, 984.4500122070312, 988.2000122070312, 968.4500122070312, 970.5399780273438, 973.3300170898438, 972.5599975585938, 1019.27001953125, 1017.1099853515624, 1016.6400146484376, 1025.5, 1025.5799560546875, 1032.47998046875, 1025.9000244140625, 1033.3299560546875, 1039.8499755859375, 1031.260009765625]\n",
            "0 [('0', 0.2265), ('-2', 0.0819), ('2', 0.0817), ('4', 0.0003), ('-4', 0.0002), ('6', 0.0), ('-6', 0.0), ('8', 0.0), ('-8', 0.0), ('10', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.12), ('2', 0.059), ('-2', 0.0454), ('4', 0.0011), ('-4', 0.0003), ('6', 0.0), ('-6', 0.0), ('10', 0.0), ('-8', 0.0), ('8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0592), ('2', 0.0308), ('-2', 0.0138), ('4', 0.0064), ('-4', 0.0008), ('-6', 0.0001), ('8', 0.0), ('6', 0.0), ('10', 0.0), ('-8', 0.0), ('-10', 0.0)]\n",
            "-2 [('0', 0.0273), ('2', 0.0102), ('4', 0.006), ('-2', 0.0056), ('-4', 0.0004), ('10', 0.0002), ('6', 0.0001), ('8', 0.0001), ('-6', 0.0), ('-10', 0.0), ('-8', 0.0)]\n",
            "0 [('0', 0.0171), ('2', 0.0076), ('10', 0.0019), ('-2', 0.0012), ('4', 0.0007), ('-4', 0.0003), ('6', 0.0), ('-10', 0.0), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "-2 [('0', 0.0136), ('10', 0.0053), ('2', 0.0046), ('-2', 0.0005), ('4', 0.0002), ('-4', 0.0002), ('-10', 0.0001), ('8', 0.0), ('-8', 0.0), ('6', 0.0), ('-6', 0.0)]\n",
            "-2 [('10', 0.0211), ('0', 0.0044), ('2', 0.0027), ('-10', 0.0006), ('-2', 0.0003), ('4', 0.0002), ('-4', 0.0002), ('6', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "0 [('10', 0.0338), ('2', 0.0017), ('-2', 0.0008), ('0', 0.0007), ('-10', 0.0003), ('4', 0.0002), ('6', 0.0001), ('-4', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "0 [('10', 0.0413), ('-10', 0.0007), ('0', 0.0007), ('2', 0.0004), ('-4', 0.0003), ('4', 0.0003), ('-2', 0.0002), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('10', 0.0529), ('-10', 0.0028), ('2', 0.0006), ('-2', 0.0003), ('0', 0.0002), ('-4', 0.0002), ('4', 0.0001), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "===========\n",
            "test_i 10\n",
            "input0 [992.0, 992.1799926757812, 992.8099975585938, 984.4500122070312, 988.2000122070312, 968.4500122070312, 970.5399780273438, 973.3300170898438, 972.5599975585938, 1019.27001953125, 1017.1099853515624, 1016.6400146484376, 1025.5, 1025.5799560546875, 1032.47998046875, 1025.9000244140625, 1033.3299560546875, 1039.8499755859375, 1031.260009765625, 1028.0699462890625]\n",
            "0 [('0', 0.2265), ('-2', 0.0819), ('2', 0.0817), ('4', 0.0003), ('-4', 0.0002), ('6', 0.0), ('-6', 0.0), ('8', 0.0), ('-8', 0.0), ('10', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.12), ('2', 0.059), ('-2', 0.0454), ('4', 0.0011), ('-4', 0.0003), ('6', 0.0), ('-6', 0.0), ('10', 0.0), ('-8', 0.0), ('8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0592), ('2', 0.0308), ('-2', 0.0138), ('4', 0.0064), ('-4', 0.0008), ('-6', 0.0001), ('8', 0.0), ('6', 0.0), ('10', 0.0), ('-8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0273), ('2', 0.0102), ('4', 0.006), ('-2', 0.0056), ('-4', 0.0004), ('10', 0.0002), ('6', 0.0001), ('8', 0.0001), ('-6', 0.0), ('-10', 0.0), ('-8', 0.0)]\n",
            "0 [('0', 0.0171), ('2', 0.0076), ('10', 0.0019), ('-2', 0.0012), ('4', 0.0007), ('-4', 0.0003), ('6', 0.0), ('-10', 0.0), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('0', 0.0136), ('10', 0.0053), ('2', 0.0046), ('-2', 0.0005), ('4', 0.0002), ('-4', 0.0002), ('-10', 0.0001), ('8', 0.0), ('-8', 0.0), ('6', 0.0), ('-6', 0.0)]\n",
            "0 [('10', 0.0211), ('0', 0.0044), ('2', 0.0027), ('-10', 0.0006), ('-2', 0.0003), ('4', 0.0002), ('-4', 0.0002), ('6', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "0 [('10', 0.0338), ('2', 0.0017), ('-2', 0.0008), ('0', 0.0007), ('-10', 0.0003), ('4', 0.0002), ('6', 0.0001), ('-4', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "2 [('10', 0.0413), ('-10', 0.0007), ('0', 0.0007), ('2', 0.0004), ('-4', 0.0003), ('4', 0.0003), ('-2', 0.0002), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "2 [('10', 0.0529), ('-10', 0.0028), ('2', 0.0006), ('-2', 0.0003), ('0', 0.0002), ('-4', 0.0002), ('4', 0.0001), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "===========\n",
            "test_i 11\n",
            "input0 [992.1799926757812, 992.8099975585938, 984.4500122070312, 988.2000122070312, 968.4500122070312, 970.5399780273438, 973.3300170898438, 972.5599975585938, 1019.27001953125, 1017.1099853515624, 1016.6400146484376, 1025.5, 1025.5799560546875, 1032.47998046875, 1025.9000244140625, 1033.3299560546875, 1039.8499755859375, 1031.260009765625, 1028.0699462890625, 1025.75]\n",
            "0 [('0', 0.2265), ('-2', 0.0819), ('2', 0.0817), ('4', 0.0003), ('-4', 0.0002), ('6', 0.0), ('-6', 0.0), ('8', 0.0), ('-8', 0.0), ('10', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.12), ('2', 0.059), ('-2', 0.0454), ('4', 0.0011), ('-4', 0.0003), ('6', 0.0), ('-6', 0.0), ('10', 0.0), ('-8', 0.0), ('8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0592), ('2', 0.0308), ('-2', 0.0138), ('4', 0.0064), ('-4', 0.0008), ('-6', 0.0001), ('8', 0.0), ('6', 0.0), ('10', 0.0), ('-8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0273), ('2', 0.0102), ('4', 0.006), ('-2', 0.0056), ('-4', 0.0004), ('10', 0.0002), ('6', 0.0001), ('8', 0.0001), ('-6', 0.0), ('-10', 0.0), ('-8', 0.0)]\n",
            "0 [('0', 0.0171), ('2', 0.0076), ('10', 0.0019), ('-2', 0.0012), ('4', 0.0007), ('-4', 0.0003), ('6', 0.0), ('-10', 0.0), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('0', 0.0136), ('10', 0.0053), ('2', 0.0046), ('-2', 0.0005), ('4', 0.0002), ('-4', 0.0002), ('-10', 0.0001), ('8', 0.0), ('-8', 0.0), ('6', 0.0), ('-6', 0.0)]\n",
            "0 [('10', 0.0211), ('0', 0.0044), ('2', 0.0027), ('-10', 0.0006), ('-2', 0.0003), ('4', 0.0002), ('-4', 0.0002), ('6', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "2 [('10', 0.0338), ('2', 0.0017), ('-2', 0.0008), ('0', 0.0007), ('-10', 0.0003), ('4', 0.0002), ('6', 0.0001), ('-4', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "2 [('10', 0.0413), ('-10', 0.0007), ('0', 0.0007), ('2', 0.0004), ('-4', 0.0003), ('4', 0.0003), ('-2', 0.0002), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "2 [('10', 0.0529), ('-10', 0.0028), ('2', 0.0006), ('-2', 0.0003), ('0', 0.0002), ('-4', 0.0002), ('4', 0.0001), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "===========\n",
            "test_i 12\n",
            "input0 [992.8099975585938, 984.4500122070312, 988.2000122070312, 968.4500122070312, 970.5399780273438, 973.3300170898438, 972.5599975585938, 1019.27001953125, 1017.1099853515624, 1016.6400146484376, 1025.5, 1025.5799560546875, 1032.47998046875, 1025.9000244140625, 1033.3299560546875, 1039.8499755859375, 1031.260009765625, 1028.0699462890625, 1025.75, 1026.0]\n",
            "0 [('0', 0.2265), ('-2', 0.0819), ('2', 0.0817), ('4', 0.0003), ('-4', 0.0002), ('6', 0.0), ('-6', 0.0), ('8', 0.0), ('-8', 0.0), ('10', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.12), ('2', 0.059), ('-2', 0.0454), ('4', 0.0011), ('-4', 0.0003), ('6', 0.0), ('-6', 0.0), ('10', 0.0), ('-8', 0.0), ('8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0592), ('2', 0.0308), ('-2', 0.0138), ('4', 0.0064), ('-4', 0.0008), ('-6', 0.0001), ('8', 0.0), ('6', 0.0), ('10', 0.0), ('-8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0273), ('2', 0.0102), ('4', 0.006), ('-2', 0.0056), ('-4', 0.0004), ('10', 0.0002), ('6', 0.0001), ('8', 0.0001), ('-6', 0.0), ('-10', 0.0), ('-8', 0.0)]\n",
            "0 [('0', 0.0171), ('2', 0.0076), ('10', 0.0019), ('-2', 0.0012), ('4', 0.0007), ('-4', 0.0003), ('6', 0.0), ('-10', 0.0), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('0', 0.0136), ('10', 0.0053), ('2', 0.0046), ('-2', 0.0005), ('4', 0.0002), ('-4', 0.0002), ('-10', 0.0001), ('8', 0.0), ('-8', 0.0), ('6', 0.0), ('-6', 0.0)]\n",
            "2 [('10', 0.0211), ('0', 0.0044), ('2', 0.0027), ('-10', 0.0006), ('-2', 0.0003), ('4', 0.0002), ('-4', 0.0002), ('6', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "2 [('10', 0.0338), ('2', 0.0017), ('-2', 0.0008), ('0', 0.0007), ('-10', 0.0003), ('4', 0.0002), ('6', 0.0001), ('-4', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "2 [('10', 0.0413), ('-10', 0.0007), ('0', 0.0007), ('2', 0.0004), ('-4', 0.0003), ('4', 0.0003), ('-2', 0.0002), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('10', 0.0529), ('-10', 0.0028), ('2', 0.0006), ('-2', 0.0003), ('0', 0.0002), ('-4', 0.0002), ('4', 0.0001), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "===========\n",
            "test_i 13\n",
            "input0 [984.4500122070312, 988.2000122070312, 968.4500122070312, 970.5399780273438, 973.3300170898438, 972.5599975585938, 1019.27001953125, 1017.1099853515624, 1016.6400146484376, 1025.5, 1025.5799560546875, 1032.47998046875, 1025.9000244140625, 1033.3299560546875, 1039.8499755859375, 1031.260009765625, 1028.0699462890625, 1025.75, 1026.0, 1020.9099731445312]\n",
            "2 [('0', 0.2265), ('-2', 0.0819), ('2', 0.0817), ('4', 0.0003), ('-4', 0.0002), ('6', 0.0), ('-6', 0.0), ('8', 0.0), ('-8', 0.0), ('10', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.12), ('2', 0.059), ('-2', 0.0454), ('4', 0.0011), ('-4', 0.0003), ('6', 0.0), ('-6', 0.0), ('10', 0.0), ('-8', 0.0), ('8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0592), ('2', 0.0308), ('-2', 0.0138), ('4', 0.0064), ('-4', 0.0008), ('-6', 0.0001), ('8', 0.0), ('6', 0.0), ('10', 0.0), ('-8', 0.0), ('-10', 0.0)]\n",
            "2 [('0', 0.0273), ('2', 0.0102), ('4', 0.006), ('-2', 0.0056), ('-4', 0.0004), ('10', 0.0002), ('6', 0.0001), ('8', 0.0001), ('-6', 0.0), ('-10', 0.0), ('-8', 0.0)]\n",
            "2 [('0', 0.0171), ('2', 0.0076), ('10', 0.0019), ('-2', 0.0012), ('4', 0.0007), ('-4', 0.0003), ('6', 0.0), ('-10', 0.0), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "2 [('0', 0.0136), ('10', 0.0053), ('2', 0.0046), ('-2', 0.0005), ('4', 0.0002), ('-4', 0.0002), ('-10', 0.0001), ('8', 0.0), ('-8', 0.0), ('6', 0.0), ('-6', 0.0)]\n",
            "4 [('10', 0.0211), ('0', 0.0044), ('2', 0.0027), ('-10', 0.0006), ('-2', 0.0003), ('4', 0.0002), ('-4', 0.0002), ('6', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "2 [('10', 0.0338), ('2', 0.0017), ('-2', 0.0008), ('0', 0.0007), ('-10', 0.0003), ('4', 0.0002), ('6', 0.0001), ('-4', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "0 [('10', 0.0413), ('-10', 0.0007), ('0', 0.0007), ('2', 0.0004), ('-4', 0.0003), ('4', 0.0003), ('-2', 0.0002), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('10', 0.0529), ('-10', 0.0028), ('2', 0.0006), ('-2', 0.0003), ('0', 0.0002), ('-4', 0.0002), ('4', 0.0001), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "===========\n",
            "test_i 14\n",
            "input0 [988.2000122070312, 968.4500122070312, 970.5399780273438, 973.3300170898438, 972.5599975585938, 1019.27001953125, 1017.1099853515624, 1016.6400146484376, 1025.5, 1025.5799560546875, 1032.47998046875, 1025.9000244140625, 1033.3299560546875, 1039.8499755859375, 1031.260009765625, 1028.0699462890625, 1025.75, 1026.0, 1020.9099731445312, 1032.5]\n",
            "-2 [('0', 0.2265), ('-2', 0.0819), ('2', 0.0817), ('4', 0.0003), ('-4', 0.0002), ('6', 0.0), ('-6', 0.0), ('8', 0.0), ('-8', 0.0), ('10', 0.0), ('-10', 0.0)]\n",
            "-2 [('0', 0.12), ('2', 0.059), ('-2', 0.0454), ('4', 0.0011), ('-4', 0.0003), ('6', 0.0), ('-6', 0.0), ('10', 0.0), ('-8', 0.0), ('8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0592), ('2', 0.0308), ('-2', 0.0138), ('4', 0.0064), ('-4', 0.0008), ('-6', 0.0001), ('8', 0.0), ('6', 0.0), ('10', 0.0), ('-8', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.0273), ('2', 0.0102), ('4', 0.006), ('-2', 0.0056), ('-4', 0.0004), ('10', 0.0002), ('6', 0.0001), ('8', 0.0001), ('-6', 0.0), ('-10', 0.0), ('-8', 0.0)]\n",
            "0 [('0', 0.0171), ('2', 0.0076), ('10', 0.0019), ('-2', 0.0012), ('4', 0.0007), ('-4', 0.0003), ('6', 0.0), ('-10', 0.0), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "2 [('0', 0.0136), ('10', 0.0053), ('2', 0.0046), ('-2', 0.0005), ('4', 0.0002), ('-4', 0.0002), ('-10', 0.0001), ('8', 0.0), ('-8', 0.0), ('6', 0.0), ('-6', 0.0)]\n",
            "2 [('10', 0.0211), ('0', 0.0044), ('2', 0.0027), ('-10', 0.0006), ('-2', 0.0003), ('4', 0.0002), ('-4', 0.0002), ('6', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "-2 [('10', 0.0338), ('2', 0.0017), ('-2', 0.0008), ('0', 0.0007), ('-10', 0.0003), ('4', 0.0002), ('6', 0.0001), ('-4', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "-2 [('10', 0.0413), ('-10', 0.0007), ('0', 0.0007), ('2', 0.0004), ('-4', 0.0003), ('4', 0.0003), ('-2', 0.0002), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "-2 [('10', 0.0529), ('-10', 0.0028), ('2', 0.0006), ('-2', 0.0003), ('0', 0.0002), ('-4', 0.0002), ('4', 0.0001), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "===========\n",
            "test_i 15\n",
            "input0 [968.4500122070312, 970.5399780273438, 973.3300170898438, 972.5599975585938, 1019.27001953125, 1017.1099853515624, 1016.6400146484376, 1025.5, 1025.5799560546875, 1032.47998046875, 1025.9000244140625, 1033.3299560546875, 1039.8499755859375, 1031.260009765625, 1028.0699462890625, 1025.75, 1026.0, 1020.9099731445312, 1032.5, 1019.0900268554688]\n",
            "0 [('0', 0.2265), ('-2', 0.0819), ('2', 0.0817), ('4', 0.0003), ('-4', 0.0002), ('6', 0.0), ('-6', 0.0), ('8', 0.0), ('-8', 0.0), ('10', 0.0), ('-10', 0.0)]\n",
            "2 [('0', 0.12), ('2', 0.059), ('-2', 0.0454), ('4', 0.0011), ('-4', 0.0003), ('6', 0.0), ('-6', 0.0), ('10', 0.0), ('-8', 0.0), ('8', 0.0), ('-10', 0.0)]\n",
            "2 [('0', 0.0592), ('2', 0.0308), ('-2', 0.0138), ('4', 0.0064), ('-4', 0.0008), ('-6', 0.0001), ('8', 0.0), ('6', 0.0), ('10', 0.0), ('-8', 0.0), ('-10', 0.0)]\n",
            "2 [('0', 0.0273), ('2', 0.0102), ('4', 0.006), ('-2', 0.0056), ('-4', 0.0004), ('10', 0.0002), ('6', 0.0001), ('8', 0.0001), ('-6', 0.0), ('-10', 0.0), ('-8', 0.0)]\n",
            "4 [('0', 0.0171), ('2', 0.0076), ('10', 0.0019), ('-2', 0.0012), ('4', 0.0007), ('-4', 0.0003), ('6', 0.0), ('-10', 0.0), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "2 [('0', 0.0136), ('10', 0.0053), ('2', 0.0046), ('-2', 0.0005), ('4', 0.0002), ('-4', 0.0002), ('-10', 0.0001), ('8', 0.0), ('-8', 0.0), ('6', 0.0), ('-6', 0.0)]\n",
            "0 [('10', 0.0211), ('0', 0.0044), ('2', 0.0027), ('-10', 0.0006), ('-2', 0.0003), ('4', 0.0002), ('-4', 0.0002), ('6', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "0 [('10', 0.0338), ('2', 0.0017), ('-2', 0.0008), ('0', 0.0007), ('-10', 0.0003), ('4', 0.0002), ('6', 0.0001), ('-4', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "0 [('10', 0.0413), ('-10', 0.0007), ('0', 0.0007), ('2', 0.0004), ('-4', 0.0003), ('4', 0.0003), ('-2', 0.0002), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "-2 [('10', 0.0529), ('-10', 0.0028), ('2', 0.0006), ('-2', 0.0003), ('0', 0.0002), ('-4', 0.0002), ('4', 0.0001), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "===========\n",
            "test_i 16\n",
            "input0 [970.5399780273438, 973.3300170898438, 972.5599975585938, 1019.27001953125, 1017.1099853515624, 1016.6400146484376, 1025.5, 1025.5799560546875, 1032.47998046875, 1025.9000244140625, 1033.3299560546875, 1039.8499755859375, 1031.260009765625, 1028.0699462890625, 1025.75, 1026.0, 1020.9099731445312, 1032.5, 1019.0900268554688, 1018.3800048828124]\n",
            "2 [('0', 0.2265), ('-2', 0.0819), ('2', 0.0817), ('4', 0.0003), ('-4', 0.0002), ('6', 0.0), ('-6', 0.0), ('8', 0.0), ('-8', 0.0), ('10', 0.0), ('-10', 0.0)]\n",
            "2 [('0', 0.12), ('2', 0.059), ('-2', 0.0454), ('4', 0.0011), ('-4', 0.0003), ('6', 0.0), ('-6', 0.0), ('10', 0.0), ('-8', 0.0), ('8', 0.0), ('-10', 0.0)]\n",
            "2 [('0', 0.0592), ('2', 0.0308), ('-2', 0.0138), ('4', 0.0064), ('-4', 0.0008), ('-6', 0.0001), ('8', 0.0), ('6', 0.0), ('10', 0.0), ('-8', 0.0), ('-10', 0.0)]\n",
            "4 [('0', 0.0273), ('2', 0.0102), ('4', 0.006), ('-2', 0.0056), ('-4', 0.0004), ('10', 0.0002), ('6', 0.0001), ('8', 0.0001), ('-6', 0.0), ('-10', 0.0), ('-8', 0.0)]\n",
            "2 [('0', 0.0171), ('2', 0.0076), ('10', 0.0019), ('-2', 0.0012), ('4', 0.0007), ('-4', 0.0003), ('6', 0.0), ('-10', 0.0), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('0', 0.0136), ('10', 0.0053), ('2', 0.0046), ('-2', 0.0005), ('4', 0.0002), ('-4', 0.0002), ('-10', 0.0001), ('8', 0.0), ('-8', 0.0), ('6', 0.0), ('-6', 0.0)]\n",
            "0 [('10', 0.0211), ('0', 0.0044), ('2', 0.0027), ('-10', 0.0006), ('-2', 0.0003), ('4', 0.0002), ('-4', 0.0002), ('6', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "0 [('10', 0.0338), ('2', 0.0017), ('-2', 0.0008), ('0', 0.0007), ('-10', 0.0003), ('4', 0.0002), ('6', 0.0001), ('-4', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "-2 [('10', 0.0413), ('-10', 0.0007), ('0', 0.0007), ('2', 0.0004), ('-4', 0.0003), ('4', 0.0003), ('-2', 0.0002), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "-2 [('10', 0.0529), ('-10', 0.0028), ('2', 0.0006), ('-2', 0.0003), ('0', 0.0002), ('-4', 0.0002), ('4', 0.0001), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "===========\n",
            "test_i 17\n",
            "input0 [973.3300170898438, 972.5599975585938, 1019.27001953125, 1017.1099853515624, 1016.6400146484376, 1025.5, 1025.5799560546875, 1032.47998046875, 1025.9000244140625, 1033.3299560546875, 1039.8499755859375, 1031.260009765625, 1028.0699462890625, 1025.75, 1026.0, 1020.9099731445312, 1032.5, 1019.0900268554688, 1018.3800048828124, 1034.489990234375]\n",
            "0 [('0', 0.2265), ('-2', 0.0819), ('2', 0.0817), ('4', 0.0003), ('-4', 0.0002), ('6', 0.0), ('-6', 0.0), ('8', 0.0), ('-8', 0.0), ('10', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.12), ('2', 0.059), ('-2', 0.0454), ('4', 0.0011), ('-4', 0.0003), ('6', 0.0), ('-6', 0.0), ('10', 0.0), ('-8', 0.0), ('8', 0.0), ('-10', 0.0)]\n",
            "2 [('0', 0.0592), ('2', 0.0308), ('-2', 0.0138), ('4', 0.0064), ('-4', 0.0008), ('-6', 0.0001), ('8', 0.0), ('6', 0.0), ('10', 0.0), ('-8', 0.0), ('-10', 0.0)]\n",
            "2 [('0', 0.0273), ('2', 0.0102), ('4', 0.006), ('-2', 0.0056), ('-4', 0.0004), ('10', 0.0002), ('6', 0.0001), ('8', 0.0001), ('-6', 0.0), ('-10', 0.0), ('-8', 0.0)]\n",
            "-2 [('0', 0.0171), ('2', 0.0076), ('10', 0.0019), ('-2', 0.0012), ('4', 0.0007), ('-4', 0.0003), ('6', 0.0), ('-10', 0.0), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "-2 [('0', 0.0136), ('10', 0.0053), ('2', 0.0046), ('-2', 0.0005), ('4', 0.0002), ('-4', 0.0002), ('-10', 0.0001), ('8', 0.0), ('-8', 0.0), ('6', 0.0), ('-6', 0.0)]\n",
            "-2 [('10', 0.0211), ('0', 0.0044), ('2', 0.0027), ('-10', 0.0006), ('-2', 0.0003), ('4', 0.0002), ('-4', 0.0002), ('6', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "-4 [('10', 0.0338), ('2', 0.0017), ('-2', 0.0008), ('0', 0.0007), ('-10', 0.0003), ('4', 0.0002), ('6', 0.0001), ('-4', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "-2 [('10', 0.0413), ('-10', 0.0007), ('0', 0.0007), ('2', 0.0004), ('-4', 0.0003), ('4', 0.0003), ('-2', 0.0002), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "-2 [('10', 0.0529), ('-10', 0.0028), ('2', 0.0006), ('-2', 0.0003), ('0', 0.0002), ('-4', 0.0002), ('4', 0.0001), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "===========\n",
            "test_i 18\n",
            "input0 [972.5599975585938, 1019.27001953125, 1017.1099853515624, 1016.6400146484376, 1025.5, 1025.5799560546875, 1032.47998046875, 1025.9000244140625, 1033.3299560546875, 1039.8499755859375, 1031.260009765625, 1028.0699462890625, 1025.75, 1026.0, 1020.9099731445312, 1032.5, 1019.0900268554688, 1018.3800048828124, 1034.489990234375, 1035.9599609375]\n",
            "0 [('0', 0.2265), ('-2', 0.0819), ('2', 0.0817), ('4', 0.0003), ('-4', 0.0002), ('6', 0.0), ('-6', 0.0), ('8', 0.0), ('-8', 0.0), ('10', 0.0), ('-10', 0.0)]\n",
            "2 [('0', 0.12), ('2', 0.059), ('-2', 0.0454), ('4', 0.0011), ('-4', 0.0003), ('6', 0.0), ('-6', 0.0), ('10', 0.0), ('-8', 0.0), ('8', 0.0), ('-10', 0.0)]\n",
            "2 [('0', 0.0592), ('2', 0.0308), ('-2', 0.0138), ('4', 0.0064), ('-4', 0.0008), ('-6', 0.0001), ('8', 0.0), ('6', 0.0), ('10', 0.0), ('-8', 0.0), ('-10', 0.0)]\n",
            "-2 [('0', 0.0273), ('2', 0.0102), ('4', 0.006), ('-2', 0.0056), ('-4', 0.0004), ('10', 0.0002), ('6', 0.0001), ('8', 0.0001), ('-6', 0.0), ('-10', 0.0), ('-8', 0.0)]\n",
            "-2 [('0', 0.0171), ('2', 0.0076), ('10', 0.0019), ('-2', 0.0012), ('4', 0.0007), ('-4', 0.0003), ('6', 0.0), ('-10', 0.0), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "-2 [('0', 0.0136), ('10', 0.0053), ('2', 0.0046), ('-2', 0.0005), ('4', 0.0002), ('-4', 0.0002), ('-10', 0.0001), ('8', 0.0), ('-8', 0.0), ('6', 0.0), ('-6', 0.0)]\n",
            "-4 [('10', 0.0211), ('0', 0.0044), ('2', 0.0027), ('-10', 0.0006), ('-2', 0.0003), ('4', 0.0002), ('-4', 0.0002), ('6', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "-2 [('10', 0.0338), ('2', 0.0017), ('-2', 0.0008), ('0', 0.0007), ('-10', 0.0003), ('4', 0.0002), ('6', 0.0001), ('-4', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "-2 [('10', 0.0413), ('-10', 0.0007), ('0', 0.0007), ('2', 0.0004), ('-4', 0.0003), ('4', 0.0003), ('-2', 0.0002), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('10', 0.0529), ('-10', 0.0028), ('2', 0.0006), ('-2', 0.0003), ('0', 0.0002), ('-4', 0.0002), ('4', 0.0001), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "===========\n",
            "test_i 19\n",
            "input0 [1019.27001953125, 1017.1099853515624, 1016.6400146484376, 1025.5, 1025.5799560546875, 1032.47998046875, 1025.9000244140625, 1033.3299560546875, 1039.8499755859375, 1031.260009765625, 1028.0699462890625, 1025.75, 1026.0, 1020.9099731445312, 1032.5, 1019.0900268554688, 1018.3800048828124, 1034.489990234375, 1035.9599609375, 1040.6099853515625]\n",
            "2 [('0', 0.2265), ('-2', 0.0819), ('2', 0.0817), ('4', 0.0003), ('-4', 0.0002), ('6', 0.0), ('-6', 0.0), ('8', 0.0), ('-8', 0.0), ('10', 0.0), ('-10', 0.0)]\n",
            "0 [('0', 0.12), ('2', 0.059), ('-2', 0.0454), ('4', 0.0011), ('-4', 0.0003), ('6', 0.0), ('-6', 0.0), ('10', 0.0), ('-8', 0.0), ('8', 0.0), ('-10', 0.0)]\n",
            "-2 [('0', 0.0592), ('2', 0.0308), ('-2', 0.0138), ('4', 0.0064), ('-4', 0.0008), ('-6', 0.0001), ('8', 0.0), ('6', 0.0), ('10', 0.0), ('-8', 0.0), ('-10', 0.0)]\n",
            "-2 [('0', 0.0273), ('2', 0.0102), ('4', 0.006), ('-2', 0.0056), ('-4', 0.0004), ('10', 0.0002), ('6', 0.0001), ('8', 0.0001), ('-6', 0.0), ('-10', 0.0), ('-8', 0.0)]\n",
            "-2 [('0', 0.0171), ('2', 0.0076), ('10', 0.0019), ('-2', 0.0012), ('4', 0.0007), ('-4', 0.0003), ('6', 0.0), ('-10', 0.0), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "-4 [('0', 0.0136), ('10', 0.0053), ('2', 0.0046), ('-2', 0.0005), ('4', 0.0002), ('-4', 0.0002), ('-10', 0.0001), ('8', 0.0), ('-8', 0.0), ('6', 0.0), ('-6', 0.0)]\n",
            "-4 [('10', 0.0211), ('0', 0.0044), ('2', 0.0027), ('-10', 0.0006), ('-2', 0.0003), ('4', 0.0002), ('-4', 0.0002), ('6', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "-2 [('10', 0.0338), ('2', 0.0017), ('-2', 0.0008), ('0', 0.0007), ('-10', 0.0003), ('4', 0.0002), ('6', 0.0001), ('-4', 0.0001), ('-6', 0.0001), ('-8', 0.0), ('8', 0.0)]\n",
            "0 [('10', 0.0413), ('-10', 0.0007), ('0', 0.0007), ('2', 0.0004), ('-4', 0.0003), ('4', 0.0003), ('-2', 0.0002), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "0 [('10', 0.0529), ('-10', 0.0028), ('2', 0.0006), ('-2', 0.0003), ('0', 0.0002), ('-4', 0.0002), ('4', 0.0001), ('6', 0.0001), ('8', 0.0), ('-6', 0.0), ('-8', 0.0)]\n",
            "===========\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.randn(5)\n",
        "data = torch.randn(1,5)\n",
        "print(data)\n",
        "print(F.softmax(data, dim=0))\n",
        "print(F.softmax(data, dim=0).sum())  # Sums to 1 because it is a distribution!\n",
        "print(F.log_softmax(data, dim=0))  # theres also log_softmax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER2XnHDPTBAr",
        "outputId": "6ba7767c-2f2a-402d-fe65-8585f8128df7"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.2507, -0.3460, -0.9908,  2.4535,  0.4385]])\n",
            "tensor([[1., 1., 1., 1., 1.]])\n",
            "tensor(5.)\n",
            "tensor([[0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TnIjV07UZtd0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "robin.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1mQ3iFxW9hgpxaNsUQ_EqKpiLC29Ucim1",
      "authorship_tag": "ABX9TyPZiYQvqkIxfK04s19HlDG6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}